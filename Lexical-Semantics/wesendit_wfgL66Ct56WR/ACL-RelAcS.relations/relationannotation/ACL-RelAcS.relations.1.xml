<?xml version="1.0" encoding="UTF-8"?>
<doc>


<text id="L08-1450"><title>
A LAF/GrAF <entity id="L08-1450.1">based</entity> Encoding <entity id="L08-1450.2">Scheme</entity> for underspecified Representations of <entity id="L08-1450.3">syntactic</entity> Annotations.
</title><abstract><entity id="L08-1450.4">Data</entity> <entity id="L08-1450.5">models</entity> and encoding <entity id="L08-1450.6">formats</entity> for syntactically annotated <entity id="L08-1450.7">text</entity> <entity id="L08-1450.8">corpora</entity> need to <entity id="L08-1450.9">deal</entity> with <entity id="L08-1450.10">syntactic</entity> <entity id="L08-1450.11">ambiguity</entity>; underspecified <entity id="L08-1450.12">representations</entity> are particularly well suited for the <entity id="L08-1450.13">representation</entity> of ambiguous<entity id="L08-1450.14">data</entity> because they allow for high informational <entity id="L08-1450.15">efficiency</entity>. We discuss the <entity id="L08-1450.16">issue</entity> of being informationally efficient, and the trade-off between efficient encoding of linguistic annotations and complete <entity id="L08-1450.17">documentation</entity> of <entity id="L08-1450.18">linguistic analyses</entity>. The <entity id="L08-1450.19">main</entity> <entity id="L08-1450.20">topic</entity> of this article is a<entity id="L08-1450.21">data</entity> <entity id="L08-1450.22">model</entity> and an encoding <entity id="L08-1450.23">scheme</entity> <entity id="L08-1450.24">based</entity> on LAF/GrAF ( <entity id="L08-1450.25">Ide</entity> and  Romary, 2006 ; <entity id="L08-1450.26">Ide</entity> and  Suderman, 2007 ) which <entity id="L08-1450.27">provides</entity> a flexible <entity id="L08-1450.28">framework</entity> for encoding underspecified <entity id="L08-1450.29">representations</entity>. We show how a set of <entity id="L08-1450.30">dependency structures</entity> and a set of <entity id="L08-1450.31">TiGer</entity> graphs ( Brants et al., 2002 ) representing the readings of an ambiguous <entity id="L08-1450.32">sentence</entity> can be encoded, and we discuss <entity id="L08-1450.33">basic</entity> <entity id="L08-1450.34">issues</entity> in <entity id="L08-1450.35">querying</entity> <entity id="L08-1450.36">corpora</entity> which are encoded using the <entity id="L08-1450.37">framework</entity> presented here.
</abstract>


model(L08-1450.5,L08-1450.8)
usedfor(L08-1450.12,L08-1450.13)
study(L08-1450.17,L08-1450.18)
usedfor(L08-1450.28,L08-1450.29)
model(L08-1450.30,L08-1450.32)
problem(L08-1450.34,L08-1450.35)
tag(L08-1450.36,L08-1450.37)

</text>

<text id="L08-1459"><title>
A <entity id="L08-1459.1">Study</entity> of Parentheticals in <entity id="L08-1459.2">Discourse</entity> <entity id="L08-1459.3">Corpora</entity> - Implications for NLG <entity id="L08-1459.4">Systems</entity></title><abstract>
This <entity id="L08-1459.5">paper</entity> presents a <entity id="L08-1459.6">corpus</entity> <entity id="L08-1459.7">study</entity> of parenthetical <entity id="L08-1459.8">constructions</entity> in two different <entity id="L08-1459.9">corpora</entity>: the Penn <entity id="L08-1459.10">Discourse</entity> Treebank (PDTB, (PDTB- Group, 2008 )) and the RST <entity id="L08-1459.11">Discourse</entity> Treebank ( Carlson et al., 2001 ). The <entity id="L08-1459.12">motivation</entity> for the <entity id="L08-1459.13">study</entity> is to <entity id="L08-1459.14">gain</entity> a better <entity id="L08-1459.15">understanding</entity> of the rhetorical <entity id="L08-1459.16">properties</entity> of parentheticals in <entity id="L08-1459.17">order</entity> to enable a <entity id="L08-1459.18">natural language generation system</entity> to produce parentheticals as <entity id="L08-1459.19">part</entity> of a rhetorically well-formed <entity id="L08-1459.20">output</entity>. We argue that there is a <entity id="L08-1459.21">correlation</entity> between <entity id="L08-1459.22">syntactic</entity> and rhetorical <entity id="L08-1459.23">types</entity> of parentheticals and establish two <entity id="L08-1459.24">main</entity> <entity id="L08-1459.25">categories</entity>: elaboration/<entity id="L08-1459.26">expansion-type</entity> <entity id="L08-1459.27">NP-modifier</entity> parentheticals and non-elaboration/<entity id="L08-1459.28">expansion-type</entity> VP- or S-<entity id="L08-1459.29">modifier</entity> parentheticals. We show several <entity id="L08-1459.30">strategies</entity> for <entity id="L08-1459.31">extracting</entity> these from the two <entity id="L08-1459.32">corpora</entity> and discuss how the seemingly contradictory <entity id="L08-1459.33">results</entity> obtained can be reconciled in light of the rhetorical and <entity id="L08-1459.34">syntactic</entity> <entity id="L08-1459.35">properties</entity> of parentheticals as well as the <entity id="L08-1459.36">decisions</entity> taken in the annotation <entity id="L08-1459.37">guidelines</entity>.
</abstract>


propose(L08-1459.5,L08-1459.7)
phenomenon(L08-1459.8,L08-1459.9)
study(L08-1459.15,L08-1459.16)
yields(L08-1459.18,L08-1459.20)
phenomenon(L08-1459.21,L08-1459.23)
usedfor(L08-1459.30,L08-1459.31)
affects(L08-1459.33,L08-1459.35,REVERSE)

</text>

<text id="I05-2027"><title>
<entity id="I05-2027.1">Machine Learning Approach</entity> to Augmenting <entity id="I05-2027.2">News</entity> <entity id="I05-2027.3">Headline</entity> <entity id="I05-2027.4">Generation</entity>
</title><abstract>In this <entity id="I05-2027.5">paper</entity>, we present the HybridTrim <entity id="I05-2027.6">system</entity> which uses a <entity id="I05-2027.7">machine</entity> learning <entity id="I05-2027.8">technique</entity> to combine linguistic, <entity id="I05-2027.9">statistical</entity> and positional <entity id="I05-2027.10">information</entity> to identify <entity id="I05-2027.11">topic</entity> labels for <entity id="I05-2027.12">headlines</entity> in a <entity id="I05-2027.13">text</entity>. We compare our <entity id="I05-2027.14">system</entity> with the Topiary <entity id="I05-2027.15">system</entity> which, in <entity id="I05-2027.16">contrast</entity>, uses a <entity id="I05-2027.17">statistical</entity> <entity id="I05-2027.18">learning approach</entity> to finding <entity id="I05-2027.19">topic</entity> descriptors for <entity id="I05-2027.20">headlines</entity>. The Topiary <entity id="I05-2027.21">system</entity>, <entity id="I05-2027.22">developed</entity> at the <entity id="I05-2027.23">University</entity> of Maryland with BBN, was the top performing <entity id="I05-2027.24">headline</entity> <entity id="I05-2027.25">generation system</entity> at DUC 2004. Topiary-style <entity id="I05-2027.26">headlines</entity> consist of a <entity id="I05-2027.27">number</entity> of general <entity id="I05-2027.28">topic</entity> labels followed by a compressed <entity id="I05-2027.29">version</entity> of the lead <entity id="I05-2027.30">sentence</entity> of a <entity id="I05-2027.31">news</entity> story. The Topiary <entity id="I05-2027.32">system</entity> uses a <entity id="I05-2027.33">statistical</entity> <entity id="I05-2027.34">learning approach</entity> to finding <entity id="I05-2027.35">topic</entity> labels. The <entity id="I05-2027.36">performance</entity> of these <entity id="I05-2027.37">systems</entity> is <entity id="I05-2027.38">evaluated</entity> using the <entity id="I05-2027.39">ROUGE</entity> <entity id="I05-2027.40">evaluation</entity> <entity id="I05-2027.41">suite</entity> on the DUC 2004 <entity id="I05-2027.42">news</entity> stories <entity id="I05-2027.43">collection</entity>.
</abstract>


usedfor(I05-2027.1,I05-2027.4)
propose(I05-2027.5,I05-2027.6)
uses_information(I05-2027.8,I05-2027.10)
phenomenon(I05-2027.12,I05-2027.13)
compare(I05-2027.14,I05-2027.15)
tag(I05-2027.19,I05-2027.20)
based_on(I05-2027.32,I05-2027.34)
yields(I05-2027.36,I05-2027.37,REVERSE)
taskapplied(I05-2027.39,I05-2027.43,REVERSE)

</text>

<text id="N03-1014"><title>
Inducing History Representations For Broad <entity id="N03-1014.1">Coverage</entity> <entity id="N03-1014.2">Statistical</entity> <entity id="N03-1014.3">Parsing</entity></title><abstract>
We present a <entity id="N03-1014.4">neural network</entity> <entity id="N03-1014.5">method</entity> for inducing <entity id="N03-1014.6">representations</entity> of <entity id="N03-1014.7">parse</entity> histories and using these history <entity id="N03-1014.8">representations</entity> to estimate the <entity id="N03-1014.9">probabilities</entity> needed by a <entity id="N03-1014.10">statistical</entity> left-corner <entity id="N03-1014.11">parser</entity>. The <entity id="N03-1014.12">resulting</entity> <entity id="N03-1014.13">statistical</entity> <entity id="N03-1014.14">parser</entity> achieves <entity id="N03-1014.15">performance</entity> (89.1% F-measure) on the <entity id="N03-1014.16">Penn Treebank</entity> which is only 0.6% below the best <entity id="N03-1014.17">current</entity> <entity id="N03-1014.18">parser</entity> for this <entity id="N03-1014.19">task</entity>, despite using a smaller <entity id="N03-1014.20">vocabulary</entity> <entity id="N03-1014.21">size</entity> and less prior <entity id="N03-1014.22">linguistic knowledge</entity>. Crucial to this <entity id="N03-1014.23">success</entity> is the use of structurally determined soft <entity id="N03-1014.24">biases</entity> in inducing the <entity id="N03-1014.25">representation</entity> of the <entity id="N03-1014.26">parse</entity> history, and no use of hard <entity id="N03-1014.27">independence</entity> <entity id="N03-1014.28">assumptions</entity>.
</abstract>


methodapplied(N03-1014.5,N03-1014.6)
usedfor(N03-1014.8,N03-1014.9)
compare(N03-1014.15,N03-1014.18)
affects(N03-1014.23,N03-1014.24,REVERSE)

</text>

<text id="N03-2021"><title><entity id="N03-2021.1">Precision</entity> And <entity id="N03-2021.2">Recall</entity> Of <entity id="N03-2021.3">Machine Translation</entity></title>
<abstract><entity id="N03-2021.4">Machine translation</entity> can be <entity id="N03-2021.5">evaluated</entity> using <entity id="N03-2021.6">precision</entity>, <entity id="N03-2021.7">recall</entity>, and the F-measure. These <entity id="N03-2021.8">standard</entity> measures have significantly higher <entity id="N03-2021.9">correlation</entity> with human <entity id="N03-2021.10">judgments</entity> than recently <entity id="N03-2021.11">proposed</entity> <entity id="N03-2021.12">alternatives</entity>. More importantly, the <entity id="N03-2021.13">standard</entity> measures have an intuitive <entity id="N03-2021.14">interpretation</entity>, which can facilitate <entity id="N03-2021.15">insights</entity> into how <entity id="N03-2021.16">MT systems</entity> might be <entity id="N03-2021.17">improved</entity>. The relevant <entity id="N03-2021.18">software</entity> is publicly available. D E F B A
</abstract>


char(N03-2021.2,N03-2021.3)
compare(N03-2021.10,N03-2021.12)
study(N03-2021.15,N03-2021.16)

</text>

<text id="N06-1042"><title><entity id="N06-1042.1">Learning</entity> Morphological <entity id="N06-1042.2">Disambiguation</entity> Rules For Turkish
</title><abstract>
In this <entity id="N06-1042.3">paper</entity>, we present a <entity id="N06-1042.4">rule</entity> <entity id="N06-1042.5">based</entity> <entity id="N06-1042.6">model</entity> for morphological <entity id="N06-1042.7">disambiguation</entity> of Turkish. The <entity id="N06-1042.8">rules</entity> are <entity id="N06-1042.9">generated</entity> by a novel <entity id="N06-1042.10">decision</entity> <entity id="N06-1042.11">list</entity> learning <entity id="N06-1042.12">algorithm</entity> using supervised <entity id="N06-1042.13">training</entity>. Morphological <entity id="N06-1042.14">ambiguity</entity> (e.g. lives = live+s or life+s) is a <entity id="N06-1042.15">challenging</entity> <entity id="N06-1042.16">problem</entity> for agglutinative <entity id="N06-1042.17">languages</entity> like Turkish where close to half of the <entity id="N06-1042.18">words</entity> in running <entity id="N06-1042.19">text</entity> are morphologically ambiguous. Furthermore, it is possible for a <entity id="N06-1042.20">word</entity> to take an unlimited <entity id="N06-1042.21">number</entity> of <entity id="N06-1042.22">suffixes</entity>, therefore the <entity id="N06-1042.23">number</entity> of possible morphological <entity id="N06-1042.24">tags</entity> is unlimited. We attempted to cope with these <entity id="N06-1042.25">problems</entity> by <entity id="N06-1042.26">training</entity> a separate <entity id="N06-1042.27">model</entity> for each of the 126 <entity id="N06-1042.28">morphological features</entity> recognized by the morphological <entity id="N06-1042.29">analyzer</entity>. The <entity id="N06-1042.30">resulting</entity> <entity id="N06-1042.31">decision</entity> <entity id="N06-1042.32">lists</entity> independently vote on each of the potential <entity id="N06-1042.33">parses</entity> of a <entity id="N06-1042.34">word</entity> and the final <entity id="N06-1042.35">parse</entity> is selected <entity id="N06-1042.36">based</entity> on our <entity id="N06-1042.37">confidence</entity> on these votes. The <entity id="N06-1042.38">accuracy</entity> of our <entity id="N06-1042.39">model</entity> (96%) is slightly above the best previously <entity id="N06-1042.40">reported</entity> <entity id="N06-1042.41">results</entity> which use <entity id="N06-1042.42">statistical models</entity>. For <entity id="N06-1042.43">comparison</entity>, when we <entity id="N06-1042.44">train</entity> a single <entity id="N06-1042.45">decision</entity> <entity id="N06-1042.46">list</entity> on full <entity id="N06-1042.47">tags</entity> instead of using separate <entity id="N06-1042.48">models</entity> on each <entity id="N06-1042.49">feature</entity> we get 91% <entity id="N06-1042.50">accuracy</entity>.
</abstract>


usedfor(N06-1042.6,N06-1042.7)
based_on(N06-1042.12,N06-1042.13,REVERSE)
problem(N06-1042.14,N06-1042.17)
composed_of(N06-1042.18,N06-1042.19)
char(N06-1042.20,N06-1042.22,REVERSE)
char(N06-1042.23,N06-1042.24)
model(N06-1042.27,N06-1042.28)
tag(N06-1042.33,N06-1042.34)
based_on(N06-1042.35,N06-1042.37)
compare(N06-1042.38,N06-1042.41)
based_on(N06-1042.46,N06-1042.47)

</text>

<text id="M92-1018"><title>
SRA SOLOMON: MUC-4 <entity id="M92-1018.1">Test</entity> <entity id="M92-1018.2">Results</entity> And <entity id="M92-1018.3">Analysis</entity></title><abstract>
In this <entity id="M92-1018.4">paper</entity>, we <entity id="M92-1018.5">report</entity> SRA's <entity id="M92-1018.6">results</entity> on the MUC-4 <entity id="M92-1018.7">task</entity> and describe how we <entity id="M92-1018.8">trained</entity> our <entity id="M92-1018.9">natural language processing system</entity> for MUC-4. We also <entity id="M92-1018.10">report</entity> on what worked, what didn't work, and lessons learned. Our MUC-4 <entity id="M92-1018.11">system</entity> embeds the SOLOMON <entity id="M92-1018.12">knowledge-based</entity> NLP shell which is <entity id="M92-1018.13">designed</entity> for both and We are currently using SOLOMON for a Spanish and <entity id="M92-1018.14">Japanese</entity> <entity id="M92-1018.15">text</entity> <entity id="M92-1018.16">understanding</entity> <entity id="M92-1018.17">project</entity> in a different <entity id="M92-1018.18">domain</entity>. Although this was our first year participating in MUC, we have built and are currently building other<entity id="M92-1018.19">data</entity> <entity id="M92-1018.20">extraction systems</entity>.
</abstract>


propose(M92-1018.4,M92-1018.6)

</text>

<text id="E95-1014"><title><entity id="E95-1014.1">Corpus-</entity><entity id="E95-1014.2">Based</entity> <entity id="E95-1014.3">Method</entity> For <entity id="E95-1014.4">Automatic</entity> <entity id="E95-1014.5">Identification</entity> Of <entity id="E95-1014.6">Support</entity> Verbs For Nominalizations
</title><abstract>
Nominalization is a highly productive <entity id="E95-1014.7">phenomena</entity> in most <entity id="E95-1014.8">languages</entity>. The <entity id="E95-1014.9">process</entity> of nominalization ejects a <entity id="E95-1014.10">verb</entity> from its <entity id="E95-1014.11">syntactic</entity> <entity id="E95-1014.12">role</entity> into a nominal position. The original <entity id="E95-1014.13">verb</entity> is often replaced by a semantically emptied <entity id="E95-1014.14">support</entity> <entity id="E95-1014.15">verb</entity> (e.g., make a <entity id="E95-1014.16">proposal</entity>).
</abstract>


usedfor(E95-1014.3,E95-1014.5)
phenomenon(E95-1014.7,E95-1014.8)
char(E95-1014.10,E95-1014.12)
compare(E95-1014.13,E95-1014.15)

</text>

<text id="A00-1030"><title>
Aggressive <entity id="A00-1030.1">Morphology</entity> For <entity id="A00-1030.2">Robust</entity> <entity id="A00-1030.3">Lexical</entity> <entity id="A00-1030.4">Coverage</entity></title><abstract>
This <entity id="A00-1030.5">paper</entity> describes an <entity id="A00-1030.6">approach</entity> to <entity id="A00-1030.7">providing</entity> <entity id="A00-1030.8">lexical information</entity> for <entity id="A00-1030.9">natural language processing</entity> in unrestricted <entity id="A00-1030.10">domains</entity>. A <entity id="A00-1030.11">system</entity> of approximately 1200 morphological <entity id="A00-1030.12">rules</entity> is used to extend a <entity id="A00-1030.13">core</entity> <entity id="A00-1030.14">lexicon</entity> of 39,000 <entity id="A00-1030.15">words</entity> to <entity id="A00-1030.16">provide</entity> <entity id="A00-1030.17">lexical</entity> <entity id="A00-1030.18">coverage</entity> that exceeds that of a <entity id="A00-1030.19">lexicon</entity> of 80,000 <entity id="A00-1030.20">words</entity> or 150,000 <entity id="A00-1030.21">word</entity> <entity id="A00-1030.22">forms</entity>. The morphological <entity id="A00-1030.23">system</entity> is described, and <entity id="A00-1030.24">lexical</entity> <entity id="A00-1030.25">coverage</entity> is <entity id="A00-1030.26">evaluated</entity> for random <entity id="A00-1030.27">words</entity> chosen from a previously unanalyzed <entity id="A00-1030.28">corpus</entity>.
</abstract>


usedfor(A00-1030.1,A00-1030.4)
propose(A00-1030.5,A00-1030.6)
uses_information(A00-1030.8,A00-1030.9)
based_on(A00-1030.11,A00-1030.12)
composed_of(A00-1030.14,A00-1030.15)
phenomenon(A00-1030.27,A00-1030.28)

</text>

<text id="A00-2029"><title>
Predicting <entity id="A00-2029.1">Automatic Speech Recognition</entity> <entity id="A00-2029.2">Performance</entity> Using Prosodic Cues
</title><abstract>
In spoken <entity id="A00-2029.3">dialogue systems</entity>, it is important for a <entity id="A00-2029.4">system</entity> to know how likely a <entity id="A00-2029.5">speech recognition</entity> <entity id="A00-2029.6">hypothesis</entity> is to be correct, so it can reprompt for fresh <entity id="A00-2029.7">input</entity>, or, in <entity id="A00-2029.8">cases</entity> where many <entity id="A00-2029.9">errors</entity> have occurred, change its <entity id="A00-2029.10">interaction</entity> <entity id="A00-2029.11">strategy</entity> or switch the caller to a human attendant. We have discovered prosodie <entity id="A00-2029.12">features</entity> which more accurately predict when a <entity id="A00-2029.13">recognition</entity> <entity id="A00-2029.14">hypothesis</entity> contains a <entity id="A00-2029.15">word</entity> <entity id="A00-2029.16">error</entity> than the acoustic <entity id="A00-2029.17">confidence</entity> score <entity id="A00-2029.18">thresholds</entity> traditionally used in <entity id="A00-2029.19">automatic speech recognition</entity>. We present analytic <entity id="A00-2029.20">results</entity> indicating that there are significant prosodie <entity id="A00-2029.21">differences</entity> between correctly and incorrectly recognized turns.
</abstract>


based_on(A00-2029.3,A00-2029.6)
affects(A00-2029.9,A00-2029.11)
char(A00-2029.14,A00-2029.16)
uses_information(A00-2029.18,A00-2029.19,REVERSE)
affects(A00-2029.20,A00-2029.21,REVERSE)

</text>

<text id="H92-1099"><title><entity id="H92-1099.1">Evaluating</entity> The Use Of Prosodic <entity id="H92-1099.2">Information</entity> In <entity id="H92-1099.3">Speech Recognition</entity> And <entity id="H92-1099.4">Understanding</entity></title><abstract>
The <entity id="H92-1099.5">goal</entity> of this <entity id="H92-1099.6">project</entity> is to investigate the use of different <entity id="H92-1099.7">levels</entity> of prosodie <entity id="H92-1099.8">information</entity> in <entity id="H92-1099.9">speech recognition</entity> and <entity id="H92-1099.10">understanding</entity>. In particular, the <entity id="H92-1099.11">current</entity> <entity id="H92-1099.12">focus</entity> of the work is the use of prosodie <entity id="H92-1099.13">phrase</entity> <entity id="H92-1099.14">boundary</entity> <entity id="H92-1099.15">information</entity> in <entity id="H92-1099.16">parsing</entity>. The <entity id="H92-1099.17">research</entity> involves determining a <entity id="H92-1099.18">representation</entity> of prosodie <entity id="H92-1099.19">information</entity> suitable for use in a <entity id="H92-1099.20">speech understanding system</entity>, <entity id="H92-1099.21">developing</entity> reliable <entity id="H92-1099.22">algorithms</entity> for <entity id="H92-1099.23">detection</entity> of the prosodie <entity id="H92-1099.24">cues</entity> in <entity id="H92-1099.25">speech</entity>, investigating <entity id="H92-1099.26">architectures</entity> for integrating prosodie <entity id="H92-1099.27">cues</entity> in a <entity id="H92-1099.28">parser</entity>, and <entity id="H92-1099.29">evaluating</entity> the potential <entity id="H92-1099.30">improvements</entity> of <entity id="H92-1099.31">prosody</entity> in the <entity id="H92-1099.32">context</entity> of the SRI <entity id="H92-1099.33">Spoken Language System</entity>. This <entity id="H92-1099.34">research</entity> is sponsored jointly by DARPA and NSF.
</abstract>


uses_information(H92-1099.2,H92-1099.3,REVERSE)
propose(H92-1099.6,H92-1099.8)
uses_information(H92-1099.15,H92-1099.16,REVERSE)
propose(H92-1099.17,H92-1099.18)
uses_information(H92-1099.19,H92-1099.20,REVERSE)
usedfor(H92-1099.22,H92-1099.23)
phenomenon(H92-1099.24,H92-1099.25)
uses_information(H92-1099.27,H92-1099.28,REVERSE)
wrt(H92-1099.30,H92-1099.33)

</text>

<text id="H93-1048"><title><entity id="H93-1048.1">Prediction</entity> Of Lexicalized <entity id="H93-1048.2">Tree</entity> Fragments In <entity id="H93-1048.3">Text</entity></title><abstract>
There is a <entity id="H93-1048.4">mismatch</entity> between the <entity id="H93-1048.5">distribution</entity> of <entity id="H93-1048.6">information</entity> in <entity id="H93-1048.7">text</entity>, and a <entity id="H93-1048.8">variety</entity> of grammatical <entity id="H93-1048.9">formalisms</entity> for describing it, <entity id="H93-1048.10">including</entity> ngrams, <entity id="H93-1048.11">context-free</entity> grammars, and <entity id="H93-1048.12">dependency grammars</entity>. Rather than adding <entity id="H93-1048.13">probabilities</entity> to existing grammars, it is <entity id="H93-1048.14">proposed</entity> to collect the <entity id="H93-1048.15">distributions</entity> of flexibly <entity id="H93-1048.16">sized</entity> <entity id="H93-1048.17">partial</entity> <entity id="H93-1048.18">trees</entity>. These can be used to enhance an ngram <entity id="H93-1048.19">model</entity>, and in analogical <entity id="H93-1048.20">parsing</entity>.
</abstract>


phenomenon(H93-1048.2,H93-1048.3)
datasource(H93-1048.6,H93-1048.7)
char(H93-1048.8,H93-1048.9)
char(H93-1048.15,H93-1048.18)

</text>

<text id="H93-1060"><title>
The COMLEX <entity id="H93-1060.1">Syntax</entity> <entity id="H93-1060.2">Project</entity></title><abstract>
"<entity id="H93-1060.3">Developing</entity> more shareable <entity id="H93-1060.4">resources</entity> to <entity id="H93-1060.5">support</entity> <entity id="H93-1060.6">natural language</entity> <entity id="H93-1060.7">analysis</entity> will make it easier and cheaper to create new <entity id="H93-1060.8">language processing</entity> <entity id="H93-1060.9">applications</entity> and to <entity id="H93-1060.10">support</entity> <entity id="H93-1060.11">research</entity> in <entity id="H93-1060.12">computational linguistics</entity>. One <entity id="H93-1060.13">natural</entity> <entity id="H93-1060.14">candidate</entity> for such a <entity id="H93-1060.15">resource</entity> is a <entity id="H93-1060.16">broad-coverage</entity> <entity id="H93-1060.17">dictionary</entity>, since the work <entity id="H93-1060.18">required</entity> to create such a <entity id="H93-1060.19">dictionary</entity> is large but there is general <entity id="H93-1060.20">agreement</entity> on at least some of the <entity id="H93-1060.21">information</entity> to be <entity id="H93-1060.22">recorded</entity> for each <entity id="H93-1060.23">word</entity>. The Linguistic <entity id="H93-1060.24">Data</entity> Consortium has begun an <entity id="H93-1060.25">effort</entity> to create several such <entity id="H93-1060.26">lexical resources</entity>, under the rubric ""COMLEX"" (<entity id="H93-1060.27">COMmon</entity> <entity id="H93-1060.28">LEXicon</entity>); one of these <entity id="H93-1060.29">projects</entity> is the COMLEX <entity id="H93-1060.30">Syntax</entity> <entity id="H93-1060.31">Project</entity>. The <entity id="H93-1060.32">goal</entity> of the COMLEX <entity id="H93-1060.33">Syntax</entity> <entity id="H93-1060.34">Project</entity> is to create a <entity id="H93-1060.35">moderately-broad-coverage</entity> shareable <entity id="H93-1060.36">dictionary</entity> containing the <entity id="H93-1060.37">syntactic features</entity> of <entity id="H93-1060.38">English</entity> <entity id="H93-1060.39">words</entity>, intended for <entity id="H93-1060.40">automatic</entity> <entity id="H93-1060.41">language analysis</entity>. We are initially aiming for a <entity id="H93-1060.42">dictionary</entity> of 35,000 to 40,000 <entity id="H93-1060.43">base</entity> <entity id="H93-1060.44">forms</entity>, although this of course may be enlarged if the initial <entity id="H93-1060.45">effort</entity> is positively received. The <entity id="H93-1060.46">dictionary</entity> should <entity id="H93-1060.47">include</entity> detailed <entity id="H93-1060.48">syntactic</entity> <entity id="H93-1060.49">specifications</entity>, particularly for subcategorization; our intent is to <entity id="H93-1060.50">provide</entity> sufficient <entity id="H93-1060.51">detail</entity> so that the <entity id="H93-1060.52">information</entity> <entity id="H93-1060.53">required</entity> by a <entity id="H93-1060.54">number</entity> of major <entity id="H93-1060.55">English</entity> <entity id="H93-1060.56">analyzers</entity> can be automatically derived from the <entity id="H93-1060.57">information</entity> we <entity id="H93-1060.58">provide</entity>. As with other Linguistic <entity id="H93-1060.59">Data</entity> Consortium <entity id="H93-1060.60">resources</entity>, our intent is to <entity id="H93-1060.61">provide</entity> a <entity id="H93-1060.62">lexicon</entity> available without <entity id="H93-1060.63">license</entity> <entity id="H93-1060.64">constraint</entity> to all Consortium members. Finally, our <entity id="H93-1060.65">goal</entity> is to <entity id="H93-1060.66">provide</entity> an initial <entity id="H93-1060.67">lexicon</entity> relatively quickly 
 within about a year, funding permitting. This implies a certain <entity id="H93-1060.68">flexibility</entity>, where some of the <entity id="H93-1060.69">features</entity> will probably be changed and refined as the <entity id="H93-1060.70">coding</entity> is taking place. "
</abstract>


usedfor(H93-1060.4,H93-1060.7)
study(H93-1060.11,H93-1060.12)
model(H93-1060.21,H93-1060.23)
propose(H93-1060.34,H93-1060.36)
model(H93-1060.37,H93-1060.39)
composed_of(H93-1060.42,H93-1060.44)
datasource(H93-1060.46,H93-1060.49,REVERSE)
uses_information(H93-1060.52,H93-1060.56,REVERSE)

</text>

<text id="A97-1008"><title>
An <entity id="A97-1008.1">Evaluation</entity> Of <entity id="A97-1008.2">Strategies</entity> For Selective <entity id="A97-1008.3">Utterance</entity> <entity id="A97-1008.4">Verification</entity> For Spoken <entity id="A97-1008.5">Natural Language</entity> <entity id="A97-1008.6">Dialog</entity></title><abstract>
As with human-human <entity id="A97-1008.7">interaction</entity>, spoken <entity id="A97-1008.8">human-computer</entity> <entity id="A97-1008.9">dialog</entity> will contain <entity id="A97-1008.10">situations</entity> where there is miscommunication. In <entity id="A97-1008.11">experimental</entity> trials consisting of eight different <entity id="A97-1008.12">users</entity>, 141 <entity id="A97-1008.13">problem-solving</entity> <entity id="A97-1008.14">dialogs</entity>, and 2840 <entity id="A97-1008.15">user</entity> <entity id="A97-1008.16">utterances</entity>, the Circuit Fix-It Shop <entity id="A97-1008.17">natural language</entity> <entity id="A97-1008.18">dialog system</entity> misinterpreted 18.5% of <entity id="A97-1008.19">user</entity> <entity id="A97-1008.20">utterances</entity>. These miscommunications created various <entity id="A97-1008.21">problems</entity> for the <entity id="A97-1008.22">dialog</entity> <entity id="A97-1008.23">interaction</entity>, ranging from repetitive <entity id="A97-1008.24">dialog</entity> to experimenter intervention to occasional failure of the <entity id="A97-1008.25">dialog</entity>. One <entity id="A97-1008.26">natural</entity> <entity id="A97-1008.27">strategy</entity> for reducing the <entity id="A97-1008.28">impact</entity> of miscommunication is selective <entity id="A97-1008.29">verification</entity> of the <entity id="A97-1008.30">user</entity>'s <entity id="A97-1008.31">utterances</entity>. This <entity id="A97-1008.32">paper</entity> <entity id="A97-1008.33">reports</entity> on both <entity id="A97-1008.34">context-independent</entity> and <entity id="A97-1008.35">context-dependent</entity> <entity id="A97-1008.36">strategies</entity> for <entity id="A97-1008.37">utterance</entity> <entity id="A97-1008.38">verification</entity> that show that the use of <entity id="A97-1008.39">dialog</entity> <entity id="A97-1008.40">context</entity> is crucial for intelligent <entity id="A97-1008.41">selection</entity> of which <entity id="A97-1008.42">utterances</entity> to verify.
</abstract>


usedfor(A97-1008.2,A97-1008.4)
phenomenon(A97-1008.9,A97-1008.10,REVERSE)
taskapplied(A97-1008.18,A97-1008.20)
taskapplied(A97-1008.29,A97-1008.31)
propose(A97-1008.32,A97-1008.36)
uses_information(A97-1008.40,A97-1008.41,REVERSE)

</text>

<text id="W97-1206"><title><entity id="W97-1206.1">Computing</entity> Prosodic Properties In A <entity id="W97-1206.2">Data-</entity>To-<entity id="W97-1206.3">Speech</entity> <entity id="W97-1206.4">System</entity></title><abstract>
We <entity id="W97-1206.5">propose</entity> a set of <entity id="W97-1206.6">rules</entity> for the <entity id="W97-1206.7">computation</entity> of <entity id="W97-1206.8">prosody</entity> which are <entity id="W97-1206.9">implemented</entity> in an existing generic <entity id="W97-1206.10">Data-to-</entity><entity id="W97-1206.11">Speech</entity> <entity id="W97-1206.12">system</entity>. The <entity id="W97-1206.13">rules</entity> make crucial use of both <entity id="W97-1206.14">sentence-internal</entity> and <entity id="W97-1206.15">sentence-external</entity> <entity id="W97-1206.16">semantic</entity> and <entity id="W97-1206.17">syntactic information</entity> <entity id="W97-1206.18">provided</entity> by the <entity id="W97-1206.19">system</entity>. In a <entity id="W97-1206.20">Text-to-</entity><entity id="W97-1206.21">Speech</entity> <entity id="W97-1206.22">system</entity>, this <entity id="W97-1206.23">information</entity> would have to be obtained through <entity id="W97-1206.24">text analysis</entity>, but in <entity id="W97-1206.25">Data-to-</entity><entity id="W97-1206.26">Speech</entity> it is readily available, and its reliable and detailed character makes it possible to <entity id="W97-1206.27">compute</entity> the prosodie <entity id="W97-1206.28">properties</entity> of <entity id="W97-1206.29">generated</entity> <entity id="W97-1206.30">sentences</entity> in a sophisticated way. This in turn allows for a close <entity id="W97-1206.31">control</entity> of prosodie <entity id="W97-1206.32">realization</entity>, <entity id="W97-1206.33">resulting</entity> in <entity id="W97-1206.34">natural-sounding</entity> <entity id="W97-1206.35">intonation</entity>.
</abstract>


usedfor(W97-1206.6,W97-1206.7)
uses_information(W97-1206.13,W97-1206.17)
yields(W97-1206.23,W97-1206.24,REVERSE)
char(W97-1206.28,W97-1206.30)

</text>

<text id="W99-0305"><title>
Standardisation <entity id="W99-0305.1">Efforts</entity> On The <entity id="W99-0305.2">Level</entity> Of <entity id="W99-0305.3">Dialogue Act</entity> In The <entity id="W99-0305.4">MATE</entity> <entity id="W99-0305.5">Project</entity></title><abstract>
This <entity id="W99-0305.6">paper</entity> describes the state of the art of <entity id="W99-0305.7">coding</entity> <entity id="W99-0305.8">schemes</entity> for <entity id="W99-0305.9">dialogue acts</entity> and the <entity id="W99-0305.10">efforts</entity> to establish a <entity id="W99-0305.11">standard</entity> in this <entity id="W99-0305.12">field</entity>. We present a <entity id="W99-0305.13">review</entity> and <entity id="W99-0305.14">comparison</entity> of currently available <entity id="W99-0305.15">schemes</entity> and <entity id="W99-0305.16">outline</entity> the <entity id="W99-0305.17">comparison</entity> <entity id="W99-0305.18">problems</entity> we had <entity id="W99-0305.19">due</entity> to <entity id="W99-0305.20">domain</entity>, <entity id="W99-0305.21">task</entity>, and <entity id="W99-0305.22">language</entity> <entity id="W99-0305.23">dependencies</entity> of <entity id="W99-0305.24">schemes</entity>. We discuss <entity id="W99-0305.25">solution</entity> <entity id="W99-0305.26">strategies</entity> which have in mind the reusability of <entity id="W99-0305.27">corpora</entity>. Reusability is a crucial point because production and annotation of <entity id="W99-0305.28">corpora</entity> is very <entity id="W99-0305.29">time</entity> and <entity id="W99-0305.30">cost</entity> consuming but the <entity id="W99-0305.31">current</entity> broad <entity id="W99-0305.32">variety</entity> of <entity id="W99-0305.33">schemes</entity> makes reusability of annotated <entity id="W99-0305.34">corpora</entity> very hard. The work of this <entity id="W99-0305.35">paper</entity> takes place in the <entity id="W99-0305.36">framework</entity> of the European Union funded <entity id="W99-0305.37">MATE</entity> <entity id="W99-0305.38">project</entity>. <entity id="W99-0305.39">MATE</entity> aims to <entity id="W99-0305.40">develop</entity> general methodological <entity id="W99-0305.41">guidelines</entity> for the <entity id="W99-0305.42">creation</entity>, annotation, <entity id="W99-0305.43">retrieval</entity> and <entity id="W99-0305.44">analysis</entity> of annotated <entity id="W99-0305.45">corpora</entity>.
</abstract>


usedfor(W99-0305.8,W99-0305.9)
study(W99-0305.14,W99-0305.15)
problem(W99-0305.23,W99-0305.24)
char(W99-0305.32,W99-0305.33)
study(W99-0305.41,W99-0305.42)

</text>

<text id="W00-1002"><title>
ADAM - An <entity id="W00-1002.1">Architecture</entity> For XML-Based <entity id="W00-1002.2">Dialogue</entity> Annotation On Multiple Levels
</title><abstract>
In this <entity id="W00-1002.3">paper</entity> annotation modularity and use of annotation meta-schemes are identified as <entity id="W00-1002.4">basic</entity> <entity id="W00-1002.5">requirements</entity> for achieving actual <entity id="W00-1002.6">corpora</entity> reusability. We discuss these <entity id="W00-1002.7">concepts</entity> and the way they are <entity id="W00-1002.8">implemented</entity> in the architectural <entity id="W00-1002.9">framework</entity> of the ADAM <entity id="W00-1002.10">corpus</entity>, which is a <entity id="W00-1002.11">corpus</entity> of 450 Italian spontaneous <entity id="W00-1002.12">dialogues</entity>. The <entity id="W00-1002.13">design</entity> of ADAM <entity id="W00-1002.14">architecture</entity> is compatible with as many <entity id="W00-1002.15">practices</entity> of <entity id="W00-1002.16">dialogue</entity> annotation as possible, as well as <entity id="W00-1002.17">approaches</entity> to annotation at different <entity id="W00-1002.18">levels</entity>.
</abstract>


composed_of(W00-1002.11,W00-1002.12)

</text>

<text id="W00-1213"><title>
Annotating <entity id="W00-1213.1">Information</entity> <entity id="W00-1213.2">Structures</entity> In <entity id="W00-1213.3">Chinese</entity> <entity id="W00-1213.4">Texts</entity> Using HowNet
</title><abstract>
This <entity id="W00-1213.5">paper</entity> <entity id="W00-1213.6">reported</entity> our work on annotating <entity id="W00-1213.7">Chinese</entity> <entity id="W00-1213.8">texts</entity> with <entity id="W00-1213.9">information structures</entity> derived from HowNet. An <entity id="W00-1213.10">information structure</entity> consists of two <entity id="W00-1213.11">components</entity>: HowNet <entity id="W00-1213.12">definitions</entity> and <entity id="W00-1213.13">dependency relations</entity>. It is the <entity id="W00-1213.14">unit</entity> of <entity id="W00-1213.15">representation</entity> of the meaning of <entity id="W00-1213.16">texts</entity>. This work is <entity id="W00-1213.17">part</entity> of a multi-sentential <entity id="W00-1213.18">approach</entity> to <entity id="W00-1213.19">Chinese</entity> <entity id="W00-1213.20">text</entity> <entity id="W00-1213.21">understanding</entity>. An <entity id="W00-1213.22">overview</entity> of HowNet and <entity id="W00-1213.23">information structure</entity> are described in this <entity id="W00-1213.24">paper</entity>.
</abstract>


phenomenon(W00-1213.2,W00-1213.4)
model(W00-1213.8,W00-1213.9,REVERSE)
part_of(W00-1213.10,W00-1213.11,REVERSE)
model(W00-1213.14,W00-1213.16)
usedfor(W00-1213.18,W00-1213.21)
propose(W00-1213.22,W00-1213.24,REVERSE)

</text>

<text id="W02-0221"><title><entity id="W02-0221.1">Training</entity> A <entity id="W02-0221.2">Dialogue Act</entity> Tagger For Human-Human And Human-<entity id="W02-0221.3">Computer</entity> Travel Dialogues
</title><abstract>
While <entity id="W02-0221.4">dialogue acts</entity> <entity id="W02-0221.5">provide</entity> a useful <entity id="W02-0221.6">schema</entity> for characterizing <entity id="W02-0221.7">dialogue</entity> <entity id="W02-0221.8">behaviors</entity> in <entity id="W02-0221.9">human-computer</entity> and human-human <entity id="W02-0221.10">dialogues</entity>, their <entity id="W02-0221.11">utility</entity> is <entity id="W02-0221.12">limited</entity> by the huge <entity id="W02-0221.13">effort</entity> involved in <entity id="W02-0221.14">hand-labelling</entity> <entity id="W02-0221.15">dialogues</entity> with a <entity id="W02-0221.16">dialogue act</entity> labelling <entity id="W02-0221.17">scheme</entity>. In this work, we examine whether it is possible to fully automate the <entity id="W02-0221.18">tagging</entity> <entity id="W02-0221.19">task</entity> with the <entity id="W02-0221.20">goal</entity> of enabling rapid <entity id="W02-0221.21">creation</entity> of <entity id="W02-0221.22">corpora</entity> for <entity id="W02-0221.23">evaluating</entity> spoken <entity id="W02-0221.24">dialogue systems</entity> and comparing them to human-human <entity id="W02-0221.25">dialogues</entity>. We <entity id="W02-0221.26">report</entity> <entity id="W02-0221.27">results</entity> for <entity id="W02-0221.28">training</entity> and <entity id="W02-0221.29">testing</entity> an <entity id="W02-0221.30">automatic</entity> <entity id="W02-0221.31">classifier</entity> to label the <entity id="W02-0221.32">information</entity> provider's <entity id="W02-0221.33">utterances</entity> in spoken <entity id="W02-0221.34">human-computer</entity> and human-human <entity id="W02-0221.35">dialogues</entity> with <entity id="W02-0221.36">DATE</entity> (<entity id="W02-0221.37">Dialogue Act</entity> <entity id="W02-0221.38">Tagging</entity> for <entity id="W02-0221.39">Evaluation</entity>) <entity id="W02-0221.40">dialogue act</entity> <entity id="W02-0221.41">tags</entity>. We <entity id="W02-0221.42">train</entity> and <entity id="W02-0221.43">test</entity> the <entity id="W02-0221.44">DATE</entity> tagger on various <entity id="W02-0221.45">combinations</entity> of the DARPA Communicator June-2000 and October-2001 <entity id="W02-0221.46">human-computer</entity> <entity id="W02-0221.47">corpora</entity>, and the CMU human-human <entity id="W02-0221.48">corpus</entity> in the travel planning <entity id="W02-0221.49">domain</entity>. Our <entity id="W02-0221.50">results</entity> show that we can achieve high <entity id="W02-0221.51">accuracies</entity> on the humancomputer data, and surprisingly, that the <entity id="W02-0221.52">human-computer</entity><entity id="W02-0221.53">data</entity> <entity id="W02-0221.54">improves</entity> <entity id="W02-0221.55">accuracy</entity> on the human-human data, when only small <entity id="W02-0221.56">amounts</entity> of human-human <entity id="W02-0221.57">training</entity><entity id="W02-0221.58">data</entity> are available.
</abstract>


usedfor(W02-0221.4,W02-0221.6)
phenomenon(W02-0221.8,W02-0221.10)
affects(W02-0221.11,W02-0221.13,REVERSE)
model(W02-0221.15,W02-0221.17,REVERSE)
usedfor(W02-0221.21,W02-0221.23)
compare(W02-0221.24,W02-0221.25)
yields(W02-0221.27,W02-0221.31,REVERSE)
phenomenon(W02-0221.33,W02-0221.35)
tag(W02-0221.40,W02-0221.41,REVERSE)
methodapplied(W02-0221.44,W02-0221.47)
yields(W02-0221.53,W02-0221.55)

</text>

<text id="W02-1504"><title><entity id="W02-1504.1">Machine Translation</entity> As A Testbed For Multilingual <entity id="W02-1504.2">Analysis</entity></title><abstract>
We <entity id="W02-1504.3">propose</entity> that <entity id="W02-1504.4">machine translation</entity> (MT) is a useful <entity id="W02-1504.5">application</entity> for <entity id="W02-1504.6">evaluating</entity> and deriving the <entity id="W02-1504.7">development</entity> of NL <entity id="W02-1504.8">components</entity>, especially in a <entity id="W02-1504.9">wide-coverage</entity> <entity id="W02-1504.10">analysis</entity> <entity id="W02-1504.11">system</entity>. Given the <entity id="W02-1504.12">architecture</entity> of our <entity id="W02-1504.13">MT system</entity>, which is a <entity id="W02-1504.14">transfer</entity> <entity id="W02-1504.15">system</entity> <entity id="W02-1504.16">based</entity> on linguistic <entity id="W02-1504.17">modules</entity>, correct <entity id="W02-1504.18">analysis</entity> is expected to be a prerequisite for correct <entity id="W02-1504.19">translation</entity>, suggesting a <entity id="W02-1504.20">correlation</entity> between the two, given relatively mature <entity id="W02-1504.21">transfer</entity> and <entity id="W02-1504.22">generation</entity> <entity id="W02-1504.23">components</entity>. We show through <entity id="W02-1504.24">error analysis</entity> that there is indeed a strong <entity id="W02-1504.25">correlation</entity> between the <entity id="W02-1504.26">quality</entity> of the <entity id="W02-1504.27">translated</entity> <entity id="W02-1504.28">output</entity> and the subjectively determined goodness of the <entity id="W02-1504.29">analysis</entity>. We use this <entity id="W02-1504.30">correlation</entity> as a guide for <entity id="W02-1504.31">development</entity> of a coordinated parallel <entity id="W02-1504.32">analysis</entity> <entity id="W02-1504.33">effort</entity> in 7 <entity id="W02-1504.34">languages</entity>.
</abstract>


usedfor(W02-1504.1,W02-1504.2,REVERSE)
usedfor(W02-1504.4,W02-1504.8,REVERSE)
based_on(W02-1504.15,W02-1504.17)
usedfor(W02-1504.18,W02-1504.19)
compare(W02-1504.28,W02-1504.29)
based_on(W02-1504.30,W02-1504.32,REVERSE)

</text>

<text id="W03-0421"><title>
A <entity id="W03-0421.1">Simple</entity> <entity id="W03-0421.2">Named</entity> <entity id="W03-0421.3">Entity</entity> <entity id="W03-0421.4">Extractor</entity> Using AdaBoost
</title><abstract>
This <entity id="W03-0421.5">paper</entity> presents a <entity id="W03-0421.6">Named</entity> <entity id="W03-0421.7">Entity</entity> <entity id="W03-0421.8">Extraction</entity> (NEE) <entity id="W03-0421.9">system</entity> for the CoNLL-2003 shared <entity id="W03-0421.10">task</entity> <entity id="W03-0421.11">competition</entity>. As in the past year edition ( Carreras et al., 2002a ), we have <entity id="W03-0421.12">approached</entity> the <entity id="W03-0421.13">task</entity> by treating the two <entity id="W03-0421.14">main</entity> sub-tasks of the <entity id="W03-0421.15">problem</entity>, <entity id="W03-0421.16">recognition</entity> (NER) and <entity id="W03-0421.17">classification</entity> (NEC), sequentially and independently with separate <entity id="W03-0421.18">modules</entity>. Both <entity id="W03-0421.19">modules</entity> are <entity id="W03-0421.20">machine</entity> learning <entity id="W03-0421.21">based</entity> <entity id="W03-0421.22">systems</entity>, which make use of binary and multiclass AdaBoost <entity id="W03-0421.23">classifiers</entity>. <entity id="W03-0421.24">Named</entity> <entity id="W03-0421.25">Entity</entity> <entity id="W03-0421.26">recognition</entity> is <entity id="W03-0421.27">performed</entity> as a greedy <entity id="W03-0421.28">sequence</entity> <entity id="W03-0421.29">tagging</entity> <entity id="W03-0421.30">procedure</entity> under the well-known BIO labelling <entity id="W03-0421.31">scheme</entity>. This <entity id="W03-0421.32">tagging</entity> <entity id="W03-0421.33">process</entity> makes use of three binary <entity id="W03-0421.34">classifiers</entity> <entity id="W03-0421.35">trained</entity> to be <entity id="W03-0421.36">experts</entity></abstract>


propose(W03-0421.5,W03-0421.9)
composed_of(W03-0421.13,W03-0421.16)
based_on(W03-0421.22,W03-0421.23)
methodapplied(W03-0421.26,W03-0421.30,REVERSE)
usedfor(W03-0421.33,W03-0421.34,REVERSE)

</text>

<text id="W03-0802"><title>
WHAT: An XSLT-Based <entity id="W03-0802.1">Infrastructure</entity> For The <entity id="W03-0802.2">Integration</entity> Of <entity id="W03-0802.3">Natural Language Processing</entity> Components
</title><abstract>
The idea of the Whiteboard <entity id="W03-0802.4">project</entity> is to integrate deep and shallow <entity id="W03-0802.5">natural language processing</entity> <entity id="W03-0802.6">components</entity> in <entity id="W03-0802.7">order</entity> to <entity id="W03-0802.8">benefit</entity> from their synergy. The <entity id="W03-0802.9">project</entity> came up with the first fully integrated hybrid <entity id="W03-0802.10">system</entity> consisting of a fast HPSG <entity id="W03-0802.11">parser</entity> that utilizes tokenization, PoS, <entity id="W03-0802.12">morphology</entity>, <entity id="W03-0802.13">lexical</entity>, <entity id="W03-0802.14">named</entity> <entity id="W03-0802.15">entity</entity>, <entity id="W03-0802.16">phrase</entity> <entity id="W03-0802.17">chunk</entity> and (for German) topological <entity id="W03-0802.18">sentence</entity> <entity id="W03-0802.19">field</entity> <entity id="W03-0802.20">analyses</entity> from shallow <entity id="W03-0802.21">components</entity>. This <entity id="W03-0802.22">integration</entity> <entity id="W03-0802.23">increases</entity> <entity id="W03-0802.24">robustness</entity>, directs the <entity id="W03-0802.25">search space</entity> and hence reduces <entity id="W03-0802.26">processing</entity> <entity id="W03-0802.27">time</entity> of the deep <entity id="W03-0802.28">parser</entity>. In this <entity id="W03-0802.29">paper</entity>, we <entity id="W03-0802.30">focus</entity> on one of the central <entity id="W03-0802.31">integration</entity> facilities, the XSLT-based Whiteboard Annotation Transformer (WHAT), <entity id="W03-0802.32">report</entity> on the <entity id="W03-0802.33">benefits</entity> of XSLT-based NLP <entity id="W03-0802.34">component</entity> <entity id="W03-0802.35">integration</entity>, and present <entity id="W03-0802.36">examples</entity> of XSL <entity id="W03-0802.37">transformation</entity> of shallow and deep annotations used in the integrated <entity id="W03-0802.38">architecture</entity>. The <entity id="W03-0802.39">infrastructure</entity> is open, portable and well suited for, but not restricted to the <entity id="W03-0802.40">development</entity> of hybrid NLP <entity id="W03-0802.41">architectures</entity> as well as <entity id="W03-0802.42">NLP applications</entity>.
</abstract>


usedfor(W03-0802.1,W03-0802.2)
yields(W03-0802.9,W03-0802.10)
based_on(W03-0802.11,W03-0802.12)
yields(W03-0802.22,W03-0802.24)
affects(W03-0802.25,W03-0802.27)
propose(W03-0802.29,W03-0802.31)
yields(W03-0802.33,W03-0802.35,REVERSE)
usedfor(W03-0802.39,W03-0802.40)

</text>

<text id="W99-0907"><title>
Detecting Sub-<entity id="W99-0907.1">Topic</entity> <entity id="W99-0907.2">Correspondence</entity> Through Bipartite <entity id="W99-0907.3">Term</entity> Clustering
</title><abstract>
This <entity id="W99-0907.4">paper</entity> addresses a novel <entity id="W99-0907.5">task</entity> of detecting <entity id="W99-0907.6">sub-topic</entity> <entity id="W99-0907.7">correspondence</entity> in a <entity id="W99-0907.8">pair</entity> of <entity id="W99-0907.9">text</entity> <entity id="W99-0907.10">fragments</entity>, enhancing <entity id="W99-0907.11">common</entity> <entity id="W99-0907.12">notions</entity> of <entity id="W99-0907.13">text</entity> <entity id="W99-0907.14">similarity</entity>. This <entity id="W99-0907.15">task</entity> is addressed by coupling corresponding <entity id="W99-0907.16">term</entity> subsets through bipartite <entity id="W99-0907.17">clustering</entity>. The <entity id="W99-0907.18">paper</entity> presents a <entity id="W99-0907.19">cost-based</entity> <entity id="W99-0907.20">clustering</entity> <entity id="W99-0907.21">scheme</entity> and compares it with a bipartite <entity id="W99-0907.22">version</entity> of the <entity id="W99-0907.23">single-link</entity> <entity id="W99-0907.24">method</entity>, <entity id="W99-0907.25">providing</entity> illustrating <entity id="W99-0907.26">results</entity>.
</abstract>


propose(W99-0907.4,W99-0907.5)
phenomenon(W99-0907.7,W99-0907.10)
usedfor(W99-0907.15,W99-0907.17,REVERSE)
propose(W99-0907.18,W99-0907.21)

</text>

<text id="W08-0327"><title>
Can we Relearn an RBMT <entity id="W08-0327.1">System</entity>?
</title><abstract>
This <entity id="W08-0327.2">paper</entity> describes SYSTRAN <entity id="W08-0327.3">submissions</entity> for the shared <entity id="W08-0327.4">task</entity> of the third <entity id="W08-0327.5">Workshop</entity> on <entity id="W08-0327.6">Statistical Machine Translation</entity> at ACL. Our <entity id="W08-0327.7">main</entity> <entity id="W08-0327.8">contribution</entity> consists in a French-<entity id="W08-0327.9">English</entity> <entity id="W08-0327.10">statistical model</entity> <entity id="W08-0327.11">trained</entity> without the use of any human-translated <entity id="W08-0327.12">parallel corpus</entity>. In <entity id="W08-0327.13">substitution</entity>, we <entity id="W08-0327.14">translated</entity> a monolingual <entity id="W08-0327.15">corpus</entity> with SYSTRAN <entity id="W08-0327.16">rule-based</entity> <entity id="W08-0327.17">translation</entity> <entity id="W08-0327.18">engine</entity> to produce the <entity id="W08-0327.19">parallel corpus</entity>. The <entity id="W08-0327.20">results</entity> are <entity id="W08-0327.21">provided</entity> herein, along with a measure of <entity id="W08-0327.22">error analysis</entity>.
</abstract>


propose(W08-0327.2,W08-0327.3)
study(W08-0327.5,W08-0327.6)
propose(W08-0327.8,W08-0327.10)
methodapplied(W08-0327.18,W08-0327.19)

</text>

<text id="J95-1004"><title>
An <entity id="J95-1004.1">Automatic</entity> <entity id="J95-1004.2">Procedure</entity> For <entity id="J95-1004.3">Topic-</entity><entity id="J95-1004.4">Focus</entity> <entity id="J95-1004.5">Identification</entity></title><abstract>
The dichotomy of <entity id="J95-1004.6">topic</entity> and <entity id="J95-1004.7">focus</entity>, <entity id="J95-1004.8">based</entity>, in the Praguean Functional Generative <entity id="J95-1004.9">Description</entity>, on the <entity id="J95-1004.10">scale</entity> of communicative dynamism, is relevant not only for a possible placement of the <entity id="J95-1004.11">sentence</entity> in a <entity id="J95-1004.12">context</entity>, but also for its <entity id="J95-1004.13">semantic interpretation</entity>. An <entity id="J95-1004.14">automatic</entity> <entity id="J95-1004.15">identification</entity> of <entity id="J95-1004.16">topic</entity> and <entity id="J95-1004.17">focus</entity> may use the <entity id="J95-1004.18">input</entity> <entity id="J95-1004.19">information</entity> on <entity id="J95-1004.20">word</entity> <entity id="J95-1004.21">order</entity>, on the systemic <entity id="J95-1004.22">ordering</entity> of <entity id="J95-1004.23">kinds</entity> of complementations (reflected by the underlying <entity id="J95-1004.24">order</entity> of the <entity id="J95-1004.25">items</entity> <entity id="J95-1004.26">included</entity> in the <entity id="J95-1004.27">focus</entity>), on definiteness, and on <entity id="J95-1004.28">lexical</entity> <entity id="J95-1004.29">semantic properties</entity> of <entity id="J95-1004.30">words</entity>. An <entity id="J95-1004.31">algorithm</entity> for the <entity id="J95-1004.32">analysis</entity> of <entity id="J95-1004.33">English</entity> <entity id="J95-1004.34">sentences</entity> has been <entity id="J95-1004.35">implemented</entity> and is discussed and illustrated on several <entity id="J95-1004.36">examples</entity>.
</abstract>


usedfor(J95-1004.2,J95-1004.5)
model(J95-1004.11,J95-1004.13)
uses_information(J95-1004.15,J95-1004.19)
char(J95-1004.24,J95-1004.25)
char(J95-1004.29,J95-1004.30)
usedfor(J95-1004.31,J95-1004.32)

</text>

<text id="J96-3003"><title>
Efficient Multilingual <entity id="J96-3003.1">Phoneme-</entity>To-Grapheme <entity id="J96-3003.2">Conversion</entity> <entity id="J96-3003.3">Based</entity> On HMM
</title>
<abstract><entity id="J96-3003.4">Grapheme-to-phoneme</entity> <entity id="J96-3003.5">conversion</entity> (GTPC) has been achieved in most European <entity id="J96-3003.6">languages</entity> by <entity id="J96-3003.7">dictionary</entity> look-up or using <entity id="J96-3003.8">rules</entity>. The <entity id="J96-3003.9">application</entity> of these <entity id="J96-3003.10">methods</entity>, however, in the reverse <entity id="J96-3003.11">process</entity>, (i.e., in <entity id="J96-3003.12">phoneme-to-grapheme</entity> <entity id="J96-3003.13">conversion</entity> [PTGC]) creates serious <entity id="J96-3003.14">problems</entity>, especially in inflectionally rich <entity id="J96-3003.15">languages</entity>. In this <entity id="J96-3003.16">paper</entity> the PTGC <entity id="J96-3003.17">problem</entity> is <entity id="J96-3003.18">approached</entity> from a completely different <entity id="J96-3003.19">point of view</entity>. Instead of <entity id="J96-3003.20">rules</entity> or a <entity id="J96-3003.21">dictionary</entity>, the <entity id="J96-3003.22">statistics</entity> of <entity id="J96-3003.23">language</entity> connecting <entity id="J96-3003.24">pronunciation</entity> to <entity id="J96-3003.25">spelling</entity> are exploited. The <entity id="J96-3003.26">novelty</entity> lies in <entity id="J96-3003.27">modeling</entity> the <entity id="J96-3003.28">natural language</entity> intraword <entity id="J96-3003.29">features</entity> using the <entity id="J96-3003.30">theory</entity> of hidden <entity id="J96-3003.31">Markov models</entity> (HMM) and <entity id="J96-3003.32">performing</entity> the <entity id="J96-3003.33">conversion</entity> using the Viterbi <entity id="J96-3003.34">algorithm</entity>. The PTGC <entity id="J96-3003.35">system</entity> has been established and <entity id="J96-3003.36">tested</entity> on various multilingual <entity id="J96-3003.37">corpora</entity>. Initially, the <entity id="J96-3003.38">first-order</entity> HMM and the <entity id="J96-3003.39">common</entity> Viterbi <entity id="J96-3003.40">algorithm</entity> were used to obtain a single <entity id="J96-3003.41">transcription</entity> for each <entity id="J96-3003.42">word</entity>. Afterwards, the <entity id="J96-3003.43">second-order</entity> HMM and the N-best <entity id="J96-3003.44">algorithm</entity> <entity id="J96-3003.45">adapted</entity> to PTGC were <entity id="J96-3003.46">implemented</entity> to <entity id="J96-3003.47">provide</entity> one or more <entity id="J96-3003.48">transcriptions</entity> for each <entity id="J96-3003.49">word</entity> <entity id="J96-3003.50">input</entity> (homophones). This <entity id="J96-3003.51">system</entity> gave an average score of more than 99% correctly transcribed <entity id="J96-3003.52">words</entity> (overall <entity id="J96-3003.53">success</entity> in the first four <entity id="J96-3003.54">candidates</entity>) for most of the seven <entity id="J96-3003.55">languages</entity> it was <entity id="J96-3003.56">tested</entity> on (Dutch, <entity id="J96-3003.57">English</entity>, French, German, <entity id="J96-3003.58">Greek</entity>, Italian, and Spanish). The <entity id="J96-3003.59">system</entity> can be <entity id="J96-3003.60">adapted</entity> to almost any <entity id="J96-3003.61">language</entity> with little <entity id="J96-3003.62">effort</entity> and can be <entity id="J96-3003.63">implemented</entity> in hardware to serve in <entity id="J96-3003.64">real-time</entity> <entity id="J96-3003.65">speech recognition systems</entity>.
</abstract>


taskapplied(J96-3003.5,J96-3003.6)
usedfor(J96-3003.10,J96-3003.11)
problem(J96-3003.14,J96-3003.15)
propose(J96-3003.16,J96-3003.17)
compare(J96-3003.20,J96-3003.22)
model(J96-3003.29,J96-3003.31,REVERSE)
usedfor(J96-3003.33,J96-3003.34,REVERSE)
methodapplied(J96-3003.35,J96-3003.37)
usedfor(J96-3003.40,J96-3003.41)
model(J96-3003.48,J96-3003.50)
yields(J96-3003.51,J96-3003.52)
methodapplied(J96-3003.59,J96-3003.61)

</text>

<text id="P80-1007"><title>
Should <entity id="P80-1007.1">Computers</entity> Write <entity id="P80-1007.2">Spoken Language</entity>?
</title><abstract></abstract>



</text>

<text id="P98-2171"><title>
From <entity id="P98-2171.1">Information Structure</entity> to <entity id="P98-2171.2">Intonation</entity>: A Phonological <entity id="P98-2171.3">Interface</entity> for <entity id="P98-2171.4">Concept-to-</entity><entity id="P98-2171.5">Speech</entity></title><abstract>
The <entity id="P98-2171.6">paper</entity> describes an <entity id="P98-2171.7">interface</entity> between <entity id="P98-2171.8">generator</entity> and synthesizer of the German <entity id="P98-2171.9">language</entity> <entity id="P98-2171.10">concept-to-speech</entity> <entity id="P98-2171.11">system</entity> VieCtoS. It discusses <entity id="P98-2171.12">phenomena</entity> in German <entity id="P98-2171.13">intonation</entity> that depend on the <entity id="P98-2171.14">interaction</entity> between grammatical <entity id="P98-2171.15">dependencies</entity> (<entity id="P98-2171.16">projection</entity> of <entity id="P98-2171.17">information structure</entity> into <entity id="P98-2171.18">syntax</entity>) and prosodie <entity id="P98-2171.19">context</entity> (<entity id="P98-2171.20">performance-related</entity> <entity id="P98-2171.21">modifications</entity> to <entity id="P98-2171.22">intonation</entity> <entity id="P98-2171.23">patterns</entity>). Phonological <entity id="P98-2171.24">processing</entity> in our <entity id="P98-2171.25">system</entity> comprises segmental as well as suprasegmental <entity id="P98-2171.26">dimensions</entity> such as syllabification, <entity id="P98-2171.27">modification</entity> of <entity id="P98-2171.28">word</entity> stress positions, and a symbolic encoding of <entity id="P98-2171.29">intonation</entity>. Phonological <entity id="P98-2171.30">phenomena</entity> often touch upon more than one of these <entity id="P98-2171.31">dimensions</entity>, so that mutual accessibility of the<entity id="P98-2171.32">data</entity> <entity id="P98-2171.33">structures</entity> on each <entity id="P98-2171.34">dimension</entity> had to be ensured. We present a linear <entity id="P98-2171.35">representation</entity> of the multidimensional phonological<entity id="P98-2171.36">data</entity> <entity id="P98-2171.37">based</entity> on a straightforward linearization <entity id="P98-2171.38">convention</entity>, which suffices to bring this conceptually multilinear<entity id="P98-2171.39">data</entity> set under the <entity id="P98-2171.40">scope</entity> of the well-known <entity id="P98-2171.41">processing</entity> <entity id="P98-2171.42">techniques</entity> for <entity id="P98-2171.43">two-level</entity> <entity id="P98-2171.44">morphology</entity>.
</abstract>


propose(P98-2171.6,P98-2171.7)
part_of(P98-2171.8,P98-2171.11)
phenomenon(P98-2171.12,P98-2171.13)
phenomenon(P98-2171.14,P98-2171.15)
phenomenon(P98-2171.21,P98-2171.23)
part_of(P98-2171.24,P98-2171.26,REVERSE)
char(P98-2171.30,P98-2171.31,REVERSE)
model(P98-2171.35,P98-2171.36)
taskapplied(P98-2171.39,P98-2171.44,REVERSE)

</text>

<text id="P98-2175"><title>
An Intelligent Multi-<entity id="P98-2175.1">Dictionary</entity> <entity id="P98-2175.2">Environment</entity></title><abstract>
An open, extendible <entity id="P98-2175.3">multi-dictionary</entity> <entity id="P98-2175.4">system</entity> is introduced in the <entity id="P98-2175.5">paper</entity>. It <entity id="P98-2175.6">supports</entity> the <entity id="P98-2175.7">translator</entity> in <entity id="P98-2175.8">accessing</entity> adequate <entity id="P98-2175.9">entries</entity> of various bi- and monolingual <entity id="P98-2175.10">dictionaries</entity> and <entity id="P98-2175.11">translation</entity> <entity id="P98-2175.12">examples</entity> from <entity id="P98-2175.13">parallel corpora</entity>. Simultaneously an unlimited <entity id="P98-2175.14">number</entity> of <entity id="P98-2175.15">dictionaries</entity> can be held open, thus by a single interrogation <entity id="P98-2175.16">step</entity>, all the <entity id="P98-2175.17">dictionaries</entity> (<entity id="P98-2175.18">translations</entity>, <entity id="P98-2175.19">explanations</entity>, <entity id="P98-2175.20">synonyms</entity>, etc.) can be <entity id="P98-2175.21">surveyed</entity>. The <entity id="P98-2175.22">implemented</entity> <entity id="P98-2175.23">system</entity> (<entity id="P98-2175.24">called</entity> MoBiDic) knows morphological <entity id="P98-2175.25">rules</entity> of the <entity id="P98-2175.26">dictionaries</entity>' <entity id="P98-2175.27">languages</entity>. Thus, never the actual (inflected) <entity id="P98-2175.28">words</entity>, but always their <entity id="P98-2175.29">lemmas</entity> - that is, the right <entity id="P98-2175.30">dictionary</entity> <entity id="P98-2175.31">entries</entity> - are looked up. MoBiDic has an open, multimedial <entity id="P98-2175.32">architecture</entity>, thus it is suitable for handling not only textual, but speaking or picture <entity id="P98-2175.33">dictionaries</entity>, as well. The same <entity id="P98-2175.34">system</entity> is also able to find <entity id="P98-2175.35">words</entity> and <entity id="P98-2175.36">expressions</entity> in <entity id="P98-2175.37">corpora</entity>, dynamically <entity id="P98-2175.38">providing</entity> the <entity id="P98-2175.39">translators</entity> with <entity id="P98-2175.40">examples</entity> from their earlier <entity id="P98-2175.41">translations</entity> or other <entity id="P98-2175.42">translators</entity>' works. MoBiDic has been <entity id="P98-2175.43">designed</entity> for <entity id="P98-2175.44">translator</entity> workgroups, where the <entity id="P98-2175.45">translators</entity>' own glossaries (built also with the <entity id="P98-2175.46">help</entity> of the <entity id="P98-2175.47">system</entity>) may also be disseminated among the members of the group, with different <entity id="P98-2175.48">access</entity> rights, if needed. The <entity id="P98-2175.49">system</entity> has a TCP/IP-based <entity id="P98-2175.50">client-server</entity> <entity id="P98-2175.51">implementation</entity> for various <entity id="P98-2175.52">platforms</entity> and available with a gradually <entity id="P98-2175.53">increasing</entity> <entity id="P98-2175.54">number</entity> of <entity id="P98-2175.55">dictionaries</entity> for numerous <entity id="P98-2175.56">language pairs</entity>.
</abstract>


propose(P98-2175.4,P98-2175.5,REVERSE)
composed_of(P98-2175.9,P98-2175.10,REVERSE)
composed_of(P98-2175.12,P98-2175.13,REVERSE)
based_on(P98-2175.23,P98-2175.25)
model(P98-2175.28,P98-2175.29,REVERSE)
usedfor(P98-2175.32,P98-2175.33)
phenomenon(P98-2175.36,P98-2175.37)
datasource(P98-2175.40,P98-2175.41,REVERSE)
part_of(P98-2175.49,P98-2175.51,REVERSE)

</text>

<text id="I08-1001"><title>
A Lemmatization <entity id="I08-1001.1">Method</entity> for Modern Mongolian and its <entity id="I08-1001.2">Application</entity> to <entity id="I08-1001.3">Information Retrieval</entity></title><abstract>
In Modern Mongolian, a <entity id="I08-1001.4">content word</entity> can be inflected when concatenated with <entity id="I08-1001.5">suffixes</entity>. <entity id="I08-1001.6">Identifying</entity> the original <entity id="I08-1001.7">forms</entity> of <entity id="I08-1001.8">content words</entity> is crucial for <entity id="I08-1001.9">natural language processing</entity> and <entity id="I08-1001.10">information retrieval</entity>. We <entity id="I08-1001.11">propose</entity> a lemmatization <entity id="I08-1001.12">method</entity> for Modern Mongolian and <entity id="I08-1001.13">apply</entity> our <entity id="I08-1001.14">method</entity> to <entity id="I08-1001.15">indexing</entity> for <entity id="I08-1001.16">information retrieval</entity>. We use technical <entity id="I08-1001.17">abstracts</entity> to show the <entity id="I08-1001.18">effectiveness</entity> of our <entity id="I08-1001.19">method</entity> experimentally.
</abstract>


usedfor(I08-1001.1,I08-1001.3)
char(I08-1001.7,I08-1001.8)
usedfor(I08-1001.14,I08-1001.15)
methodapplied(I08-1001.17,I08-1001.19,REVERSE)

</text>

<text id="W04-2003"><title>
A <entity id="W04-2003.1">Robust</entity> And Hybrid Deep-<entity id="W04-2003.2">Linguistic Theory</entity> <entity id="W04-2003.3">Applied</entity> To Large-<entity id="W04-2003.4">Scale</entity> <entity id="W04-2003.5">Parsing</entity></title><abstract>
Modern <entity id="W04-2003.6">statistical</entity> <entity id="W04-2003.7">parsers</entity> are <entity id="W04-2003.8">robust</entity> and quite fast, but their <entity id="W04-2003.9">output</entity> is relatively shallow when compared to formal grammar <entity id="W04-2003.10">parsers</entity>. We suggest to extend <entity id="W04-2003.11">statistical</entity> <entity id="W04-2003.12">approaches</entity> to a more <entity id="W04-2003.13">deep-linguistic analysis</entity> while at the same <entity id="W04-2003.14">time</entity> keeping the <entity id="W04-2003.15">speed</entity> and low <entity id="W04-2003.16">complexity</entity> of a <entity id="W04-2003.17">statistical</entity> <entity id="W04-2003.18">parser</entity>. The <entity id="W04-2003.19">resulting</entity> <entity id="W04-2003.20">parsing</entity> <entity id="W04-2003.21">architecture</entity> suggested, <entity id="W04-2003.22">implemented</entity> and <entity id="W04-2003.23">evaluated</entity> here is highly robust and hybrid on a number of <entity id="W04-2003.24">levels</entity>, combining <entity id="W04-2003.25">statistical</entity> and <entity id="W04-2003.26">rule-based approaches</entity>, <entity id="W04-2003.27">constituency</entity> and <entity id="W04-2003.28">dependency grammar</entity>, shallow and deep <entity id="W04-2003.29">processing</entity>, full and near-full <entity id="W04-2003.30">parsing</entity>. With its <entity id="W04-2003.31">parsing</entity> <entity id="W04-2003.32">speed</entity> of about 300,000 <entity id="W04-2003.33">words</entity> per hour and state-of-the-art <entity id="W04-2003.34">performance</entity> the <entity id="W04-2003.35">parser</entity> is reliable for a <entity id="W04-2003.36">number</entity> of <entity id="W04-2003.37">large-scale</entity> <entity id="W04-2003.38">applications</entity> discussed in the article.
</abstract>


usedfor(W04-2003.2,W04-2003.5)
compare(W04-2003.7,W04-2003.10)
char(W04-2003.16,W04-2003.18)
usedfor(W04-2003.35,W04-2003.38)

</text>

<text id="W04-2306"><title>
Semi-<entity id="W04-2306.1">Automatic</entity> <entity id="W04-2306.2">Generation</entity> Of <entity id="W04-2306.3">Dialogue</entity> <entity id="W04-2306.4">Applications</entity> In The GEMINI <entity id="W04-2306.5">Project</entity></title><abstract>
GEMINI (Generic <entity id="W04-2306.6">Environment</entity> for Multilingual Interactive <entity id="W04-2306.7">Natural</entity> Interfaces) is an EC funded <entity id="W04-2306.8">research project</entity>, which has two <entity id="W04-2306.9">main</entity> <entity id="W04-2306.10">objectives</entity>: First, the <entity id="W04-2306.11">development</entity> of a flexible <entity id="W04-2306.12">platform</entity> able to produce <entity id="W04-2306.13">user-friendly</entity> interactive multilingual and multi-modal <entity id="W04-2306.14">dialogue</entity> <entity id="W04-2306.15">interfaces</entity> to <entity id="W04-2306.16">databases</entity> with a <entity id="W04-2306.17">minimum</entity> of human <entity id="W04-2306.18">effort</entity>, and, second, the <entity id="W04-2306.19">demonstration</entity> of the <entity id="W04-2306.20">platform</entity>'s <entity id="W04-2306.21">efficiency</entity> through the <entity id="W04-2306.22">development</entity> of two different <entity id="W04-2306.23">applications</entity> <entity id="W04-2306.24">based</entity> on this <entity id="W04-2306.25">platform</entity>: EG-Banking, a voice-portal for <entity id="W04-2306.26">high-quality</entity> <entity id="W04-2306.27">interactions</entity> for <entity id="W04-2306.28">bank</entity> <entity id="W04-2306.29">customers</entity>, and CitizenCare, an e-government <entity id="W04-2306.30">platform</entity> <entity id="W04-2306.31">framework</entity> for citizen-to-administration <entity id="W04-2306.32">interaction</entity> which are available for spoken and web-based <entity id="W04-2306.33">user</entity> <entity id="W04-2306.34">interaction</entity>.
</abstract>


propose(W04-2306.8,W04-2306.11)
usedfor(W04-2306.12,W04-2306.14)
part_of(W04-2306.15,W04-2306.16)
char(W04-2306.20,W04-2306.21,REVERSE)
based_on(W04-2306.23,W04-2306.25)
usedfor(W04-2306.31,W04-2306.32)

</text>

<text id="W04-2501"><title><entity id="W04-2501.1">Strategies</entity> For Advanced <entity id="W04-2501.2">Question Answering</entity></title>
<abstract><entity id="W04-2501.3">Progress</entity> in <entity id="W04-2501.4">Question Answering</entity> can be achieved by (1) combining multiple <entity id="W04-2501.5">strategies</entity> that optimally resolve different <entity id="W04-2501.6">question</entity> <entity id="W04-2501.7">classes</entity> of various <entity id="W04-2501.8">degrees</entity> of <entity id="W04-2501.9">complexity</entity>; (2) enhancing the <entity id="W04-2501.10">precision</entity> of <entity id="W04-2501.11">question</entity> <entity id="W04-2501.12">interpretation</entity> and answer <entity id="W04-2501.13">extraction</entity>; and (3) <entity id="W04-2501.14">question</entity> <entity id="W04-2501.15">decomposition</entity> and answer <entity id="W04-2501.16">fusion</entity>. In this <entity id="W04-2501.17">paper</entity> we also present the <entity id="W04-2501.18">impact</entity> of <entity id="W04-2501.19">modeling</entity> the <entity id="W04-2501.20">user</entity> <entity id="W04-2501.21">background</entity> on Q/A and discuss the pragmatics pf <entity id="W04-2501.22">processing</entity> <entity id="W04-2501.23">negation</entity> in Q/A.
</abstract>


usedfor(W04-2501.1,W04-2501.2)
usedfor(W04-2501.4,W04-2501.5,REVERSE)
char(W04-2501.7,W04-2501.9,REVERSE)
char(W04-2501.10,W04-2501.12)
propose(W04-2501.17,W04-2501.18)

</text>

<text id="W05-0617"><title><entity id="W05-0617.1">Morphology</entity> <entity id="W05-0617.2">Induction</entity> From <entity id="W05-0617.3">Term</entity> Clusters
</title><abstract>
We address the <entity id="W05-0617.4">problem</entity> of learning a morphological automaton directly from a monolingual <entity id="W05-0617.5">text</entity> <entity id="W05-0617.6">corpus</entity> without recourse to additional <entity id="W05-0617.7">resources</entity>. Like previous work in this <entity id="W05-0617.8">area</entity>, our <entity id="W05-0617.9">approach</entity> exploits orthographic <entity id="W05-0617.10">regularities</entity> in a <entity id="W05-0617.11">search</entity> for possible morphological segmentation points. Instead of affixes, however, we <entity id="W05-0617.12">search</entity> for affix <entity id="W05-0617.13">transformation</entity> <entity id="W05-0617.14">rules</entity> that express <entity id="W05-0617.15">correspondences</entity> between <entity id="W05-0617.16">term</entity> <entity id="W05-0617.17">clusters</entity> induced from the<entity id="W05-0617.18">data</entity>. This <entity id="W05-0617.19">focuses</entity> the <entity id="W05-0617.20">system</entity> on substrings having <entity id="W05-0617.21">syntactic function</entity>, and <entity id="W05-0617.22">yields</entity> <entity id="W05-0617.23">cluster-to-cluster</entity> <entity id="W05-0617.24">transformation</entity> <entity id="W05-0617.25">rules</entity> which enable the <entity id="W05-0617.26">system</entity> to <entity id="W05-0617.27">process</entity> unknown morphological <entity id="W05-0617.28">forms</entity> of known <entity id="W05-0617.29">words</entity> accurately. A <entity id="W05-0617.30">stem-weighting</entity> <entity id="W05-0617.31">algorithm</entity> <entity id="W05-0617.32">based</entity> on Hubs and Authorities is used to clarify ambiguous segmentation points. We <entity id="W05-0617.33">evaluate</entity> our <entity id="W05-0617.34">approach</entity> using the CELEX <entity id="W05-0617.35">database</entity>.
</abstract>


uses_information(W05-0617.9,W05-0617.10)
model(W05-0617.14,W05-0617.15)
datasource(W05-0617.17,W05-0617.18)
methodapplied(W05-0617.26,W05-0617.28)
methodapplied(W05-0617.34,W05-0617.35)

</text>

<text id="W05-0802"><title><entity id="W05-0802.1">Cross</entity> <entity id="W05-0802.2">Language</entity> <entity id="W05-0802.3">Text Categorization</entity> By Acquiring Multilingual <entity id="W05-0802.4">Domain</entity> <entity id="W05-0802.5">Models</entity> From Comparable <entity id="W05-0802.6">Corpora</entity></title><abstract>
In a multilingual <entity id="W05-0802.7">scenario</entity>, the classical monolingual <entity id="W05-0802.8">text categorization</entity> <entity id="W05-0802.9">problem</entity> can be reformulated as a <entity id="W05-0802.10">cross</entity> <entity id="W05-0802.11">language</entity> TC <entity id="W05-0802.12">English</entity> Italian). <entity id="W05-0802.13">English</entity>), Italian).
</abstract>


based_on(W05-0802.3,W05-0802.5)

</text>

<text id="W05-1514"><title><entity id="W05-1514.1">Chunk</entity> <entity id="W05-1514.2">Parsing</entity> Revisited
</title><abstract><entity id="W05-1514.3">Chunk</entity> <entity id="W05-1514.4">parsing</entity> is conceptually appealing but its <entity id="W05-1514.5">performance</entity> has not been satisfactory for practical use. In this <entity id="W05-1514.6">paper</entity> we show that <entity id="W05-1514.7">chunk</entity> <entity id="W05-1514.8">parsing</entity> can <entity id="W05-1514.9">perform</entity> significantly better than previously <entity id="W05-1514.10">reported</entity> by using a <entity id="W05-1514.11">simple</entity> <entity id="W05-1514.12">sliding-window</entity> <entity id="W05-1514.13">method</entity> and <entity id="W05-1514.14">maximum entropy</entity> <entity id="W05-1514.15">classifiers</entity> for <entity id="W05-1514.16">phrase</entity> <entity id="W05-1514.17">recognition</entity> in each <entity id="W05-1514.18">level</entity> of <entity id="W05-1514.19">chunking</entity>. <entity id="W05-1514.20">Experimental</entity> <entity id="W05-1514.21">results</entity> with the <entity id="W05-1514.22">Penn Treebank</entity> <entity id="W05-1514.23">corpus</entity> show that our <entity id="W05-1514.24">chunk</entity> <entity id="W05-1514.25">parser</entity> can give <entity id="W05-1514.26">high-precision</entity> <entity id="W05-1514.27">parsing</entity> <entity id="W05-1514.28">outputs</entity> with very high <entity id="W05-1514.29">speed</entity> (14 msec/<entity id="W05-1514.30">sentence</entity>). We also present a <entity id="W05-1514.31">parsing</entity> <entity id="W05-1514.32">method</entity> for <entity id="W05-1514.33">searching</entity> the best <entity id="W05-1514.34">parse</entity> by considering the <entity id="W05-1514.35">probabilities</entity> <entity id="W05-1514.36">output</entity> by the <entity id="W05-1514.37">maximum entropy</entity> <entity id="W05-1514.38">classifiers</entity>, and show that the <entity id="W05-1514.39">search</entity> <entity id="W05-1514.40">method</entity> can further <entity id="W05-1514.41">improve</entity> the <entity id="W05-1514.42">parsing</entity> <entity id="W05-1514.43">accuracy</entity>.
</abstract>


usedfor(W05-1514.8,W05-1514.13,REVERSE)
usedfor(W05-1514.15,W05-1514.17)
yields(W05-1514.25,W05-1514.28)
usedfor(W05-1514.32,W05-1514.33)
yields(W05-1514.40,W05-1514.43)

</text>

<text id="W06-0205"><title><entity id="W06-0205.1">Automatic</entity> <entity id="W06-0205.2">Knowledge Representation</entity> Using A Graph-<entity id="W06-0205.3">Based</entity> <entity id="W06-0205.4">Algorithm</entity> For <entity id="W06-0205.5">Language-</entity>Independent <entity id="W06-0205.6">Lexical</entity> Chaining
</title><abstract><entity id="W06-0205.7">Lexical Chains</entity> are powerful <entity id="W06-0205.8">representations</entity> of <entity id="W06-0205.9">documents</entity>. In particular, they have successfully been used in the <entity id="W06-0205.10">field</entity> of <entity id="W06-0205.11">Automatic</entity> <entity id="W06-0205.12">Text Summarization</entity>. However, until now, <entity id="W06-0205.13">Lexical</entity> Chaining <entity id="W06-0205.14">algorithms</entity> have only been <entity id="W06-0205.15">proposed</entity> for <entity id="W06-0205.16">English</entity>. In this <entity id="W06-0205.17">paper</entity>, we <entity id="W06-0205.18">propose</entity> a greedy <entity id="W06-0205.19">Language-</entity>Independent <entity id="W06-0205.20">algorithm</entity> that automatically <entity id="W06-0205.21">extracts</entity> <entity id="W06-0205.22">Lexical Chains</entity> from <entity id="W06-0205.23">texts</entity>. For that <entity id="W06-0205.24">purpose</entity>, we build a hierarchical <entity id="W06-0205.25">lexico-semantic knowledge</entity> <entity id="W06-0205.26">base</entity> from a <entity id="W06-0205.27">collection</entity> of <entity id="W06-0205.28">texts</entity> by using the Pole-<entity id="W06-0205.29">Based</entity> Overlapping <entity id="W06-0205.30">Clustering Algorithm</entity>. As a consequence, our <entity id="W06-0205.31">methodology</entity> can be <entity id="W06-0205.32">applied</entity> to any <entity id="W06-0205.33">language</entity> and <entity id="W06-0205.34">proposes</entity> a <entity id="W06-0205.35">solution</entity> to <entity id="W06-0205.36">language-dependent</entity> <entity id="W06-0205.37">Lexical</entity> Chainers.
</abstract>


usedfor(W06-0205.2,W06-0205.4,REVERSE)
model(W06-0205.7,W06-0205.9)
methodapplied(W06-0205.14,W06-0205.16)
propose(W06-0205.17,W06-0205.20)
datasource(W06-0205.22,W06-0205.23)
datasource(W06-0205.26,W06-0205.28)
methodapplied(W06-0205.31,W06-0205.33)

</text>

<text id="W06-1002"><title>
The <entity id="W06-1002.1">Role</entity> Of <entity id="W06-1002.2">Lexical</entity> Resources In CJK <entity id="W06-1002.3">Natural Language</entity> <entity id="W06-1002.4">Processing</entity></title><abstract>
The <entity id="W06-1002.5">role</entity> of <entity id="W06-1002.6">lexical resources</entity> is often understated in NLP <entity id="W06-1002.7">research</entity>. The <entity id="W06-1002.8">complexity</entity> of <entity id="W06-1002.9">Chinese</entity>, <entity id="W06-1002.10">Japanese</entity> and Korean (CJK) poses special <entity id="W06-1002.11">challenges</entity> to <entity id="W06-1002.12">developers</entity> of NLP <entity id="W06-1002.13">tools</entity>, especially in the <entity id="W06-1002.14">area</entity> of <entity id="W06-1002.15">word segmentation</entity> (WS), <entity id="W06-1002.16">information retrieval</entity> (IR), <entity id="W06-1002.17">named</entity> <entity id="W06-1002.18">entity</entity> <entity id="W06-1002.19">extraction</entity> (NER), and <entity id="W06-1002.20">machine translation</entity> (MT). These <entity id="W06-1002.21">difficulties</entity> are exacerbated by the <entity id="W06-1002.22">lack</entity> of comprehensive <entity id="W06-1002.23">lexical resources</entity>, especially for proper <entity id="W06-1002.24">nouns</entity>, and the <entity id="W06-1002.25">lack</entity> of a standardized orthography, especially in <entity id="W06-1002.26">Japanese</entity>. This <entity id="W06-1002.27">paper</entity> summarizes some of the major linguistic <entity id="W06-1002.28">issues</entity> in the <entity id="W06-1002.29">development</entity> <entity id="W06-1002.30">NLP applications</entity> that are dependent on <entity id="W06-1002.31">lexical resources</entity>, and discusses the central <entity id="W06-1002.32">role</entity> such <entity id="W06-1002.33">resources</entity> should play in enhancing the <entity id="W06-1002.34">accuracy</entity> of NLP <entity id="W06-1002.35">tools</entity>.
</abstract>


study(W06-1002.6,W06-1002.7,REVERSE)
problem(W06-1002.8,W06-1002.9)
problem(W06-1002.11,W06-1002.13)
problem(W06-1002.25,W06-1002.26)
propose(W06-1002.27,W06-1002.28)
uses_information(W06-1002.30,W06-1002.31)
affects(W06-1002.33,W06-1002.34)

</text>

<text id="W06-1006"><title>
Multilingual <entity id="W06-1006.1">Collocation</entity> <entity id="W06-1006.2">Extraction</entity>: <entity id="W06-1006.3">Issues</entity> And Solutions
</title><abstract>
Although traditionally seen as a <entity id="W06-1006.4">language-independent</entity> <entity id="W06-1006.5">task</entity>, <entity id="W06-1006.6">collocation</entity> <entity id="W06-1006.7">extraction</entity> relies nowadays more and more on the linguistic preprocessing of <entity id="W06-1006.8">texts</entity> (e.g., lemmatization, <entity id="W06-1006.9">POS tagging</entity>, <entity id="W06-1006.10">chunking</entity> or <entity id="W06-1006.11">parsing</entity>) prior to the <entity id="W06-1006.12">application</entity> of <entity id="W06-1006.13">statistical</entity> measures. This <entity id="W06-1006.14">paper</entity> <entity id="W06-1006.15">provides</entity> a <entity id="W06-1006.16">language-oriented</entity> <entity id="W06-1006.17">review</entity> of the existing <entity id="W06-1006.18">extraction</entity> work. It points out several <entity id="W06-1006.19">language-specific</entity> <entity id="W06-1006.20">issues</entity> related to <entity id="W06-1006.21">extraction</entity> and <entity id="W06-1006.22">proposes</entity> a <entity id="W06-1006.23">strategy</entity> for coping with them. It then describes a hybrid <entity id="W06-1006.24">extraction system</entity> <entity id="W06-1006.25">based</entity> on a multilingual <entity id="W06-1006.26">parser</entity>. Finally, it presents a <entity id="W06-1006.27">case-study</entity> on the <entity id="W06-1006.28">performance</entity> of an <entity id="W06-1006.29">association</entity> measure across a <entity id="W06-1006.30">number</entity> of <entity id="W06-1006.31">languages</entity>.
</abstract>


usedfor(W06-1006.7,W06-1006.9,REVERSE)
propose(W06-1006.14,W06-1006.17)
problem(W06-1006.20,W06-1006.21)
based_on(W06-1006.24,W06-1006.26)
study(W06-1006.27,W06-1006.28)

</text>

<text id="W06-1303"><title><entity id="W06-1303.1">Building</entity> Effective <entity id="W06-1303.2">Question Answering</entity> Characters
</title><abstract>
In this <entity id="W06-1303.3">paper</entity>, we describe <entity id="W06-1303.4">methods</entity> for <entity id="W06-1303.5">building</entity> and <entity id="W06-1303.6">evaluation</entity> of limited <entity id="W06-1303.7">domain</entity> <entity id="W06-1303.8">question-answering</entity> characters. Several <entity id="W06-1303.9">classification</entity> <entity id="W06-1303.10">techniques</entity> are <entity id="W06-1303.11">tested</entity>, <entity id="W06-1303.12">including</entity> <entity id="W06-1303.13">text classification</entity> using <entity id="W06-1303.14">support vector machines</entity>, <entity id="W06-1303.15">language-model</entity> <entity id="W06-1303.16">based</entity> <entity id="W06-1303.17">retrieval</entity>, and <entity id="W06-1303.18">cross-language</entity> <entity id="W06-1303.19">information retrieval</entity> <entity id="W06-1303.20">techniques</entity>, with the latter having the highest <entity id="W06-1303.21">success</entity> <entity id="W06-1303.22">rate</entity>. We also <entity id="W06-1303.23">evaluated</entity> the <entity id="W06-1303.24">effect</entity> of <entity id="W06-1303.25">speech recognition</entity> <entity id="W06-1303.26">errors</entity> on <entity id="W06-1303.27">performance</entity> with <entity id="W06-1303.28">users</entity>, finding that <entity id="W06-1303.29">retrieval</entity> is <entity id="W06-1303.30">robust</entity> until <entity id="W06-1303.31">recognition</entity> <entity id="W06-1303.32">reaches</entity> over 50% WER.
</abstract>


propose(W06-1303.3,W06-1303.4)
usedfor(W06-1303.13,W06-1303.14,REVERSE)
yields(W06-1303.20,W06-1303.22)
affects(W06-1303.26,W06-1303.27)

</text>

<text id="I08-2123"><title>
A <entity id="I08-2123.1">Co-occurrence</entity> <entity id="I08-2123.2">Graph-based Approach</entity> for Personal <entity id="I08-2123.3">Name</entity> <entity id="I08-2123.4">Alias</entity> <entity id="I08-2123.5">Extraction</entity> from Anchor <entity id="I08-2123.6">Texts</entity></title><abstract>
A person may have multiple <entity id="I08-2123.7">name</entity> <entity id="I08-2123.8">aliases</entity> on the Web. <entity id="I08-2123.9">Identifying</entity> <entity id="I08-2123.10">aliases</entity> of a <entity id="I08-2123.11">name</entity> is important for various <entity id="I08-2123.12">tasks</entity> such as <entity id="I08-2123.13">information retrieval</entity>, <entity id="I08-2123.14">sentiment analysis</entity> and <entity id="I08-2123.15">name</entity> <entity id="I08-2123.16">disambiguation</entity>. We introduce the <entity id="I08-2123.17">notion</entity> of a <entity id="I08-2123.18">word</entity> <entity id="I08-2123.19">co-occurrence</entity> graph to represent the mutual <entity id="I08-2123.20">relations</entity> between <entity id="I08-2123.21">words</entity> that appear in <entity id="I08-2123.22">anchor texts</entity>. <entity id="I08-2123.23">Words</entity> in <entity id="I08-2123.24">anchor texts</entity> are represented as <entity id="I08-2123.25">nodes</entity> in the <entity id="I08-2123.26">co-occurrence</entity> graph and an <entity id="I08-2123.27">edge</entity> is <entity id="I08-2123.28">formed</entity> between <entity id="I08-2123.29">nodes</entity> which <entity id="I08-2123.30">link</entity> to the same url. For a given personal <entity id="I08-2123.31">name</entity>, its <entity id="I08-2123.32">neighboring</entity> <entity id="I08-2123.33">nodes</entity> in the graph are considered as <entity id="I08-2123.34">candidates</entity> of its <entity id="I08-2123.35">aliases</entity>. We formalize <entity id="I08-2123.36">alias</entity> <entity id="I08-2123.37">identification</entity> as a <entity id="I08-2123.38">problem</entity> of ranking <entity id="I08-2123.39">nodes</entity> in this graph with <entity id="I08-2123.40">respect</entity> to a given <entity id="I08-2123.41">name</entity>. We integrate various ranking scores through <entity id="I08-2123.42">support vector machines</entity> to <entity id="I08-2123.43">leverage</entity> a <entity id="I08-2123.44">robust</entity> ranking <entity id="I08-2123.45">function</entity> and use it to <entity id="I08-2123.46">extract</entity> <entity id="I08-2123.47">aliases</entity> for a given <entity id="I08-2123.48">name</entity>. <entity id="I08-2123.49">Experimental</entity> <entity id="I08-2123.50">results</entity> on a dataset of <entity id="I08-2123.51">Japanese</entity> celebrities show that the <entity id="I08-2123.52">proposed</entity> <entity id="I08-2123.53">method</entity> outperforms all baselines, <entity id="I08-2123.54">displaying</entity> a MRR score of 0.562.
</abstract>


usedfor(I08-2123.2,I08-2123.5)
phenomenon(I08-2123.20,I08-2123.22)
model(I08-2123.23,I08-2123.25,REVERSE)
model(I08-2123.33,I08-2123.35)
usedfor(I08-2123.42,I08-2123.45)

</text>

<text id="W06-2801"><title><entity id="W06-2801.1">Text</entity> Linkage In The Wiki Medium - A Comparative <entity id="W06-2801.2">Study</entity></title><abstract>
We analyze four different <entity id="W06-2801.3">types</entity> of <entity id="W06-2801.4">document</entity> <entity id="W06-2801.5">networks</entity> with <entity id="W06-2801.6">respect</entity> to their small world <entity id="W06-2801.7">characteristics</entity>. These <entity id="W06-2801.8">characteristics</entity> allow distinguishing <entity id="W06-2801.9">wiki-based systems</entity> from <entity id="W06-2801.10">citation</entity> and more traditional <entity id="W06-2801.11">text-based</entity> <entity id="W06-2801.12">networks</entity> augmented by hyperlinks. The <entity id="W06-2801.13">study</entity> <entity id="W06-2801.14">provides</entity> <entity id="W06-2801.15">evidence</entity> that a more appropriate <entity id="W06-2801.16">network</entity> <entity id="W06-2801.17">model</entity> is needed which better reflects the specifics of wiki <entity id="W06-2801.18">systems</entity>. It puts emphasize on their topological <entity id="W06-2801.19">differences</entity> as a <entity id="W06-2801.20">result</entity> of <entity id="W06-2801.21">wiki-related</entity> <entity id="W06-2801.22">linking</entity> compared to other <entity id="W06-2801.23">text-based</entity> <entity id="W06-2801.24">networks</entity>.
</abstract>


char(W06-2801.5,W06-2801.7,REVERSE)
compare(W06-2801.9,W06-2801.12)
propose(W06-2801.13,W06-2801.15)
compare(W06-2801.22,W06-2801.24)

</text>

<text id="W06-2802"><title>
Errors In Wikis
</title><abstract>
This <entity id="W06-2802.1">discussion</entity> <entity id="W06-2802.2">document</entity> <entity id="W06-2802.3">concerns</entity> the <entity id="W06-2802.4">challenges</entity> to <entity id="W06-2802.5">assessments</entity> of <entity id="W06-2802.6">reliability</entity> posed by wikis and the potential for <entity id="W06-2802.7">language processing</entity> <entity id="W06-2802.8">techniques</entity> for aiding readers to decide whether to trust particular <entity id="W06-2802.9">text</entity>.
</abstract>


study(W06-2802.2,W06-2802.4)

</text>

<text id="W06-3115"><title>
NTT <entity id="W06-3115.1">System</entity> <entity id="W06-3115.2">Description</entity> For The WMT2006 <entity id="W06-3115.3">Shared Task</entity></title><abstract>
"We present two <entity id="W06-3115.4">translation systems</entity> <entity id="W06-3115.5">experimented</entity> for the <entity id="W06-3115.6">shared-task</entity> of ""<entity id="W06-3115.7">Workshop</entity> on <entity id="W06-3115.8">Statistical Machine Translation</entity>,"" a <entity id="W06-3115.9">phrase-based model</entity> and a hierarchical <entity id="W06-3115.10">phrase-based model</entity>. The former uses a phrasal <entity id="W06-3115.11">unit</entity> for <entity id="W06-3115.12">translation</entity>, whereas the latter is conceptualized as a synchronous-CFG in which <entity id="W06-3115.13">phrases</entity> are hierarchically combined using non-terminals. <entity id="W06-3115.14">Experiments</entity> showed that the hierarchical <entity id="W06-3115.15">phrase-based model</entity> <entity id="W06-3115.16">performed</entity> very comparable to the <entity id="W06-3115.17">phrase-based model</entity>. We also <entity id="W06-3115.18">report</entity> a <entity id="W06-3115.19">phrase</entity>/<entity id="W06-3115.20">rule</entity> <entity id="W06-3115.21">extraction</entity> <entity id="W06-3115.22">technique</entity> differentiating tokenization of <entity id="W06-3115.23">corpora</entity>. "
</abstract>


methodapplied(W06-3115.1,W06-3115.3)
methodapplied(W06-3115.4,W06-3115.6)
usedfor(W06-3115.11,W06-3115.12)
compare(W06-3115.15,W06-3115.17)
methodapplied(W06-3115.22,W06-3115.23)

</text>

<text id="W06-1710"><title>
Web <entity id="W06-1710.1">Corpus</entity> Mining By <entity id="W06-1710.2">Instance</entity> Of Wikipedia
</title><abstract>
In this <entity id="W06-1710.3">paper</entity> we present an <entity id="W06-1710.4">approach</entity> to <entity id="W06-1710.5">structure</entity> learning in the <entity id="W06-1710.6">area</entity> of <entity id="W06-1710.7">web documents</entity>. This is done in <entity id="W06-1710.8">order</entity> to <entity id="W06-1710.9">approach</entity> the <entity id="W06-1710.10">goal</entity> of webgenre <entity id="W06-1710.11">tagging</entity> in the <entity id="W06-1710.12">area</entity> of web <entity id="W06-1710.13">corpus</entity> <entity id="W06-1710.14">linguistics</entity>. A central <entity id="W06-1710.15">outcome</entity> of the <entity id="W06-1710.16">paper</entity> is that purely <entity id="W06-1710.17">structure</entity> oriented <entity id="W06-1710.18">approaches</entity> to <entity id="W06-1710.19">web document</entity> <entity id="W06-1710.20">classification</entity> <entity id="W06-1710.21">provide</entity> an <entity id="W06-1710.22">information gain</entity> which may be utilized in combined <entity id="W06-1710.23">approaches</entity> of web <entity id="W06-1710.24">content</entity> and <entity id="W06-1710.25">structure</entity> <entity id="W06-1710.26">analysis</entity>.
</abstract>


propose(W06-1710.3,W06-1710.4)
model(W06-1710.5,W06-1710.7)
yields(W06-1710.18,W06-1710.22)
usedfor(W06-1710.23,W06-1710.26)

</text>

<text id="W06-1906"><title>
BRUJA: <entity id="W06-1906.1">Question</entity> <entity id="W06-1906.2">Classification</entity> For Spanish Using <entity id="W06-1906.3">Machine</entity> Translation and An <entity id="W06-1906.4">English</entity> <entity id="W06-1906.5">Classifier</entity></title>
<abstract><entity id="W06-1906.6">Question</entity> <entity id="W06-1906.7">Classification</entity> is an important <entity id="W06-1906.8">task</entity> in <entity id="W06-1906.9">Question Answering</entity> <entity id="W06-1906.10">Systems</entity>. This <entity id="W06-1906.11">paper</entity> presents a Spanish <entity id="W06-1906.12">Question</entity> <entity id="W06-1906.13">Classifier</entity> <entity id="W06-1906.14">based</entity> on <entity id="W06-1906.15">machine learning</entity>, <entity id="W06-1906.16">automatic</entity> online <entity id="W06-1906.17">translators</entity> and different <entity id="W06-1906.18">language</entity> <entity id="W06-1906.19">features</entity>. Our <entity id="W06-1906.20">system</entity> works with <entity id="W06-1906.21">English</entity> <entity id="W06-1906.22">collections</entity> and bilingual <entity id="W06-1906.23">questions</entity> (<entity id="W06-1906.24">English</entity>/Spanish). We have <entity id="W06-1906.25">tested</entity> two Spanish-<entity id="W06-1906.26">English</entity> online <entity id="W06-1906.27">translators</entity> to identify the lost of <entity id="W06-1906.28">precision</entity>. We have made <entity id="W06-1906.29">experiments</entity> using <entity id="W06-1906.30">lexical</entity>, <entity id="W06-1906.31">syntactic</entity> and <entity id="W06-1906.32">semantic features</entity> to <entity id="W06-1906.33">test</entity> which ones made a better <entity id="W06-1906.34">performance</entity>. The obtained <entity id="W06-1906.35">results</entity> show that our <entity id="W06-1906.36">system</entity> makes good <entity id="W06-1906.37">classifications</entity>, over a 80% in <entity id="W06-1906.38">terms</entity> of <entity id="W06-1906.39">accuracy</entity> using the original <entity id="W06-1906.40">English</entity> <entity id="W06-1906.41">questions</entity> and over a 65% using Spanish <entity id="W06-1906.42">questions</entity> and <entity id="W06-1906.43">machine translation systems</entity>. Our <entity id="W06-1906.44">conclusion</entity> about the <entity id="W06-1906.45">features</entity> is that a <entity id="W06-1906.46">lexical</entity>, <entity id="W06-1906.47">syntactic</entity> and <entity id="W06-1906.48">semantic features</entity> <entity id="W06-1906.49">combination</entity> obtains the best <entity id="W06-1906.50">result</entity>.
</abstract>


usedfor(W06-1906.2,W06-1906.5,REVERSE)
part_of(W06-1906.7,W06-1906.10)
based_on(W06-1906.13,W06-1906.15)
methodapplied(W06-1906.20,W06-1906.22)
yields(W06-1906.32,W06-1906.34)
yields(W06-1906.36,W06-1906.37)
yields(W06-1906.49,W06-1906.50)

</text>

<text id="I08-4033"><title>
Achilles: NiCT/ATR <entity id="I08-4033.1">Chinese</entity> Morphological <entity id="I08-4033.2">Analyzer</entity> for the Fourth Sighan Bakeoff
</title><abstract>
We created a new <entity id="I08-4033.3">Chinese</entity> morphological <entity id="I08-4033.4">analyzer</entity>, Achilles , by integrating <entity id="I08-4033.5">rule-based</entity>, <entity id="I08-4033.6">dictionary-based</entity>, and <entity id="I08-4033.7">statistical</entity> <entity id="I08-4033.8">machine</entity> learning <entity id="I08-4033.9">method</entity>, <entity id="I08-4033.10">conditional random fields</entity> (CRF). The <entity id="I08-4033.11">rule-based method</entity> is used to recognize regular <entity id="I08-4033.12">expressions</entity>: <entity id="I08-4033.13">numbers</entity>, <entity id="I08-4033.14">time</entity> and alphabets. The <entity id="I08-4033.15">dictionary-based method</entity> is used to find <entity id="I08-4033.16">in-vocabulary</entity> (IV) <entity id="I08-4033.17">words</entity> while <entity id="I08-4033.18">out-of-vocabulary</entity> (OOV) <entity id="I08-4033.19">words</entity> are detected by the CRFs. At last, <entity id="I08-4033.20">confidence</entity> measure <entity id="I08-4033.21">based</entity> <entity id="I08-4033.22">approach</entity> is used to weigh all the <entity id="I08-4033.23">results</entity> and <entity id="I08-4033.24">output</entity> the best ones. Achilles was used and <entity id="I08-4033.25">evaluated</entity> in the bakeoff. We participated the closed tracks of <entity id="I08-4033.26">word segmentation</entity> and <entity id="I08-4033.27">part-of-speech</entity> <entity id="I08-4033.28">tagging</entity> for all the <entity id="I08-4033.29">provided</entity> <entity id="I08-4033.30">corpus</entity>. In <entity id="I08-4033.31">spite</entity> of an unexpected file encoding <entity id="I08-4033.32">errors</entity>, the <entity id="I08-4033.33">system</entity> exhibited a top <entity id="I08-4033.34">level</entity> <entity id="I08-4033.35">performance</entity>. A higher <entity id="I08-4033.36">word segmentation</entity> <entity id="I08-4033.37">accuracy</entity> for the <entity id="I08-4033.38">corpus</entity> ckip and ncc were achieved. We are <entity id="I08-4033.39">ranked</entity> at the fifth and eighth position out of all 19 and 26 <entity id="I08-4033.40">submissions</entity> respectively for the two <entity id="I08-4033.41">corpus</entity>. Achilles uses a <entity id="I08-4033.42">feature</entity> combined <entity id="I08-4033.43">approach</entity> for <entity id="I08-4033.44">part-of-speech</entity> <entity id="I08-4033.45">tagging</entity>. Our <entity id="I08-4033.46">post-evaluation results</entity> prove the <entity id="I08-4033.47">effectiveness</entity> of this <entity id="I08-4033.48">approach</entity> for <entity id="I08-4033.49">POS tagging</entity>.
</abstract>


usedfor(I08-4033.4,I08-4033.9,REVERSE)
methodapplied(I08-4033.11,I08-4033.12)
methodapplied(I08-4033.15,I08-4033.17)
methodapplied(I08-4033.22,I08-4033.23)
taskapplied(I08-4033.28,I08-4033.30)
yields(I08-4033.33,I08-4033.35)
taskapplied(I08-4033.36,I08-4033.38)
usedfor(I08-4033.43,I08-4033.45)
yields(I08-4033.46,I08-4033.48,REVERSE)

</text>

<text id="P07-1078"><title>
Self-<entity id="P07-1078.1">Training</entity> for <entity id="P07-1078.2">Enhancement</entity> and <entity id="P07-1078.3">Domain Adaptation</entity> of <entity id="P07-1078.4">Statistical</entity> Parsers <entity id="P07-1078.5">Trained</entity> on Small Datasets
</title><abstract>
Creating large <entity id="P07-1078.6">amounts</entity> of annotated <entity id="P07-1078.7">data</entity> to <entity id="P07-1078.8">train</entity> <entity id="P07-1078.9">statistical</entity> PCFG <entity id="P07-1078.10">parsers</entity> is expensive, and the <entity id="P07-1078.11">performance</entity> of such <entity id="P07-1078.12">parsers</entity> declines when <entity id="P07-1078.13">training</entity> and <entity id="P07-1078.14">test</entity><entity id="P07-1078.15">data</entity> are taken from different <entity id="P07-1078.16">domains</entity>. In this <entity id="P07-1078.17">paper</entity> we use <entity id="P07-1078.18">self-training</entity> in <entity id="P07-1078.19">order</entity> to <entity id="P07-1078.20">improve</entity> the <entity id="P07-1078.21">quality</entity> of a <entity id="P07-1078.22">parser</entity> and to <entity id="P07-1078.23">adapt</entity> it to a different <entity id="P07-1078.24">domain</entity>, using only small <entity id="P07-1078.25">amounts</entity> of manually annotated <entity id="P07-1078.26">seed</entity><entity id="P07-1078.27">data</entity>. We <entity id="P07-1078.28">report</entity> significant <entity id="P07-1078.29">improvement</entity> both when the <entity id="P07-1078.30">seed</entity> and <entity id="P07-1078.31">test</entity><entity id="P07-1078.32">data</entity> are in the same <entity id="P07-1078.33">domain</entity> and in the <entity id="P07-1078.34">out-of-domain adaptation</entity> <entity id="P07-1078.35">scenario</entity>. In particular, we achieve 50% <entity id="P07-1078.36">reduction</entity> in annotation <entity id="P07-1078.37">cost</entity> for the <entity id="P07-1078.38">in-domain</entity> <entity id="P07-1078.39">case</entity>, <entity id="P07-1078.40">yielding</entity> an <entity id="P07-1078.41">improvement</entity> of 66% over previous work, and a 20-33% <entity id="P07-1078.42">reduction</entity> for the <entity id="P07-1078.43">domain adaptation</entity> <entity id="P07-1078.44">case</entity>. This is the first <entity id="P07-1078.45">time</entity> that <entity id="P07-1078.46">self-training</entity> with small labeled datasets is <entity id="P07-1078.47">applied</entity> successfully to these <entity id="P07-1078.48">tasks</entity>. We were also able to formulate a <entity id="P07-1078.49">characterization</entity> of when <entity id="P07-1078.50">self-training</entity> is valuable.
</abstract>


usedfor(P07-1078.1,P07-1078.2)
taskapplied(P07-1078.7,P07-1078.10,REVERSE)
affects(P07-1078.11,P07-1078.16,REVERSE)
usedfor(P07-1078.18,P07-1078.22)
wrt(P07-1078.36,P07-1078.37)
taskapplied(P07-1078.46,P07-1078.48)

</text>

<text id="W05-1104"><title>
Designing an Extensible API for Integrating <entity id="W05-1104.1">Language Modeling</entity> and <entity id="W05-1104.2">Realization</entity></title><abstract>
"We present an extensible API for integrating <entity id="W05-1104.3">language modeling</entity> and <entity id="W05-1104.4">realization</entity>, describing its <entity id="W05-1104.5">design</entity> and efficient <entity id="W05-1104.6">implementation</entity> in the OpenCCG <entity id="W05-1104.7">surface</entity> realizer. With OpenCCG, <entity id="W05-1104.8">language models</entity> may be used to select <entity id="W05-1104.9">realizations</entity> with preferred <entity id="W05-1104.10">word</entity> <entity id="W05-1104.11">orders</entity>, promote <entity id="W05-1104.12">alignment</entity> with a conversational partner, avoid repetitive <entity id="W05-1104.13">language</entity> use, and <entity id="W05-1104.14">increase</entity> the <entity id="W05-1104.15">speed</entity> of the best-first anytime <entity id="W05-1104.16">search</entity>. The API enables a <entity id="W05-1104.17">variety</entity> of <entity id="W05-1104.18">n-gram models</entity> to be easily combined and used in <entity id="W05-1104.19">conjunction</entity> with appropriate <entity id="W05-1104.20">edge</entity> pruning <entity id="W05-1104.21">strategies</entity>. The <entity id="W05-1104.22">n-gram models</entity> may be of any <entity id="W05-1104.23">order</entity>, operate in reverse (""right-to-left""), and selectively replace certain <entity id="W05-1104.24">words</entity> with their <entity id="W05-1104.25">semantic classes</entity>. Factored <entity id="W05-1104.26">language models</entity> with <entity id="W05-1104.27">generalized</entity> backoff may also be employed, over <entity id="W05-1104.28">words</entity> represented as bundles of <entity id="W05-1104.29">factors</entity> such as <entity id="W05-1104.30">form</entity>, <entity id="W05-1104.31">pitch</entity> accent, <entity id="W05-1104.32">stem</entity>, <entity id="W05-1104.33">part of speech</entity>, supertag, and <entity id="W05-1104.34">semantic class</entity>. "
</abstract>


usedfor(W05-1104.8,W05-1104.9)
char(W05-1104.15,W05-1104.16)
char(W05-1104.22,W05-1104.23,REVERSE)
model(W05-1104.24,W05-1104.25,REVERSE)
model(W05-1104.28,W05-1104.29,REVERSE)

</text>

<text id="L08-1203">
<title>
KnoFusius: a New <entity id="L08-1203.1">Knowledge</entity> <entity id="L08-1203.2">Fusion</entity> <entity id="L08-1203.3">System</entity> for <entity id="L08-1203.4">Interpretation</entity> of <entity id="L08-1203.5">Gene</entity> <entity id="L08-1203.6">Expression</entity> <entity id="L08-1203.7">Data</entity></title>
<abstract>
This <entity id="L08-1203.8">paper</entity> introduces a new <entity id="L08-1203.9">architecture</entity> that aims at combining molecular <entity id="L08-1203.10">biology</entity> <entity id="L08-1203.11">data</entity> with <entity id="L08-1203.12">information</entity> automatically <entity id="L08-1203.13">extracted</entity> from relevant <entity id="L08-1203.14">scientific literature</entity> ( using <entity id="L08-1203.15">text</entity> mining <entity id="L08-1203.16">techniques</entity> on PubMed <entity id="L08-1203.17">abstracts</entity> and fulltext <entity id="L08-1203.18">papers</entity> ) to <entity id="L08-1203.19">help</entity> biomedical <entity id="L08-1203.20">experts</entity> to interpret <entity id="L08-1203.21">experimental</entity> <entity id="L08-1203.22">results</entity> in <entity id="L08-1203.23">hand</entity> . The infrastructural <entity id="L08-1203.24">level</entity> bears on <entity id="L08-1203.25">semantic-web</entity> <entity id="L08-1203.26">technologies</entity> and <entity id="L08-1203.27">standards</entity> that facilitate the actual <entity id="L08-1203.28">fusion</entity> of the <entity id="L08-1203.29">multi-source</entity> <entity id="L08-1203.30">knowledge</entity> .
</abstract>


usedfor(L08-1203.3,L08-1203.4)
propose(L08-1203.8,L08-1203.9)
datasource(L08-1203.12,L08-1203.14)
methodapplied(L08-1203.16,L08-1203.17)
usedfor(L08-1203.27,L08-1203.28)

</text>

<text id="L08-1204">
<title>
Modelling <entity id="L08-1204.1">Word</entity> <entity id="L08-1204.2">Similarity</entity> : an <entity id="L08-1204.3">Evaluation</entity> of <entity id="L08-1204.4">Automatic</entity> Synonymy <entity id="L08-1204.5">Extraction</entity> <entity id="L08-1204.6">Algorithms</entity> .
</title>
<abstract><entity id="L08-1204.7">Vector-based models</entity> of <entity id="L08-1204.8">lexical semantics</entity> retrieve semantically related <entity id="L08-1204.9">words</entity> automatically from large <entity id="L08-1204.10">corpora</entity> by exploiting the <entity id="L08-1204.11">property</entity> that <entity id="L08-1204.12">words</entity> with a similar meaning tend to occur in similar <entity id="L08-1204.13">contexts</entity> . Despite their <entity id="L08-1204.14">increasing</entity> <entity id="L08-1204.15">popularity</entity> , it is unclear which <entity id="L08-1204.16">kind</entity> of <entity id="L08-1204.17">semantic similarity</entity> they actually capture and for which <entity id="L08-1204.18">kind</entity> of <entity id="L08-1204.19">words</entity> . In this <entity id="L08-1204.20">paper</entity> , we use three <entity id="L08-1204.21">vector-based models</entity> to retrieve semantically related <entity id="L08-1204.22">words</entity> for a set of Dutch <entity id="L08-1204.23">nouns</entity> and we analyse whether three linguistic  <entity id="L08-1204.24">properties</entity> of the <entity id="L08-1204.25">nouns</entity> <entity id="L08-1204.26">influence</entity> the <entity id="L08-1204.27">results</entity> . In particular, we compare <entity id="L08-1204.28">results</entity> from a <entity id="L08-1204.29">dependency-based model</entity>  with those from a 1st and 2nd <entity id="L08-1204.30">order</entity> <entity id="L08-1204.31">bag-of-words</entity> <entity id="L08-1204.32">model</entity> and we examine the <entity id="L08-1204.33">effect</entity> of the <entity id="L08-1204.34">nouns</entity> ' <entity id="L08-1204.35">frequency</entity> , <entity id="L08-1204.36">semantic</entity> speficity and <entity id="L08-1204.37">semantic class</entity> . We find that all three <entity id="L08-1204.38">models</entity> find more <entity id="L08-1204.39">synonyms</entity> for <entity id="L08-1204.40">high-frequency</entity> <entity id="L08-1204.41">nouns</entity> and those belonging to <entity id="L08-1204.42">abstract</entity> <entity id="L08-1204.43">semantic</entity> classses. <entity id="L08-1204.44">Semantic</entity> specificty does not have a clear <entity id="L08-1204.45">influence</entity> .
</abstract>


propose(L08-1204.20,L08-1204.21)
affects(L08-1204.24,L08-1204.27)
yields(L08-1204.28,L08-1204.29,REVERSE)

</text>

<text id="L08-1205">
<title>
Childrens Oral Reading <entity id="L08-1205.1">Corpus</entity> (CHOREC): <entity id="L08-1205.2">Description</entity> and <entity id="L08-1205.3">Assessment</entity> of Annotator <entity id="L08-1205.4">Agreement</entity></title>
<abstract>
Within the <entity id="L08-1205.5">scope</entity> of the <entity id="L08-1205.6">SPACE</entity> <entity id="L08-1205.7">project</entity> , the CHildren's Oral REading <entity id="L08-1205.8">Corpus</entity> (CHOREC) is <entity id="L08-1205.9">developed</entity> . This <entity id="L08-1205.10">database</entity> contains <entity id="L08-1205.11">recorded</entity> , transcribed and annotated read <entity id="L08-1205.12">speech </entity> (42 GB or 130 hours) of 400 Dutch speaking elementary school children with or without reading <entity id="L08-1205.13">difficulties</entity> .  <entity id="L08-1205.14">Analyses</entity> of inter- and intra-annotator <entity id="L08-1205.15">agreement</entity> are carried out in <entity id="L08-1205.16">order</entity> to investigate the  <entity id="L08-1205.17">consistency</entity>  with which reading <entity id="L08-1205.18">errors</entity> are detected, orthographic and phonetic <entity id="L08-1205.19">transcriptions</entity> are made, and reading <entity id="L08-1205.20">errors</entity> and reading <entity id="L08-1205.21">strategies</entity> are labeled. <entity id="L08-1205.22">Percentage</entity> <entity id="L08-1205.23">agreement</entity> scores and <entity id="L08-1205.24">kappa</entity> values both show that <entity id="L08-1205.25">agreement</entity> between annotations, and therefore the <entity id="L08-1205.26">quality</entity> of the annotations, is high. Taken all double or <entity id="L08-1205.27">triple</entity> annotations (for 10% resp. 30% of the <entity id="L08-1205.28">corpus</entity> ) together, % <entity id="L08-1205.29">agreement</entity> varies between 86.4% and 98.6%, whereas <entity id="L08-1205.30">kappa</entity> varies between 0.72 and 0.97 depending on the annotation tier that is being assessed. School <entity id="L08-1205.31">type</entity> and reading  <entity id="L08-1205.32">type</entity> seem to account for systematic <entity id="L08-1205.33">differences</entity> in % <entity id="L08-1205.34">agreement</entity> , but these <entity id="L08-1205.35">differences</entity> disappear when <entity id="L08-1205.36">kappa</entity> values are calculated that correct for chance <entity id="L08-1205.37">agreement</entity> . To conclude, an  <entity id="L08-1205.38">analysis</entity> of the annotation <entity id="L08-1205.39">differences</entity>  with <entity id="L08-1205.40">respect</entity> to the '*s' label (i.e. a label that is used to annotate undistinguishable spelling <entity id="L08-1205.41">behaviour</entity> ), <entity id="L08-1205.42">phoneme</entity> labels, reading <entity id="L08-1205.43">strategy</entity> and <entity id="L08-1205.44">error</entity> labels is given.
</abstract>


composed_of(L08-1205.10,L08-1205.12)
study(L08-1205.14,L08-1205.17)
affects(L08-1205.32,L08-1205.33)
study(L08-1205.38,L08-1205.39)

</text>

<text id="L08-1206">
<title>
A Bilingual  <entity id="L08-1206.1">Corpus</entity> of Inter-linked <entity id="L08-1206.2">Events</entity></title>
<abstract>
This <entity id="L08-1206.3">paper</entity> describes the <entity id="L08-1206.4">creation</entity>  of a bilingual <entity id="L08-1206.5">corpus</entity>  of inter-linked <entity id="L08-1206.6">events</entity>  for Italian and <entity id="L08-1206.7">English</entity> . Linkage is accomplished through the Inter- <entity id="L08-1206.8">Lingual</entity> <entity id="L08-1206.9">Index</entity> (ILI) that <entity id="L08-1206.10">links</entity> ItalWordNet with WordNet. The <entity id="L08-1206.11">availability</entity> of this <entity id="L08-1206.12">resource</entity> , on the one <entity id="L08-1206.13">hand</entity> , enables  contrastive <entity id="L08-1206.14">analysis</entity>  of the linguistic <entity id="L08-1206.15">phenomena</entity>  surrounding <entity id="L08-1206.16">events</entity> in both <entity id="L08-1206.17">languages</entity> , and on the other <entity id="L08-1206.18">hand</entity> , can be used to <entity id="L08-1206.19">perform</entity> multilingual temporal <entity id="L08-1206.20">analysis</entity> of <entity id="L08-1206.21">texts</entity> . In <entity id="L08-1206.22">addition</entity> to describing the <entity id="L08-1206.23">methodology</entity> for <entity id="L08-1206.24">construction</entity> of the inter-linked <entity id="L08-1206.25">corpus</entity> and the <entity id="L08-1206.26">analysis</entity> of the <entity id="L08-1206.27">data</entity> collected, we demonstrate that the ILI could potentially be used to <entity id="L08-1206.28">bootstrap</entity> the <entity id="L08-1206.29">creation</entity> of comparable <entity id="L08-1206.30">corpora</entity> by exporting <entity id="L08-1206.31">layers</entity> of annotation for <entity id="L08-1206.32">words</entity> that have the same <entity id="L08-1206.33">sense</entity> .
</abstract>


composed_of(L08-1206.1,L08-1206.2)
propose(L08-1206.3,L08-1206.4)
composed_of(L08-1206.5,L08-1206.6)
study(L08-1206.14,L08-1206.15)
study(L08-1206.20,L08-1206.21)
usedfor(L08-1206.23,L08-1206.24)

</text>

<text id="L08-1207">
<title>
New Resources for <entity id="L08-1207.1">Document Classification</entity> , <entity id="L08-1207.2">Analysis</entity> and <entity id="L08-1207.3">Translation</entity> Technologies
</title>
<abstract>
The <entity id="L08-1207.4">goal</entity> of the DARPA MADCAT (Multilingual <entity id="L08-1207.5">Automatic</entity> <entity id="L08-1207.6">Document Classification</entity> <entity id="L08-1207.7">Analysis</entity> and <entity id="L08-1207.8">Translation</entity> ) <entity id="L08-1207.9">Program</entity> is to automatically convert <entity id="L08-1207.10">foreign language</entity> <entity id="L08-1207.11">text</entity> images into <entity id="L08-1207.12">English</entity> <entity id="L08-1207.13">transcripts</entity> , for use by humans and downstream <entity id="L08-1207.14">applications</entity> . The first <entity id="L08-1207.15">phase</entity> the <entity id="L08-1207.16">program</entity> <entity id="L08-1207.17">focuses</entity> on <entity id="L08-1207.18">translation</entity> of handwritten Arabic <entity id="L08-1207.19">documents</entity> . Linguistic <entity id="L08-1207.20">Data</entity> Consortium (LDC) is creating publicly available <entity id="L08-1207.21">linguistic resources</entity> for MADCAT <entity id="L08-1207.22">technologies</entity> , on a <entity id="L08-1207.23">scale</entity> and <entity id="L08-1207.24">richness</entity> not previously available. <entity id="L08-1207.25">Corpora</entity> will consist of existing LDC <entity id="L08-1207.26">corpora</entity> and <entity id="L08-1207.27">data</entity> donations from MADCAT partners, plus new <entity id="L08-1207.28">data</entity> <entity id="L08-1207.29">collection</entity> to <entity id="L08-1207.30">provide</entity> <entity id="L08-1207.31">high quality</entity> material for <entity id="L08-1207.32">evaluation</entity> and to address strategic <entity id="L08-1207.33">gaps</entity> (for <entity id="L08-1207.34">genre</entity> , <entity id="L08-1207.35">dialect</entity> , image <entity id="L08-1207.36">quality</entity> , etc.) in the existing <entity id="L08-1207.37">resources</entity> . <entity id="L08-1207.38">Training</entity> and <entity id="L08-1207.39">test</entity> <entity id="L08-1207.40">data</entity> <entity id="L08-1207.41">properties</entity> will expand over <entity id="L08-1207.42">time</entity> to encompass a wide range of <entity id="L08-1207.43">topics</entity> and <entity id="L08-1207.44">genres</entity> : letters, diaries, <entity id="L08-1207.45">training</entity> <entity id="L08-1207.46">manuals</entity> , brochures, signs, ledgers, memos, <entity id="L08-1207.47">instructions</entity> , post
cards and <entity id="L08-1207.48">forms</entity> among others. <entity id="L08-1207.49">Data</entity> will be ground truthed, with line, <entity id="L08-1207.50">word</entity> and token segmentation and zoning, and <entity id="L08-1207.51">translations</entity> and <entity id="L08-1207.52">word alignments</entity> will be produced for a subset. <entity id="L08-1207.53">Evaluation</entity> <entity id="L08-1207.54">data</entity> will be carefully selected from the available <entity id="L08-1207.55">data</entity> pools and <entity id="L08-1207.56">high quality</entity> <entity id="L08-1207.57">references</entity> will be produced, which can be used to compare MADCAT <entity id="L08-1207.58">system</entity> <entity id="L08-1207.59">performance</entity> against the human-produced <entity id="L08-1207.60">gold standard</entity> .
</abstract>


taskapplied(L08-1207.18,L08-1207.19)
compare(L08-1207.59,L08-1207.60)

</text>

<text id="L08-1208">
<title>
Approximating <entity id="L08-1208.1">Learning</entity> Curves for Active- <entity id="L08-1208.2">Learning-</entity> Driven Annotation
</title>
<abstract><entity id="L08-1208.3">Active learning</entity> (AL) is getting more and more popular as a <entity id="L08-1208.4">methodology</entity> to considerably reduce the annotation <entity id="L08-1208.5">effort</entity> when <entity id="L08-1208.6">building</entity> <entity id="L08-1208.7">training</entity> material for <entity id="L08-1208.8">statistical</entity> <entity id="L08-1208.9">learning methods</entity> for various <entity id="L08-1208.10">NLP tasks</entity> . A crucial <entity id="L08-1208.11">issue</entity> rarely addressed, however, is when to actually stop the annotation <entity id="L08-1208.12">process</entity> to profit from the <entity id="L08-1208.13">savings</entity> in <entity id="L08-1208.14">efforts</entity> . This <entity id="L08-1208.15">question</entity> is tightly related to estimating the <entity id="L08-1208.16">classifier</entity> <entity id="L08-1208.17">performance</entity> after a certain <entity id="L08-1208.18">amount</entity> of <entity id="L08-1208.19">data</entity> has already been annotated. While learning curves are the <entity id="L08-1208.20">default</entity> means to monitor the <entity id="L08-1208.21">progress</entity> of the annotation <entity id="L08-1208.22">process</entity> in <entity id="L08-1208.23">terms</entity> of <entity id="L08-1208.24">classifier</entity> <entity id="L08-1208.25">performance</entity> , this <entity id="L08-1208.26">requires</entity> a labeled <entity id="L08-1208.27">gold standard</entity> which - in realistic annotation settings, at least - is often unavailable. We here <entity id="L08-1208.28">propose</entity> a <entity id="L08-1208.29">method</entity> for committee-based AL to approximate the progression of the learning curve <entity id="L08-1208.30">based</entity> on the <entity id="L08-1208.31">disagreement</entity> among the committee members. This  <entity id="L08-1208.32">method</entity> relies on a separate, unlabeled <entity id="L08-1208.33">corpus</entity> and is thus well suited for <entity id="L08-1208.34">situations</entity> where a labeled <entity id="L08-1208.35">gold standard</entity> is not available or would be too expensive to obtain. Considering <entity id="L08-1208.36">named</entity> <entity id="L08-1208.37">entity</entity> <entity id="L08-1208.38">recognition</entity> as a <entity id="L08-1208.39">test</entity> <entity id="L08-1208.40">case</entity> we <entity id="L08-1208.41">provide</entity> empirical <entity id="L08-1208.42">evidence</entity> that this <entity id="L08-1208.43">approach</entity> works well under <entity id="L08-1208.44">simulation</entity> as well as under real-world annotation conditions.
</abstract>


isa(L08-1208.3,L08-1208.4)
affects(L08-1208.15,L08-1208.17)
methodapplied(L08-1208.32,L08-1208.33)
usedfor(L08-1208.38,L08-1208.43,REVERSE)

</text>

<text id="L08-1209">
<title><entity id="L08-1209.1">Lexicon</entity> Schemas and <entity id="L08-1209.2">Related</entity> <entity id="L08-1209.3">Data</entity> <entity id="L08-1209.4">Models</entity> : when Standards Meet Users
</title>
<abstract><entity id="L08-1209.5">Lexicon</entity> <entity id="L08-1209.6">schemas</entity> and their use are discussed in this <entity id="L08-1209.7">paper</entity> from the <entity id="L08-1209.8">perspective</entity> of lexicographers and <entity id="L08-1209.9">field</entity> <entity id="L08-1209.10">linguists</entity> . A <entity id="L08-1209.11">variety</entity> of <entity id="L08-1209.12">lexicon</entity> <entity id="L08-1209.13">schemas</entity> have been <entity id="L08-1209.14">developed</entity> , with <entity id="L08-1209.15">goals</entity> ranging from <entity id="L08-1209.16">computational</entity> lexicography (DATR) through <entity id="L08-1209.17">archiving</entity> (LIFT, TEI) to standardization (LMF, FSR). A <entity id="L08-1209.18">number</entity> of <entity id="L08-1209.19">requirements</entity> for <entity id="L08-1209.20">lexicon</entity> <entity id="L08-1209.21">schemas</entity> are given. The <entity id="L08-1209.22">lexicon</entity> <entity id="L08-1209.23">schemas</entity> are introduced and compared to each other in <entity id="L08-1209.24">terms</entity> of <entity id="L08-1209.25">conversion</entity> and usability for this particular <entity id="L08-1209.26">user</entity> group, using a <entity id="L08-1209.27">common</entity> <entity id="L08-1209.28">lexicon</entity> <entity id="L08-1209.29">entry</entity> and <entity id="L08-1209.30">providing</entity> <entity id="L08-1209.31">examples</entity> for each <entity id="L08-1209.32">schema</entity> under <entity id="L08-1209.33">consideration</entity> . The <entity id="L08-1209.34">formats</entity> are assessed and the final <entity id="L08-1209.35">recommendation</entity> is given for the potential <entity id="L08-1209.36">users</entity> , namely to request <entity id="L08-1209.37">standard</entity> compliance from the <entity id="L08-1209.38">developers</entity> of the <entity id="L08-1209.39">tools</entity> used. This <entity id="L08-1209.40">paper</entity> should foster a <entity id="L08-1209.41">discussion</entity> between authors of <entity id="L08-1209.42">standards</entity> , lexicographers and <entity id="L08-1209.43">field</entity> <entity id="L08-1209.44">linguists</entity> .
</abstract>


propose(L08-1209.6,L08-1209.7,REVERSE)
usedfor(L08-1209.13,L08-1209.17)

</text>

<text id="L08-1210">
<title>
LexSchem: a Large Subcategorization <entity id="L08-1210.1">Lexicon</entity> for French Verbs
</title>
<abstract>
This <entity id="L08-1210.2">paper</entity> presents LexSchem
</abstract>



</text>

<text id="L08-1211">
<title>
Arabic WordNet: <entity id="L08-1211.1">Semi-automatic</entity> <entity id="L08-1211.2">Extensions</entity> using Bayesian <entity id="L08-1211.3">Inference</entity></title>
<abstract>This <entity id="L08-1211.4">presentation</entity> <entity id="L08-1211.5">focuses</entity> on the <entity id="L08-1211.6">semi-automatic</entity> <entity id="L08-1211.7">extension</entity> of Arabic WordNet (AWN) using <entity id="L08-1211.8">lexical</entity> and morphological <entity id="L08-1211.9">rules</entity> and <entity id="L08-1211.10">applying</entity> Bayesian <entity id="L08-1211.11">inference</entity> . We briefly <entity id="L08-1211.12">report</entity> on the <entity id="L08-1211.13">current</entity> <entity id="L08-1211.14">status</entity> of AWN and <entity id="L08-1211.15">propose</entity> a way of extending its <entity id="L08-1211.16">coverage</entity> by taking <entity id="L08-1211.17">advantage</entity> of a limited set of highly productive Arabic morphological <entity id="L08-1211.18">rules</entity> for deriving a range of semantically related <entity id="L08-1211.19">word</entity> <entity id="L08-1211.20">forms</entity> from <entity id="L08-1211.21">verb</entity> <entity id="L08-1211.22">entries</entity> . The <entity id="L08-1211.23">application</entity> of this set of <entity id="L08-1211.24">rules</entity> , combined with the use of bilingual Arabic- <entity id="L08-1211.25">English</entity> <entity id="L08-1211.26">resources</entity> and Princeton's WordNet, allows the <entity id="L08-1211.27">generation</entity> of a graph representing the <entity id="L08-1211.28">semantic</entity> neighbourhood of the original <entity id="L08-1211.29">word</entity> . In previous work, a set of <entity id="L08-1211.30">associations</entity> between the hypothesized Arabic <entity id="L08-1211.31">words</entity> and <entity id="L08-1211.32">English</entity> synsets was <entity id="L08-1211.33">proposed</entity> on the <entity id="L08-1211.34">basis</entity> of this graph. Here, a novel <entity id="L08-1211.35">approach</entity> to extending AWN is presented whereby a Bayesian <entity id="L08-1211.36">Network</entity> is automatically built from the graph and then the net is used as an <entity id="L08-1211.37">inferencing</entity> <entity id="L08-1211.38">mechanism</entity> for scoring the set of <entity id="L08-1211.39">candidate</entity> <entity id="L08-1211.40">associations</entity> . Both on its own and in <entity id="L08-1211.41">combination</entity> with the previous <entity id="L08-1211.42">technique</entity> , this new <entity id="L08-1211.43">approach</entity> has led to <entity id="L08-1211.44">improved</entity> <entity id="L08-1211.45">results</entity> .
</abstract>


usedfor(L08-1211.2,L08-1211.3,REVERSE)
propose(L08-1211.4,L08-1211.7)
usedfor(L08-1211.24,L08-1211.27)
usedfor(L08-1211.36,L08-1211.38)
yields(L08-1211.43,L08-1211.45)

</text>

<text id="L08-1212">
<title>
Subjective <entity id="L08-1212.1">Evaluation</entity> of an Emotional <entity id="L08-1212.2">Speech</entity> <entity id="L08-1212.3">Database</entity> for Basque
///q</title>
<abstract>
This <entity id="L08-1212.4">paper</entity> describes the <entity id="L08-1212.5">evaluation</entity> <entity id="L08-1212.6">process</entity> of an emotional <entity id="L08-1212.7">speech</entity> <entity id="L08-1212.8">database</entity> <entity id="L08-1212.9">recorded</entity> for <entity id="L08-1212.10">standard</entity> Basque, in <entity id="L08-1212.11">order</entity> to determine its <entity id="L08-1212.12">adequacy</entity> for the <entity id="L08-1212.13">analysis</entity> of emotional <entity id="L08-1212.14">models</entity> and its use in <entity id="L08-1212.15">speech synthesis</entity> . The <entity id="L08-1212.16">corpus</entity> consists of seven hundred semantically neutral <entity id="L08-1212.17">sentences</entity> that were <entity id="L08-1212.18">recorded</entity> for the Big Six <entity id="L08-1212.19">emotions</entity> and neutral style, by two professional actors. The <entity id="L08-1212.20">test</entity> <entity id="L08-1212.21">results</entity> show that every <entity id="L08-1212.22">emotion</entity> is readily recognized far above chance <entity id="L08-1212.23">level</entity> for both speakers. Therefore the <entity id="L08-1212.24">database</entity> is a valid <entity id="L08-1212.25">linguistic resource</entity> for the <entity id="L08-1212.26">research</entity> and <entity id="L08-1212.27">development</entity> <entity id="L08-1212.28">purposes</entity> it was <entity id="L08-1212.29">designed</entity> for.
</abstract>


propose(L08-1212.4,L08-1212.6)
composed_of(L08-1212.16,L08-1212.17)
usedfor(L08-1212.24,L08-1212.28)

</text>

<text id="L08-1213">
<title>
How to Compare Treebanks
</title>
<abstract>
Recent years have seen an <entity id="L08-1213.1">increasing</entity> interest in <entity id="L08-1213.2">developing</entity> <entity id="L08-1213.3">standards</entity> for linguistic annotation, with a <entity id="L08-1213.4">focus</entity> on the interoperability of the <entity id="L08-1213.5">resources</entity> . This <entity id="L08-1213.6">effort</entity> , however, <entity id="L08-1213.7">requires</entity> a profound <entity id="L08-1213.8">knowledge</entity> of the <entity id="L08-1213.9">advantages</entity> and disadvantages of linguistic annotation <entity id="L08-1213.10">schemes</entity> in <entity id="L08-1213.11">order</entity> to avoid importing the flaws and weaknesses of existing encoding <entity id="L08-1213.12">schemes</entity> into the new <entity id="L08-1213.13">standards</entity> . This <entity id="L08-1213.14">paper</entity> addresses the <entity id="L08-1213.15">question</entity> how to compare syntactically annotated <entity id="L08-1213.16">corpora</entity> and <entity id="L08-1213.17">gain</entity> <entity id="L08-1213.18">insights</entity> into the <entity id="L08-1213.19">usefulness</entity> of specific <entity id="L08-1213.20">design</entity> <entity id="L08-1213.21">decisions</entity> . We present an exhaustive <entity id="L08-1213.22">evaluation</entity> of two German treebanks with crucially different encoding <entity id="L08-1213.23">schemes</entity> . We <entity id="L08-1213.24">evaluate</entity> three different <entity id="L08-1213.25">parsers</entity> <entity id="L08-1213.26">trained</entity> on the two treebanks and compare <entity id="L08-1213.27">results</entity> using EvalB, the Leaf-Ancestor <entity id="L08-1213.28">metric</entity> , and a <entity id="L08-1213.29">dependency-based</entity> <entity id="L08-1213.30">evaluation</entity> . Furthermore, we present TePaCoC, a new testsuite for the <entity id="L08-1213.31">evaluation</entity> of <entity id="L08-1213.32">parsers</entity> on <entity id="L08-1213.33">complex</entity> German grammatical <entity id="L08-1213.34">constructions</entity> . The testsuite <entity id="L08-1213.35">provides</entity> a well thought-out <entity id="L08-1213.36">error</entity> <entity id="L08-1213.37">classification</entity> , which enables us to compare <entity id="L08-1213.38">parser</entity> <entity id="L08-1213.39">output</entity> for <entity id="L08-1213.40">parsers</entity> <entity id="L08-1213.41">trained</entity> on treebanks with different encoding <entity id="L08-1213.42">schemes</entity> and <entity id="L08-1213.43">provides</entity> interesting <entity id="L08-1213.44">insights</entity> into the <entity id="L08-1213.45">impact</entity> of treebank annotation <entity id="L08-1213.46">schemes</entity> on specific <entity id="L08-1213.47">constructions</entity> like PP <entity id="L08-1213.48">attachment</entity> or <entity id="L08-1213.49">non-constituent</entity> <entity id="L08-1213.50">coordination</entity> .
</abstract>


affects(L08-1213.46,L08-1213.47)

</text>

<text id="L08-1214">
<title>
The INFILE <entity id="L08-1214.1">Project</entity> : a Crosslingual Filtering <entity id="L08-1214.2">Systems</entity> <entity id="L08-1214.3">Evaluation</entity> Campaign
</title>
<abstract>
The InFile <entity id="L08-1214.4">project</entity> ( <entity id="L08-1214.5">INformation</entity> , FILtering, <entity id="L08-1214.6">Evaluation</entity> ) is a <entity id="L08-1214.7">cross-language</entity> adaptive filtering <entity id="L08-1214.8">evaluation</entity> campaign, sponsored by the French National <entity id="L08-1214.9">Research</entity> Agency. The campaign is organized by the CEA <entity id="L08-1214.10">LIST</entity> , ELDA and the <entity id="L08-1214.11">University</entity> of Lille3-GERiiCO. It has an international <entity id="L08-1214.12">scope</entity> as it is a <entity id="L08-1214.13">pilot</entity> track of the CLEF 2008 campaigns. The <entity id="L08-1214.14">corpus</entity> is built from a <entity id="L08-1214.15">collection</entity> of about 1,4 millions newswires (10 GB) in three <entity id="L08-1214.16">languages</entity> , Arabic, <entity id="L08-1214.17">English</entity> and French <entity id="L08-1214.18">provided</entity> by Agence France Press (AFP) and selected from a 3 years period. The profiles <entity id="L08-1214.19">corpus</entity> is made of 50 profiles from which 30 <entity id="L08-1214.20">concern</entity> general <entity id="L08-1214.21">news</entity> and <entity id="L08-1214.22">events</entity> (national and international affairs, politics, <entity id="L08-1214.23">sports</entity> ...) and 20 <entity id="L08-1214.24">concern</entity> scientific and technical subjects.
</abstract>


composed_of(L08-1214.14,L08-1214.15)
composed_of(L08-1214.19,L08-1214.22)

</text>

<text id="L08-1215">
<title>
DIAC+: a Professional Diacritics Recovering <entity id="L08-1215.1">System</entity></title>
<abstract>
In <entity id="L08-1215.2">languages</entity> that use diacritical characters, if these special signs are stripped-off from a <entity id="L08-1215.3">word</entity> , the <entity id="L08-1215.4">resulted</entity> <entity id="L08-1215.5">string</entity> of characters may not exist in the <entity id="L08-1215.6">language</entity> , and therefore its normative <entity id="L08-1215.7">form</entity> is, in general, easy to recover. However, this is not always the <entity id="L08-1215.8">case</entity> , as <entity id="L08-1215.9">presence</entity> or <entity id="L08-1215.10">absence</entity> of a diacritical sign attached to a <entity id="L08-1215.11">base</entity> letter of a <entity id="L08-1215.12">word</entity> which exists in both <entity id="L08-1215.13">variants</entity> , may change its grammatical <entity id="L08-1215.14">properties</entity> or even the meaning, making the <entity id="L08-1215.15">recovery</entity> of the missing diacritics a difficult <entity id="L08-1215.16">task</entity> , not only for a <entity id="L08-1215.17">program</entity> but sometimes even for a human reader. We describe and <entity id="L08-1215.18">evaluate</entity> an accurate <entity id="L08-1215.19">knowledge-based system</entity> for <entity id="L08-1215.20">automatic</entity> recovering the missing diacritics in MS-Office <entity id="L08-1215.21">documents</entity> written in Romanian. For the rare <entity id="L08-1215.22">cases</entity> when the <entity id="L08-1215.23">system</entity> is not able to reliably make a <entity id="L08-1215.24">decision</entity>,it either <entity id="L08-1215.25">provides</entity> the <entity id="L08-1215.26">user</entity> a <entity id="L08-1215.27">list</entity> of <entity id="L08-1215.28">words</entity> with their <entity id="L08-1215.29">recovery</entity> <entity id="L08-1215.30">suggestions</entity> , or probabilistically choose one of the possible changes, but leaves a trace (a highlighted comment) on each <entity id="L08-1215.31">word</entity> the <entity id="L08-1215.32">modification</entity> of which was uncertain.
</abstract>


phenomenon(L08-1215.5,L08-1215.6)

</text>

<text id="L08-1216">
<title>
Annotating an Arabic Learner <entity id="L08-1216.1">Corpus</entity> for <entity id="L08-1216.2">Error</entity></title>
<abstract>
This <entity id="L08-1216.3">paper</entity> describes an ongoing <entity id="L08-1216.4">project</entity> in which we are collecting a learner <entity id="L08-1216.5">corpus</entity> of Arabic, <entity id="L08-1216.6">developing</entity> a tagset for <entity id="L08-1216.7">error</entity> annotation and <entity id="L08-1216.8">performing</entity> <entity id="L08-1216.9">Computer-aided</entity> <entity id="L08-1216.10">Error Analysis</entity> (CEA) on the <entity id="L08-1216.11">data</entity> . We <entity id="L08-1216.12">adapted</entity> the French Interlanguage <entity id="L08-1216.13">Database</entity> FRIDA tagset ( Granger, 2003a ) to the <entity id="L08-1216.14">data</entity> . We chose FRIDA in <entity id="L08-1216.15">order</entity> to follow a known <entity id="L08-1216.16">standard</entity> and to see whether the changes needed to move from a French to an Arabic tagset would give us a measure of the <entity id="L08-1216.17">distance</entity> between the two <entity id="L08-1216.18">languages</entity> with <entity id="L08-1216.19">respect</entity> to learner <entity id="L08-1216.20">difficulty</entity> . The <entity id="L08-1216.21">current</entity> <entity id="L08-1216.22">collection</entity> of <entity id="L08-1216.23">texts</entity> , which is constantly growing, contains intermediate and <entity id="L08-1216.24">advanced-level</entity> student writings . We describe the need for such <entity id="L08-1216.25">corpora</entity> , the learner <entity id="L08-1216.26">data</entity> we have collected and the tagset we have <entity id="L08-1216.27">developed</entity> . We also describe the <entity id="L08-1216.28">error</entity> <entity id="L08-1216.29">frequency</entity> <entity id="L08-1216.30">distribution</entity> of both <entity id="L08-1216.31">proficiency</entity> <entity id="L08-1216.32">levels</entity> and the ongoing work.
</abstract>


propose(L08-1216.3,L08-1216.4)
taskapplied(L08-1216.10,L08-1216.11)
problem(L08-1216.18,L08-1216.20,REVERSE)
composed_of(L08-1216.22,L08-1216.24)
composed_of(L08-1216.25,L08-1216.26)

</text>

<text id="L08-1217">
<title>
All, and only, the Errors: more Complete and Consistent Spelling and <entity id="L08-1217.1">OCR-Error</entity> <entity id="L08-1217.2">Correction</entity> <entity id="L08-1217.3">Evaluation</entity></title>
<abstract>
Some <entity id="L08-1217.4">time</entity> in the future, some <entity id="L08-1217.5">spelling</entity> <entity id="L08-1217.6">error</entity> <entity id="L08-1217.7">correction</entity> <entity id="L08-1217.8">system</entity> will correct all the <entity id="L08-1217.9">errors</entity> , and only the <entity id="L08-1217.10">errors</entity> . We need <entity id="L08-1217.11">evaluation metrics</entity> that will tell us when this has been achieved and that can <entity id="L08-1217.12">help</entity> guide us there. We <entity id="L08-1217.13">survey</entity> the <entity id="L08-1217.14">current</entity> <entity id="L08-1217.15">practice</entity> in the <entity id="L08-1217.16">form</entity> of the <entity id="L08-1217.17">evaluation</entity> <entity id="L08-1217.18">scheme</entity> of the latest major publication on <entity id="L08-1217.19">spelling</entity> <entity id="L08-1217.20">correction</entity> in a leading <entity id="L08-1217.21">journal</entity> . We are forced to conclude that while the <entity id="L08-1217.22">metric</entity> used there can tell us exactly when the ultimate <entity id="L08-1217.23">goal</entity> of <entity id="L08-1217.24">spelling</entity> <entity id="L08-1217.25">correction</entity> <entity id="L08-1217.26">research</entity> has been achieved, it offers little in the way of <entity id="L08-1217.27">directions</entity> to be followed to eventually get there. We <entity id="L08-1217.28">propose</entity> to consistently use the well-known <entity id="L08-1217.29">metrics</entity> <entity id="L08-1217.30">Recall</entity> and <entity id="L08-1217.31">Precision</entity> , as combined in the F score, on 5 possible <entity id="L08-1217.32">levels</entity> of measurement that should guide us more informedly along that <entity id="L08-1217.33">path</entity> . We describe briefly what is then measured or measurable at these <entity id="L08-1217.34">levels</entity> and <entity id="L08-1217.35">propose</entity> a <entity id="L08-1217.36">framework</entity> that should allow for concisely stating what it is one <entity id="L08-1217.37">performs</entity> in one's <entity id="L08-1217.38">evaluations</entity> . We finally <entity id="L08-1217.39">contrast</entity> our preferred <entity id="L08-1217.40">metrics</entity> to <entity id="L08-1217.41">Accuracy</entity> , which is widely used in this <entity id="L08-1217.42">field</entity> to this day and to the <entity id="L08-1217.43">Area-</entity> Under-the-Curve, which is increasingly finding acceptance in other <entity id="L08-1217.44">fields</entity> .
</abstract>


taskapplied(L08-1217.1,L08-1217.2,REVERSE)
usedfor(L08-1217.8,L08-1217.9)
study(L08-1217.14,L08-1217.17,REVERSE)
compare(L08-1217.40,L08-1217.41)

</text>

<text id="L08-1218">
<title>
Using Movie Subtitles for Creating a Large- <entity id="L08-1218.1">Scale</entity> Bilingual <entity id="L08-1218.2">Corpora</entity></title>
<abstract>
This <entity id="L08-1218.3">paper</entity> presents a <entity id="L08-1218.4">method</entity> for compiling a <entity id="L08-1218.5">large-scale</entity> bilingual <entity id="L08-1218.6">corpus</entity> from a <entity id="L08-1218.7">database</entity> of movie subtitles . To create the <entity id="L08-1218.8">corpus</entity> , we <entity id="L08-1218.9">propose</entity> an <entity id="L08-1218.10">algorithm</entity> <entity id="L08-1218.11">based</entity> on <entity id="L08-1218.12">Gale</entity> and Church's <entity id="L08-1218.13">sentence</entity> <entity id="L08-1218.14">alignment</entity> <entity id="L08-1218.15">algorithm</entity> (1993). However, our <entity id="L08-1218.16">algorithm</entity> not only relies on character <entity id="L08-1218.17">length</entity> <entity id="L08-1218.18">information</entity> , but also uses <entity id="L08-1218.19">subtitle-timing</entity> <entity id="L08-1218.20">information</entity> , which is encoded in the subtitle files. <entity id="L08-1218.21">Timing</entity> is highly correlated between subtitles in different <entity id="L08-1218.22">versions</entity> (for the same movie), since subtitles that <entity id="L08-1218.23">match</entity> should be <entity id="L08-1218.24">displayed</entity> at the same <entity id="L08-1218.25">time</entity> . However, the absolute <entity id="L08-1218.26">time</entity> values can't be used for <entity id="L08-1218.27">alignment</entity> , since the <entity id="L08-1218.28">timing</entity> is usually specified by <entity id="L08-1218.29">frame</entity> <entity id="L08-1218.30">numbers</entity> and not by <entity id="L08-1218.31">real time</entity> , and converting it to <entity id="L08-1218.32">real time</entity> values is not always possible, hence we  use normalized subtitle <entity id="L08-1218.33">duration</entity> instead . This <entity id="L08-1218.34">results</entity> in a significant <entity id="L08-1218.35">reduction</entity> in the <entity id="L08-1218.36">alignment</entity> <entity id="L08-1218.37">error rate</entity>.
</abstract>


propose(L08-1218.3,L08-1218.4)
composed_of(L08-1218.6,L08-1218.7)
based_on(L08-1218.10,L08-1218.15)
uses_information(L08-1218.16,L08-1218.18)
uses_information(L08-1218.26,L08-1218.27,REVERSE)

</text>

<text id="L08-1219">
<title>
The IFADV <entity id="L08-1219.1">Corpus</entity> : a Free <entity id="L08-1219.2">Dialog</entity> <entity id="L08-1219.3">Video</entity> <entity id="L08-1219.4">Corpus</entity></title>
<abstract>
"<entity id="L08-1219.5">Research</entity> into spoken <entity id="L08-1219.6">language</entity> has become more visual over the years. Both fundamental and <entity id="L08-1219.7">applied</entity> <entity id="L08-1219.8">research</entity> have progressively <entity id="L08-1219.9">included</entity> <entity id="L08-1219.10">gestures</entity> , gaze, and facial <entity id="L08-1219.11">expression</entity> . <entity id="L08-1219.12">Corpora</entity> of multi-modal conversational <entity id="L08-1219.13">speech</entity> are rare and frequently difficult to use <entity id="L08-1219.14">due</entity> to privacy and copyright <entity id="L08-1219.15">restrictions</entity> . A freely available annotated <entity id="L08-1219.16">corpus</entity> is presented, gratis and libre, of <entity id="L08-1219.17">high quality</entity> <entity id="L08-1219.18">video</entity> <entity id="L08-1219.19">recordings</entity> of face-to-face conversational <entity id="L08-1219.20">speech</entity> . Within the <entity id="L08-1219.21">bounds</entity> of the law, everything has been done to remove copyright and use <entity id="L08-1219.22">restrictions</entity> . Annotations have been <entity id="L08-1219.23">processed</entity> to RDBMS <entity id="L08-1219.24">tables</entity> that allow SQL <entity id="L08-1219.25">queries</entity> and direct connections to <entity id="L08-1219.26">statistical</entity> <entity id="L08-1219.27">software</entity> . From our <entity id="L08-1219.28">experiences</entity> we would like to advocate the <entity id="L08-1219.29">formulation</entity> of ""best practises"" for both legal handling and <entity id="L08-1219.30">database</entity> <entity id="L08-1219.31">storage</entity> of <entity id="L08-1219.32">recordings</entity> and annotations. "
</abstract>


composed_of(L08-1219.12,L08-1219.13)
composed_of(L08-1219.16,L08-1219.18)
composed_of(L08-1219.30,L08-1219.32)

</text>

<text id="L08-1220">
<title>
WOZ Acoustic <entity id="L08-1220.1">Data</entity> <entity id="L08-1220.2">Collection</entity> for Interactive TV
</title>
<abstract>This <entity id="L08-1220.3">paper</entity> describes a multichannel acoustic <entity id="L08-1220.4">data</entity> <entity id="L08-1220.5">collection</entity> <entity id="L08-1220.6">recorded</entity> under the European DICIT <entity id="L08-1220.7">project</entity> , during the Wizard of Oz (WOZ) <entity id="L08-1220.8">experiments</entity> carried out at FAU and FBK-irst <entity id="L08-1220.9">laboratories</entity> . The <entity id="L08-1220.10">scenario</entity> is a distant-talking <entity id="L08-1220.11">interface</entity> for interactive <entity id="L08-1220.12">control</entity> of a TV. The <entity id="L08-1220.13">experiments</entity> involve the <entity id="L08-1220.14">acquisition</entity> of multichannel <entity id="L08-1220.15">data</entity> for <entity id="L08-1220.16">signal <entity id="L08-1220.17">processing</entity></entity> front-end and were carried out <entity id="L08-1220.18">due</entity> to the need to collect a <entity id="L08-1220.19">database</entity> for testing acoustic <entity id="L08-1220.20">pre-processing</entity> <entity id="L08-1220.21">algorithms</entity> . In this way, realistic <entity id="L08-1220.22">scenarios</entity> can be simulated at a preliminary stage, instead of <entity id="L08-1220.23">real-time</entity> <entity id="L08-1220.24">implementations</entity> , allowing for repeatable <entity id="L08-1220.25">experiments</entity> . To <entity id="L08-1220.26">match</entity> the <entity id="L08-1220.27">project</entity> <entity id="L08-1220.28">requirements</entity> , the WOZ <entity id="L08-1220.29">experiments</entity> were <entity id="L08-1220.30">recorded</entity> in three <entity id="L08-1220.31">languages</entity> : <entity id="L08-1220.32">English</entity> , German and Italian. Besides the <entity id="L08-1220.33">user</entity> <entity id="L08-1220.34">inputs</entity> , the <entity id="L08-1220.35">database</entity> also contains <entity id="L08-1220.36">non-speech</entity> related acoustic <entity id="L08-1220.37">events</entity> , room impulse response measurements and <entity id="L08-1220.38">video</entity> data, the latter used to <entity id="L08-1220.39">compute</entity> 3D labels . Sessions were manually transcribed and segmented at <entity id="L08-1220.40">word</entity> <entity id="L08-1220.41">level</entity> , introducing also specific labels for acoustic <entity id="L08-1220.42">events</entity> .
</abstract>


propose(L08-1220.3,L08-1220.4)
usedfor(L08-1220.11,L08-1220.12)
usedfor(L08-1220.14,L08-1220.16)
usedfor(L08-1220.19,L08-1220.20)
usedfor(L08-1220.22,L08-1220.25)
composed_of(L08-1220.35,L08-1220.37)
usedfor(L08-1220.38,L08-1220.39)

</text>

<text id="L08-1221">
<title><entity id="L08-1221.1">Process</entity> <entity id="L08-1221.2">Model</entity> for Composing <entity id="L08-1221.3">High-quality</entity> <entity id="L08-1221.4">Text</entity> <entity id="L08-1221.5">Corpora</entity></title>
<abstract>The Teko <entity id="L08-1221.6">corpus</entity> composing <entity id="L08-1221.7">model</entity> offers a decentralized, dynamic way of collecting <entity id="L08-1221.8">high-quality</entity> <entity id="L08-1221.9">text</entity> <entity id="L08-1221.10">corpora</entity> for linguistic <entity id="L08-1221.11">research</entity> . The  <entity id="L08-1221.12">resulting</entity> <entity id="L08-1221.13">corpus</entity> consists of independent <entity id="L08-1221.14">text</entity> sets. The sets are composed in <entity id="L08-1221.15">cooperation</entity> with linguistic <entity id="L08-1221.16">research projects</entity> , so each of them responds to a specific <entity id="L08-1221.17">research</entity> need. The <entity id="L08-1221.18">corpora</entity> are morphologically annotated and XML-based, with in-built compatibilty with the Kaino <entity id="L08-1221.19">user interface</entity> used in the <entity id="L08-1221.20">corpus</entity> <entity id="L08-1221.21">server</entity> of the <entity id="L08-1221.22">Research</entity> Institute for the <entity id="L08-1221.23">Languages</entity> of Finland. Furthermore, <entity id="L08-1221.24">software</entity> for <entity id="L08-1221.25">extracting</entity> <entity id="L08-1221.26">standard</entity> quantitative <entity id="L08-1221.27">reports</entity> from the <entity id="L08-1221.28">text</entity> sets has been created during the <entity id="L08-1221.29">project</entity> . The <entity id="L08-1221.30">paper</entity> describes the <entity id="L08-1221.31">project</entity> , and estimates its <entity id="L08-1221.32">benefits</entity> and <entity id="L08-1221.33">problems</entity> . It also gives an <entity id="L08-1221.34">overview</entity> of the technical <entity id="L08-1221.35">qualities</entity> of the <entity id="L08-1221.36">corpora</entity> and <entity id="L08-1221.37">corpus</entity> <entity id="L08-1221.38">interface</entity> connected to the Teko <entity id="L08-1221.39">project</entity> .
</abstract>


usedfor(L08-1221.1,L08-1221.5)
usedfor(L08-1221.6,L08-1221.7,REVERSE)
usedfor(L08-1221.10,L08-1221.11)
composed_of(L08-1221.13,L08-1221.14)
usedfor(L08-1221.24,L08-1221.25)
propose(L08-1221.30,L08-1221.31)
study(L08-1221.34,L08-1221.35)

</text>

<text id="L08-1222">
<title>
AnCora: Multilevel Annotated <entity id="L08-1222.1">Corpora</entity> for Catalan and Spanish
</title>
<abstract>
This <entity id="L08-1222.2">paper</entity> presents AnCora, a multilingual <entity id="L08-1222.3">corpus</entity> annotated at different linguistic <entity id="L08-1222.4">levels</entity> consisting of 500,000 <entity id="L08-1222.5">words</entity> in Catalan (AnCora-Ca) and in Spanish (AnCora-Es). At present AnCora is the largest multilayer annotated <entity id="L08-1222.6">corpus</entity> of these <entity id="L08-1222.7">languages</entity> freely available from http://clic. ub. edu/ancora. The two <entity id="L08-1222.8">corpora</entity> consist mainly of <entity id="L08-1222.9">newspaper</entity> <entity id="L08-1222.10">texts</entity> annotated at different <entity id="L08-1222.11">levels</entity> of <entity id="L08-1222.12">linguistic description</entity> : morphological (PoS and <entity id="L08-1222.13">lemmas</entity> ), <entity id="L08-1222.14">syntactic</entity> ( <entity id="L08-1222.15">constituents</entity> and <entity id="L08-1222.16">functions</entity> ), and <entity id="L08-1222.17">semantic</entity> ( <entity id="L08-1222.18">argument structures</entity> , thematic <entity id="L08-1222.19">roles</entity> , <entity id="L08-1222.20">semantic</entity> <entity id="L08-1222.21">verb classes</entity> , <entity id="L08-1222.22">named</entity> <entity id="L08-1222.23">entities</entity> , and WordNet nominal senses). All <entity id="L08-1222.24">resulting</entity> <entity id="L08-1222.25">layers</entity> are independent of each other, thus making easier the <entity id="L08-1222.26">data</entity> <entity id="L08-1222.27">management</entity> . The annotation was <entity id="L08-1222.28">performed</entity> manually, semiautomatically, or fully automatically, depending on the encoded <entity id="L08-1222.29">linguistic information</entity> . The <entity id="L08-1222.30">development</entity> of these <entity id="L08-1222.31">basic</entity> <entity id="L08-1222.32">resources</entity> constituted a primary <entity id="L08-1222.33">objective</entity> , since there was a <entity id="L08-1222.34">lack</entity> of such <entity id="L08-1222.35">resources</entity> for these <entity id="L08-1222.36">languages</entity> . A second <entity id="L08-1222.37">goal</entity> was the <entity id="L08-1222.38">definition</entity> of a consistent <entity id="L08-1222.39">methodology</entity> that can be followed in further annotations. The <entity id="L08-1222.40">current</entity> <entity id="L08-1222.41">versions</entity> of AnCora have been used in several international <entity id="L08-1222.42">evaluation</entity> <entity id="L08-1222.43">competitions</entity></abstract>


composed_of(L08-1222.3,L08-1222.5)
composed_of(L08-1222.6,L08-1222.7)
composed_of(L08-1222.8,L08-1222.10)

</text>

<text id="W08-0213">
<title>
Studying <entity id="W08-0213.1">Discourse</entity> and <entity id="W08-0213.2">Dialogue</entity> with SIDGrid
</title>
<abstract>
Teaching <entity id="W08-0213.3">Computational Linguistics</entity> is inherently multi-disciplinary and frequently poses <entity id="W08-0213.4">challenges</entity> and <entity id="W08-0213.5">provides</entity> opportunities in teaching to a student body with diverse educational <entity id="W08-0213.6">backgrounds</entity> and <entity id="W08-0213.7">goals</entity> . This <entity id="W08-0213.8">paper</entity> describes the use of a <entity id="W08-0213.9">computational</entity> <entity id="W08-0213.10">environment</entity> (SIDGrid) that facilitates interdisciplinary <entity id="W08-0213.11">instruction</entity> by <entity id="W08-0213.12">providing</entity> <entity id="W08-0213.13">support</entity> for students with little <entity id="W08-0213.14">computational</entity> <entity id="W08-0213.15">background</entity> as well as extending the <entity id="W08-0213.16">scale</entity> of <entity id="W08-0213.17">projects</entity> accessible to students with more <entity id="W08-0213.18">advanced</entity> <entity id="W08-0213.19">computational</entity> skills. The <entity id="W08-0213.20">environment</entity> facilitates the use of hands-on exercises and is being <entity id="W08-0213.21">applied</entity> to interdisciplinary <entity id="W08-0213.22">instruction</entity> in <entity id="W08-0213.23">Discourse</entity> and <entity id="W08-0213.24">Dialogue</entity> .
</abstract>


usedfor(W08-0213.10,W08-0213.11)
usedfor(W08-0213.20,W08-0213.22)

</text>

<text id="L08-1227">
<title>
Relationships between Nursing Converstaions and Activities
</title>
<abstract>
In this <entity id="L08-1227.1">paper</entity> , we determine the <entity id="L08-1227.2">relationships</entity> between nursing activities and nurseing <entity id="L08-1227.3">conversations</entity> <entity id="L08-1227.4">based</entity> on the <entity id="L08-1227.5">principle</entity> of <entity id="L08-1227.6">maximum entropy</entity> . For <entity id="L08-1227.7">analysis</entity> of the <entity id="L08-1227.8">features</entity> of nursing activities, we built nursing <entity id="L08-1227.9">corpora</entity> from actual nursing <entity id="L08-1227.10">conversation</entity> sets collected in hospitals that involve various <entity id="L08-1227.11">information</entity> about nursing activities. Ex-nurses manually assigned nursing activity <entity id="L08-1227.12">information</entity> to the nursing <entity id="L08-1227.13">conversations</entity> in the <entity id="L08-1227.14">corpora</entity> . Since it is inefficient and too expensive to attach all <entity id="L08-1227.15">information</entity> manually, we introduced an <entity id="L08-1227.16">automatic</entity> nursing activity <entity id="L08-1227.17">determination</entity> <entity id="L08-1227.18">method</entity> for which we built <entity id="L08-1227.19">models</entity> of <entity id="L08-1227.20">relationships</entity> between nursing <entity id="L08-1227.21">conversations</entity> and activities. In this <entity id="L08-1227.22">paper</entity> , we adopted a <entity id="L08-1227.23">maximum entropy</entity> <entity id="L08-1227.24">approach</entity> for learning. Even though the <entity id="L08-1227.25">conversation</entity> <entity id="L08-1227.26">data</entity> set is not large enough for learning, acceptable <entity id="L08-1227.27">results</entity> were obtained.
</abstract>


study(L08-1227.7,L08-1227.8)
composed_of(L08-1227.9,L08-1227.10)
tag(L08-1227.12,L08-1227.13)
propose(L08-1227.22,L08-1227.24)

</text>

<text id="D08-1022">
<title><entity id="D08-1022.1">Forest-based</entity> <entity id="D08-1022.2">Translation</entity> <entity id="D08-1022.3">Rule</entity> <entity id="D08-1022.4">Extraction</entity></title> 
<abstract><entity id="D08-1022.5">Translation</entity> <entity id="D08-1022.6">rule</entity> <entity id="D08-1022.7">extraction</entity> is a fundamental <entity id="D08-1022.8">problem</entity> in <entity id="D08-1022.9">machine <entity id="D08-1022.10">translation</entity></entity> , especially for linguistically <entity id="D08-1022.11">syntax-based</entity> packed <entity id="D08-1022.12">forest</entity></abstract>


problem(D08-1022.7,D08-1022.9)

</text>

<text id="D08-1048">
<title><entity id="D08-1048.1">Automatic</entity> <entity id="D08-1048.2">induction</entity> of FrameNet <entity id="D08-1048.3">lexical</entity> <entity id="D08-1048.4">units</entity></title>
<abstract>
Most attempts to integrate FrameNet in <entity id="D08-1048.5">NLP systems</entity> have so far failed because of its limited <entity id="D08-1048.6">coverage</entity> . In this <entity id="D08-1048.7">paper</entity> , we investigate the <entity id="D08-1048.8">applicability</entity> of distributional and <entity id="D08-1048.9">WordNet-based <entity id="D08-1048.10">models</entity></entity> on the <entity id="D08-1048.11">task</entity> of <entity id="D08-1048.12">lexical</entity> <entity id="D08-1048.13">unit</entity> <entity id="D08-1048.14">induction</entity> ,
</abstract>


propose(D08-1048.7,D08-1048.8)
methodapplied(D08-1048.9,D08-1048.14)

</text>

<text id="I05-1037">
<title>
A Preliminary Work on Classifying <entity id="I05-1037.1">Time</entity> Granularities of Temporal <entity id="I05-1037.2">Questions</entity></title> 
<abstract><entity id="I05-1037.3">Abstract</entity> .
</abstract>



</text>

<text id="I05-1038">
<title><entity id="I05-1038.1">Classification</entity> of Multiple- <entity id="I05-1038.2">Sentence</entity> <entity id="I05-1038.3">Questions</entity></title> 
<abstract><entity id="I05-1038.4">Abstract</entity> .
</abstract>


model(I05-1038.1,I05-1038.3)

</text>

<text id="I05-1050">
<title><entity id="I05-1050.1">Automatic</entity> <entity id="I05-1050.2">Extraction</entity> of Fixed Multiword Expressions
</title>
<abstract><entity id="I05-1050.3">Abstract</entity> .
</abstract>



</text>

<text id="I05-1067">
<title>Using the <entity id="I05-1067.1">Structure</entity> of a Conceptual <entity id="I05-1067.2">Network</entity> in <entity id="I05-1067.3">Computing</entity> <entity id="I05-1067.4">Semantic</entity> <entity id="I05-1067.5">Relatedness</entity></title> 
<abstract><entity id="I05-1067.6">Abstract</entity> . proper
</abstract>


usedfor(I05-1067.1,I05-1067.3)

</text>

<text id="E99-1033">
<title>
Investigating NLG Architectures: Taking Style Into <entity id="E99-1033.1">Consideration</entity></title>
<abstract>
In this <entity id="E99-1033.2">paper</entity> we <entity id="E99-1033.3">propose</entity> a <entity id="E99-1033.4">methodology</entity> for investigating the <entity id="E99-1033.5">relationship</entity> between <entity id="E99-1033.6">architectures</entity> of <entity id="E99-1033.7">natural language generation</entity> (NLG)
</abstract>


propose(E99-1033.2,E99-1033.4)

</text>

<text id="E03-1010">
<title><entity id="E03-1010.1">Automatic <entity id="E03-1010.2">Evaluation</entity></entity> For A Palpable Measure Of A Speech <entity id="E03-1010.3">Translation <entity id="E03-1010.4">System</entity></entity> 's <entity id="E03-1010.5">Capability</entity></title>
<abstract>
The <entity id="E03-1010.6">main</entity> <entity id="E03-1010.7">goal</entity> of this <entity id="E03-1010.8">paper</entity> is to <entity id="E03-1010.9">propose</entity> <entity id="E03-1010.10">automatic</entity> <entity id="E03-1010.11">schemes</entity> for the <entity id="E03-1010.12">translation</entity> <entity id="E03-1010.13">paired</entity> <entity id="E03-1010.14">comparison</entity> <entity id="E03-1010.15">method</entity> . This <entity id="E03-1010.16">method</entity> was <entity id="E03-1010.17">proposed</entity> to precisely <entity id="E03-1010.18">evaluate</entity> a <entity id="E03-1010.19">speech translation</entity> <entity id="E03-1010.20">system</entity> 's <entity id="E03-1010.21">capability</entity> . Furthermore, the <entity id="E03-1010.22">method</entity> gives an <entity id="E03-1010.23">objective</entity> <entity id="E03-1010.24">evaluation <entity id="E03-1010.25">result</entity></entity> , i.e., a score of the <entity id="E03-1010.26">Test</entity> of <entity id="E03-1010.27">English</entity> for International <entity id="E03-1010.28">Communication</entity> (TOEIC). The TOEIC score is used as a measure of one's <entity id="E03-1010.29">speech translation</entity> <entity id="E03-1010.30">capability</entity> . However, this <entity id="E03-1010.31">method</entity> <entity id="E03-1010.32">requires</entity> tremendous <entity id="E03-1010.33">evaluation</entity> <entity id="E03-1010.34">costs</entity> . Accordingly, automatization of this <entity id="E03-1010.35">method</entity> is an important subject for <entity id="E03-1010.36">study</entity> . In the <entity id="E03-1010.37">proposed</entity> <entity id="E03-1010.38">method</entity> , currently available automatic <entity id="E03-1010.39">evaluation <entity id="E03-1010.40">methods</entity></entity> are <entity id="E03-1010.41">applied</entity> to automate the <entity id="E03-1010.42">translation</entity> <entity id="E03-1010.43">paired</entity> <entity id="E03-1010.44">comparison</entity> <entity id="E03-1010.45">method</entity> . In the <entity id="E03-1010.46">experiments</entity> , several <entity id="E03-1010.47">automatic evaluation</entity> <entity id="E03-1010.48">methods</entity> (BLEU, NIST, <entity id="E03-1010.49">DP-based method</entity> ) are <entity id="E03-1010.50">applied</entity> . The <entity id="E03-1010.51">experimental</entity> <entity id="E03-1010.52">results</entity> of these <entity id="E03-1010.53">automatic</entity> measures show a good <entity id="E03-1010.54">correlation</entity> with <entity id="E03-1010.55">evaluation <entity id="E03-1010.56">results</entity></entity> of the <entity id="E03-1010.57">translation</entity> <entity id="E03-1010.58">paired</entity> <entity id="E03-1010.59">comparison</entity> <entity id="E03-1010.60">method</entity> .
</abstract>


usedfor(E03-1010.1,E03-1010.3)
propose(E03-1010.8,E03-1010.11)
methodapplied(E03-1010.16,E03-1010.19)
yields(E03-1010.22,E03-1010.24)
usedfor(E03-1010.39,E03-1010.45)
wrt(E03-1010.52,E03-1010.55)

</text>

<text id="E03-1014">
<title>
Arabic <entity id="E03-1014.1">Syntactic</entity> Trees: From <entity id="E03-1014.2">Constituency</entity> To <entity id="E03-1014.3">Dependency</entity></title>
<abstract>
This <entity id="E03-1014.4">research</entity> <entity id="E03-1014.5">note</entity> <entity id="E03-1014.6">reports</entity> on the work in <entity id="E03-1014.7">progress</entity> which regards <entity id="E03-1014.8">automatic</entity> <entity id="E03-1014.9">transformation</entity> of <entity id="E03-1014.10">phrase-structure</entity> <entity id="E03-1014.11">syntactic</entity> <entity id="E03-1014.12">trees</entity> of Arabic into <entity id="E03-1014.13">dependency-driven</entity> analytical ones. <entity id="E03-1014.14">Guidelines</entity> for these <entity id="E03-1014.15">descriptions</entity> have been <entity id="E03-1014.16">developed</entity> at the Linguistic <entity id="E03-1014.17">Data</entity> Consortium, <entity id="E03-1014.18">University</entity> of Pennsylvania, and at the <entity id="E03-1014.19">Faculty</entity> of Mathematics and Physics and the <entity id="E03-1014.20">Faculty</entity> of Arts, Charles <entity id="E03-1014.21">University</entity> in Prague, respectively. The <entity id="E03-1014.22">transformation</entity> consists of (i) a recursive <entity id="E03-1014.23">function</entity> <entity id="E03-1014.24">translating</entity> the <entity id="E03-1014.25">topology</entity> of a <entity id="E03-1014.26">phrase</entity> <entity id="E03-1014.27">tree</entity> into a corresponding <entity id="E03-1014.28">dependency tree</entity> , and (ii) a <entity id="E03-1014.29">procedure</entity> assigning analytical <entity id="E03-1014.30">functions</entity> to the <entity id="E03-1014.31">nodes</entity> of the <entity id="E03-1014.32">dependency <entity id="E03-1014.33">tree</entity></entity> . Apart from an <entity id="E03-1014.34">outline</entity> of the annotation <entity id="E03-1014.35">schemes</entity> and a deeper <entity id="E03-1014.36">insight</entity> into these <entity id="E03-1014.37">procedures</entity> , <entity id="E03-1014.38">model</entity> <entity id="E03-1014.39">application</entity> of the <entity id="E03-1014.40">transformation</entity> is given herein.
</abstract>


propose(E03-1014.4,E03-1014.9)
usedfor(E03-1014.14,E03-1014.15)
taskapplied(E03-1014.24,E03-1014.27)
part_of(E03-1014.31,E03-1014.32)
model(E03-1014.38,E03-1014.40)

</text>

<text id="N03-1008">
<title>
Latent <entity id="N03-1008.1">Semantic Information</entity> In <entity id="N03-1008.2">Maximum Entropy</entity> <entity id="N03-1008.3">Language</entity> <entity id="N03-1008.4">Models</entity> For Conversational <entity id="N03-1008.5">Speech <entity id="N03-1008.6">Recognition</entity></entity></title> 
<abstract><entity id="N03-1008.7">Latent <entity id="N03-1008.8">semantic analysis</entity></entity> (LSA), first exploited in <entity id="N03-1008.9">indexing</entity> <entity id="N03-1008.10">documents</entity> for <entity id="N03-1008.11">information <entity id="N03-1008.12">retrieval</entity></entity> , has since been used by several <entity id="N03-1008.13">researchers</entity> to demonstrate impressive <entity id="N03-1008.14">reductions</entity> in the <entity id="N03-1008.15">perplexity</entity> of <entity id="N03-1008.16">statistical language models</entity> on <entity id="N03-1008.17">text</entity> <entity id="N03-1008.18">corpora</entity> such as the <entity id="N03-1008.19">Wall Street Journal</entity> . In this <entity id="N03-1008.20">paper</entity> we present an <entity id="N03-1008.21">investigation</entity> into the use of LSA in <entity id="N03-1008.22">language <entity id="N03-1008.23">modeling</entity></entity> for conversational <entity id="N03-1008.24">speech <entity id="N03-1008.25">recognition</entity></entity> . We find that previously <entity id="N03-1008.26">proposed</entity> <entity id="N03-1008.27">methods</entity> of combining an LSA-based unigram <entity id="N03-1008.28">model</entity> with an N- <entity id="N03-1008.29">feature</entity></abstract>


model(N03-1008.4,N03-1008.5)
usedfor(N03-1008.7,N03-1008.11)
wrt(N03-1008.14,N03-1008.15)
propose(N03-1008.20,N03-1008.21)
usedfor(N03-1008.22,N03-1008.24)

</text>

<text id="N03-1013">
<title>
A Categorial <entity id="N03-1013.1">Variation</entity> <entity id="N03-1013.2">Database</entity> For <entity id="N03-1013.3">English</entity></title>
<abstract>
"We describe our <entity id="N03-1013.4">approach</entity> to the <entity id="N03-1013.5">construction</entity> and <entity id="N03-1013.6">evaluation</entity> of a <entity id="N03-1013.7">large-scale</entity> <entity id="N03-1013.8">database</entity> <entity id="N03-1013.9">called</entity> ""CatVar"" which contains categorial <entity id="N03-1013.10">variations</entity> of <entity id="N03-1013.11">English</entity> lexemes. <entity id="N03-1013.12">Due</entity> to the prevalence of <entity id="N03-1013.13">cross-language</entity> categorial <entity id="N03-1013.14">variation</entity> in multilingual <entity id="N03-1013.15">applications</entity> , our <entity id="N03-1013.16">categorial-variation</entity> <entity id="N03-1013.17">resource</entity> may serve as an integral <entity id="N03-1013.18">part</entity> of a diverse range of <entity id="N03-1013.19">natural language</entity> <entity id="N03-1013.20">applications</entity> . Thus, the <entity id="N03-1013.21">research</entity> <entity id="N03-1013.22">reported</entity> herein overlaps heavily with that of the <entity id="N03-1013.23">machine-translation</entity> , <entity id="N03-1013.24">lexicon-construction</entity> , and <entity id="N03-1013.25">information-retrieval</entity> <entity id="N03-1013.26">communities</entity> . We <entity id="N03-1013.27">apply</entity> the <entity id="N03-1013.28">information-retrieval</entity> <entity id="N03-1013.29">metrics</entity> of <entity id="N03-1013.30">precision</entity> and <entity id="N03-1013.31">recall</entity> to <entity id="N03-1013.32">evaluate</entity> the <entity id="N03-1013.33">accuracy</entity> and <entity id="N03-1013.34">coverage</entity> of our <entity id="N03-1013.35">database</entity> with <entity id="N03-1013.36">respect</entity> to a human-produced <entity id="N03-1013.37">gold <entity id="N03-1013.38">standard</entity></entity> . This <entity id="N03-1013.39">evaluation</entity> reveals that the categorial <entity id="N03-1013.40">database</entity> achieves a high <entity id="N03-1013.41">degree</entity> of <entity id="N03-1013.42">precision</entity> and <entity id="N03-1013.43">recall</entity> . Additionally, we demonstrate that the <entity id="N03-1013.44">database</entity> <entity id="N03-1013.45">improves</entity> on the linkability of Porter stemmer by over 30%. "
</abstract>


composed_of(N03-1013.8,N03-1013.10)
part_of(N03-1013.17,N03-1013.20)
compare(N03-1013.33,N03-1013.37)

</text>

<text id="M91-1007">
<title>
GE NLTOOLSET: MUC-3 <entity id="M91-1007.1">Test</entity> <entity id="M91-1007.2">Results</entity> And <entity id="M91-1007.3">Analysis</entity></title>
<abstract>
This <entity id="M91-1007.4">paper</entity> <entity id="M91-1007.5">reports</entity> on the GE NLTOOLSET customization <entity id="M91-1007.6">effort</entity> for MUC-3, and analyzes the <entity id="M91-1007.7">results</entity> of the TST2 run. Although our own <entity id="M91-1007.8">tests</entity> had shown steady <entity id="M91-1007.9">improvement</entity> between TST1 and TST2, our official scores on TST2 were lo wer than on TST1. The <entity id="M91-1007.10">analysis</entity> of this unexpected <entity id="M91-1007.11">result</entity> explains some of the <entity id="M91-1007.12">details</entity> of th e MUC-3 <entity id="M91-1007.13">test</entity> , and we <entity id="M91-1007.14">propose</entity> ways of looking at the scores to distinguish different <entity id="M91-1007.15">aspects</entity> of <entity id="M91-1007.16">system</entity> <entity id="M91-1007.17">performance</entity> .
</abstract>


study(M91-1007.10,M91-1007.11)

</text>

<text id="M92-1004">
<title><entity id="M92-1004.1">Text</entity> Filtering In MUC-3 And MUC-4
</title>
<abstract>
"One of the changes from the Third (MUC-3) to the Fourth (MUC-4) <entity id="M92-1004.2">Message</entity> <entity id="M92-1004.3">Understanding</entity> Conference was the emergence of <entity id="M92-1004.4">text</entity> filtering as an explicit <entity id="M92-1004.5">topic</entity> of <entity id="M92-1004.6">discussion</entity> . In this <entity id="M92-1004.7">paper</entity> we examine <entity id="M92-1004.8">text</entity> filtering in MUC <entity id="M92-1004.9">systems</entity> with three <entity id="M92-1004.10">goals</entity> in mind. First, we clarify the <entity id="M92-1004.11">difference</entity> between two uses of the <entity id="M92-1004.12">term</entity> ""<entity id="M92-1004.13">text</entity> filtering"" in the <entity id="M92-1004.14">context</entity> of <entity id="M92-1004.15">data</entity> <entity id="M92-1004.16">extraction systems</entity> , and put these <entity id="M92-1004.17">phenomena</entity> in the <entity id="M92-1004.18">context</entity> of prior <entity id="M92-1004.19">research</entity> on <entity id="M92-1004.20">information retrieval</entity> (IR). Secondly, we discuss the use of <entity id="M92-1004.21">text</entity> filtering <entity id="M92-1004.22">components</entity> in MUC-3 and MUC-4 <entity id="M92-1004.23">systems</entity> , and present a preliminary <entity id="M92-1004.24">scheme</entity> for classifying <entity id="M92-1004.25">data</entity> <entity id="M92-1004.26">extraction <entity id="M92-1004.27">systems</entity></entity> in <entity id="M92-1004.28">terms</entity> of the <entity id="M92-1004.29">features</entity> over which they do <entity id="M92-1004.30">text</entity> filtering. Finally, we examine the <entity id="M92-1004.31">text</entity> filtering <entity id="M92-1004.32">effectiveness</entity> of MUC-3 and MUC-4 <entity id="M92-1004.33">systems</entity> , and introduce some <entity id="M92-1004.34">approaches</entity> to the <entity id="M92-1004.35">evaluation</entity> of <entity id="M92-1004.36">text</entity> filtering <entity id="M92-1004.37">systems</entity> which may be of interest themselves. Two <entity id="M92-1004.38">questions</entity> of crucial interest are whether <entity id="M92-1004.39">sites</entity> <entity id="M92-1004.40">improved</entity> their <entity id="M92-1004.41">system</entity> <entity id="M92-1004.42">level</entity> <entity id="M92-1004.43">text</entity> filtering <entity id="M92-1004.44">effectiveness</entity> from MUC-3 to MUC-4, and what the <entity id="M92-1004.45">effectiveness</entity> of MUC <entity id="M92-1004.46">systems</entity> would be on <entity id="M92-1004.47">real world</entity> <entity id="M92-1004.48">data</entity> <entity id="M92-1004.49">streams</entity> . Because of changes in both <entity id="M92-1004.50">test set</entity> and <entity id="M92-1004.51">system</entity> <entity id="M92-1004.52">design</entity> since MUC-3 we were not able to address the first <entity id="M92-1004.53">question</entity> . However, with <entity id="M92-1004.54">respect</entity> to the second <entity id="M92-1004.55">question</entity> , we present preliminary <entity id="M92-1004.56">evidence</entity> suggesting that the <entity id="M92-1004.57">text</entity> filtering <entity id="M92-1004.58">precision</entity> of MUC <entity id="M92-1004.59">systems</entity> declines with the <entity id="M92-1004.60">generality</entity> of the <entity id="M92-1004.61">data</entity> <entity id="M92-1004.62">stream</entity> they <entity id="M92-1004.63">process</entity> , i.e. the proportion of relevant <entity id="M92-1004.64">documents</entity> . The ramifications of this for future <entity id="M92-1004.65">research</entity> and for operational <entity id="M92-1004.66">systems</entity> are discussed. "
</abstract>


propose(M92-1004.7,M92-1004.8)
part_of(M92-1004.22,M92-1004.23)
model(M92-1004.24,M92-1004.26)
usedfor(M92-1004.34,M92-1004.35)
affects(M92-1004.58,M92-1004.60,REVERSE)

</text>

<text id="A83-1012">
<title><entity id="A83-1012.1">Knowledge Based</entity> <entity id="A83-1012.2">Question Answering</entity></title>



</text>

<abstract></abstract>

<text id="A83-1015">
<title>
The Fitted <entity id="A83-1015.1">Parse</entity> : 100% <entity id="A83-1015.2">Parsing</entity> <entity id="A83-1015.3">Capability</entity> In A <entity id="A83-1015.4">Syntactic</entity> Grammar Of <entity id="A83-1015.5">English</entity></title>
<abstract>
A <entity id="A83-1015.6">technique</entity> is described for <entity id="A83-1015.7">performing</entity> fitted
</abstract>



</text>

<text id="T87-1017">
<title>
Possible Implications Of Connectionism
</title>
<abstract>
As far as I can tell the most exciting thing happening in AI these days is the invasion of the brain people (a.k.a. the connectionists). The connectionists haven't really invaded the AI <entity id="T87-1017.1">community</entity> in the <entity id="T87-1017.2">sense</entity> of making a planned assault - it just seems that connectionism is the sexiest thing around. The AI <entity id="T87-1017.3">community</entity> has very suddenly become very interested in connectionist <entity id="T87-1017.4">techniques</entity> and it is only a slight exaggeration for me to say that all the first year <entity id="T87-1017.5">graduate</entity> students I meet express an interest in connectionism. So perhaps it would be useful to talk about the <entity id="T87-1017.6">status</entity> of connectionism with <entity id="T87-1017.7">respect</entity> to the old formal/commonsense <entity id="T87-1017.8">semantic</entity> <entity id="T87-1017.9">arguments</entity> . Let's try to pigeon-hole this new <entity id="T87-1017.10">paradigm</entity> in <entity id="T87-1017.11">terms</entity> of our old formal/procedural/episodic/ <entity id="T87-1017.12">semantic</entity> <entity id="T87-1017.13">distinctions</entity> and see what happens.
</abstract>



</text>

<text id="H89-1013">
<title><entity id="H89-1013.1">Portability</entity> In The JANUS <entity id="H89-1013.2">Natural Language Interface</entity></title> 
<abstract>Ballard , Bruce W.; Stumberger , Douglas E., <entity id="H89-1013.3">Semantic</entity> <entity id="H89-1013.4">Acquisition</entity> In TELL: A Transportable, <entity id="H89-1013.5">User-</entity> Customized <entity id="H89-1013.6">Natural Language Processor</entity> ,Annual Meeting Of The <entity id="H89-1013.7">Association</entity> For <entity id="H89-1013.8">Computation</entity> al <entity id="H89-1013.9">Linguistics</entity> ,1986 *** Ayuso , Damaris M.; Shaked , Varda ; Weischedel , Ralph M. ,An <entity id="H89-1013.10">Environment</entity> For Acquiring <entity id="H89-1013.11">Semantic Information</entity> ,Annual Meeting Of The <entity id="H89-1013.12">Association</entity> For <entity id="H89-1013.13">Computation</entity> al <entity id="H89-1013.14">Linguistics</entity> ,1987</abstract>



</text>

<text id="H89-1039">
<title>
A Preprocessor For <entity id="H89-1039.1">Speech Recognition</entity> <entity id="H89-1039.2">Systems</entity> Operating In Noisy Environments
</title>



</text>

<abstract></abstract>

<text id="H89-1040">
<title>
Auditory <entity id="H89-1040.1">Speech</entity> Preprocessors
</title>



</text>

<abstract></abstract>

<text id="X93-1015">
<title><entity id="X93-1015.1">Template</entity> <entity id="X93-1015.2">Design</entity> For <entity id="X93-1015.3">Information <entity id="X93-1015.4">Extraction</entity></entity></title>
<abstract>
The <entity id="X93-1015.5">design</entity> of the <entity id="X93-1015.6">template</entity> for an <entity id="X93-1015.7">information extraction</entity> <entity id="X93-1015.8">application</entity> (or exercise) reflects the <entity id="X93-1015.9">nature</entity> of the <entity id="X93-1015.10">task</entity> and therefore crucially <entity id="X93-1015.11">affects</entity> the <entity id="X93-1015.12">success</entity> of the attempt to capture <entity id="X93-1015.13">information</entity> from <entity id="X93-1015.14">text</entity> . This <entity id="X93-1015.15">paper</entity> addresses the <entity id="X93-1015.16">template</entity> <entity id="X93-1015.17">design</entity> <entity id="X93-1015.18">requirement</entity> by discussing the general <entity id="X93-1015.19">principles</entity> or <entity id="X93-1015.20">template</entity> <entity id="X93-1015.21">definition</entity> <entity id="X93-1015.22">effort</entity> which is explicitly discussed in a <entity id="X93-1015.23">Case <entity id="X93-1015.24">Study</entity></entity> in the last <entity id="X93-1015.25">section</entity> of this <entity id="X93-1015.26">paper</entity> .
</abstract>


usedfor(X93-1015.2,X93-1015.3)
usedfor(X93-1015.6,X93-1015.8)
propose(X93-1015.15,X93-1015.19)
propose(X93-1015.23,X93-1015.25,REVERSE)

</text>

<text id="X96-1027">
<title>
TIPSTER-Compatible Projects At Sheffield
</title>
<abstract>
	"Boitet, Christian; Seligman , Mark ,The ""Whiteboard"" <entity id="X96-1027.1">Architecture</entity> : A Way To Integrate Heterogeneous Components Of NLP <entity id="X96-1027.2">Systems</entity> ,International Conference On <entity id="X96-1027.3">Computation</entity> al <entity id="X96-1027.4">Linguistics</entity> ,1994 ***Gaizauskas, Robert J. ; Wakao, Takahiro ; Humphreys , Kevin ; Cunningham , Hamish ; Wilks , Yorick, <entity id="X96-1027.5">University</entity> Of Sheffield: <entity id="X96-1027.6">Description</entity> Of The LaSIE <entity id="X96-1027.7">System</entity> As Used For MUC-6, <entity id="X96-1027.8">Message</entity> <entity id="X96-1027.9">Understanding</entity> Conference,1995 "
</abstract>



</text>

<text id="W90-0111">
<title><entity id="W90-0111.1">Selection</entity> : Salience, <entity id="W90-0111.2">Relevance</entity> And The Coupling Between <entity id="W90-0111.3">Domain-</entity> <entity id="W90-0111.4">Level</entity> Tasks And <entity id="W90-0111.5">Text</entity> Planning
</title>
<abstract>
In this <entity id="W90-0111.6">paper</entity> we examine some <entity id="W90-0111.7">issues</entity> pertaining to the <entity id="W90-0111.8">task</entity> of <entity id="W90-0111.9">selection</entity> in <entity id="W90-0111.10">text</entity> planning. We attempt to distinguish salience and <entity id="W90-0111.11">relevance</entity> , and characterize their <entity id="W90-0111.12">role</entity> as important fundamental <entity id="W90-0111.13">notions</entity> governing <entity id="W90-0111.14">selection</entity> . We also formulate the <entity id="W90-0111.15">problem</entity> of <entity id="W90-0111.16">selection</entity> of <entity id="W90-0111.17">text</entity> <entity id="W90-0111.18">content</entity> in <entity id="W90-0111.19">terms</entity> of the coupling between <entity id="W90-0111.20">domain-level</entity> <entity id="W90-0111.21">tasks</entity> and <entity id="W90-0111.22">text</entity> planning <entity id="W90-0111.23">tasks</entity> . We describe our <entity id="W90-0111.24">research</entity> on <entity id="W90-0111.25">generating</entity> bus <entity id="W90-0111.26">route</entity> <entity id="W90-0111.27">descriptions</entity> .Keywords: <entity id="W90-0111.28">Natural Language Generation</entity> , <entity id="W90-0111.29">Text</entity> Planning, <entity id="W90-0111.30">Selection</entity> , Salience, <entity id="W90-0111.31">Relevance</entity> , Coupling, <entity id="W90-0111.32">Route</entity> Descriptions
</abstract>


propose(W90-0111.6,W90-0111.7)
study(W90-0111.24,W90-0111.27)

</text>

<text id="W93-0213">
<title>
Using <entity id="W93-0213.1">Cue</entity> Phrases To Determine Rhetorical <entity id="W93-0213.2">Relations</entity></title>
<abstract>
'<entity id="W93-0213.3">Relation</entity> <entity id="W93-0213.4">based</entity> ' <entity id="W93-0213.5">approaches</entity> to <entity id="W93-0213.6">discourse <entity id="W93-0213.7">analysis</entity></entity> and <entity id="W93-0213.8">text generation</entity> suffer from a <entity id="W93-0213.9">common</entity> <entity id="W93-0213.10">problem</entity> : there is considerable <entity id="W93-0213.11">disagreement</entity> between <entity id="W93-0213.12">researchers</entity> over the set of <entity id="W93-0213.13">relations</entity> which is <entity id="W93-0213.14">proposed</entity> . Few <entity id="W93-0213.15">researchers</entity> use identical sets of <entity id="W93-0213.16">relations</entity> , and many use <entity id="W93-0213.17">relations</entity> not found in any other sets. This proliferation of <entity id="W93-0213.18">relations</entity> has been pointed out before (eg Hovy [1]), and several <entity id="W93-0213.19">methods</entity> for justifying a <entity id="W93-0213.20">standard</entity> set of <entity id="W93-0213.21">relations</entity> have been <entity id="W93-0213.22">proposed</entity> : this <entity id="W93-0213.23">paper</entity> <entity id="W93-0213.24">reviews</entity> some of these, and presents a new <entity id="W93-0213.25">method</entity> of <entity id="W93-0213.26">justification</entity> which overcomes some awkward <entity id="W93-0213.27">problems</entity> .
</abstract>


usedfor(W93-0213.5,W93-0213.6)
propose(W93-0213.23,W93-0213.25)

</text>

<text id="W93-0229">
<title>
A <entity id="W93-0229.1">Model</entity> Of <entity id="W93-0229.2">Speech Act</entity> Planner <entity id="W93-0229.3">Adapted</entity> To Multiagent Universes
</title>
<abstract>Grosz , Barbara J.; Sidner , Candace L. ,Attention, Intentions, And The <entity id="W93-0229.4">Structure</entity> Of <entity id="W93-0229.5">Discourse</entity> , <entity id="W93-0229.6">Computation</entity> al <entity id="W93-0229.7">Linguistics</entity> ,1986 *** Lambert , Lynn ; Carberry , Sandra , <entity id="W93-0229.8">Modeling</entity> Negotiation Subdialogues,Annual Meeting Of The <entity id="W93-0229.9">Association</entity> For <entity id="W93-0229.10">Computation</entity> al <entity id="W93-0229.11">Linguistics</entity> ,1992</abstract>



</text>

<text id="W93-0231">
<title><entity id="W93-0231.1">Domain</entity> <entity id="W93-0231.2">Structure</entity> , Rhetorical <entity id="W93-0231.3">Structure</entity> , And <entity id="W93-0231.4">Text Structure</entity></title>
<abstract>
It is generally agreed that <entity id="W93-0231.5">text</entity> has <entity id="W93-0231.6">structure</entity> (at least, coherent <entity id="W93-0231.7">text</entity> does). Therefore, an <entity id="W93-0231.8">understanding</entity> and appreciation of <entity id="W93-0231.9">text <entity id="W93-0231.10">structure</entity></entity> must play some <entity id="W93-0231.11">role</entity> in building <entity id="W93-0231.12">computational</entity> <entity id="W93-0231.13">systems</entity> that are capable of using <entity id="W93-0231.14">text</entity> as people do. What is less clear is what are necessary and sufficient <entity id="W93-0231.15">sources</entity> of structure for a text-using system , and further, what such a <entity id="W93-0231.16">system</entity> needs to know about and do with these <entity id="W93-0231.17">structures</entity> in the <entity id="W93-0231.18">process</entity> of using <entity id="W93-0231.19">text</entity> . By using <entity id="W93-0231.20">text</entity> , I mean <entity id="W93-0231.21">understanding</entity> it or producing it; speaking it, writing it, or thinking about it. Li this <entity id="W93-0231.22">paper</entity> , I present a <entity id="W93-0231.23">case</entity> for the <entity id="W93-0231.24">importance</entity> of <entity id="W93-0231.25">domain</entity> <entity id="W93-0231.26">structure</entity> in <entity id="W93-0231.27">structuring</entity> <entity id="W93-0231.28">text</entity> , and discuss the <entity id="W93-0231.29">role</entity> of rhetorical <entity id="W93-0231.30">structure</entity> and intentionality.
</abstract>


char(W93-0231.5,W93-0231.6,REVERSE)
study(W93-0231.8,W93-0231.9)
propose(W93-0231.22,W93-0231.23)
affects(W93-0231.26,W93-0231.28)

</text>

<text id="W93-0311">
<title><entity id="W93-0311.1">Corpus-</entity> <entity id="W93-0311.2">Based</entity> <entity id="W93-0311.3">Adaptation</entity> Mechanisms For <entity id="W93-0311.4">Chinese</entity> Homophone <entity id="W93-0311.5">Disambiguation</entity></title> 
<abstract><entity id="W93-0311.6">Based</entity> on the <entity id="W93-0311.7">concepts</entity> of bidirectional <entity id="W93-0311.8">conversion</entity> and <entity id="W93-0311.9">automatic evaluation</entity> , we <entity id="W93-0311.10">propose</entity> two nser-adapiation <entity id="W93-0311.11">mechanisms</entity> , <entity id="W93-0311.12">character-preference</entity> <entity id="W93-0311.13">learning</entity> and <entity id="W93-0311.14">pstlido-word</entity> <entity id="W93-0311.15">learning</entity> , for resolving <entity id="W93-0311.16">Chinese</entity> homophone <entity id="W93-0311.17">ambiguities</entity> in syllable-to-character <entity id="W93-0311.18">conversion</entity> . The 1991  United Daily <entity id="W93-0311.19">corpus</entity> oj approximately 10 million <entity id="W93-0311.20">Chinese</entity> characters is used for <entity id="W93-0311.21">extraction</entity> of 10 reporter-specific article <entity id="W93-0311.22">databases</entity> and for <entity id="W93-0311.23">computation</entity> of <entity id="W93-0311.24">word</entity> <entity id="W93-0311.25">frequencies</entity> and character bi-grams. <entity id="W93-0311.26">Experiments</entity> show that 20.5 percent (testing sets) to 71.8 percent ( <entity id="W93-0311.27">training sets</entity> ) of <entity id="W93-0311.28">conversion</entity> <entity id="W93-0311.29">errors</entity> can be eliminated through the <entity id="W93-0311.30">proposed</entity> <entity id="W93-0311.31">mechanisms</entity> . These <entity id="W93-0311.32">concepts</entity> are thus very useful m <entity id="W93-0311.33">applications</entity> such as <entity id="W93-0311.34">Chinese</entity> <entity id="W93-0311.35">input</entity> <entity id="W93-0311.36">methods</entity> and <entity id="W93-0311.37">speech recognition systems</entity></abstract>


usedfor(W93-0311.3,W93-0311.5)
problem(W93-0311.17,W93-0311.18)
datasource(W93-0311.19,W93-0311.22,REVERSE)

</text>

<text id="W94-0330">
<title>
Semanitic <entity id="W94-0330.1">Syntax</entity> At Work
</title>



</text>

<abstract></abstract>

<text id="W95-0109">
<title><entity id="W95-0109.1">Automatic</entity> <entity id="W95-0109.2">Construction</entity> Of A <entity id="W95-0109.3">Chinese</entity> <entity id="W95-0109.4">Electronic Dictionary</entity></title>
<abstract>
    In this <entity id="W95-0109.5">paper</entity> , an unsupervised <entity id="W95-0109.6">approach</entity> for <entity id="W95-0109.7">constructing</entity> a <entity id="W95-0109.8">large-scale</entity> <entity id="W95-0109.9">Chinese</entity> <entity id="W95-0109.10">electronic dictionary</entity> is <entity id="W95-0109.11">surveyed</entity> . The <entity id="W95-0109.12">main</entity> <entity id="W95-0109.13">purpose</entity> is to enable cheap and quick <entity id="W95-0109.14">acquisition</entity> of a <entity id="W95-0109.15">large-scale</entity> <entity id="W95-0109.16">dictionary</entity> from a large untagged <entity id="W95-0109.17">text</entity> <entity id="W95-0109.18">corpus</entity> with the aid of the <entity id="W95-0109.19">information</entity> in a small <entity id="W95-0109.20">tagged</entity> <entity id="W95-0109.21">seed</entity> <entity id="W95-0109.22">corpus</entity> . The <entity id="W95-0109.23">basic</entity> <entity id="W95-0109.24">model</entity> is <entity id="W95-0109.25">based</entity> on a Viterbi reestimation <entity id="W95-0109.26">technique</entity> . During the <entity id="W95-0109.27">dictionary</entity> <entity id="W95-0109.28">construction</entity> <entity id="W95-0109.29">process</entity> , it tries to optimize the <entity id="W95-0109.30">automatic</entity> segmentation and <entity id="W95-0109.31">tagging</entity> <entity id="W95-0109.32">process</entity> by repeatedly refining the set of <entity id="W95-0109.33">parameters</entity> of the underlying <entity id="W95-0109.34">language <entity id="W95-0109.35">model</entity></entity> . The refined <entity id="W95-0109.36">parameters</entity> are then used to further get a better <entity id="W95-0109.37">tagging</entity> <entity id="W95-0109.38">result</entity> . In <entity id="W95-0109.39">addition</entity> , a <entity id="W95-0109.40">two-class</entity> <entity id="W95-0109.41">classifier</entity> , which is capable of classifying an <entity id="W95-0109.42">n-gram</entity> either as a <entity id="W95-0109.43">word</entity> or a <entity id="W95-0109.44">non-word</entity> , is used in <entity id="W95-0109.45">combination</entity> with the Viterbi <entity id="W95-0109.46">training</entity> <entity id="W95-0109.47">module</entity> to <entity id="W95-0109.48">improve</entity> the <entity id="W95-0109.49">system</entity> <entity id="W95-0109.50">performance</entity> . Two different <entity id="W95-0109.51">system</entity> <entity id="W95-0109.52">configurations</entity> had been <entity id="W95-0109.53">developed</entity> to <entity id="W95-0109.54">construct</entity> the <entity id="W95-0109.55">dictionary</entity> . The <entity id="W95-0109.56">configurations</entity> <entity id="W95-0109.57">include</entity> (1) a Viterbi <entity id="W95-0109.58">word</entity> <entity id="W95-0109.59">identification</entity> <entity id="W95-0109.60">module</entity> followed by a Viterbi <entity id="W95-0109.61">POS tagging</entity> <entity id="W95-0109.62">module</entity> and (2) a <entity id="W95-0109.63">two-class</entity> <entity id="W95-0109.64">classification</entity> <entity id="W95-0109.65">module</entity> as the postfilter for the above Viterbi <entity id="W95-0109.66">word</entity> <entity id="W95-0109.67">identification</entity> <entity id="W95-0109.68">module</entity> . With a <entity id="W95-0109.69">seed</entity> of 1,000 <entity id="W95-0109.70">sentences</entity> and an untagged <entity id="W95-0109.71">corpus</entity> of 311,591 <entity id="W95-0109.72">sentences</entity> , the <entity id="W95-0109.73">performance</entity> for bigram <entity id="W95-0109.74">word</entity> <entity id="W95-0109.75">identification</entity> is 56.88% in <entity id="W95-0109.76">precision</entity> and 77.37% in <entity id="W95-0109.77">recall</entity> when the <entity id="W95-0109.78">two-class </entity><entity id="W95-0109.79">classifier</entity> is <entity id="W95-0109.80">applied</entity> to the <entity id="W95-0109.81">word</entity> <entity id="W95-0109.82">list</entity> suggested by the Viterbi <entity id="W95-0109.83">word</entity> <entity id="W95-0109.84">identification</entity> <entity id="W95-0109.85">module</entity> . The Viterbi <entity id="W95-0109.86">part of <entity id="W95-0109.87">speech</entity> <entity id="W95-0109.88">tag</entity></entity> reestimation stage gives the <entity id="W95-0109.89">figures</entity> of 71.16% and 71.81% weighted <entity id="W95-0109.90">precision</entity> <entity id="W95-0109.91">rates</entity> and 73.42% and 73.83% weighted <entity id="W95-0109.92">recall</entity> <entity id="W95-0109.93">rates</entity> for the 2 different <entity id="W95-0109.94">configurations</entity> when using a <entity id="W95-0109.95">seed</entity> <entity id="W95-0109.96">corpus</entity> of 9676 <entity id="W95-0109.97">sentences</entity> .
</abstract>


propose(W95-0109.5,W95-0109.6)
datasource(W95-0109.16,W95-0109.18)
datasource(W95-0109.19,W95-0109.22)
based_on(W95-0109.24,W95-0109.26)
based_on(W95-0109.32,W95-0109.34)
usedfor(W95-0109.36,W95-0109.37)
taskapplied(W95-0109.41,W95-0109.42)
part_of(W95-0109.56,W95-0109.60,REVERSE)
yields(W95-0109.75,W95-0109.76)
taskapplied(W95-0109.79,W95-0109.82)
yields(W95-0109.86,W95-0109.91)

</text>

<text id="W96-0201">
<title>
A Geometric <entity id="W96-0201.1">Approach</entity> To <entity id="W96-0201.2">Mapping</entity> Bitext <entity id="W96-0201.3">Correspondence</entity></title>
<abstract>
The <entity id="W96-0201.4">first step</entity> in most <entity id="W96-0201.5">corpus-based</entity> multilingual NLP work is to <entity id="W96-0201.6">construct</entity> a <entity id="W96-0201.7">detailed</entity> <entity id="W96-0201.8">map</entity> of the <entity id="W96-0201.9">correspondence</entity> between a <entity id="W96-0201.10">text</entity> and its <entity id="W96-0201.11">translation</entity> . Several <entity id="W96-0201.12">automatic</entity> <entity id="W96-0201.13">methods</entity> for this <entity id="W96-0201.14">task</entity> have been <entity id="W96-0201.15">proposed</entity> in recent years. Yet even the best of these <entity id="W96-0201.16">methods</entity> can err by several typeset <entity id="W96-0201.17">pages</entity> . The <entity id="W96-0201.18">Smooth</entity> Injective <entity id="W96-0201.19">Map</entity> Recognizer (SIMR) is a new bitext <entity id="W96-0201.20">mapping</entity> <entity id="W96-0201.21">algorithm</entity> . SIMR's <entity id="W96-0201.22">errors</entity> are smaller than those of the previous front-runner by more than a <entity id="W96-0201.23">factor</entity> of 4. Its <entity id="W96-0201.24">robustness</entity> has enabled new <entity id="W96-0201.25">commercial-quality</entity> <entity id="W96-0201.26">applications</entity> . The greedy <entity id="W96-0201.27">nature</entity> of the <entity id="W96-0201.28">algorithm</entity> makes it independent of <entity id="W96-0201.29">memory</entity> <entity id="W96-0201.30">resources</entity> . Unlike other bitext <entity id="W96-0201.31">mapping</entity> <entity id="W96-0201.32">algorithms</entity> , SIMR allows <entity id="W96-0201.33">crossing</entity> <entity id="W96-0201.34">correspondences</entity> to account for <entity id="W96-0201.35">word</entity> <entity id="W96-0201.36">order</entity> <entity id="W96-0201.37">differences</entity> . Its <entity id="W96-0201.38">output</entity> can be converted quickly and easily into a <entity id="W96-0201.39">sentence</entity> <entity id="W96-0201.40">alignment</entity> . SIMR's <entity id="W96-0201.41">output</entity> has been used to align more than 200 megabytes of the Canadian Hansards for publication by the Linguistic <entity id="W96-0201.42">Data</entity> Consortium.
</abstract>


usedfor(W96-0201.1,W96-0201.2)
model(W96-0201.8,W96-0201.9)
isa(W96-0201.18,W96-0201.21)

</text>

<text id="W96-0210">
<title>
The Measure Of A <entity id="W96-0210.1">Model</entity></title>
<abstract>
This <entity id="W96-0210.2">paper</entity> describes measures for <entity id="W96-0210.3">evaluating</entity> the three determinants of how well a probabilistic <entity id="W96-0210.4">classifier</entity> <entity id="W96-0210.5">performs</entity> on a given <entity id="W96-0210.6">test set</entity> . These determinants are the <entity id="W96-0210.7">appropriateness</entity> , for the <entity id="W96-0210.8">test set</entity> , of the <entity id="W96-0210.9">results</entity> of (1) <entity id="W96-0210.10">feature selection</entity> , (2) <entity id="W96-0210.11">formulation</entity> of the parametric <entity id="W96-0210.12">form</entity> of the <entity id="W96-0210.13">model</entity> , and (3) <entity id="W96-0210.14">parameter estimation</entity> . These are <entity id="W96-0210.15">part</entity> of any <entity id="W96-0210.16">model</entity> <entity id="W96-0210.17">formulation</entity> <entity id="W96-0210.18">procedure</entity> , even if not broken out as separate <entity id="W96-0210.19">steps</entity> , so the tradeoffs explored in this <entity id="W96-0210.20">paper</entity> are relevant to a wide <entity id="W96-0210.21">variety</entity> of <entity id="W96-0210.22">methods</entity> . The measures are demonstrated in a large <entity id="W96-0210.23">experiment</entity> , in which they are used to analyze the <entity id="W96-0210.24">results</entity> of roughly 300 <entity id="W96-0210.25">classifiers</entity> that <entity id="W96-0210.26">perform</entity> <entity id="W96-0210.27"><entity id="W96-0210.28">word-sense</entity> <entity id="W96-0210.29">disambiguation</entity></entity> .
</abstract>


taskapplied(W96-0210.4,W96-0210.6)
char(W96-0210.7,W96-0210.9)
usedfor(W96-0210.25,W96-0210.27)

</text>

<text id="W96-0404">
<title>
Approximate <entity id="W96-0404.1">Generation</entity> From Non-Hierarchical Representations
</title>
<abstract>
This <entity id="W96-0404.2">paper</entity> presents a <entity id="W96-0404.3">technique</entity> for <entity id="W96-0404.4">sentence generation</entity> . We argue that the <entity id="W96-0404.5">input</entity> to <entity id="W96-0404.6">generators</entity> should have a non-hierarchical <entity id="W96-0404.7">nature</entity> . This allows us to investigate a more general <entity id="W96-0404.8">version</entity> of the <entity id="W96-0404.9">sentence generation</entity> <entity id="W96-0404.10">problem</entity> where one is not pre-committed to a <entity id="W96-0404.11">choice</entity> of the syntactically prominent elements in the initial <entity id="W96-0404.12">semantics</entity> . We also consider that a <entity id="W96-0404.13">generator</entity> can happen to convey more (or less) <entity id="W96-0404.14">information</entity> than is originally specified in its <entity id="W96-0404.15">semantic</entity> <entity id="W96-0404.16">input</entity> . In <entity id="W96-0404.17">order</entity> to constrain this approximate matching of the <entity id="W96-0404.18">input</entity> we impose additional <entity id="W96-0404.19">restrictions</entity> on the <entity id="W96-0404.20">semantics</entity> of the <entity id="W96-0404.21">generated</entity> <entity id="W96-0404.22">sentence</entity> . Our <entity id="W96-0404.23">technique</entity> <entity id="W96-0404.24">provides</entity> <entity id="W96-0404.25">flexibility</entity> to address <entity id="W96-0404.26">cases</entity> where the entire <entity id="W96-0404.27">input</entity> cannot be precisely expressed in a single <entity id="W96-0404.28">sentence</entity> . Thus the <entity id="W96-0404.29">generator</entity> does not rely on the strategic <entity id="W96-0404.30">component</entity> having <entity id="W96-0404.31">linguistic knowledge</entity> . We show clearly how the <entity id="W96-0404.32">semantic <entity id="W96-0404.33">structure</entity></entity> is declaratively related to linguistically motivated <entity id="W96-0404.34">syntactic <entity id="W96-0404.35">representation</entity></entity> .
</abstract>


propose(W96-0404.2,W96-0404.3)
char(W96-0404.32,W96-0404.34)

</text>

<text id="W96-0405">
<title><entity id="W96-0405.1">Input</entity> <entity id="W96-0405.2">Specification</entity> In The WAG <entity id="W96-0405.3">Sentence Generation</entity> <entity id="W96-0405.4">System</entity></title>
<abstract>
This <entity id="W96-0405.5">paper</entity> describes the <entity id="W96-0405.6">input</entity> <entity id="W96-0405.7">specification</entity> <entity id="W96-0405.8">language</entity> of the WAG <entity id="W96-0405.9">Sentence Generation</entity> <entity id="W96-0405.10">system</entity> . The <entity id="W96-0405.11">input</entity> is described in <entity id="W96-0405.12">terms</entity> of Halliday 's (1978) three meaning <entity id="W96-0405.13">components</entity> , ideational meaning (the propositional <entity id="W96-0405.14">content</entity> to be expressed), interactional meaning (what the speaker intends the <entity id="W96-0405.15">listener</entity> to do in making the <entity id="W96-0405.16">utterance</entity> ), and textual meaning (how the <entity id="W96-0405.17">content</entity> is <entity id="W96-0405.18">structured</entity> as a <entity id="W96-0405.19">message</entity> , in <entity id="W96-0405.20">terms</entity> of theme, <entity id="W96-0405.21">reference</entity> , etc.).
</abstract>


propose(W96-0405.5,W96-0405.8)

</text>

<text id="W97-0406">
<title><entity id="W97-0406.1">Dealing</entity> With Multilinguality In A <entity id="W97-0406.2">Spoken Language</entity> <entity id="W97-0406.3">Query</entity> <entity id="W97-0406.4">Translator</entity></title> 
<abstract><entity id="W97-0406.5">Robustness</entity> is an important <entity id="W97-0406.6">issue</entity> for multilingual <entity id="W97-0406.7">speech </entity><entity id="W97-0406.8">interfaces</entity> for spoken <entity id="W97-0406.9">language</entity> <entity id="W97-0406.10">translation <entity id="W97-0406.11">systems</entity></entity> . We have <entity id="W97-0406.12">studied</entity> three <entity id="W97-0406.13">aspects</entity> of <entity id="W97-0406.14">robustness</entity> in such a <entity id="W97-0406.15">system</entity> : accent <entity id="W97-0406.16">differences</entity> , mixed <entity id="W97-0406.17">language</entity> <entity id="W97-0406.18">input</entity> , and the use of <entity id="W97-0406.19">common</entity> <entity id="W97-0406.20">feature sets</entity> for HMM-based <entity id="W97-0406.21">speech</entity> recognizers for <entity id="W97-0406.22">English</entity> and Cantonese. The <entity id="W97-0406.23">results</entity> of our preliminary <entity id="W97-0406.24">experiments</entity> show that accent <entity id="W97-0406.25">differences</entity> cause recognizer <entity id="W97-0406.26">performance</entity> to degrade . A rather surprising <entity id="W97-0406.27">finding</entity> is that for mixed <entity id="W97-0406.28">language</entity> <entity id="W97-0406.29">input</entity> , a straight forward <entity id="W97-0406.30">implementation</entity> of a mixed <entity id="W97-0406.31">language <entity id="W97-0406.32">model-based</entity></entity> <entity id="W97-0406.33">speech</entity> recognizer <entity id="W97-0406.34">performs</entity> less well than the concatenation of pure <entity id="W97-0406.35">language</entity> recognizers. Our <entity id="W97-0406.36">experimental</entity> <entity id="W97-0406.37">results</entity> also show that a <entity id="W97-0406.38">common</entity> <entity id="W97-0406.39">feature set</entity> , <entity id="W97-0406.40">parameter</entity> set, and <entity id="W97-0406.41">common</entity> <entity id="W97-0406.42">algorithm</entity> lead to different <entity id="W97-0406.43">performance</entity> <entity id="W97-0406.44">output</entity> for Cantonese and <entity id="W97-0406.45">English</entity> <entity id="W97-0406.46">speech recognition</entity> <entity id="W97-0406.47">modules</entity> .
</abstract>


usedfor(W97-0406.8,W97-0406.10)
affects(W97-0406.25,W97-0406.26)
compare(W97-0406.31,W97-0406.35)
affects(W97-0406.38,W97-0406.44)

</text>

<text id="W97-0408">
<title><entity id="W97-0408.1">English-</entity> To-Mandarin <entity id="W97-0408.2">Speech Translation</entity> With Head Transducers
</title>
<abstract>
We describe the head transducer <entity id="W97-0408.3">model</entity> used in an <entity id="W97-0408.4">experimental</entity> <entity id="W97-0408.5">English-to-</entity> Mandarin speech <entity id="W97-0408.6">translation <entity id="W97-0408.7">system</entity></entity> . Head <entity id="W97-0408.8">transduction</entity> is a <entity id="W97-0408.9">translation</entity> <entity id="W97-0408.10">method</entity> in which weighted <entity id="W97-0408.11">finite state transducers</entity> are associated with <entity id="W97-0408.12">source-target word</entity> <entity id="W97-0408.13">pairs</entity> . The <entity id="W97-0408.14">method</entity> is suitable for <entity id="W97-0408.15">speech <entity id="W97-0408.16">translation</entity></entity> because it allows efficient bottom up <entity id="W97-0408.17">processing</entity> . The head transducers in the <entity id="W97-0408.18">experimental</entity> <entity id="W97-0408.19">system</entity> have a wider range of <entity id="W97-0408.20">output</entity> positions than <entity id="W97-0408.21">input</entity> positions. This asymmetry is motivated by a tradeoff between <entity id="W97-0408.22">model</entity> <entity id="W97-0408.23">complexity</entity> and <entity id="W97-0408.24">search</entity> <entity id="W97-0408.25">efficiency</entity> .
</abstract>


usedfor(W97-0408.3,W97-0408.6)
isa(W97-0408.8,W97-0408.10)
usedfor(W97-0408.14,W97-0408.15)

</text>

<text id="W97-0615">
<title>
Filtering Errors And Repairing Linguistic Anomalies For <entity id="W97-0615.1">Spoken Dialogue</entity> <entity id="W97-0615.2">Systems</entity></title>
<abstract>
Our work addresses the <entity id="W97-0615.3">integration</entity> of <entity id="W97-0615.4">speech recognition</entity> and <entity id="W97-0615.5">language <entity id="W97-0615.6">processing</entity></entity> for whole spoken <entity id="W97-0615.7">dialogue <entity id="W97-0615.8">systems</entity></entity> .To filter ill-recognized <entity id="W97-0615.9">words</entity> , we <entity id="W97-0615.10">design</entity> an on-line <entity id="W97-0615.11">computing</entity> of <entity id="W97-0615.12">word</entity> <entity id="W97-0615.13">confidence</entity> scores <entity id="W97-0615.14">based</entity> on the recognizer <entity id="W97-0615.15">output</entity> <entity id="W97-0615.16">hypothesis</entity> . To infer as much <entity id="W97-0615.17">information</entity> as possible from the retained <entity id="W97-0615.18">sequence</entity> of <entity id="W97-0615.19">words</entity> , we <entity id="W97-0615.20">propose</entity> a bottom-up <entity id="W97-0615.21">syntactico-semantic</entity> <entity id="W97-0615.22">robust</entity> <entity id="W97-0615.23">parsing</entity> relying on a lexi-calized <entity id="W97-0615.24">tree</entity> grammar and on integrated <entity id="W97-0615.25">repairing</entity> <entity id="W97-0615.26">strategies</entity> .
</abstract>


usedfor(W97-0615.5,W97-0615.7)
based_on(W97-0615.23,W97-0615.26)

</text>

<text id="W97-0618">
<title>
A Programmable Multi-Blackboard <entity id="W97-0618.1">Architecture</entity> For <entity id="W97-0618.2">Dialogue</entity> <entity id="W97-0618.3">Processing</entity> <entity id="W97-0618.4">Systems</entity></title>
<abstract>
In <entity id="W97-0618.5">current</entity> <entity id="W97-0618.6">Natural Language Processing</entity> <entity id="W97-0618.7">Systems</entity> , different <entity id="W97-0618.8">components</entity> for different <entity id="W97-0618.9">processing</entity> <entity id="W97-0618.10">tasks</entity> and <entity id="W97-0618.11">input</entity> / <entity id="W97-0618.12">output</entity> <entity id="W97-0618.13">modalities</entity> have to be integrated. Once integrated, the <entity id="W97-0618.14">interactions</entity> between the <entity id="W97-0618.15">components</entity> have to be specified. Interactions in <entity id="W97-0618.16">dialogue systems</entity> can be <entity id="W97-0618.17">complex</entity> <entity id="W97-0618.18">due</entity> in <entity id="W97-0618.19">part</entity> to the many states the <entity id="W97-0618.20">system</entity> can be in. When <entity id="W97-0618.21">porting</entity> the <entity id="W97-0618.22">system</entity> to another <entity id="W97-0618.23">domain</entity> , <entity id="W97-0618.24">parts</entity> of the <entity id="W97-0618.25">integration</entity> <entity id="W97-0618.26">process</entity> have to be repeated. To overcome these <entity id="W97-0618.27">difficulties</entity> , we <entity id="W97-0618.28">propose</entity> a multi-blackboard <entity id="W97-0618.29">architecture</entity> that is controlled by a set of <entity id="W97-0618.30">expert-system</entity> like <entity id="W97-0618.31">rules</entity> . These <entity id="W97-0618.32">rules</entity> may contain <entity id="W97-0618.33">typed</entity> <entity id="W97-0618.34">variables</entity> . Variables can be substituted by <entity id="W97-0618.35">representations</entity> with an appropriate <entity id="W97-0618.36">type</entity> stored in the blackboards. Furthermore, the <entity id="W97-0618.37">representations</entity> in the blackboards allow to represent <entity id="W97-0618.38">partial</entity> <entity id="W97-0618.39">information</entity> and to leave <entity id="W97-0618.40">disjunctions</entity> unresolved. Moreover, the conditions of the <entity id="W97-0618.41">rule</entity> may depend on the <entity id="W97-0618.42">specificity</entity> of the <entity id="W97-0618.43">representations</entity> with which the <entity id="W97-0618.44">variables</entity> are instantiated. For this <entity id="W97-0618.45">reason</entity> , the <entity id="W97-0618.46">interaction</entity> is <entity id="W97-0618.47">information-driven</entity> . The described <entity id="W97-0618.48">system</entity> has been <entity id="W97-0618.49">implemented</entity> and has been integrated with the <entity id="W97-0618.50">speech</entity> recognizer JANUS.
</abstract>


model(W97-0618.1,W97-0618.4)
usedfor(W97-0618.8,W97-0618.10)
part_of(W97-0618.32,W97-0618.34,REVERSE)
tag(W97-0618.37,W97-0618.39)
based_on(W97-0618.41,W97-0618.42)

</text>

<text id="J82-1001">
<title><entity id="J82-1001.1">Phrase Structure</entity> Trees Bear More Fruit Than You Would Have Thought
</title>
<abstract>
In this <entity id="J82-1001.2">paper</entity> we will present several <entity id="J82-1001.3">results</entity> <entity id="J82-1001.4">concerning</entity> <entity id="J82-1001.5">phrase structure trees</entity> . These <entity id="J82-1001.6">results</entity> show that <entity id="J82-1001.7">phrase structure trees</entity> , when viewed in certain ways, have much more descriptive power than one would have thought. We have given a brief account of local <entity id="J82-1001.8">constraints</entity> on <entity id="J82-1001.9">structural</entity> <entity id="J82-1001.10">descriptions</entity> and an intuitive proof of a <entity id="J82-1001.11">theorem</entity> about local <entity id="J82-1001.12">constraints</entity> . We have compared the local <entity id="J82-1001.13">constraints</entity> <entity id="J82-1001.14">approach</entity> to some <entity id="J82-1001.15">aspects</entity> of Gazdar 's <entity id="J82-1001.16">framework</entity> and that of Peters and Ritchie and of Karttunen . We have also presented some <entity id="J82-1001.17">results</entity> on skeletons ( <entity id="J82-1001.18">phrase structure trees</entity> without labels) which show that <entity id="J82-1001.19">phrase <entity id="J82-1001.20">structure</entity> <entity id="J82-1001.21">trees</entity></entity> , even when deprived of the labels, retain in a certain <entity id="J82-1001.22">sense</entity> all the <entity id="J82-1001.23">structural</entity> <entity id="J82-1001.24">information</entity> . This <entity id="J82-1001.25">result</entity> has <entity id="J82-1001.26">implications</entity> for grammatical <entity id="J82-1001.27">inference</entity> <entity id="J82-1001.28">procedures</entity> .
</abstract>


propose(J82-1001.2,J82-1001.3)
study(J82-1001.11,J82-1001.12)
compare(J82-1001.14,J82-1001.16)
tag(J82-1001.19,J82-1001.24)

</text>

<text id="J82-2002">
<title><entity id="J82-2002.1">Natural-</entity> <entity id="J82-2002.2">Language</entity> <entity id="J82-2002.3">Interface</entity></title>
<abstract>
A major <entity id="J82-2002.4">problem</entity> faced by would-be <entity id="J82-2002.5">users</entity> of <entity id="J82-2002.6">computer</entity> <entity id="J82-2002.7">systems</entity> is that <entity id="J82-2002.8">computers</entity> generally make use of <entity id="J82-2002.9">special-purpose</entity> <entity id="J82-2002.10">languages</entity> familiar only to those <entity id="J82-2002.11">trained</entity> in <entity id="J82-2002.12">computer science</entity> . For a large <entity id="J82-2002.13">number</entity> of <entity id="J82-2002.14">applications</entity> <entity id="J82-2002.15">requiring</entity> <entity id="J82-2002.16">interaction</entity> between humans and <entity id="J82-2002.17">computer</entity> <entity id="J82-2002.18">systems</entity> , it would be highly desirable for <entity id="J82-2002.19">machines</entity> to converse in <entity id="J82-2002.20">English</entity> or other <entity id="J82-2002.21">natural languages</entity> familiar to their human <entity id="J82-2002.22">users</entity> . Over the last decade, in <entity id="J82-2002.23">laboratories</entity> around the world, several <entity id="J82-2002.24">computer</entity> <entity id="J82-2002.25">systems</entity> have been <entity id="J82-2002.26">developed</entity> that <entity id="J82-2002.27">support</entity> at least elementary <entity id="J82-2002.28">levels</entity> of <entity id="J82-2002.29">natural-language</entity> <entity id="J82-2002.30">interaction</entity> . Among these are such <entity id="J82-2002.31">systems</entity> as those described in the several <entity id="J82-2002.32">references</entity> at the end of this <entity id="J82-2002.33">paper</entity> .
</abstract>


based_on(J82-2002.8,J82-2002.10)
propose(J82-2002.32,J82-2002.33,REVERSE)

</text>

<text id="P80-1002">
<title><entity id="P80-1002.1">Understanding</entity> Scene Descriptions As <entity id="P80-1002.2">Event</entity> Simulations
</title>
<abstract>
"The <entity id="P80-1002.3">language</entity> of scene <entity id="P80-1002.4">descriptions</entity> must allow a hearer to build <entity id="P80-1002.5">structures</entity> of sch
mas similar (to some <entity id="P80-1002.6">level</entity> of <entity id="P80-1002.7">detail</entity> ) to those the speaker has built via perceptual <entity id="P80-1002.8">processes</entity> . The <entity id="P80-1002.9">understanding</entity> <entity id="P80-1002.10">process</entity> in general <entity id="P80-1002.11">requires</entity> a hearer to create and run ""<entity id="P80-1002.12">event</entity> <entity id="P80-1002.13">simulations</entity> """
</abstract>



</text>

<text id="P98-1099">
<title><entity id="P98-1099.1">Combining</entity> Multiple, Large- <entity id="P98-1099.2">Scale</entity> Resources in a Reusable <entity id="P98-1099.3">Lexicon</entity> for <entity id="P98-1099.4">Natural <entity id="P98-1099.5">Language Generation</entity></entity></title>
<abstract>
A <entity id="P98-1099.6">lexicon</entity> is an essential <entity id="P98-1099.7">component</entity> in a <entity id="P98-1099.8">generation <entity id="P98-1099.9">system</entity></entity> but few <entity id="P98-1099.10">efforts</entity> have been made to build a rich, <entity id="P98-1099.11">large-scale</entity> <entity id="P98-1099.12">lexicon</entity> and make it reusable for different <entity id="P98-1099.13">generation</entity> <entity id="P98-1099.14">applications</entity> . In this <entity id="P98-1099.15">paper</entity> , we describe our work to build such a <entity id="P98-1099.16">lexicon</entity> by combining multiple, heterogeneous <entity id="P98-1099.17">linguistic resources</entity> which have been <entity id="P98-1099.18">developed</entity> for other <entity id="P98-1099.19">purposes</entity> . Novel <entity id="P98-1099.20">transformation</entity> and <entity id="P98-1099.21">integration</entity> of <entity id="P98-1099.22">resources</entity> is <entity id="P98-1099.23">required</entity> to reuse them for <entity id="P98-1099.24">generation</entity> . We also <entity id="P98-1099.25">applied</entity> the <entity id="P98-1099.26">lexicon</entity> to the <entity id="P98-1099.27">lexical <entity id="P98-1099.28">choice</entity></entity> and <entity id="P98-1099.29">realization</entity> <entity id="P98-1099.30">component</entity> of a practical <entity id="P98-1099.31">generation</entity> <entity id="P98-1099.32">application</entity> by using a <entity id="P98-1099.33">multi-level</entity> <entity id="P98-1099.34">feedback</entity> <entity id="P98-1099.35">architecture</entity> . The <entity id="P98-1099.36">integration</entity> of the <entity id="P98-1099.37">lexicon</entity> and the <entity id="P98-1099.38">architecture</entity> is able to effectively <entity id="P98-1099.39">improve</entity> the <entity id="P98-1099.40">system</entity> paraphrasing power, minimize the chance of grammatical <entity id="P98-1099.41">errors</entity> , and simplify the <entity id="P98-1099.42">development</entity> <entity id="P98-1099.43">process</entity> substantially.
</abstract>


usedfor(P98-1099.3,P98-1099.4)
part_of(P98-1099.6,P98-1099.8)
propose(P98-1099.15,P98-1099.16)
usedfor(P98-1099.26,P98-1099.27)
usedfor(P98-1099.31,P98-1099.35,REVERSE)
affects(P98-1099.36,P98-1099.41)

</text>

<text id="P98-1107">
<title>
A <entity id="P98-1107.1">Method</entity> for Correcting Errors in <entity id="P98-1107.2">Speech <entity id="P98-1107.3">Recognition</entity></entity> using the <entity id="P98-1107.4">Statistical</entity> <entity id="P98-1107.5">Features</entity> of Character <entity id="P98-1107.6">Co-occurrence</entity></title>
<abstract>
It is important to correct the <entity id="P98-1107.7">errors</entity> in the <entity id="P98-1107.8">results</entity> of <entity id="P98-1107.9">speech recognition</entity> to <entity id="P98-1107.10">increase</entity> the <entity id="P98-1107.11">performance</entity> of a speech <entity id="P98-1107.12">translation <entity id="P98-1107.13">system</entity></entity> . This <entity id="P98-1107.14">paper</entity> <entity id="P98-1107.15">proposes</entity> a <entity id="P98-1107.16">method</entity> for correcting <entity id="P98-1107.17">errors</entity> using the <entity id="P98-1107.18">statistical</entity> <entity id="P98-1107.19">features</entity> of character <entity id="P98-1107.20">co-occurrence</entity> , and <entity id="P98-1107.21">evaluates</entity> the <entity id="P98-1107.22">method</entity> . The <entity id="P98-1107.23">proposed</entity> <entity id="P98-1107.24">method</entity> comprises two successive correcting <entity id="P98-1107.25">processes</entity> . The first <entity id="P98-1107.26">process</entity> uses <entity id="P98-1107.27">pairs</entity> of <entity id="P98-1107.28">strings</entity> : the first <entity id="P98-1107.29">string</entity> is an erroneous substring of the <entity id="P98-1107.30">utterance</entity> predicted by <entity id="P98-1107.31">speech <entity id="P98-1107.32">recognition</entity></entity> , the second <entity id="P98-1107.33">string</entity> is the corresponding <entity id="P98-1107.34">section</entity> of the actual <entity id="P98-1107.35">utterance</entity> . Errors are detected and corrected according to the <entity id="P98-1107.36">database</entity> learned from erroneous-correct <entity id="P98-1107.37">utterance</entity> <entity id="P98-1107.38">pairs</entity> . The remaining <entity id="P98-1107.39">errors</entity> are passed to the posterior <entity id="P98-1107.40">process</entity> which uses a <entity id="P98-1107.41">string</entity> in the <entity id="P98-1107.42">corpus</entity> that is similar to the <entity id="P98-1107.43">string</entity> <entity id="P98-1107.44">including</entity> <entity id="P98-1107.45">recognition</entity> <entity id="P98-1107.46">errors</entity> . The <entity id="P98-1107.47">results</entity> of our <entity id="P98-1107.48">evaluation</entity> show that the use of our <entity id="P98-1107.49">proposed</entity> <entity id="P98-1107.50">method</entity> as a <entity id="P98-1107.51">post-processor</entity> for <entity id="P98-1107.52">speech <entity id="P98-1107.53">recognition</entity></entity> is likely to make a significant <entity id="P98-1107.54">contribution</entity> to the <entity id="P98-1107.55">performance</entity> of speech <entity id="P98-1107.56">translation systems</entity> . <entity id="P98-1107.57">method</entity> also obtains reliably recognized <entity id="P98-1107.58">partial</entity> <entity id="P98-1107.59">segments</entity> of an <entity id="P98-1107.60">utterance</entity> by cooperatively using both grammatical and <entity id="P98-1107.61">n-gram</entity> <entity id="P98-1107.62">based</entity> <entity id="P98-1107.63">statistical</entity> <entity id="P98-1107.64">language</entity> <entity id="P98-1107.65">constraints</entity> , and uses a <entity id="P98-1107.66">robust</entity> <entity id="P98-1107.67">parsing</entity> <entity id="P98-1107.68">technique</entity> to <entity id="P98-1107.69">apply</entity> the grammatical <entity id="P98-1107.70">constraints</entity> described by <entity id="P98-1107.71">context-free</entity> grammar ( Tsukada</abstract>


usedfor(P98-1107.2,P98-1107.6,REVERSE)
phenomenon(P98-1107.7,P98-1107.8)
char(P98-1107.11,P98-1107.12)
methodapplied(P98-1107.16,P98-1107.17)
part_of(P98-1107.24,P98-1107.25,REVERSE)
based_on(P98-1107.26,P98-1107.27)
yields(P98-1107.29,P98-1107.31,REVERSE)
tag(P98-1107.33,P98-1107.35)
composed_of(P98-1107.36,P98-1107.38)
based_on(P98-1107.40,P98-1107.41)
phenomenon(P98-1107.43,P98-1107.46,REVERSE)
usedfor(P98-1107.51,P98-1107.52)
wrt(P98-1107.54,P98-1107.55)
yields(P98-1107.57,P98-1107.59)

</text>

<text id="P98-2134">
<title>
Bitext Correspondences through Rich Mark-up</title>
<abstract>
Rich mark-up can considerably <entity id="P98-2134.1">benefit</entity> the <entity id="P98-2134.2">process</entity> of establishing bitext <entity id="P98-2134.3">correspondences</entity> , that is, the <entity id="P98-2134.4">task</entity> of <entity id="P98-2134.5">providing</entity> correct <entity id="P98-2134.6">identification</entity> and <entity id="P98-2134.7">alignment</entity> <entity id="P98-2134.8">methods</entity> for <entity id="P98-2134.9">text</entity> <entity id="P98-2134.10">segments</entity> that are <entity id="P98-2134.11">translation</entity> <entity id="P98-2134.12">equivalences</entity> of each other in a <entity id="P98-2134.13">parallel corpus</entity> . We present a <entity id="P98-2134.14">sentence</entity> <entity id="P98-2134.15">alignment</entity> <entity id="P98-2134.16">algorithm</entity> that, by taking <entity id="P98-2134.17">advantage</entity> of previously annotated <entity id="P98-2134.18">texts</entity> , obtains <entity id="P98-2134.19">accuracy</entity> <entity id="P98-2134.20">rates</entity> close to 100%. The <entity id="P98-2134.21">algorithm</entity> <entity id="P98-2134.22">evaluates</entity> the <entity id="P98-2134.23">similarity</entity> of the linguistic and extra-linguistic mark-up in both <entity id="P98-2134.24">sides</entity> of a bitext. Given that annotations are neutral with <entity id="P98-2134.25">respect</entity> to typological, grammatical and orthographical <entity id="P98-2134.26">differences</entity> between <entity id="P98-2134.27">languages</entity> , rich mark-up becomes an <entity id="P98-2134.28">optimal</entity> foundation to <entity id="P98-2134.29">support</entity> bitext <entity id="P98-2134.30">correspondences</entity> . The <entity id="P98-2134.31">main</entity> originality of this <entity id="P98-2134.32">approach</entity> is that it makes maximal use of annotations, which is a very sensible and efficient <entity id="P98-2134.33">method</entity> for the <entity id="P98-2134.34">exploitation</entity> of <entity id="P98-2134.35">parallel corpora</entity> when annotations exist.
</abstract>


taskapplied(P98-2134.7,P98-2134.10)
yields(P98-2134.16,P98-2134.19)

</text>

<text id="P98-2154">
<title>
Translating a <entity id="P98-2154.1">Unification</entity> Grammar with Disjunctions into Logical Constraints
</title>
<abstract>
This <entity id="P98-2154.2">paper</entity> <entity id="P98-2154.3">proposes</entity> a <entity id="P98-2154.4">method</entity> for <entity id="P98-2154.5">generating</entity> a <entity id="P98-2154.6">logical-constraint-based</entity> internal <entity id="P98-2154.7">representation</entity> from a <entity id="P98-2154.8">unification</entity> grammar <entity id="P98-2154.9">formalism</entity> with disjunctive <entity id="P98-2154.10">information</entity> . <entity id="P98-2154.11">Unification</entity> grammar <entity id="P98-2154.12">formalisms</entity> <entity id="P98-2154.13">based</entity> on <entity id="P98-2154.14">path</entity> <entity id="P98-2154.15">equations</entity> and <entity id="P98-2154.16">lists</entity> of <entity id="P98-2154.17">pairs</entity> of labels and values are better than those <entity id="P98-2154.18">based</entity> on <entity id="P98-2154.19">first-order</entity> <entity id="P98-2154.20">terms</entity> in that the former is easier to describe and to understand. <entity id="P98-2154.21">Parsing</entity> with <entity id="P98-2154.22">term-based</entity> internal <entity id="P98-2154.23">representations</entity> is more efficient than <entity id="P98-2154.24">parsing</entity> with graph-based <entity id="P98-2154.25">representations</entity> . Therefore, it is effective to <entity id="P98-2154.26">translate</entity> <entity id="P98-2154.27">unification</entity> grammar <entity id="P98-2154.28">formalism</entity> <entity id="P98-2154.29">based</entity> on <entity id="P98-2154.30">path</entity> <entity id="P98-2154.31">equations</entity> and <entity id="P98-2154.32">lists</entity> of <entity id="P98-2154.33">pairs</entity> of labels and values into a <entity id="P98-2154.34">term-based</entity> internal <entity id="P98-2154.35">representation</entity> . Previous <entity id="P98-2154.36">translation</entity> <entity id="P98-2154.37">methods</entity> cannot <entity id="P98-2154.38">deal</entity> with disjunctive <entity id="P98-2154.39">feature</entity> <entity id="P98-2154.40">descriptions</entity> , which reduce <entity id="P98-2154.41">redundancies</entity> in the grammar and make <entity id="P98-2154.42">parsing</entity> efficient. Since the <entity id="P98-2154.43">proposed</entity> <entity id="P98-2154.44">method</entity> <entity id="P98-2154.45">translates</entity> a <entity id="P98-2154.46">formalism</entity> without expanding <entity id="P98-2154.47">disjunctions</entity> , <entity id="P98-2154.48">parsing</entity> with the <entity id="P98-2154.49">resulting</entity> <entity id="P98-2154.50">representation</entity> is efficient.
</abstract>


propose(P98-2154.2,P98-2154.4)
datasource(P98-2154.7,P98-2154.10)
based_on(P98-2154.12,P98-2154.16)
compare(P98-2154.21,P98-2154.24)
based_on(P98-2154.28,P98-2154.32)
problem(P98-2154.37,P98-2154.40,REVERSE)

</text>

<text id="C08-1013">
<title>
ParaMetric: An <entity id="C08-1013.1">Automatic Evaluation</entity> <entity id="C08-1013.2">Metric</entity> for Paraphrasing
</title>
<abstract>
We present ParaMetric, an <entity id="C08-1013.3">automatic evaluation</entity> <entity id="C08-1013.4">metric</entity> for <entity id="C08-1013.5">data-driven</entity> <entity id="C08-1013.6">approaches</entity> to paraphrasing. ParaMetric <entity id="C08-1013.7">provides</entity> an <entity id="C08-1013.8">objective</entity> measure of <entity id="C08-1013.9">quality</entity> using a <entity id="C08-1013.10">collection</entity> of multiple <entity id="C08-1013.11">translations</entity> whose paraphrases have been manually annotated. ParaMetric calculates <entity id="C08-1013.12">precision</entity> and <entity id="C08-1013.13">recall</entity> scores by comparing the paraphrases discovered by <entity id="C08-1013.14">automatic</entity> paraphrasing <entity id="C08-1013.15">techniques</entity> against <entity id="C08-1013.16">gold standard</entity> <entity id="C08-1013.17">alignments</entity> of <entity id="C08-1013.18">words</entity> and <entity id="C08-1013.19">phrases</entity> within equivalent <entity id="C08-1013.20">sentences</entity> . We <entity id="C08-1013.21">report</entity> scores for several established paraphrasing <entity id="C08-1013.22">techniques</entity> .
</abstract>


tag(C08-1013.17,C08-1013.20)

</text>

<text id="C08-1025">
<title><entity id="C08-1025.1">Re-estimation</entity> of <entity id="C08-1025.2">Lexical</entity> Parameters for Treebank PCFGs
</title>
<abstract>
We present <entity id="C08-1025.3">procedures</entity> which pool <entity id="C08-1025.4">lexical <entity id="C08-1025.5">information</entity></entity> estimated from unlabeled <entity id="C08-1025.6">data</entity> via the Inside-Outside <entity id="C08-1025.7">algorithm</entity> , with <entity id="C08-1025.8">lexical information</entity> from a treebank PCFG. The <entity id="C08-1025.9">procedures</entity> produce substantial <entity id="C08-1025.10">improvements</entity> (up to 31.6% <entity id="C08-1025.11">error</entity> <entity id="C08-1025.12">reduction</entity> ) on the <entity id="C08-1025.13">task</entity> of determining subcategorization <entity id="C08-1025.14">frames</entity> of novel <entity id="C08-1025.15">verbs</entity> , <entity id="C08-1025.16">relative</entity> to a <entity id="C08-1025.17">smoothed</entity> <entity id="C08-1025.18">Penn Treebank-trained</entity> PCFG. Even with relatively small <entity id="C08-1025.19">quantities</entity> of unlabeled <entity id="C08-1025.20">training</entity> data, the re-estimated <entity id="C08-1025.21">models</entity> show promising <entity id="C08-1025.22">improvements</entity> in labeled <entity id="C08-1025.23">bracketing</entity> /scores on <entity id="C08-1025.24">Wall Street Journal</entity> <entity id="C08-1025.25">parsing</entity> , and substantial <entity id="C08-1025.26">benefit</entity> in acquiring the subcategorization <entity id="C08-1025.27">preferences</entity> of <entity id="C08-1025.28">low-frequency</entity> <entity id="C08-1025.29">verbs</entity> .
</abstract>


datasource(C08-1025.4,C08-1025.6)
yields(C08-1025.9,C08-1025.10)
datasource(C08-1025.14,C08-1025.18)
wrt(C08-1025.22,C08-1025.23)
wrt(C08-1025.26,C08-1025.27)

</text>

<text id="C08-1082">
<title><entity id="C08-1082.1">Semantic</entity> <entity id="C08-1082.2">Classification</entity> with Distributional Kernels
</title>
<abstract>
Distributional measures of <entity id="C08-1082.3">lexical</entity> <entity id="C08-1082.4">similarity</entity> and <entity id="C08-1082.5">kernel <entity id="C08-1082.6">methods</entity></entity> for <entity id="C08-1082.7">classification</entity> are well-known <entity id="C08-1082.8">tools</entity> in <entity id="C08-1082.9">Natural Language Processing</entity> . We bring these two <entity id="C08-1082.10">methods</entity> together by introducing distributional kernels
</abstract>


usedfor(C08-1082.5,C08-1082.7)

</text>

<text id="C08-1125">
<title><entity id="C08-1125.1">Domain Adaptation</entity> for <entity id="C08-1125.2">Statistical Machine Translation</entity> with <entity id="C08-1125.3">Domain</entity> <entity id="C08-1125.4">Dictionary</entity> and Monolingual <entity id="C08-1125.5">Corpora</entity></title> 
<abstract><entity id="C08-1125.6">Statistical <entity id="C08-1125.7">machine translation systems</entity></entity> are usually <entity id="C08-1125.8">trained</entity> on large <entity id="C08-1125.9">amounts</entity> of bilingual <entity id="C08-1125.10">text</entity> and monolingual <entity id="C08-1125.11">text</entity> . In this <entity id="C08-1125.12">paper</entity> , we <entity id="C08-1125.13">propose</entity> a <entity id="C08-1125.14">method</entity> to <entity id="C08-1125.15">perform</entity> <entity id="C08-1125.16">domain adaptation</entity> for <entity id="C08-1125.17">statistical machine translation</entity> , where <entity id="C08-1125.18">in-domain</entity> bilingual <entity id="C08-1125.19">corpora</entity> do not exist. This <entity id="C08-1125.20">method</entity> first uses <entity id="C08-1125.21">out-of-domain</entity> <entity id="C08-1125.22">corpora</entity> to <entity id="C08-1125.23">train</entity> a <entity id="C08-1125.24">baseline system</entity> and then uses <entity id="C08-1125.25">in-domain</entity> <entity id="C08-1125.26">translation</entity> <entity id="C08-1125.27">dictionaries</entity> and <entity id="C08-1125.28">in-domain</entity> monolingual <entity id="C08-1125.29">corpora</entity> to <entity id="C08-1125.30">improve</entity> the indomain <entity id="C08-1125.31">performance</entity> . We <entity id="C08-1125.32">propose</entity> an <entity id="C08-1125.33">algorithm</entity> to combine these different <entity id="C08-1125.34">resources</entity> in a unified <entity id="C08-1125.35">framework</entity> . <entity id="C08-1125.36">Experimental</entity> <entity id="C08-1125.37">results</entity> indicate that our <entity id="C08-1125.38">method</entity> achieves absolute <entity id="C08-1125.39">improvements</entity> of 8.16 and 3.36 BLEU scores on <entity id="C08-1125.40">Chinese</entity> to <entity id="C08-1125.41">English</entity> <entity id="C08-1125.42">translation</entity> and <entity id="C08-1125.43">English</entity> to French <entity id="C08-1125.44">translation</entity> respectively, as compared with the baselines using only <entity id="C08-1125.45">out-of-domain</entity> <entity id="C08-1125.46">corpora</entity> .
</abstract>


based_on(C08-1125.6,C08-1125.10)
propose(C08-1125.12,C08-1125.14)
based_on(C08-1125.20,C08-1125.22)
wrt(C08-1125.39,C08-1125.42)

</text>

<text id="C08-1137">
<title><entity id="C08-1137.1">Sentence</entity> <entity id="C08-1137.2">Type</entity> <entity id="C08-1137.3">Based</entity> <entity id="C08-1137.4">Reordering <entity id="C08-1137.5">Model</entity></entity> for <entity id="C08-1137.6">Statistical <entity id="C08-1137.7">Machine Translation</entity></entity></title>
<abstract>
Many reordering <entity id="C08-1137.8">approaches</entity> have been <entity id="C08-1137.9">proposed</entity> for the <entity id="C08-1137.10">statistical machine translation</entity> (SMT) <entity id="C08-1137.11">system</entity> . However, the <entity id="C08-1137.12">information</entity> about the <entity id="C08-1137.13">type</entity> of <entity id="C08-1137.14">source <entity id="C08-1137.15">sentence</entity></entity> is ignored in the previous works. In this <entity id="C08-1137.16">paper</entity> , we <entity id="C08-1137.17">propose</entity> a group of novel <entity id="C08-1137.18">reordering <entity id="C08-1137.19">models</entity></entity> <entity id="C08-1137.20">based</entity> on the <entity id="C08-1137.21">source sentence</entity> <entity id="C08-1137.22">type</entity> for <entity id="C08-1137.23">Chinese-to-</entity> <entity id="C08-1137.24">English</entity> <entity id="C08-1137.25">translation</entity> . In our <entity id="C08-1137.26">approach</entity> , an SVM-based <entity id="C08-1137.27">classifier</entity> is employed to classify the given <entity id="C08-1137.28">Chinese</entity> <entity id="C08-1137.29">sentences</entity> into three <entity id="C08-1137.30">types</entity> : special interrogative <entity id="C08-1137.31">sentences</entity> , other interrogative <entity id="C08-1137.32">sentences</entity> , and <entity id="C08-1137.33">non-question</entity> <entity id="C08-1137.34">sentences</entity> . The different <entity id="C08-1137.35">reordering <entity id="C08-1137.36">models</entity></entity> are <entity id="C08-1137.37">developed</entity> oriented to the different <entity id="C08-1137.38">sentence</entity> <entity id="C08-1137.39">types</entity> . Our <entity id="C08-1137.40">experiments</entity> show that the novel <entity id="C08-1137.41">reordering <entity id="C08-1137.42">models</entity></entity> have obtained an <entity id="C08-1137.43">improvement</entity> of more than 2.65% in BLEU for a <entity id="C08-1137.44">phrase-based</entity> spoken <entity id="C08-1137.45">language</entity> <entity id="C08-1137.46">translation system</entity> .
</abstract>


usedfor(C08-1137.4,C08-1137.6)
tag(C08-1137.12,C08-1137.14)
propose(C08-1137.16,C08-1137.18)
taskapplied(C08-1137.27,C08-1137.29)
based_on(C08-1137.35,C08-1137.39)
yields(C08-1137.41,C08-1137.43)

</text>

<text id="C80-1002">
<title><entity id="C80-1002.1">Automatic</entity> <entity id="C80-1002.2">Processing</entity> Of Written French <entity id="C80-1002.3">Language</entity></title>
<abstract>
An <entity id="C80-1002.4">automatic</entity> <entity id="C80-1002.5">processor</entity> of written French <entity id="C80-1002.6">language</entity> is described. This <entity id="C80-1002.7">processor</entity> uses <entity id="C80-1002.8">syntactic</entity> and <entity id="C80-1002.9">semantic <entity id="C80-1002.10">informations</entity></entity> about <entity id="C80-1002.11">words</entity> in <entity id="C80-1002.12">order</entity> to <entity id="C80-1002.13">construct</entity> a <entity id="C80-1002.14">semantic</entity> net representing the meaning of the <entity id="C80-1002.15">sentences</entity> . The <entity id="C80-1002.16">structure</entity> of the <entity id="C80-1002.17">network</entity> and the <entity id="C80-1002.18">principles</entity> of the <entity id="C80-1002.19">parser</entity> are explained. An <entity id="C80-1002.20">application</entity> to the <entity id="C80-1002.21">processing</entity> of the medical <entity id="C80-1002.22">records</entity> is then discussed.
</abstract>


methodapplied(C80-1002.5,C80-1002.6)
based_on(C80-1002.7,C80-1002.9)
taskapplied(C80-1002.21,C80-1002.22)

</text>

<text id="C80-1005">
<title><entity id="C80-1005.1">Computer-</entity> Aided Grammatical <entity id="C80-1005.2">Tagging</entity> Of Spoken <entity id="C80-1005.3">English</entity></title>
<abstract></abstract>



taskapplied(C80-1005.2,C80-1005.3)

</text>

<text id="C80-1008">
<title>
A <entity id="C80-1008.1">Rule-</entity> <entity id="C80-1008.2">Based</entity> <entity id="C80-1008.3">Approach</entity> To Ill- <entity id="C80-1008.4">Formed</entity> <entity id="C80-1008.5">Input</entity></title>
<abstract>
Though <entity id="C80-1008.6">natural language understanding systems</entity> have <entity id="C80-1008.7">improved</entity> markedly in recent years, they have only begun to consider a major <entity id="C80-1008.8">problem</entity> of truly <entity id="C80-1008.9">natural</entity> <entity id="C80-1008.10">input</entity> : ill-formedness. Quite often <entity id="C80-1008.11">natural language</entity> <entity id="C80-1008.12">input</entity> is ill-formed in the <entity id="C80-1008.13">sense</entity> of being misspelled, ungrammatical, or not entirely meaningful. A <entity id="C80-1008.14">requirement</entity> for any successful <entity id="C80-1008.15">natural language interface</entity> must be that the <entity id="C80-1008.16">system</entity> either intelligently guesses at a <entity id="C80-1008.17">user</entity> 's intent, requests direct <entity id="C80-1008.18">clarification</entity> , or at the very least, accurately identifies the ill-formedness. This <entity id="C80-1008.19">paper</entity> presents a <entity id="C80-1008.20">proposal</entity> for the proper <entity id="C80-1008.21">treatment</entity> of ill-formed <entity id="C80-1008.22">input</entity> . Our conjecture is that ill-formedness should be treated as <entity id="C80-1008.23">rule-based</entity> . Violation of the <entity id="C80-1008.24">rules</entity> of normal <entity id="C80-1008.25">processing</entity> should be used to <entity id="C80-1008.26">signal</entity> ill-formedness. Meta-rules modifying the <entity id="C80-1008.27">rules</entity> of normal <entity id="C80-1008.28">processing</entity> should be used for <entity id="C80-1008.29">error</entity> <entity id="C80-1008.30">identification</entity> and <entity id="C80-1008.31">recovery</entity> . These meta-rules correspond to <entity id="C80-1008.32">types</entity> of <entity id="C80-1008.33">errors</entity> . <entity id="C80-1008.34">Evidence</entity> for this conjecture is presented as well as some open <entity id="C80-1008.35">questions</entity> .
</abstract>


propose(C80-1008.19,C80-1008.20)
usedfor(C80-1008.27,C80-1008.30)

</text>

<text id="C80-1022">
<title>
The <entity id="C80-1022.1">Knowledge <entity id="C80-1022.2">Representation</entity></entity> For A Story <entity id="C80-1022.3">Understanding</entity> And <entity id="C80-1022.4">Simulation</entity> <entity id="C80-1022.5">System</entity></title>
<abstract>
TOYONAKA,  OSAKA 560, JAPAN !!!! MATSUSHITA ELECTRIC  INDUSTRIAL CO.,LTD. KADOMA,  OSAKA 571, JAPAN Abstruet</abstract>


usedfor(C80-1022.1,C80-1022.3)

</text>

<text id="L08-1232">
<title><entity id="L08-1232.1">Language</entity> Resources and <entity id="L08-1232.2">Chemical</entity> Informatics
</title>
<abstract>
Chemistry <entity id="L08-1232.3">research</entity> <entity id="L08-1232.4">papers</entity> are a primary <entity id="L08-1232.5">source</entity> of <entity id="L08-1232.6">information</entity> about chemistry, as in any scientific <entity id="L08-1232.7">field</entity> . The <entity id="L08-1232.8">presentation</entity> of the <entity id="L08-1232.9">data</entity> is, predominantly, unstructured <entity id="L08-1232.10">information</entity> , and so not immediately susceptible to <entity id="L08-1232.11">processes</entity> <entity id="L08-1232.12">developed</entity> within <entity id="L08-1232.13">chemical</entity> informatics for carrying out chemistry <entity id="L08-1232.14">research</entity> by <entity id="L08-1232.15">information processing</entity> <entity id="L08-1232.16">techniques</entity> . At one <entity id="L08-1232.17">level</entity> , <entity id="L08-1232.18">extracting</entity> the relevant <entity id="L08-1232.19">information</entity> from <entity id="L08-1232.20">research</entity> <entity id="L08-1232.21">papers</entity> is a <entity id="L08-1232.22">text</entity> mining <entity id="L08-1232.23">task</entity> , <entity id="L08-1232.24">requiring</entity> both extensive <entity id="L08-1232.25">language resources</entity> and specialised <entity id="L08-1232.26">knowledge</entity> of the subject <entity id="L08-1232.27">domain</entity> . However, the <entity id="L08-1232.28">papers</entity> also encode <entity id="L08-1232.29">information</entity> about the way the <entity id="L08-1232.30">research</entity> is conducted and the <entity id="L08-1232.31">structure</entity> of the <entity id="L08-1232.32">field</entity> itself. <entity id="L08-1232.33">Applying</entity> <entity id="L08-1232.34">language technology</entity> to <entity id="L08-1232.35">research</entity> <entity id="L08-1232.36">papers</entity> in chemistry can facilitate eScience on several different <entity id="L08-1232.37">levels</entity> . The SciBorg <entity id="L08-1232.38">project</entity> sets out to <entity id="L08-1232.39">provide</entity> an extensive, analysed <entity id="L08-1232.40">corpus</entity> of published chemistry <entity id="L08-1232.41">research</entity> . This relies on the <entity id="L08-1232.42">cooperation</entity> of several <entity id="L08-1232.43">journal</entity> publishers to <entity id="L08-1232.44">provide</entity> <entity id="L08-1232.45">papers</entity> in an appropriate <entity id="L08-1232.46">form</entity> . The work is carried out as a <entity id="L08-1232.47">collaboration</entity> involving the <entity id="L08-1232.48">Computer</entity> <entity id="L08-1232.49">Laboratory</entity> , Chemistry <entity id="L08-1232.50">Department</entity> and eScience Centre at Cambridge <entity id="L08-1232.51">University</entity> , and is funded under the UK eScience programme.
</abstract>


datasource(L08-1232.4,L08-1232.6)
datasource(L08-1232.19,L08-1232.21)
datasource(L08-1232.28,L08-1232.29,REVERSE)
composed_of(L08-1232.40,L08-1232.41)

</text>

<text id="L08-1236">
<title>
MeSH: from a Controlled <entity id="L08-1236.1">Vocabulary</entity> to a Processable <entity id="L08-1236.2">Resource</entity></title>
<abstract>
Large <entity id="L08-1236.3">repositories</entity> of life <entity id="L08-1236.4">science</entity> <entity id="L08-1236.5">data</entity> in the <entity id="L08-1236.6">form</entity> of <entity id="L08-1236.7">domain-specific</entity> <entity id="L08-1236.8">literature</entity> , textual <entity id="L08-1236.9">databases</entity> and other large specialised textual <entity id="L08-1236.10">collections</entity> ( <entity id="L08-1236.11">corpora</entity> ) in electronic <entity id="L08-1236.12">form</entity> <entity id="L08-1236.13">increase</entity> on a daily <entity id="L08-1236.14">basis</entity> to a <entity id="L08-1236.15">level</entity> beyond the human mind can grasp and interpret. As the <entity id="L08-1236.16">volume</entity> of <entity id="L08-1236.17">data</entity> continues to <entity id="L08-1236.18">increase</entity> , substantial <entity id="L08-1236.19">support</entity> from new <entity id="L08-1236.20">information technologies</entity> and <entity id="L08-1236.21">computational</entity> <entity id="L08-1236.22">techniques</entity> grounded in the <entity id="L08-1236.23">form</entity> of the ever <entity id="L08-1236.24">increasing</entity> <entity id="L08-1236.25">applications</entity> of the mining <entity id="L08-1236.26">paradigm</entity></abstract>


composed_of(L08-1236.3,L08-1236.5)

</text>

<text id="L08-1378">
<title>
An <entity id="L08-1378.1">Evaluation</entity> of Spoken and Textual <entity id="L08-1378.2">Interaction</entity> in the RITEL Interactive <entity id="L08-1378.3">Question <entity id="L08-1378.4">Answering System</entity></entity></title>
<abstract>
The RITEL <entity id="L08-1378.5">project</entity> aims to integrate a spoken <entity id="L08-1378.6">language</entity> <entity id="L08-1378.7">dialogue system</entity> and an <entity id="L08-1378.8">open-domain</entity> <entity id="L08-1378.9">information retrieval system</entity> in <entity id="L08-1378.10">order</entity> to enable human <entity id="L08-1378.11">users</entity> to ask a general <entity id="L08-1378.12">question</entity> and to refine their <entity id="L08-1378.13">search</entity> for <entity id="L08-1378.14">information</entity> interactively. This <entity id="L08-1378.15">type</entity> of <entity id="L08-1378.16">system</entity> is often referred to as an Interactive <entity id="L08-1378.17">Question Answering</entity> (IQA) <entity id="L08-1378.18">system</entity> . In this <entity id="L08-1378.19">paper</entity> , we present an <entity id="L08-1378.20">evaluation</entity> of how the <entity id="L08-1378.21">performance</entity> of the RITEL <entity id="L08-1378.22">system</entity> differs when <entity id="L08-1378.23">users</entity> interact with it using spoken versus textual <entity id="L08-1378.24">input</entity> and <entity id="L08-1378.25">output</entity> . Our <entity id="L08-1378.26">results</entity> indicate that while <entity id="L08-1378.27">users</entity> do not perceive the two <entity id="L08-1378.28">versions</entity> to <entity id="L08-1378.29">perform</entity> significantly differently, many more <entity id="L08-1378.30">questions</entity> are asked in a typical <entity id="L08-1378.31">text-based</entity> <entity id="L08-1378.32">dialogue</entity> .
</abstract>


study(L08-1378.1,L08-1378.3)
propose(L08-1378.19,L08-1378.20)
char(L08-1378.21,L08-1378.22)

</text>

<text id="D08-1093">
<title><entity id="D08-1093.1">Automatic</entity> <entity id="D08-1093.2">Prediction</entity> of <entity id="D08-1093.3">Parser</entity> <entity id="D08-1093.4">Accuracy</entity></title> 
<abstract><entity id="D08-1093.5">Statistical</entity> <entity id="D08-1093.6">parsers</entity> have become increasingly accurate, to the point where they are useful in many <entity id="D08-1093.7">natural language</entity> <entity id="D08-1093.8">applications</entity> . However, estimating <entity id="D08-1093.9">parsing</entity> <entity id="D08-1093.10">accuracy</entity> on a wide <entity id="D08-1093.11">variety</entity> of <entity id="D08-1093.12">domains</entity> and <entity id="D08-1093.13">genres</entity> is still a <entity id="D08-1093.14">challenge</entity> in the <entity id="D08-1093.15">absence</entity> of <entity id="D08-1093.16">gold-standard</entity> <entity id="D08-1093.17">parse trees</entity> . In this <entity id="D08-1093.18">paper</entity> , we <entity id="D08-1093.19">propose</entity> a <entity id="D08-1093.20">technique</entity> that automatically takes into account certain <entity id="D08-1093.21">characteristics</entity> of the <entity id="D08-1093.22">domains</entity> of interest, and accurately predicts <entity id="D08-1093.23">parser</entity> <entity id="D08-1093.24">performance</entity> on <entity id="D08-1093.25">data</entity> from these new <entity id="D08-1093.26">domains</entity> . As a <entity id="D08-1093.27">result</entity> , we have a cheap (no annotation involved) and effective recipe for measuring the <entity id="D08-1093.28">performance</entity> of a <entity id="D08-1093.29">statistical</entity> <entity id="D08-1093.30">parser</entity> on any given <entity id="D08-1093.31">domain</entity> .
</abstract>


propose(D08-1093.18,D08-1093.20)
char(D08-1093.28,D08-1093.30)

</text>

<text id="I05-1062">
<title>
French- <entity id="I05-1062.1">English</entity> <entity id="I05-1062.2">Terminology</entity> <entity id="I05-1062.3">Extraction</entity> from Comparable <entity id="I05-1062.4">Corpora</entity></title> 
<abstract><entity id="I05-1062.5">Abstract</entity> .
</abstract>


datasource(I05-1062.2,I05-1062.4)

</text>

<text id="I05-3010">
<title>
Turn-taking in Mandarin <entity id="I05-3010.1">Dialogue</entity> : Interactions of Tone and <entity id="I05-3010.2">Intonation</entity></title>
<abstract>
Fluent <entity id="I05-3010.3">dialogue</entity> <entity id="I05-3010.4">requires</entity> that speakers successfully negotiate and <entity id="I05-3010.5">signal</entity> turn-taking. While many <entity id="I05-3010.6">cues</entity> to turn change have been <entity id="I05-3010.7">proposed</entity> , especially in multi-modal <entity id="I05-3010.8">frameworks</entity> , here we <entity id="I05-3010.9">focus</entity> on the use ofprosodic <entity id="I05-3010.10">cues</entity> to these <entity id="I05-3010.11">functions</entity> . In particular, we consider the use of prosodic <entity id="I05-3010.12">cues</entity> in a tone <entity id="I05-3010.13">language</entity> , Mandarin <entity id="I05-3010.14">Chinese</entity> , where <entity id="I05-3010.15">variations</entity> in <entity id="I05-3010.16">pitch</entity> height and slope additionally serve to determine <entity id="I05-3010.17">word meaning</entity> . Within a <entity id="I05-3010.18">corpus</entity> of spontaneous <entity id="I05-3010.19">Chinese</entity> <entity id="I05-3010.20">dialogues</entity> , we find that <entity id="I05-3010.21">turn-unit</entity> final syllables are significantly lower in average <entity id="I05-3010.22">pitch</entity> and intensity than <entity id="I05-3010.23">turn-unit</entity> initial syllables in both <entity id="I05-3010.24">smooth</entity> turn changes and <entity id="I05-3010.25">segments</entity> ended by speaker overlap. Interruptions are characterized by significant prosodic <entity id="I05-3010.26">differences</entity> from <entity id="I05-3010.27">smooth</entity> turn initiations. Furthermore, we demonstrate that these <entity id="I05-3010.28">contrasts</entity> correspond to an overall lowering across all tones in final position, which largely preserves the <entity id="I05-3010.29">relative</entity> heights of the <entity id="I05-3010.30">lexical</entity> tones. In <entity id="I05-3010.31">classification tasks</entity> , we <entity id="I05-3010.32">contrast</entity> the use of <entity id="I05-3010.33">text</entity> and prosodic <entity id="I05-3010.34">features</entity> . Finally, we demonstrate that, on balanced <entity id="I05-3010.35">training</entity> and <entity id="I05-3010.36">test sets</entity> , we can distinguish <entity id="I05-3010.37">turn-unit</entity> final <entity id="I05-3010.38">words</entity> from other <entity id="I05-3010.39">words</entity> at 
 93% <entity id="I05-3010.40">accuracy</entity> and interruptions from <entity id="I05-3010.41">smooth</entity> turn <entity id="I05-3010.42">unit</entity> initiations at 62% <entity id="I05-3010.43">accuracy</entity> .
</abstract>


char(I05-3010.15,I05-3010.16)
composed_of(I05-3010.18,I05-3010.20)

</text>

<text id="E03-1033">
<title>
Rigid Grammars In The Associative-Commutative Lambek <entity id="E03-1033.1">Calculus</entity> Are Not Learnable
</title>
<abstract>
In ( Kanazawa, 1998 ) it was shown that rigid Classical Categorial Grammars are learnable (in the <entity id="E03-1033.2">sense</entity> of ( <entity id="E03-1033.3">Gold</entity> , 1967 )) from <entity id="E03-1033.4">strings</entity> . Surprisingly there <entity id="E03-1033.5">arc</entity> recent negative <entity id="E03-1033.6">results</entity> for, among others, rigid associative Lambek (L) LP LP0
</abstract>



</text>

<text id="E03-1036">
<title>
Multi-Modal Combinatory <entity id="E03-1036.1">Categorial Grammar</entity></title>
<abstract>
The <entity id="E03-1036.2">paper</entity> shows how Combinatory <entity id="E03-1036.3">Categorial Grammar</entity> (CCG) can be <entity id="E03-1036.4">adapted</entity> to take <entity id="E03-1036.5">advantage</entity> of the extra <entity id="E03-1036.6">resource-sensitivity</entity> <entity id="E03-1036.7">provided</entity> by the Categorial <entity id="E03-1036.8">Type</entity> <entity id="E03-1036.9">Logic</entity> <entity id="E03-1036.10">framework</entity> . The <entity id="E03-1036.11">resulting</entity> reformulation, Multi-Modal CCG, <entity id="E03-1036.12">supports</entity> lexically specified <entity id="E03-1036.13">control</entity> over the <entity id="E03-1036.14">applicability</entity> of combinatory <entity id="E03-1036.15">rules</entity> , permitting a universal rale <entity id="E03-1036.16">component</entity> and shedding the need for <entity id="E03-1036.17">language-specific</entity> <entity id="E03-1036.18">restrictions</entity> on <entity id="E03-1036.19">rules</entity> . We discuss some of the linguistic <entity id="E03-1036.20">motivation</entity> for these changes, define the Multi-Modal CCG <entity id="E03-1036.21">system</entity> and demonstrate how it works on some <entity id="E03-1036.22">basic</entity> <entity id="E03-1036.23">examples</entity> . We furthermore <entity id="E03-1036.24">outline</entity> some possible <entity id="E03-1036.25">extensions</entity> and address <entity id="E03-1036.26">computational</entity> <entity id="E03-1036.27">aspects</entity> of Multi-Modal CCG.
</abstract>


propose(E03-1036.2,E03-1036.3)

</text>

<text id="E03-1061">
<title><entity id="E03-1061.1">Automatic</entity> <entity id="E03-1061.2">Acquisition</entity> Of <entity id="E03-1061.3">Script</entity> <entity id="E03-1061.4">Knowledge</entity> From A <entity id="E03-1061.5">Text</entity> <entity id="E03-1061.6">Collection</entity></title>
<abstract>
In this <entity id="E03-1061.7">paper</entity> , we describe a <entity id="E03-1061.8">method</entity> for <entity id="E03-1061.9">automatic</entity> <entity id="E03-1061.10">acquisition</entity> of <entity id="E03-1061.11">script</entity> <entity id="E03-1061.12">knowledge</entity> from a <entity id="E03-1061.13">Japanese</entity> <entity id="E03-1061.14">text</entity> <entity id="E03-1061.15">collection</entity> . <entity id="E03-1061.16">Script</entity> <entity id="E03-1061.17">knowledge</entity> represents a typical <entity id="E03-1061.18">sequence</entity> of <entity id="E03-1061.19">actions</entity> that occur in a particular <entity id="E03-1061.20">situation</entity> . We <entity id="E03-1061.21">extracted</entity> <entity id="E03-1061.22">sequences</entity> ( <entity id="E03-1061.23">pairs</entity> ) of <entity id="E03-1061.24">actions</entity> occurring in <entity id="E03-1061.25">time</entity> <entity id="E03-1061.26">order</entity> from a <entity id="E03-1061.27">Japanese</entity> <entity id="E03-1061.28">text</entity> <entity id="E03-1061.29">collection</entity> and then chose those that were typical of certain <entity id="E03-1061.30">situations</entity> by <entity id="E03-1061.31">ranking</entity> these <entity id="E03-1061.32">sequences</entity> ( <entity id="E03-1061.33">pairs</entity> ) in <entity id="E03-1061.34">terms</entity> of the <entity id="E03-1061.35">frequency</entity> of their <entity id="E03-1061.36">occurrence</entity> . To <entity id="E03-1061.37">extract</entity> <entity id="E03-1061.38">sequences</entity> of <entity id="E03-1061.39">actions</entity> occurring in <entity id="E03-1061.40">time</entity> <entity id="E03-1061.41">order</entity> , we <entity id="E03-1061.42">constructed</entity> a <entity id="E03-1061.43">text</entity> <entity id="E03-1061.44">collection</entity> in which <entity id="E03-1061.45">texts</entity> describing facts relating to a similar <entity id="E03-1061.46">situation</entity> were <entity id="E03-1061.47">clustered</entity> together and arranged in <entity id="E03-1061.48">time</entity> <entity id="E03-1061.49">order</entity> . We also describe a preliminary <entity id="E03-1061.50">experiment</entity> with our <entity id="E03-1061.51">acquisition</entity> <entity id="E03-1061.52">system</entity> and discuss the <entity id="E03-1061.53">results</entity> .
</abstract>


datasource(E03-1061.4,E03-1061.6)
propose(E03-1061.7,E03-1061.8)
datasource(E03-1061.12,E03-1061.15)
datasource(E03-1061.22,E03-1061.29)
char(E03-1061.35,E03-1061.36)

</text>

<text id="E03-2007">
<title>
WASPBENCH: A Lexicographer's Workbench Incorporating State-Of-The-Art <entity id="E03-2007.1">Word Sense Disambiguation</entity></title> 
<abstract><entity id="E03-2007.2">word sense disambiguation</entity> .Adam Kilgarriff , Roger Evans , Rob Koeling Michael Rundell , David Tugwell</abstract>



</text>

<text id="E06-1040">
<title>
Comparing <entity id="E06-1040.1">Automatic</entity> And Human <entity id="E06-1040.2">Evaluation</entity> Of NLG <entity id="E06-1040.3">Systems</entity></title>
<abstract>
We consider the <entity id="E06-1040.4">evaluation</entity> <entity id="E06-1040.5">problem</entity> in <entity id="E06-1040.6">Natural <entity id="E06-1040.7">Language Generation</entity></entity> (nlg) and present <entity id="E06-1040.8">results</entity> for <entity id="E06-1040.9">evaluating</entity> several nlg <entity id="E06-1040.10">systems</entity> with similar <entity id="E06-1040.11">functionality</entity> , <entity id="E06-1040.12">including</entity> a <entity id="E06-1040.13">knowledge-based</entity> <entity id="E06-1040.14">generator</entity> and several <entity id="E06-1040.15">statistical</entity> <entity id="E06-1040.16">systems</entity> . We compare <entity id="E06-1040.17">evaluation results</entity> for these <entity id="E06-1040.18">systems</entity> by human <entity id="E06-1040.19">domain</entity> <entity id="E06-1040.20">experts</entity> , human non-experts, and several automatic <entity id="E06-1040.21">evaluation metrics</entity> , <entity id="E06-1040.22">including</entity> nist, bleu, and <entity id="E06-1040.23">rouge</entity> . We find that nist scores correlate best (> 0.8) with human <entity id="E06-1040.24">judgments</entity> , but that all <entity id="E06-1040.25">automatic</entity> <entity id="E06-1040.26">metrics</entity> we examined are <entity id="E06-1040.27">biased</entity> in favour of <entity id="E06-1040.28">generators</entity> that select on the <entity id="E06-1040.29">basis</entity> of <entity id="E06-1040.30">frequency</entity> alone. We conclude that <entity id="E06-1040.31">automatic <entity id="E06-1040.32">evaluation</entity></entity> of nlg <entity id="E06-1040.33">systems</entity> has considerable potential, in particular where <entity id="E06-1040.34">high-quality</entity> <entity id="E06-1040.35">reference</entity> <entity id="E06-1040.36">texts</entity> and only a small <entity id="E06-1040.37">number</entity> of human evalua-tors are available. However, in general it is probably best for <entity id="E06-1040.38">automatic evaluations</entity> to be <entity id="E06-1040.39">supported</entity> by human-based <entity id="E06-1040.40">evaluations</entity> , or at least by <entity id="E06-1040.41">studies</entity> that demonstrate that a particular <entity id="E06-1040.42">metric</entity> correlates well with human <entity id="E06-1040.43">judgments</entity> in a given <entity id="E06-1040.44">domain</entity> .
</abstract>


study(E06-1040.2,E06-1040.3)
problem(E06-1040.4,E06-1040.6)
problem(E06-1040.26,E06-1040.27,REVERSE)
study(E06-1040.31,E06-1040.33)

</text>

<text id="N03-2017">
<title><entity id="N03-2017.1">Word <entity id="N03-2017.2">Alignment</entity></entity> With <entity id="N03-2017.3">Cohesion</entity> <entity id="N03-2017.4">Constraint</entity></title>
<abstract>
We present a <entity id="N03-2017.5">syntax-based</entity> <entity id="N03-2017.6">constraint</entity> for <entity id="N03-2017.7">word alignment</entity> , known as the <entity id="N03-2017.8">cohesion</entity> <entity id="N03-2017.9">constraint</entity> . It <entity id="N03-2017.10">requires</entity> disjoint <entity id="N03-2017.11">English</entity> <entity id="N03-2017.12">phrases</entity> to be <entity id="N03-2017.13">mapped</entity> to non-overlapping <entity id="N03-2017.14">intervals</entity> in the French <entity id="N03-2017.15">sentence</entity> . We <entity id="N03-2017.16">evaluate</entity> the <entity id="N03-2017.17">utility</entity> of this <entity id="N03-2017.18">constraint</entity> in two different <entity id="N03-2017.19">algorithms</entity> . The <entity id="N03-2017.20">results</entity> show that it can <entity id="N03-2017.21">provide</entity> a significant <entity id="N03-2017.22">improvement</entity> in <entity id="N03-2017.23">alignment</entity> <entity id="N03-2017.24">quality</entity> .
</abstract>


based_on(N03-2017.1,N03-2017.3)
wrt(N03-2017.22,N03-2017.24)

</text>

<text id="N03-2027">
<title>
Bayesian Nets For <entity id="N03-2027.1">Syntactic</entity> <entity id="N03-2027.2">Categorization</entity> Of Novel <entity id="N03-2027.3">Words</entity></title>
<abstract>
This <entity id="N03-2027.4">paper</entity> presents an <entity id="N03-2027.5">application</entity> of a Dynamic Bayesian <entity id="N03-2027.6">Network</entity> (DBN) to the <entity id="N03-2027.7">task</entity> of assigning <entity id="N03-2027.8">Part-of-</entity> <entity id="N03-2027.9">Speech</entity> (PoS) <entity id="N03-2027.10">tags</entity> to novel <entity id="N03-2027.11">text</entity> . This <entity id="N03-2027.12">task</entity> is particularly <entity id="N03-2027.13">challenging</entity> for <entity id="N03-2027.14">non-standard</entity> <entity id="N03-2027.15">corpora</entity> , such as Internet lingo, where a large proportion of <entity id="N03-2027.16">words</entity> are unknown. Previous work reveals that <entity id="N03-2027.17">PoS <entity id="N03-2027.18">tags</entity></entity> depend on a <entity id="N03-2027.19">variety</entity> of morphological and <entity id="N03-2027.20">contextual <entity id="N03-2027.21">features</entity></entity> . Representing these <entity id="N03-2027.22">dependencies</entity> in a DBN <entity id="N03-2027.23">results</entity> into an elegant and effective PoS tagger.
</abstract>


taskapplied(N03-2027.2,N03-2027.3)
propose(N03-2027.4,N03-2027.5)
taskapplied(N03-2027.10,N03-2027.11)
affects(N03-2027.17,N03-2027.20,REVERSE)

</text>

<text id="N04-1018">
<title>
Detecting <entity id="N04-1018.1">Structural</entity> Metadata With <entity id="N04-1018.2">Decision</entity> Trees And <entity id="N04-1018.3">Transformation-</entity> <entity id="N04-1018.4">Based</entity> Learning
</title>
<abstract>
The regular <entity id="N04-1018.5">occurrence</entity> of disfluencies is a distinguishing <entity id="N04-1018.6">characteristic</entity> of <entity id="N04-1018.7">spontaneous speech</entity> . Detecting and removing such disfluencies can substantially <entity id="N04-1018.8">improve</entity> the <entity id="N04-1018.9">usefulness</entity> of <entity id="N04-1018.10">spontaneous speech</entity> <entity id="N04-1018.11">transcripts</entity> . This <entity id="N04-1018.12">paper</entity> presents a <entity id="N04-1018.13">system</entity> that detects various <entity id="N04-1018.14">types</entity> of disfluencies and other <entity id="N04-1018.15">structural</entity> <entity id="N04-1018.16">information</entity> with <entity id="N04-1018.17">cues</entity> obtained from <entity id="N04-1018.18">lexical</entity> and prosodic <entity id="N04-1018.19">information <entity id="N04-1018.20">sources</entity></entity> . Specifically, <entity id="N04-1018.21">combinations</entity> of <entity id="N04-1018.22">decision trees</entity> and <entity id="N04-1018.23">language models</entity> are used to predict <entity id="N04-1018.24">sentence</entity> ends and interruption points and, given these <entity id="N04-1018.25">events</entity> , <entity id="N04-1018.26">transformation-based</entity> <entity id="N04-1018.27">learning</entity> is used to detect edit disfluencies and conversational <entity id="N04-1018.28">fillers</entity> . <entity id="N04-1018.29">Results</entity> are <entity id="N04-1018.30">reported</entity> on human and <entity id="N04-1018.31">automatic</entity> <entity id="N04-1018.32">transcripts</entity> of conversational <entity id="N04-1018.33">telephone</entity> <entity id="N04-1018.34">speech</entity> .
</abstract>


propose(N04-1018.12,N04-1018.13)
datasource(N04-1018.17,N04-1018.19)
datasource(N04-1018.32,N04-1018.34)

</text>

<text id="N04-4021">
<title><entity id="N04-4021.1">Feature-</entity> <entity id="N04-4021.2">Based</entity> <entity id="N04-4021.3">Pronunciation</entity> <entity id="N04-4021.4">Modeling</entity> For <entity id="N04-4021.5">Speech <entity id="N04-4021.6">Recognition</entity></entity></title>
<abstract>
We present an <entity id="N04-4021.7">approach</entity> to <entity id="N04-4021.8">pronunciation</entity> <entity id="N04-4021.9">modeling</entity> in which the <entity id="N04-4021.10">evolution</entity> of multiple <entity id="N04-4021.11">linguistic feature</entity> <entity id="N04-4021.12">streams</entity> is explicitly represented. This differs from <entity id="N04-4021.13">phone-based models</entity> in that <entity id="N04-4021.14">pronunciation</entity> <entity id="N04-4021.15">variation</entity> is viewed as the <entity id="N04-4021.16">result</entity> of <entity id="N04-4021.17">feature</entity> asynchrony and changes in <entity id="N04-4021.18">feature values</entity> , rather than <entity id="N04-4021.19">phone</entity> <entity id="N04-4021.20">substitutions</entity> , <entity id="N04-4021.21">insertions</entity> , and <entity id="N04-4021.22">deletions</entity> . We have <entity id="N04-4021.23">implemented</entity> a flexible <entity id="N04-4021.24">feature-based</entity> <entity id="N04-4021.25">pronunciation</entity> <entity id="N04-4021.26">model</entity> using dynamic Bayesian <entity id="N04-4021.27">networks</entity> . In this <entity id="N04-4021.28">paper</entity> , we describe our <entity id="N04-4021.29">approach</entity> and <entity id="N04-4021.30">report</entity> on a <entity id="N04-4021.31">pilot</entity> <entity id="N04-4021.32">experiment</entity> using phonetic <entity id="N04-4021.33">transcriptions</entity> of <entity id="N04-4021.34">utterances</entity> from the Switchboard <entity id="N04-4021.35">corpus</entity> . The <entity id="N04-4021.36">experimental</entity> <entity id="N04-4021.37">results</entity> , as well as the <entity id="N04-4021.38">model</entity> 's qualitative <entity id="N04-4021.39">behavior</entity> , suggest that this is a promising way of <entity id="N04-4021.40">accounting</entity> for the <entity id="N04-4021.41">types</entity> of <entity id="N04-4021.42">pronunciation</entity> <entity id="N04-4021.43">variation</entity> often seen in <entity id="N04-4021.44">spontaneous speech</entity> .
</abstract>


usedfor(N04-4021.4,N04-4021.5)
based_on(N04-4021.26,N04-4021.27)
propose(N04-4021.28,N04-4021.29)
datasource(N04-4021.33,N04-4021.35)

</text>

<text id="N04-4028">
<title><entity id="N04-4028.1">Confidence</entity> <entity id="N04-4028.2">Estimation</entity> For <entity id="N04-4028.3">Information Extraction</entity></title> 
<abstract><entity id="N04-4028.4">Information extraction</entity> <entity id="N04-4028.5">techniques</entity> automatically create <entity id="N04-4028.6">structured</entity> <entity id="N04-4028.7">databases</entity> from unstructured <entity id="N04-4028.8">data</entity> <entity id="N04-4028.9">sources</entity> , such as the Web or newswire <entity id="N04-4028.10">documents</entity> . Despite the <entity id="N04-4028.11">successes</entity> of these <entity id="N04-4028.12">systems</entity> , <entity id="N04-4028.13">accuracy</entity> will always be imperfect. For many <entity id="N04-4028.14">reasons</entity> , it is highly desirable to accurately estimate the <entity id="N04-4028.15">confidence</entity> the <entity id="N04-4028.16">system</entity> has in the <entity id="N04-4028.17">correctness</entity> of each <entity id="N04-4028.18">extracted</entity> <entity id="N04-4028.19">field</entity> . The <entity id="N04-4028.20">information <entity id="N04-4028.21">extraction system</entity></entity> we <entity id="N04-4028.22">evaluate</entity> is <entity id="N04-4028.23">based</entity> on a <entity id="N04-4028.24">linear-chain</entity> <entity id="N04-4028.25">conditional random <entity id="N04-4028.26">field</entity></entity> (CRF), a <entity id="N04-4028.27">probabilistic model</entity> which has <entity id="N04-4028.28">performed</entity> well on information <entity id="N04-4028.29">extraction tasks</entity> because of its <entity id="N04-4028.30">ability</entity> to capture arbitrary, overlapping <entity id="N04-4028.31">features</entity> of the <entity id="N04-4028.32">input</entity> in a <entity id="N04-4028.33">Markov model</entity> . We <entity id="N04-4028.34">implement</entity> several <entity id="N04-4028.35">techniques</entity> to estimate the <entity id="N04-4028.36">confidence</entity> of both <entity id="N04-4028.37">extracted</entity> <entity id="N04-4028.38">fields</entity> and entire <entity id="N04-4028.39">multi-field</entity> <entity id="N04-4028.40">records</entity> , obtaining an average <entity id="N04-4028.41">precision</entity> of 98% for retrieving correct <entity id="N04-4028.42">fields</entity> and 87% for <entity id="N04-4028.43">multi-field</entity> <entity id="N04-4028.44">records</entity> .
</abstract>


datasource(N04-4028.7,N04-4028.9)
based_on(N04-4028.20,N04-4028.25)
model(N04-4028.31,N04-4028.32)
yields(N04-4028.35,N04-4028.41)

</text>

<text id="N06-4001">
<title>
InfoMagnets: Making <entity id="N06-4001.1">Sense</entity> Of <entity id="N06-4001.2">Corpus</entity> <entity id="N06-4001.3">Data</entity></title>
<abstract>
We introduce a new interactive <entity id="N06-4001.4">corpus</entity> <entity id="N06-4001.5">exploration</entity> <entity id="N06-4001.6">tool</entity> <entity id="N06-4001.7">called</entity> InfoMagnets. InfoMagnets aims at making exploratory <entity id="N06-4001.8">corpus</entity> <entity id="N06-4001.9">analysis</entity> accessible to <entity id="N06-4001.10">researchers</entity> who are not <entity id="N06-4001.11">experts</entity> in <entity id="N06-4001.12">text</entity> mining. As <entity id="N06-4001.13">evidence</entity> of its <entity id="N06-4001.14">usefulness</entity> and usability, it has been used successfully in a <entity id="N06-4001.15">research</entity> <entity id="N06-4001.16">context</entity> to uncover <entity id="N06-4001.17">relationships</entity> between <entity id="N06-4001.18">language</entity> and behavioral <entity id="N06-4001.19">patterns</entity> in two distinct <entity id="N06-4001.20">domains</entity> : tutorial <entity id="N06-4001.21">dialogue</entity> ( Kumar et al., submitted) and on-line <entity id="N06-4001.22">communities</entity> ( Arguello et al., 2006 ). As an educational <entity id="N06-4001.23">tool</entity> , it has been used as <entity id="N06-4001.24">part</entity> of a <entity id="N06-4001.25">unit</entity> on <entity id="N06-4001.26">protocol</entity> <entity id="N06-4001.27">analysis</entity> in an Educational <entity id="N06-4001.28">Research</entity> <entity id="N06-4001.29">Methods</entity> course.
</abstract>



</text>

<text id="M91-1029">
<title>
PRC Inc: <entity id="M91-1029.1">Description</entity> Of The PAKTUS <entity id="M91-1029.2">System</entity> Used For MUC-3
</title>
<abstract>
The PRC Adaptive <entity id="M91-1029.3">Knowledge-based</entity> <entity id="M91-1029.4">Text</entity> <entity id="M91-1029.5">Understanding System</entity> (PAKTUS) has been under <entity id="M91-1029.6">development</entity> as an Independent <entity id="M91-1029.7">Research</entity> and <entity id="M91-1029.8">Development</entity> <entity id="M91-1029.9">project</entity> at PRC since 1984. The <entity id="M91-1029.10">objective</entity> is a generic <entity id="M91-1029.11">system</entity> of <entity id="M91-1029.12">tools</entity> , <entity id="M91-1029.13">including</entity> a <entity id="M91-1029.14">core</entity> <entity id="M91-1029.15">English</entity> <entity id="M91-1029.16">lexicon</entity> , grammar, and <entity id="M91-1029.17">concept</entity> <entity id="M91-1029.18">representations</entity> , for <entity id="M91-1029.19">building</entity> <entity id="M91-1029.20">natural language processing</entity> (NLP) <entity id="M91-1029.21">systems</entity> for <entity id="M91-1029.22">text</entity> <entity id="M91-1029.23">understanding</entity> . <entity id="M91-1029.24">Systems</entity> built with PAKTUS are intended to <entity id="M91-1029.25">generate</entity> <entity id="M91-1029.26">input</entity> to <entity id="M91-1029.27">knowledge based</entity> <entity id="M91-1029.28">systems</entity> or <entity id="M91-1029.29">data</entity> <entity id="M91-1029.30">base</entity> <entity id="M91-1029.31">systems</entity> . <entity id="M91-1029.32">Input</entity> to the <entity id="M91-1029.33">NLP system</entity> is typically derived from an existing electronic <entity id="M91-1029.34">message</entity> <entity id="M91-1029.35">stream</entity> , such as a <entity id="M91-1029.36">news</entity> wire. PAKTUS <entity id="M91-1029.37">supports</entity> the <entity id="M91-1029.38">adaptation</entity> of the generic <entity id="M91-1029.39">core</entity> to a <entity id="M91-1029.40">variety</entity> of <entity id="M91-1029.41">domains</entity> : JINTACCS <entity id="M91-1029.42">messages</entity> , RAINFORM <entity id="M91-1029.43">messages</entity> , <entity id="M91-1029.44">news</entity> <entity id="M91-1029.45">reports</entity> about a specific <entity id="M91-1029.46">type</entity> of <entity id="M91-1029.47">event</entity> , such as financial <entity id="M91-1029.48">transfers</entity> or terrorist acts, etc., by acquiring sublanguage and <entity id="M91-1029.49">domain-specific</entity> grammar, <entity id="M91-1029.50">words</entity> , conceptual <entity id="M91-1029.51">mappings</entity> , and <entity id="M91-1029.52">discourse</entity> <entity id="M91-1029.53">patterns</entity> . The <entity id="M91-1029.54">long-term</entity> <entity id="M91-1029.55">goal</entity> is a <entity id="M91-1029.56">system</entity> that can <entity id="M91-1029.57">support</entity> the <entity id="M91-1029.58">processing</entity> of relatively long <entity id="M91-1029.59">discourses</entity> in <entity id="M91-1029.60">domains</entity> that are fairly broad with a high <entity id="M91-1029.61">rate</entity> of <entity id="M91-1029.62">success</entity> .
</abstract>


model(M91-1029.1,M91-1029.2)
part_of(M91-1029.11,M91-1029.16,REVERSE)
usedfor(M91-1029.21,M91-1029.23)
datasource(M91-1029.32,M91-1029.35)
methodapplied(M91-1029.56,M91-1029.59)

</text>

<text id="M95-1007">
<title><entity id="M95-1007.1">University</entity> Of Durham: <entity id="M95-1007.2">Description</entity> Of The LOLITA <entity id="M95-1007.3">System</entity> As Used In MUC-6
</title>
<abstract><entity id="M95-1007.4">UNIVERSITY</entity> OF DURHAM: <entity id="M95-1007.5">DESCRIPTION</entity> OF THE LOLITA <entity id="M95-1007.6">SYSTEM</entity> AS USED IN MUC-6. <entity id="M95-1007.7">Laboratory</entity> for <entity id="M95-1007.8">Natural Language Engineering</entity> <entity id="M95-1007.9">Department</entity> of <entity id="M95-1007.10">Computer Science University</entity> of Durham South Road Durham, DH1 3LE, United Kingdom, email:
</abstract>



</text>

<text id="A92-1035">
<title>
Practical World <entity id="A92-1035.1">Modeling</entity> For <entity id="A92-1035.2">NLP <entity id="A92-1035.3">Applications</entity></entity></title>


usedfor(A92-1035.1,A92-1035.2)

</text>

<abstract></abstract>

<text id="A92-1041">
<title><entity id="A92-1041.1">Lexicon</entity> <entity id="A92-1041.2">Design</entity> Using A Paradigmatic <entity id="A92-1041.3">Approach</entity></title>
<abstract>
The <entity id="A92-1041.4">paper</entity> describes <entity id="A92-1041.5">models</entity> for <entity id="A92-1041.6">representation</entity> and <entity id="A92-1041.7">methods</entity> to handle lexicographic <entity id="A92-1041.8">structures</entity> supplied by the
</abstract>


propose(A92-1041.4,A92-1041.5)

</text>

<text id="A94-1002">
<title>
Practical Issues In <entity id="A94-1002.1">Automatic</entity> <entity id="A94-1002.2">Documentation</entity> <entity id="A94-1002.3">Generation</entity></title>
<abstract>
PLANDoc, a <entity id="A94-1002.4">system</entity> under joint <entity id="A94-1002.5">development</entity> by Columbia and Bellcore, <entity id="A94-1002.6">documents</entity> the activity of planning engineers as they <entity id="A94-1002.7">study</entity> <entity id="A94-1002.8">telephone</entity> <entity id="A94-1002.9">routes</entity> . It takes as <entity id="A94-1002.10">input</entity> a trace of the engineer's <entity id="A94-1002.11">interaction</entity> with a <entity id="A94-1002.12">network</entity> planning <entity id="A94-1002.13">tool</entity> and produces 1-2 <entity id="A94-1002.14">page</entity> <entity id="A94-1002.15">summary</entity> . In this <entity id="A94-1002.16">paper</entity> , we describe the <entity id="A94-1002.17">user</entity> needs <entity id="A94-1002.18">analysis</entity> we <entity id="A94-1002.19">performed</entity> and how it <entity id="A94-1002.20">influenced</entity> the <entity id="A94-1002.21">development</entity> of PLANDoc. In particular, we show how it pinpointed the need for a sublanguage <entity id="A94-1002.22">specification</entity> , allowing us to identify <entity id="A94-1002.23">input</entity> <entity id="A94-1002.24">messages</entity> and to characterize the different <entity id="A94-1002.25">sentence</entity> paraphrases for realizing them. We <entity id="A94-1002.26">focus</entity> on the systematic use of <entity id="A94-1002.27">conjunction</entity> in <entity id="A94-1002.28">combination</entity> with paraphrase that we <entity id="A94-1002.29">developed</entity> for PLANDoc, which allows for the <entity id="A94-1002.30">generation</entity> of <entity id="A94-1002.31">summaries</entity> that are both concise-avoiding <entity id="A94-1002.32">repetition</entity> of similar <entity id="A94-1002.33">information</entity> , and fluent-avoiding <entity id="A94-1002.34">repetition</entity> of similar phrasing.
</abstract>


propose(A94-1002.16,A94-1002.18)

</text>

<text id="E93-1053">
<title>
Localising Barriers <entity id="E93-1053.1">Theory</entity></title>
<abstract>
Government-Binding <entity id="E93-1053.2">Parsing</entity> has become attractive in the last few years. A <entity id="E93-1053.3">variety</entity> of <entity id="E93-1053.4">systems</entity> have been <entity id="E93-1053.5">designed</entity> in view of a <entity id="E93-1053.6">correspondence</entity> as direct as possible with <entity id="E93-1053.7">linguistic theory</entity> ([ Johnson, 1989 ], [ Pollard and  <entity id="E93-1053.8">Sag</entity> , 1991 ], [ Kroch, 1989 ]). These <entity id="E93-1053.9">approaches</entity> can be classified by their <entity id="E93-1053.10">method</entity> of handling
</abstract>



</text>

<text id="H89-1050">
<title>
Reducing <entity id="H89-1050.1">Search</entity> By Partitioning The <entity id="H89-1050.2">Word</entity> <entity id="H89-1050.3">Network</entity></title> 
<abstract><entity id="H89-1050.4">Palmer</entity> , Martha ; Dahl , Deborah A. ; Schiffman , Rebecca J. ; Hirschman , Lynette ; Linebarger , Marcia C. ; Dowding, John ,Recovering Implicit <entity id="H89-1050.5">Information</entity> ,Annual Meeting Of The <entity id="H89-1050.6">Association</entity> For <entity id="H89-1050.7">Computation</entity> al <entity id="H89-1050.8">Linguistics</entity> ,1986</abstract>



</text>

<text id="H90-1017">
<title>
The Dragon <entity id="H90-1017.1">Continuous Speech Recognition System</entity> : A Real- <entity id="H90-1017.2">Time</entity> <entity id="H90-1017.3">Implementation</entity></title>
<abstract>
We present a 1000- <entity id="H90-1017.4">word</entity> <entity id="H90-1017.5">continuous speech recognition</entity> (CSR) <entity id="H90-1017.6">system</entity> that operates in <entity id="H90-1017.7">real time</entity> on a personal <entity id="H90-1017.8">computer</entity> (PC). The <entity id="H90-1017.9">system</entity> , <entity id="H90-1017.10">designed</entity> for large <entity id="H90-1017.11">vocabulary</entity> <entity id="H90-1017.12">natural language</entity> <entity id="H90-1017.13">tasks</entity> , makes use of phonetic <entity id="H90-1017.14">Hidden Markov models</entity> (HMM) and incorporates acoustic, phonetic, and linguistic <entity id="H90-1017.15">sources</entity> of <entity id="H90-1017.16">knowledge</entity> to achieve high <entity id="H90-1017.17">recognition</entity> <entity id="H90-1017.18">performance</entity> . We describe the various <entity id="H90-1017.19">components</entity> of this <entity id="H90-1017.20">system</entity> . We also present our <entity id="H90-1017.21">strategy</entity> for achieving <entity id="H90-1017.22">real time</entity> <entity id="H90-1017.23">recognition</entity> on the PC. Using a 486- <entity id="H90-1017.24">based</entity> PC with a 29K- <entity id="H90-1017.25">based</entity> add-on board, the recognizer has been <entity id="H90-1017.26">timed</entity> at 1.1 <entity id="H90-1017.27">times</entity> <entity id="H90-1017.28">real time</entity> .
</abstract>


usedfor(H90-1017.9,H90-1017.13)

</text>

<text id="H90-1028">
<title>
Preliminary ATIS <entity id="H90-1028.1">Development</entity> At MIT
</title>
<abstract>
"DARPA has recently initiated a plan for a <entity id="H90-1028.2">common</entity> spoken <entity id="H90-1028.3">language</entity> <entity id="H90-1028.4">task</entity> , to be <entity id="H90-1028.5">developed</entity> independently by all members of the DARPA <entity id="H90-1028.6">community</entity> , with the hope that it will <entity id="H90-1028.7">provide</entity> a <entity id="H90-1028.8">mechanism</entity> leading to appropriate formal <entity id="H90-1028.9">evaluation</entity> <entity id="H90-1028.10">procedures</entity> at the <entity id="H90-1028.11">level</entity> of spoken <entity id="H90-1028.12">language</entity> . The <entity id="H90-1028.13">task</entity> that was selected for this <entity id="H90-1028.14">purpose</entity> is the Air Travel <entity id="H90-1028.15">Information System</entity> (ATIS) <entity id="H90-1028.16">task</entity> , <entity id="H90-1028.17">based</entity> on selected <entity id="H90-1028.18">tables</entity> from the Official Airline Guide (OAG). It was decided that the first <entity id="H90-1028.19">evaluation</entity> would be limited in <entity id="H90-1028.20">scope</entity> to <entity id="H90-1028.21">deal</entity> with <entity id="H90-1028.22">text</entity> <entity id="H90-1028.23">input</entity> only, and to cover only <entity id="H90-1028.24">sentences</entity> that could be understood unambiguously out of <entity id="H90-1028.25">context</entity> . <entity id="H90-1028.26">Data</entity> have been <entity id="H90-1028.27">recorded</entity> over the past several months at Texas Instruments, using an <entity id="H90-1028.28">interface</entity> that involves a ""wizard"" who fully interprets the meaning of the subject's <entity id="H90-1028.29">sentences</entity> , and <entity id="H90-1028.30">generates</entity> <entity id="H90-1028.31">database</entity> responses using a <entity id="H90-1028.32">menu</entity> driven <entity id="H90-1028.33">data</entity> <entity id="H90-1028.34">access</entity> <entity id="H90-1028.35">system</entity> . We have been actively engaged in the last few months in <entity id="H90-1028.36">developing</entity> the <entity id="H90-1028.37">natural language</entity> and back end <entity id="H90-1028.38">portions</entity> of the MIT <entity id="H90-1028.39">version</entity> of the ATIS <entity id="H90-1028.40">domain</entity> . This <entity id="H90-1028.41">paper</entity> describes our <entity id="H90-1028.42">progress</entity> to <entity id="H90-1028.43">date</entity> on this <entity id="H90-1028.44">effort</entity> , <entity id="H90-1028.45">including</entity> an <entity id="H90-1028.46">evaluation</entity> of the <entity id="H90-1028.47">performance</entity> of the <entity id="H90-1028.48">system</entity> on the recently released designated DARPA <entity id="H90-1028.49">test set</entity> . The <entity id="H90-1028.50">remainder</entity> of this <entity id="H90-1028.51">paper</entity> is organized as follows. First we will give a general <entity id="H90-1028.52">description</entity> of the <entity id="H90-1028.53">system</entity> we are <entity id="H90-1028.54">developing</entity> , emphasizing those <entity id="H90-1028.55">aspects</entity> that differ from the <entity id="H90-1028.56">current</entity> general conception of the <entity id="H90-1028.57">common</entity> <entity id="H90-1028.58">task</entity> . Next we will describe in greater <entity id="H90-1028.59">detail</entity> certain <entity id="H90-1028.60">aspects</entity> of the back end, <entity id="H90-1028.61">including</entity> <entity id="H90-1028.62">knowledge representation</entity> , <entity id="H90-1028.63">control</entity> <entity id="H90-1028.64">strategy</entity> , the <entity id="H90-1028.65">user interface</entity> , and our preliminary <entity id="H90-1028.66">treatment</entity> of <entity id="H90-1028.67">discourse</entity> history. This is followed by a <entity id="H90-1028.68">section</entity> describing changes made in the <entity id="H90-1028.69">parser</entity> , in the <entity id="H90-1028.70">areas</entity> of <entity id="H90-1028.71">semantics</entity> , the <entity id="H90-1028.72">interface</entity> with the back-end, and a preliminary <entity id="H90-1028.73">new-word</entity> <entity id="H90-1028.74">treatment</entity> . This <entity id="H90-1028.75">section</entity> also <entity id="H90-1028.76">includes</entity> a brief <entity id="H90-1028.77">discussion</entity> of some interesting <entity id="H90-1028.78">phenomena</entity> that occurred in the <entity id="H90-1028.79">training</entity> <entity id="H90-1028.80">sentences</entity> . An <entity id="H90-1028.81">evaluation</entity> <entity id="H90-1028.82">section</entity> follows, discussing our <entity id="H90-1028.83">system</entity> 's <entity id="H90-1028.84">performance</entity> on both <entity id="H90-1028.85">training</entity> and <entity id="H90-1028.86">test</entity> data, as well as a preliminary <entity id="H90-1028.87">assessment</entity> of the <entity id="H90-1028.88">perplexity</entity> of the <entity id="H90-1028.89">system</entity> . We conclude with a <entity id="H90-1028.90">summary</entity> of our <entity id="H90-1028.91">results</entity> and our position on the <entity id="H90-1028.92">nature</entity> of the <entity id="H90-1028.93">common</entity> <entity id="H90-1028.94">task</entity> . "
</abstract>


isa(H90-1028.13,H90-1028.16)
methodapplied(H90-1028.19,H90-1028.23)
char(H90-1028.24,H90-1028.25)
propose(H90-1028.41,H90-1028.42)
study(H90-1028.46,H90-1028.47)
model(H90-1028.52,H90-1028.53)
propose(H90-1028.68,H90-1028.69)
propose(H90-1028.75,H90-1028.77)
phenomenon(H90-1028.78,H90-1028.80)
propose(H90-1028.82,H90-1028.84)
propose(H90-1028.90,H90-1028.91)

</text>

<text id="H91-1023">
<title>
Session 3: <entity id="H91-1023.1">Machine Translation</entity></title> 
<abstract><entity id="H91-1023.2">Semantic <entity id="H91-1023.3">analysis</entity></entity> to resolve <entity id="H91-1023.4">lexical</entity> and <entity id="H91-1023.5">syntactic</entity> <entity id="H91-1023.6">ambiguities</entity> during <entity id="H91-1023.7">parsing</entity> , and thus reduce <entity id="H91-1023.8">translation</entity> <entity id="H91-1023.9">errors</entity> very significantly. 
 <entity id="H91-1023.10">Unification</entity> grammars allowing <entity id="H91-1023.11">syntactic</entity> and <entity id="H91-1023.12">semantic</entity> <entity id="H91-1023.13">constraints</entity> to be <entity id="H91-1023.14">checked</entity> in a unified <entity id="H91-1023.15">manner</entity> while <entity id="H91-1023.16">parsing</entity> , and permitting reversible grammars
i.e., the same grammars to be used for <entity id="H91-1023.17">generation</entity> as well as for <entity id="H91-1023.18">analysis</entity> . 
 Advanced <entity id="H91-1023.19">parsing</entity> <entity id="H91-1023.20">methodologies</entity> , <entity id="H91-1023.21">including</entity> augmented-LR <entity id="H91-1023.22">compilation</entity> where <entity id="H91-1023.23">knowledge sources</entity> ( <entity id="H91-1023.24">syntactic</entity> grammars, <entity id="H91-1023.25">lexicons</entity> , and <entity id="H91-1023.26">semantic</entity> <entity id="H91-1023.27">ontologies</entity> ) can be defined and maintained separately but are jointly compiled to <entity id="H91-1023.28">apply</entity> simultaneously at run <entity id="H91-1023.29">time</entity> , both in <entity id="H91-1023.30">parsing</entity> and in <entity id="H91-1023.31">generation</entity> . 
 <entity id="H91-1023.32">Natural language generation</entity> , <entity id="H91-1023.33">focusing</entity> on how to <entity id="H91-1023.34">structure</entity> fluent <entity id="H91-1023.35">target-language</entity> <entity id="H91-1023.36">output</entity> , an activity not truly investigated in the pre-ALPAC days. 
 Automated <entity id="H91-1023.37">corpus</entity> <entity id="H91-1023.38">analysis</entity> <entity id="H91-1023.39">tools</entity> , <entity id="H91-1023.40">statistical</entity> and other means of <entity id="H91-1023.41">extracting</entity> useful <entity id="H91-1023.42">information</entity> from large bi- or <entity id="H91-1023.43">multi-lingual</entity> <entity id="H91-1023.44">corpora</entity> , <entity id="H91-1023.45">including</entity> <entity id="H91-1023.46">collocations</entity> , <entity id="H91-1023.47">transfers</entity> , and contextual <entity id="H91-1023.48">cues</entity> for <entity id="H91-1023.49">disambiguation</entity> . 
 MRDs => MTDs, use of electronic <entity id="H91-1023.50">machine-readable</entity> <entity id="H91-1023.51">dictionaries</entity> (MRDs) to partially automate the <entity id="H91-1023.52">creation</entity> of <entity id="H91-1023.53">machine-tractable</entity> <entity id="H91-1023.54">dictionaries</entity> (MTDs) in processable internal <entity id="H91-1023.55">form</entity> for <entity id="H91-1023.56">parsers</entity> and <entity id="H91-1023.57">generators</entity> , permitting principled <entity id="H91-1023.58">scaling</entity> up in MT <entity id="H91-1023.59">configurations</entity> .
</abstract>


methodapplied(H91-1023.2,H91-1023.6)
part_of(H91-1023.20,H91-1023.22,REVERSE)
datasource(H91-1023.42,H91-1023.44)
usedfor(H91-1023.51,H91-1023.54)

</text>

<text id="H91-1045">
<title>
Calculating The <entity id="H91-1045.1">Probability</entity> Of A <entity id="H91-1045.2">Partial</entity> <entity id="H91-1045.3">Parse</entity> Of A <entity id="H91-1045.4">Sentence</entity></title>
<abstract>
A <entity id="H91-1045.5">standard</entity> <entity id="H91-1045.6">problem</entity> iu parsiug <entity id="H91-1045.7">algorithms</entity> is the <entity id="H91-1045.8">organization</entity> o[ branched <entity id="H91-1045.9">searches</entity> lo <entity id="H91-1045.10">deal</entity> with ambiguous <entity id="H91-1045.11">sentences</entity> . We discuss <entity id="H91-1045.12">shift-reduce</entity> parsiug of stochastic <entity id="H91-1045.13">context-free</entity> grammars and show how to <entity id="H91-1045.14">construct</entity> a probabilistic score for ranking competing <entity id="H91-1045.15">parse</entity> <entity id="H91-1045.16">hypotheses</entity> . The score we use is the likelihood that the <entity id="H91-1045.17">collection</entity> of subtrees can be completed into a full <entity id="H91-1045.18">parse tree</entity> by means of the <entity id="H91-1045.19">steps</entity> the <entity id="H91-1045.20">parser</entity> is constrained lo follow.
</abstract>


model(H91-1045.1,H91-1045.4)

</text>

<text id="H91-1064">
<title><entity id="H91-1064.1">Discourse Structure</entity> In The TRAINS <entity id="H91-1064.2">Project</entity></title>
<abstract>
In a <entity id="H91-1064.3">natural</entity> <entity id="H91-1064.4">dialog</entity> , a considerable proportion of the <entity id="H91-1064.5">utterances</entity> actually relate to the <entity id="H91-1064.6">maintenance</entity> of the <entity id="H91-1064.7">dialog</entity> itself rather than to furthering the <entity id="H91-1064.8">task</entity> or <entity id="H91-1064.9">goals</entity> motivating the <entity id="H91-1064.10">conversation</entity> . For <entity id="H91-1064.11">example</entity> , many <entity id="H91-1064.12">utterances</entity> serve to acknowledge, clarify, correct a previous <entity id="H91-1064.13">utterance</entity> rather than pursue some <entity id="H91-1064.14">goal</entity> in the <entity id="H91-1064.15">domain</entity> . In <entity id="H91-1064.16">addition</entity> , <entity id="H91-1064.17">natural</entity> <entity id="H91-1064.18">dialog</entity> is full of false starts, ungrammatical <entity id="H91-1064.19">sentences</entity> and other <entity id="H91-1064.20">complexities</entity> not found in in written <entity id="H91-1064.21">language</entity> . This <entity id="H91-1064.22">paper</entity> describes our recent <entity id="H91-1064.23">efforts</entity> to define and <entity id="H91-1064.24">construct</entity> a <entity id="H91-1064.25">model</entity> of <entity id="H91-1064.26">discourse</entity> <entity id="H91-1064.27">interaction</entity> that handle <entity id="H91-1064.28">dialogs</entity> that are rich in these <entity id="H91-1064.29">natural</entity> <entity id="H91-1064.30">dialog-related</entity> <entity id="H91-1064.31">phenomena</entity> .
</abstract>


propose(H91-1064.22,H91-1064.23)
model(H91-1064.25,H91-1064.26)
phenomenon(H91-1064.28,H91-1064.31,REVERSE)

</text>

<text id="H93-1063">
<title>
Session 11: <entity id="H93-1063.1">Prosody</entity></title>
<abstract>
This <entity id="H93-1063.2">paper</entity> <entity id="H93-1063.3">provides</entity> a brief <entity id="H93-1063.4">introduction</entity> to <entity id="H93-1063.5">prosody</entity> <entity id="H93-1063.6">research</entity> in the <entity id="H93-1063.7">context</entity> of <entity id="H93-1063.8">human-computer</entity> <entity id="H93-1063.9">communication</entity> and an <entity id="H93-1063.10">overview</entity> of the <entity id="H93-1063.11">contributions</entity> of the <entity id="H93-1063.12">papers</entity> in the session.
</abstract>


propose(H93-1063.2,H93-1063.4)

</text>

<text id="H93-1078">
<title>
Gisting Continuous <entity id="H93-1078.1">Speech</entity></title>
<abstract>
"The <entity id="H93-1078.2">objective</entity> of this woik is <entity id="H93-1078.3">automatic</entity> , <entity id="H93-1078.4">real-time</entity> ""gisting"" of voice traffic for <entity id="H93-1078.5">updating</entity> of <entity id="H93-1078.6">information</entity> in <entity id="H93-1078.7">databases</entity> , for producing timely <entity id="H93-1078.8">reports</entity> , and for prompt notification of <entity id="H93-1078.9">events</entity> of interest. Specifically, the <entity id="H93-1078.10">goal</entity> is to build a <entity id="H93-1078.11">prototype</entity> , <entity id="H93-1078.12">real-time</entity> <entity id="H93-1078.13">system</entity> capable of <entity id="H93-1078.14">processing</entity> radio <entity id="H93-1078.15">communication</entity> between air traffic controllers and <entity id="H93-1078.16">pilots</entity> , identifying <entity id="H93-1078.17">dialogs</entity> and <entity id="H93-1078.18">extracting</entity> their ""gist"" (e.g., identifying flights, determining whether they are landing or taking off), and producing a continuous <entity id="H93-1078.19">output</entity> <entity id="H93-1078.20">stream</entity> with that <entity id="H93-1078.21">information</entity> . The <entity id="H93-1078.22">approach</entity> is intended to be general and applicable to other <entity id="H93-1078.23">domains</entity> . The <entity id="H93-1078.24">system</entity> is built upon state-of-the-art <entity id="H93-1078.25">techniques</entity> in <entity id="H93-1078.26">speech recognition</entity> , speaker <entity id="H93-1078.27">identification</entity> , <entity id="H93-1078.28">natural language analysis</entity> , and <entity id="H93-1078.29">topic</entity> <entity id="H93-1078.30">statistical</entity> <entity id="H93-1078.31">classification</entity> . These <entity id="H93-1078.32">techniques</entity> have been extended where necessary to address specific <entity id="H93-1078.33">aspects</entity> of the gisting <entity id="H93-1078.34">problem</entity> . Because various <entity id="H93-1078.35">sources</entity> of <entity id="H93-1078.36">information</entity> must be combined, the <entity id="H93-1078.37">system</entity> <entity id="H93-1078.38">design</entity> <entity id="H93-1078.39">features</entity> a high <entity id="H93-1078.40">degree</entity> of <entity id="H93-1078.41">interaction</entity> between the <entity id="H93-1078.42">natural language</entity> and <entity id="H93-1078.43">domain-knowledge</entity> <entity id="H93-1078.44">components</entity> and the <entity id="H93-1078.45">speech processing</entity> <entity id="H93-1078.46">components</entity> . "
</abstract>


usedfor(H93-1078.13,H93-1078.14)
based_on(H93-1078.24,H93-1078.25)

</text>

<text id="H94-1029">
<title>
The <entity id="H94-1029.1">Automatic</entity> <entity id="H94-1029.2">Component</entity> Of The LINGSTAT <entity id="H94-1029.3">Machine-</entity> Aided <entity id="H94-1029.4">Translation <entity id="H94-1029.5">System</entity></entity></title>
<abstract>
We present the newest <entity id="H94-1029.6">implementation</entity> of the LINGSTAT <entity id="H94-1029.7">machine-aided</entity> <entity id="H94-1029.8">translation system</entity> . The most significant change from earlier <entity id="H94-1029.9">versions</entity> is a new set of <entity id="H94-1029.10">modules</entity> that produce a draft <entity id="H94-1029.11">translation</entity> of the <entity id="H94-1029.12">document</entity> for the <entity id="H94-1029.13">user</entity> to refer to or modify. This <entity id="H94-1029.14">paper</entity> describes these <entity id="H94-1029.15">modules</entity> , with special emphasis on an automatically <entity id="H94-1029.16">trained</entity> lexicalized grammar used in the <entity id="H94-1029.17">parsing</entity> <entity id="H94-1029.18">module</entity> . Some preliminary <entity id="H94-1029.19">results</entity> from the January  1994  ARPA <entity id="H94-1029.20">evaluation</entity> are <entity id="H94-1029.21">reported</entity> .
</abstract>


part_of(H94-1029.2,H94-1029.4)
yields(H94-1029.10,H94-1029.11)
propose(H94-1029.14,H94-1029.15)

</text>

<text id="A97-1025">
<title>
Contextual Spelling <entity id="A97-1025.1">Correction</entity> Using <entity id="A97-1025.2">Latent <entity id="A97-1025.3">Semantic Analysis</entity></entity></title>
<abstract>Contextual <entity id="A97-1025.4">spelling</entity> <entity id="A97-1025.5">errors</entity> are denned as the use of an incorrect, though valid, <entity id="A97-1025.6">word</entity> in a particular <entity id="A97-1025.7">sentence</entity> or <entity id="A97-1025.8">context</entity> . Traditional <entity id="A97-1025.9">spelling</entity> checkers flag misspelled <entity id="A97-1025.10">words</entity> , but they do not typically attempt to identify <entity id="A97-1025.11">words</entity> that are used incorrectly in a <entity id="A97-1025.12">sentence</entity> . We explore the use of
</abstract>


usedfor(A97-1025.1,A97-1025.2,REVERSE)
char(A97-1025.6,A97-1025.7)
problem(A97-1025.11,A97-1025.12)

</text>

<text id="X96-1046">
<title>
The <entity id="X96-1046.1">Text REtrieval</entity> Conferences (TRECs) - <entity id="X96-1046.2">Summary</entity> <entity id="X96-1046.3">Results</entity> Of TREC-3 And TREC-4
</title>
<abstract>
"There have been four <entity id="X96-1046.4">Text REtrieval</entity> Conferences (TRECs); TREC-1 in November  1992 , TREC-2 in August  1993 , TREC-3 in November  1994  and TREC-4 in November  1995 . The <entity id="X96-1046.5">number</entity> of participating <entity id="X96-1046.6">systems</entity> has grown from 25 in TREC-1 to 36 in TREC-4, <entity id="X96-1046.7">including</entity> most of the major <entity id="X96-1046.8">text retrieval</entity> <entity id="X96-1046.9">software</entity> companies and most of the <entity id="X96-1046.10">universities</entity> doing <entity id="X96-1046.11">research</entity> in <entity id="X96-1046.12">text <entity id="X96-1046.13">retrieval</entity></entity> (see <entity id="X96-1046.14">table</entity> for some of the <entity id="X96-1046.15">participants</entity> ). The <entity id="X96-1046.16">diversity</entity> of the participating groups has ensured that TREC represents many different <entity id="X96-1046.17">approaches</entity> to <entity id="X96-1046.18">text <entity id="X96-1046.19">retrieval</entity></entity> , while the emphasis on <entity id="X96-1046.20">individual</entity> <entity id="X96-1046.21">experiments</entity> <entity id="X96-1046.22">evaluated</entity> in a <entity id="X96-1046.23">common</entity> setting has proven to be a major <entity id="X96-1046.24">strength</entity> of TREC. The <entity id="X96-1046.25">test</entity> <entity id="X96-1046.26">design</entity> and <entity id="X96-1046.27">test</entity> <entity id="X96-1046.28">collection</entity> used for <entity id="X96-1046.29">document</entity> <entity id="X96-1046.30">detection</entity> in TIPSTER was also used in TREC. The <entity id="X96-1046.31">participants</entity> ran the various <entity id="X96-1046.32">tasks</entity> , sent <entity id="X96-1046.33">results</entity> into NIST for <entity id="X96-1046.34">evaluation</entity> , presented the <entity id="X96-1046.35">results</entity> at the TREC conferences, and submitted <entity id="X96-1046.36">papers</entity> for a <entity id="X96-1046.37">proceedings</entity> . The <entity id="X96-1046.38">test</entity> <entity id="X96-1046.39">collection</entity> consists of over 1 million <entity id="X96-1046.40">documents</entity> from diverse <entity id="X96-1046.41">full-text</entity> <entity id="X96-1046.42">sources</entity> , 250 <entity id="X96-1046.43">topics</entity> , and the set of relevant <entity id="X96-1046.44">documents</entity> or ""right answers"" to those <entity id="X96-1046.45">topics</entity> . A Spanish <entity id="X96-1046.46">collection</entity> has been built and used during TREC-3 and TREC-4, with a total of 50 <entity id="X96-1046.47">topics</entity> . TREC-1 <entity id="X96-1046.48">required</entity> significant <entity id="X96-1046.49">system</entity> rebuilding by most groups <entity id="X96-1046.50">due</entity> to the huge <entity id="X96-1046.51">increase</entity> in the <entity id="X96-1046.52">size</entity> of the <entity id="X96-1046.53">document</entity> <entity id="X96-1046.54">collection</entity> (from a traditional <entity id="X96-1046.55">test</entity> <entity id="X96-1046.56">collection</entity> of several megabytes in <entity id="X96-1046.57">size</entity> to the 2 gigabyte TIPSTER <entity id="X96-1046.58">collection</entity> ). The <entity id="X96-1046.59">results</entity> from TREC-2 showed significant <entity id="X96-1046.60">improvements</entity> over the TREC-1 <entity id="X96-1046.61">results</entity> , and should be viewed as the appropriate baseline representing state-of-the-art <entity id="X96-1046.62">retrieval</entity> <entity id="X96-1046.63">techniques</entity> as <entity id="X96-1046.64">scaled</entity> up to handling a 2 gigabyte <entity id="X96-1046.65">collection</entity> . TREC-3 therefore <entity id="X96-1046.66">provided</entity> the first opportunity for more <entity id="X96-1046.67">complex</entity> <entity id="X96-1046.68">experimentation</entity> . The major <entity id="X96-1046.69">experiments</entity> in TREC-3 <entity id="X96-1046.70">included</entity> the <entity id="X96-1046.71">development</entity> of <entity id="X96-1046.72">automatic</entity> <entity id="X96-1046.73">query expansion</entity> <entity id="X96-1046.74">techniques</entity> , the use of passages or sub-documents to <entity id="X96-1046.75">increase</entity> the <entity id="X96-1046.76">precision</entity> of <entity id="X96-1046.77">retrieval</entity> <entity id="X96-1046.78">results</entity> , and the use of the <entity id="X96-1046.79">training</entity> <entity id="X96-1046.80">information</entity> to select only the best <entity id="X96-1046.81">terms</entity> for <entity id="X96-1046.82">routing</entity> <entity id="X96-1046.83">queries</entity> . Some groups explored hybrid <entity id="X96-1046.84">approaches</entity> (such as the use of the Rocchio <entity id="X96-1046.85">methodology</entity> in <entity id="X96-1046.86">systems</entity> not using a <entity id="X96-1046.87">vector <entity id="X96-1046.88">space</entity> <entity id="X96-1046.89">model</entity></entity> ), and others tried <entity id="X96-1046.90">approaches</entity> that were radically different from their original <entity id="X96-1046.91">approaches</entity> . TREC-4 allowed a continuation of many of these <entity id="X96-1046.92">complex</entity> <entity id="X96-1046.93">experiments</entity> . The <entity id="X96-1046.94">topics</entity> were made much shorter and this change triggered extensive <entity id="X96-1046.95">investigations</entity> in <entity id="X96-1046.96">automatic</entity> <entity id="X96-1046.97">query <entity id="X96-1046.98">expansion</entity></entity> . There were also five new <entity id="X96-1046.99">tasks</entity> , <entity id="X96-1046.100">called</entity> tracks. These were added to <entity id="X96-1046.101">help</entity> <entity id="X96-1046.102">focus</entity> <entity id="X96-1046.103">research</entity> on certain known <entity id="X96-1046.104">problem</entity> <entity id="X96-1046.105">areas</entity> , and <entity id="X96-1046.106">included</entity> such <entity id="X96-1046.107">issues</entity> as investigating <entity id="X96-1046.108">searching</entity> as an interactive <entity id="X96-1046.109">task</entity> by examining the <entity id="X96-1046.110">process</entity> as well as the <entity id="X96-1046.111">outcome</entity> , investigating <entity id="X96-1046.112">techniques</entity> for merging <entity id="X96-1046.113">results</entity> from the various TREC subcollections, examining the <entity id="X96-1046.114">effects</entity> of corrupted data, and <entity id="X96-1046.115">evaluating</entity> <entity id="X96-1046.116">routing</entity> <entity id="X96-1046.117">systems</entity> using a specific <entity id="X96-1046.118">effectiveness</entity> measure. Additionally more groups participated in a track for Spanish <entity id="X96-1046.119">retrieval</entity> . The TREC conferences have proven to be very successful, allowing broad <entity id="X96-1046.120">participation</entity> in the overall DARPA TIPSTER <entity id="X96-1046.121">effort</entity> , and causing widespread use of a very large <entity id="X96-1046.122">test</entity> <entity id="X96-1046.123">collection</entity> . All conferences have had very open, honest <entity id="X96-1046.124">discussions</entity> of technical <entity id="X96-1046.125">issues</entity> , and there have been large <entity id="X96-1046.126">amounts</entity> of ""<entity id="X96-1046.127">cross-fertilization</entity> "" of ideas. This will be a continuing <entity id="X96-1046.128">effort</entity> , with a TREC-5 conference scheduled in November of 1996. "
</abstract>


study(X96-1046.11,X96-1046.12)
usedfor(X96-1046.17,X96-1046.18)
based_on(X96-1046.28,X96-1046.30,REVERSE)
composed_of(X96-1046.39,X96-1046.40)
composed_of(X96-1046.46,X96-1046.47)
char(X96-1046.52,X96-1046.54)
char(X96-1046.56,X96-1046.57,REVERSE)
wrt(X96-1046.60,X96-1046.61)
part_of(X96-1046.69,X96-1046.74,REVERSE)
usedfor(X96-1046.86,X96-1046.87,REVERSE)
compare(X96-1046.90,X96-1046.91)
study(X96-1046.95,X96-1046.97)
methodapplied(X96-1046.112,X96-1046.113)

</text>

<text id="W93-0110">
<title>
Acquiring Predicate- <entity id="W93-0110.1">Argument</entity> <entity id="W93-0110.2">Mapping</entity> <entity id="W93-0110.3">Information</entity> From Multilingual <entity id="W93-0110.4">Texts</entity></title>
<abstract>
This <entity id="W93-0110.5">paper</entity> discusses <entity id="W93-0110.6">automatic</entity> <entity id="W93-0110.7">acquisition</entity> of <entity id="W93-0110.8">predicate-argument</entity> <entity id="W93-0110.9">mapping</entity> <entity id="W93-0110.10">information</entity> from multilingual <entity id="W93-0110.11">texts</entity> . The <entity id="W93-0110.12">lexicon</entity> of our <entity id="W93-0110.13">NLP <entity id="W93-0110.14">system</entity></entity> <entity id="W93-0110.15">abstracts</entity> the <entity id="W93-0110.16">language-dependent</entity> <entity id="W93-0110.17">portion</entity> of <entity id="W93-0110.18">predicate-argument</entity> <entity id="W93-0110.19">mapping</entity> <entity id="W93-0110.20">information</entity> from the <entity id="W93-0110.21">core</entity> meaning of <entity id="W93-0110.22">verb</entity> senses (i.e.
</abstract>


datasource(W93-0110.3,W93-0110.4)
propose(W93-0110.5,W93-0110.7)
datasource(W93-0110.10,W93-0110.11)
part_of(W93-0110.12,W93-0110.13)

</text>

<text id="W94-0203">
<title>
Constraints, Exceptions And Representations
</title>
<abstract>
This <entity id="W94-0203.1">paper</entity> shows that <entity id="W94-0203.2">default-based</entity> <entity id="W94-0203.3">phonologies</entity> have the potential to capture morphophonological generalisations which cannot be captured by <entity id="W94-0203.4">non-default</entity> <entity id="W94-0203.5">theories</entity> . In achieving this <entity id="W94-0203.6">result</entity> , I offer a characterisation of Underspecification <entity id="W94-0203.7">Theory</entity> and Optimality <entity id="W94-0203.8">Theory</entity> in <entity id="W94-0203.9">terms</entity> of their <entity id="W94-0203.10">methods</entity> for <entity id="W94-0203.11">ordering</entity> <entity id="W94-0203.12">defaults</entity> . The <entity id="W94-0203.13">result</entity> means that <entity id="W94-0203.14">machine</entity> learning <entity id="W94-0203.15">techniques</entity> for building declarative <entity id="W94-0203.16">analyses</entity> may not <entity id="W94-0203.17">provide</entity> an adequate <entity id="W94-0203.18">basis</entity> for morphophonological <entity id="W94-0203.19">analysis</entity> .
</abstract>


methodapplied(W94-0203.10,W94-0203.12)

</text>

<text id="W97-0103">
<title><entity id="W97-0103.1">Commercial</entity> <entity id="W97-0103.2">Impact</entity> Of VLC <entity id="W97-0103.3">Research</entity></title>



</text>

<abstract></abstract>

<text id="W97-1106">
<title>
A Czech Morphological <entity id="W97-1106.1">Lexicon</entity></title>
<abstract>
In this <entity id="W97-1106.2">paper</entity> , a <entity id="W97-1106.3">treatment</entity> of Czech phonological <entity id="W97-1106.4">rules</entity> in <entity id="W97-1106.5">two-level</entity> <entity id="W97-1106.6">morphology</entity> <entity id="W97-1106.7">approach</entity> is described . First the possible phonological <entity id="W97-1106.8">alternations</entity> in Czech are <entity id="W97-1106.9">listed</entity> and then their <entity id="W97-1106.10">treatment</entity> in a <entity id="W97-1106.11">practical application</entity> of a Czech morphological <entity id="W97-1106.12">lexicon</entity> .
</abstract>


propose(W97-1106.2,W97-1106.7)

</text>

<text id="W98-0208">
<title><entity id="W98-0208.1">Semantic</entity> <entity id="W98-0208.2">Visualization</entity></title>
<abstract>
This <entity id="W98-0208.3">paper</entity> summarizes several <entity id="W98-0208.4">initiatives</entity> at MITRE that are investigating the <entity id="W98-0208.5">visualization</entity> of a range of <entity id="W98-0208.6">content</entity> . We present <entity id="W98-0208.7">results</entity> of our work in relevancy <entity id="W98-0208.8">visualization</entity> , <entity id="W98-0208.9">news</entity> <entity id="W98-0208.10">visualization</entity> , world <entity id="W98-0208.11">events</entity> <entity id="W98-0208.12">visualization</entity> and sensor/battlefield <entity id="W98-0208.13">visualization</entity> to enhance <entity id="W98-0208.14">user</entity> <entity id="W98-0208.15">interaction</entity> in <entity id="W98-0208.16">information access</entity> and <entity id="W98-0208.17">exploitation</entity> <entity id="W98-0208.18">tasks</entity> . We summarize several <entity id="W98-0208.19">initiatives</entity> we are currently pursuing and enumerate unsolved <entity id="W98-0208.20">problems</entity> .
</abstract>


propose(W98-0208.3,W98-0208.4)

</text>

<text id="W98-0613">
<title>
Nominal Metonymy <entity id="W98-0613.1">Processing</entity></title> 
<abstract><entity id="W98-0613.2">Abstract</entity> . We argue for the <entity id="W98-0613.3">necessity</entity> of <entity id="W98-0613.4">resolution</entity> of metonymies for nominals (and other <entity id="W98-0613.5">cases</entity> ) in the <entity id="W98-0613.6">context</entity> of <entity id="W98-0613.7">semantics-based</entity> <entity id="W98-0613.8">machine translation</entity> . By using an <entity id="W98-0613.9">ontology</entity> as a <entity id="W98-0613.10">search space</entity> , we are able to identify and resolve m
tonymie <entity id="W98-0613.11">expressions</entity> with significant <entity id="W98-0613.12">accuracy</entity> , both for a pre-deterrnined <entity id="W98-0613.13">inventory</entity> of metonymie <entity id="W98-0613.14">types</entity> and for previously unseen <entity id="W98-0613.15">cases</entity> . The <entity id="W98-0613.16">entity</entity> replaced by the metonymy is made explicitly available in our meaning <entity id="W98-0613.17">representation</entity> , to <entity id="W98-0613.18">support</entity> <entity id="W98-0613.19">translation</entity> , anaphora, and other <entity id="W98-0613.20">mechanisms</entity> .
</abstract>


composed_of(W98-0613.13,W98-0613.14)

</text>

<text id="W98-0802">
<title>
Towards Multimodal <entity id="W98-0802.1">Spoken Language</entity> <entity id="W98-0802.2">Corpora</entity> : TransTool And SyncTool
</title>
<abstract>
This <entity id="W98-0802.3">paper</entity> argues for the <entity id="W98-0802.4">usefulness</entity> of multimodal spoken <entity id="W98-0802.5">language</entity> <entity id="W98-0802.6">corpora</entity> and specifies <entity id="W98-0802.7">components</entity> of a <entity id="W98-0802.8">platform</entity> for the <entity id="W98-0802.9">creation</entity> , <entity id="W98-0802.10">maintenance</entity> and <entity id="W98-0802.11">exploitation</entity> of such <entity id="W98-0802.12">corpora</entity> . Two of the <entity id="W98-0802.13">components</entity> , which have already been <entity id="W98-0802.14">implemented</entity> as <entity id="W98-0802.15">prototypes</entity> , are described in more <entity id="W98-0802.16">detail</entity> : TransTool and SyncTool. TransTool is a <entity id="W98-0802.17">transcription</entity> editor meant to facilitate and partially automate the <entity id="W98-0802.18">task</entity> of a human transcriber, while SyncTool is a <entity id="W98-0802.19">tool</entity> for aligning the <entity id="W98-0802.20">resulting</entity> <entity id="W98-0802.21">transcriptions</entity> with a digitized audio and <entity id="W98-0802.22">video</entity> <entity id="W98-0802.23">recording</entity> in <entity id="W98-0802.24">order</entity> to allow synchronized <entity id="W98-0802.25">presentation</entity> of different <entity id="W98-0802.26">representations</entity> (e.g., <entity id="W98-0802.27">text</entity> , audio, <entity id="W98-0802.28">video</entity> , acoustic <entity id="W98-0802.29">analysis</entity> ). Finally, a brief <entity id="W98-0802.30">comparison</entity> is made between these <entity id="W98-0802.31">tools</entity> and other <entity id="W98-0802.32">programs</entity> <entity id="W98-0802.33">developed</entity> for similar <entity id="W98-0802.34">purposes</entity> .
</abstract>


propose(W98-0802.3,W98-0802.6)
part_of(W98-0802.7,W98-0802.8)
methodapplied(W98-0802.19,W98-0802.21)
compare(W98-0802.31,W98-0802.32)

</text>

<text id="W98-1001">
<title>
Discovering <entity id="W98-1001.1">Lexical Information</entity> By <entity id="W98-1001.2">Tagging</entity> Arabic <entity id="W98-1001.3">Newspaper</entity> <entity id="W98-1001.4">Text</entity></title>
<abstract>
In this <entity id="W98-1001.5">paper</entity> we describe a <entity id="W98-1001.6">system</entity> for building an Arabic <entity id="W98-1001.7">lexicon</entity> automatically by <entity id="W98-1001.8">tagging</entity> Arabic <entity id="W98-1001.9">newspaper</entity> <entity id="W98-1001.10">text</entity> . In this <entity id="W98-1001.11">system</entity> we are using several <entity id="W98-1001.12">techniques</entity> for <entity id="W98-1001.13">tagging</entity> the <entity id="W98-1001.14">words</entity> in the <entity id="W98-1001.15">text</entity> and <entity id="W98-1001.16">figuring</entity> out their <entity id="W98-1001.17">types</entity> and their <entity id="W98-1001.18">features</entity> . The major <entity id="W98-1001.19">techniques</entity> that we are using are: finding <entity id="W98-1001.20">phrases</entity> , analyzing the affixes of the <entity id="W98-1001.21">words</entity> , and analyzing their <entity id="W98-1001.22">patterns</entity> . Proper <entity id="W98-1001.23">nouns</entity> are particularly difficult to identify in the Arabic <entity id="W98-1001.24">language</entity> ; we describe <entity id="W98-1001.25">techniques</entity> for isolating them.
</abstract>


taskapplied(W98-1001.2,W98-1001.4)
propose(W98-1001.5,W98-1001.6)
taskapplied(W98-1001.8,W98-1001.10)
part_of(W98-1001.11,W98-1001.12,REVERSE)
taskapplied(W98-1001.13,W98-1001.14)

</text>

<text id="W99-0310">
<title>
A <entity id="W99-0310.1">Recognition-</entity> <entity id="W99-0310.2">Based</entity> Meta- <entity id="W99-0310.3">Scheme</entity> For <entity id="W99-0310.4">Dialogue</entity> Acts Annotation
</title>
<abstract>
The <entity id="W99-0310.5">paper</entity> describes a new formal <entity id="W99-0310.6">framework</entity> for <entity id="W99-0310.7">comparison</entity> , <entity id="W99-0310.8">design</entity> and standardization of annotation <entity id="W99-0310.9">schemes</entity> for <entity id="W99-0310.10">dialogue acts</entity> . The <entity id="W99-0310.11">framework</entity> takes a <entity id="W99-0310.12"><entity id="W99-0310.13">recognition-based</entity> <entity id="W99-0310.14">approach</entity></entity> to <entity id="W99-0310.15">dialogue</entity> <entity id="W99-0310.16">tagging</entity> and defines four independent <entity id="W99-0310.17">taxonomies</entity> of <entity id="W99-0310.18">tags</entity> , one for each orthogonal <entity id="W99-0310.19">dimension</entity> of linguistic and contextual <entity id="W99-0310.20">analysis</entity> assumed to have a bearing on <entity id="W99-0310.21">identification</entity> of illocutionary acts. The <entity id="W99-0310.22">advantages</entity> and <entity id="W99-0310.23">limitations</entity> of this <entity id="W99-0310.24">proposal</entity> over other previous attempts are discussed and concretely exemplified.
</abstract>


propose(W99-0310.5,W99-0310.6)
usedfor(W99-0310.12,W99-0310.15)

</text>

<text id="W00-0409">
<title>
Multi- <entity id="W00-0409.1">Document Summarization</entity> By Visualizing Topical <entity id="W00-0409.2">Content</entity></title> 
<abstract>Mani , Inderjeet; House, David ; Klein , Gary ; Hirschman , Lynette ; Firmin <entity id="W00-0409.3">Hand</entity> , Therese ; Sundheim , Beth M. ,The TIPSTER SUMMAC <entity id="W00-0409.4">Text Summarization</entity> <entity id="W00-0409.5">Evaluation</entity> ,Conference Of The European <entity id="W00-0409.6">Association</entity> For <entity id="W00-0409.7">Computation</entity> al <entity id="W00-0409.8">Linguistics</entity> ,1999 *** Nagao , Katashi; Hasida, Koiti, <entity id="W00-0409.9">Automatic</entity> <entity id="W00-0409.10">Text Summarization</entity> <entity id="W00-0409.11">Based</entity> on the Global <entity id="W00-0409.12">Document</entity> Annotation,COLING-ACL,1998***Power, Richard ; Scott , Donia R.,Multilingual Authoring using <entity id="W00-0409.13">Feedback</entity> <entity id="W00-0409.14">Texts</entity> ,COLING-ACL,1998***Mani, Inderjeet; Gates , Barbara ; Bloedorn , Eric ,Improving Summaries By Revising Them,Annual Meeting Of The <entity id="W00-0409.15">Association</entity> For <entity id="W00-0409.16">Computation</entity> al <entity id="W00-0409.17">Linguistics</entity> ,1999</abstract>


based_on(W00-0409.9,W00-0409.12)

</text>

<text id="W00-1009">
<title>
A <entity id="W00-1009.1">Common</entity> <entity id="W00-1009.2">Theory</entity> Of <entity id="W00-1009.3">Information</entity> <entity id="W00-1009.4">Fusion</entity> From Multiple <entity id="W00-1009.5">Text</entity> <entity id="W00-1009.6">Sources</entity> <entity id="W00-1009.7">Step</entity> One: <entity id="W00-1009.8">Cross-</entity> <entity id="W00-1009.9">Document</entity> <entity id="W00-1009.10">Structure</entity></title>
<abstract>
We introduce CST ( <entity id="W00-1009.11">cross-document</entity> <entity id="W00-1009.12">structure</entity> <entity id="W00-1009.13">theory</entity> ), a <entity id="W00-1009.14">paradigm</entity> for <entity id="W00-1009.15">multi-document</entity> <entity id="W00-1009.16">analysis</entity> . CST takes into account the rhetorical <entity id="W00-1009.17">structure</entity> of <entity id="W00-1009.18">clusters</entity> of related textual <entity id="W00-1009.19">documents</entity> . We present a <entity id="W00-1009.20">taxonomy</entity> of <entity id="W00-1009.21">cross-document</entity> <entity id="W00-1009.22">relationships</entity> . We argue that CST can be the <entity id="W00-1009.23">basis</entity> for <entity id="W00-1009.24">multi-document <entity id="W00-1009.25">summarization</entity></entity> guided by <entity id="W00-1009.26">user</entity> <entity id="W00-1009.27">preferences</entity> for <entity id="W00-1009.28">summary</entity> <entity id="W00-1009.29">length</entity> , <entity id="W00-1009.30">information</entity> provenance, <entity id="W00-1009.31">cross-source</entity> <entity id="W00-1009.32">agreement</entity> , and chronological <entity id="W00-1009.33">ordering</entity> of facts.
</abstract>


usedfor(W00-1009.14,W00-1009.16)
model(W00-1009.18,W00-1009.19)
model(W00-1009.20,W00-1009.22)
based_on(W00-1009.24,W00-1009.27)

</text>

<text id="W00-1309">
<title><entity id="W00-1309.1">Error-</entity> Driven HMM-Based <entity id="W00-1309.2">Chunk</entity> Tagger With <entity id="W00-1309.3">Context-</entity> Dependent <entity id="W00-1309.4">Lexicon</entity></title>
<abstract>
This <entity id="W00-1309.5">paper</entity> <entity id="W00-1309.6">proposes</entity> a new <entity id="W00-1309.7">error-driven</entity> HMM-based <entity id="W00-1309.8">text</entity> <entity id="W00-1309.9">chunk</entity> tagger with <entity id="W00-1309.10">context-dependent</entity> <entity id="W00-1309.11">lexicon</entity> . Compared with <entity id="W00-1309.12">standard</entity> HMM-based tagger, this tagger uses a new Hidden Markov Modelling <entity id="W00-1309.13">approach</entity> which incorporates more <entity id="W00-1309.14">contextual <entity id="W00-1309.15">information</entity></entity> into a <entity id="W00-1309.16">lexical <entity id="W00-1309.17">entry</entity></entity> . Moreover, an <entity id="W00-1309.18">error-driven</entity> <entity id="W00-1309.19">learning <entity id="W00-1309.20">approach</entity></entity> is adopted to decrease the <entity id="W00-1309.21">memory</entity> <entity id="W00-1309.22">requirement</entity> by keeping only positive <entity id="W00-1309.23">lexical entries</entity> and makes it possible to further incorporate more <entity id="W00-1309.24">context-dependent</entity> <entity id="W00-1309.25">lexical entries</entity> . <entity id="W00-1309.26">Experiments</entity> show that this <entity id="W00-1309.27">technique</entity> achieves overall <entity id="W00-1309.28">precision</entity> and <entity id="W00-1309.29">recall</entity> <entity id="W00-1309.30">rates</entity> of 93.40% and 93.95% for all <entity id="W00-1309.31">chunk</entity> <entity id="W00-1309.32">types</entity> , 93.60% and 94.64% for <entity id="W00-1309.33">noun phrases</entity> , and 94.64% and 94.75% for <entity id="W00-1309.34">verb</entity> <entity id="W00-1309.35">phrases</entity> when <entity id="W00-1309.36">trained</entity> on PENN WSJ TreeBank <entity id="W00-1309.37">section</entity> 00-19 and <entity id="W00-1309.38">tested</entity> on <entity id="W00-1309.39">section</entity> 20-24, while 25-fold <entity id="W00-1309.40">validation</entity> <entity id="W00-1309.41">experiments</entity> of PENN WSJ TreeBank show overall <entity id="W00-1309.42">precision</entity> and <entity id="W00-1309.43">recall</entity> <entity id="W00-1309.44">rates</entity> of 96.40% and 96.47% for all <entity id="W00-1309.45">chunk</entity> <entity id="W00-1309.46">types</entity> , 96.49% and 96.99% for <entity id="W00-1309.47">noun phrases</entity> , and 97.13% and 97.36% for <entity id="W00-1309.48">verb</entity> <entity id="W00-1309.49">phrases</entity> .
</abstract>


part_of(W00-1309.14,W00-1309.16)
affects(W00-1309.19,W00-1309.21)
yields(W00-1309.27,W00-1309.30)
yields(W00-1309.41,W00-1309.44)

</text>

<text id="W00-1326">
<title>
One <entity id="W00-1326.1">Sense</entity> Per <entity id="W00-1326.2">Collocation</entity> And <entity id="W00-1326.3">Genre</entity> / <entity id="W00-1326.4">Topic</entity> Variations
</title>
<abstract>
This <entity id="W00-1326.5">paper</entity> revisits the one <entity id="W00-1326.6">sense</entity> per <entity id="W00-1326.7">collocation</entity> <entity id="W00-1326.8">hypothesis</entity> using fine-grained <entity id="W00-1326.9">sense</entity> <entity id="W00-1326.10">distinctions</entity> and two different <entity id="W00-1326.11">corpora</entity> . We show that the <entity id="W00-1326.12">hypothesis</entity> is weaker for fine-grained <entity id="W00-1326.13">sense</entity> <entity id="W00-1326.14">distinctions</entity> (70% vs. 99% <entity id="W00-1326.15">reported</entity> earlier on 2-way <entity id="W00-1326.16">ambiguities</entity> ). We also show that one <entity id="W00-1326.17">sense</entity> per <entity id="W00-1326.18">collocation</entity> does hold across <entity id="W00-1326.19">corpora</entity> , but that <entity id="W00-1326.20">collocations</entity> vary from one <entity id="W00-1326.21">corpus</entity> to the other, following <entity id="W00-1326.22">genre</entity> and <entity id="W00-1326.23">topic</entity> <entity id="W00-1326.24">variations</entity> . This explains the low <entity id="W00-1326.25">results</entity> when <entity id="W00-1326.26">performing</entity> <entity id="W00-1326.27">word sense disambiguation</entity> across <entity id="W00-1326.28">corpora</entity> . In fact, we demonstrate that when two independent <entity id="W00-1326.29">corpora</entity> share a related <entity id="W00-1326.30">genre</entity> / <entity id="W00-1326.31">topic</entity> , the <entity id="W00-1326.32">word sense disambiguation</entity> <entity id="W00-1326.33">results</entity> would be better. Future work on <entity id="W00-1326.34">word sense disambiguation</entity> will have to take into account <entity id="W00-1326.35">genre</entity> and <entity id="W00-1326.36">topic</entity> as important <entity id="W00-1326.37">parameters</entity> on their <entity id="W00-1326.38">models</entity> .
</abstract>


propose(W00-1326.5,W00-1326.8)
affects(W00-1326.20,W00-1326.22,REVERSE)

</text>

<text id="W01-0701">
<title>
Multidimensional <entity id="W01-0701.1">Transformation-</entity> <entity id="W01-0701.2">Based</entity> Learning
</title>
<abstract>
This <entity id="W01-0701.3">paper</entity> presents a novel <entity id="W01-0701.4">method</entity> that allows a <entity id="W01-0701.5">machine</entity> learning <entity id="W01-0701.6">algorithm</entity> following the <entity id="W01-0701.7">transformation-based</entity> <entity id="W01-0701.8">learning</entity> <entity id="W01-0701.9">paradigm</entity> ( Brill, 1995 ) to be <entity id="W01-0701.10">applied</entity> to multiple <entity id="W01-0701.11">classification tasks</entity> by <entity id="W01-0701.12">training</entity> jointly and simultaneously on all <entity id="W01-0701.13">fields</entity> . The <entity id="W01-0701.14">motivation</entity> for <entity id="W01-0701.15">constructing</entity> such a <entity id="W01-0701.16">system</entity> <entity id="W01-0701.17">stems</entity> from the <entity id="W01-0701.18">observation</entity> that many <entity id="W01-0701.19">tasks</entity> in <entity id="W01-0701.20">natural language processing</entity> are naturally composed of multiple subtasks which need to be resolved simultaneously; also <entity id="W01-0701.21">tasks</entity> usually learned in <entity id="W01-0701.22">isolation</entity> can possibly <entity id="W01-0701.23">benefit</entity> from being learned in a joint <entity id="W01-0701.24">framework</entity> , as the <entity id="W01-0701.25">signals</entity> for the extra <entity id="W01-0701.26">tasks</entity> usually constitute inductive <entity id="W01-0701.27">bias</entity> . The <entity id="W01-0701.28">proposed</entity> <entity id="W01-0701.29">algorithm</entity> is <entity id="W01-0701.30">evaluated</entity> in two <entity id="W01-0701.31">experiments</entity> : in one, the <entity id="W01-0701.32">system</entity> is used to jointly predict the <entity id="W01-0701.33">part-of-speech</entity> and <entity id="W01-0701.34">text</entity> <entity id="W01-0701.35">chunks</entity> /baseNP <entity id="W01-0701.36">chunks</entity> of an <entity id="W01-0701.37">English</entity> <entity id="W01-0701.38">corpus</entity> ; and in the second it is used to learn the joint <entity id="W01-0701.39">prediction</entity> of <entity id="W01-0701.40">word</entity> <entity id="W01-0701.41">segment</entity> <entity id="W01-0701.42">boundaries</entity> and <entity id="W01-0701.43">part-of-speech</entity> <entity id="W01-0701.44">tagging</entity> for <entity id="W01-0701.45">Chinese</entity> . The <entity id="W01-0701.46">results</entity> show that the simultaneous <entity id="W01-0701.47">learning</entity> of multiple <entity id="W01-0701.48">tasks</entity> does achieve an <entity id="W01-0701.49">improvement</entity> in each <entity id="W01-0701.50">task</entity> upon <entity id="W01-0701.51">training</entity> the same <entity id="W01-0701.52">tasks</entity> sequentially. The <entity id="W01-0701.53">part-of-speech</entity> <entity id="W01-0701.54">tagging</entity> <entity id="W01-0701.55">result</entity> of 96.63% is state-of-the-art for <entity id="W01-0701.56">individual</entity> <entity id="W01-0701.57">systems</entity> on the particular <entity id="W01-0701.58">train</entity> / <entity id="W01-0701.59">test</entity> split.
</abstract>


propose(W01-0701.3,W01-0701.4)
based_on(W01-0701.6,W01-0701.9)
methodapplied(W01-0701.32,W01-0701.38)
taskapplied(W01-0701.44,W01-0701.45)

</text>

<text id="W02-0303">
<title><entity id="W02-0303.1">Contrast</entity> And <entity id="W02-0303.2">Variability</entity> In <entity id="W02-0303.3">Gene</entity> Names
</title>
<abstract>
We <entity id="W02-0303.4">studied</entity> <entity id="W02-0303.5">contrast</entity> and <entity id="W02-0303.6">variability</entity> in a <entity id="W02-0303.7">corpus</entity> of <entity id="W02-0303.8">gene</entity> <entity id="W02-0303.9">names</entity> to identify potential heuristics for use in <entity id="W02-0303.10">performing</entity> <entity id="W02-0303.11">entity</entity> <entity id="W02-0303.12">identification</entity> in the molecular <entity id="W02-0303.13">biology</entity> <entity id="W02-0303.14">domain</entity> . <entity id="W02-0303.15">Based</entity> on our <entity id="W02-0303.16">findings</entity> , we <entity id="W02-0303.17">developed</entity> heuristics for <entity id="W02-0303.18">mapping</entity> weakly <entity id="W02-0303.19">matching</entity> <entity id="W02-0303.20">gene</entity> <entity id="W02-0303.21">names</entity> to their official <entity id="W02-0303.22">gene</entity> <entity id="W02-0303.23">names</entity> . We then <entity id="W02-0303.24">tested</entity> these heuristics against a large body of Medline <entity id="W02-0303.25">abstracts</entity> , and found that using these heuristics can <entity id="W02-0303.26">increase</entity> <entity id="W02-0303.27">recall</entity> , with varying <entity id="W02-0303.28">levels</entity> of <entity id="W02-0303.29">precision</entity> . Our <entity id="W02-0303.30">findings</entity> also underscored the <entity id="W02-0303.31">importance</entity> of good <entity id="W02-0303.32">information retrieval</entity> and of the <entity id="W02-0303.33">ability</entity> to <entity id="W02-0303.34">disambiguate</entity> between <entity id="W02-0303.35">genes</entity> , <entity id="W02-0303.36">proteins</entity> , RNA, and a <entity id="W02-0303.37">variety</entity> of other <entity id="W02-0303.38">referents</entity> for <entity id="W02-0303.39">performing</entity> <entity id="W02-0303.40">entity</entity> <entity id="W02-0303.41">identification</entity> with high <entity id="W02-0303.42">precision</entity> .
</abstract>


composed_of(W02-0303.7,W02-0303.9)

</text>

<text id="W02-1706">
<title>
XML-Based NLP Tools For Analysing And Annotating Medical <entity id="W02-1706.1">Language</entity></title>
<abstract>
We describe the use of a <entity id="W02-1706.2">suite</entity> of highly flexible xml-based nlp <entity id="W02-1706.3">tools</entity> in a <entity id="W02-1706.4">project</entity> for <entity id="W02-1706.5">processing</entity> and interpreting <entity id="W02-1706.6">text</entity> in the medical <entity id="W02-1706.7">domain</entity> . The <entity id="W02-1706.8">main</entity> aim of the <entity id="W02-1706.9">paper</entity> is to demonstrate the central <entity id="W02-1706.10">role</entity> that xml mark-up and xml nlp <entity id="W02-1706.11">tools</entity> have played in the <entity id="W02-1706.12">analysis</entity> <entity id="W02-1706.13">process</entity> and to describe the resultant annotated <entity id="W02-1706.14">corpus</entity> of medline <entity id="W02-1706.15">abstracts</entity> . In <entity id="W02-1706.16">addition</entity> to the xml <entity id="W02-1706.17">tools</entity> , we have succeeded in integrating a <entity id="W02-1706.18">variety</entity> of non-xml 'off the shelf' nlp <entity id="W02-1706.19">tools</entity> into our <entity id="W02-1706.20">pipelines</entity> , so that their <entity id="W02-1706.21">output</entity> is added into the mark-up. We demonstrate the <entity id="W02-1706.22">utility</entity> of the annotations that <entity id="W02-1706.23">result</entity> in two ways. First, we investigate how they can be used to <entity id="W02-1706.24">improve</entity> <entity id="W02-1706.25">parse</entity> <entity id="W02-1706.26">coverage</entity> ofa <entity id="W02-1706.27">hand-crafted</entity> grammar that <entity id="W02-1706.28">generates</entity> <entity id="W02-1706.29">logical forms</entity> . And second, we investigate how they contribute to <entity id="W02-1706.30">automatic</entity> <entity id="W02-1706.31">lexical</entity> <entity id="W02-1706.32">semantic</entity> <entity id="W02-1706.33">acquisition</entity> <entity id="W02-1706.34">processes</entity> .
</abstract>


taskapplied(W02-1706.5,W02-1706.6)
propose(W02-1706.9,W02-1706.11)
composed_of(W02-1706.14,W02-1706.15)
part_of(W02-1706.19,W02-1706.20)

</text>

<text id="W03-0305">
<title>
Reducing <entity id="W03-0305.1">Parameter</entity> <entity id="W03-0305.2">Space</entity> For <entity id="W03-0305.3">Word Alignment</entity></title>
<abstract>
This <entity id="W03-0305.4">paper</entity> presents the <entity id="W03-0305.5">experimental</entity> <entity id="W03-0305.6">results</entity> of our attemps to reduce the <entity id="W03-0305.7">size</entity> of the <entity id="W03-0305.8">parameter</entity> <entity id="W03-0305.9">space</entity> in <entity id="W03-0305.10">word alignment</entity> <entity id="W03-0305.11">algorithm</entity> . We use <entity id="W03-0305.12">IBM Model</entity> 4 as a baseline. In <entity id="W03-0305.13">order</entity> to reduce the <entity id="W03-0305.14">parameter</entity> <entity id="W03-0305.15">space</entity> , we pre-processed the <entity id="W03-0305.16">training <entity id="W03-0305.17">corpus</entity></entity> using a <entity id="W03-0305.18">word</entity> lemmatizer and a bilingual <entity id="W03-0305.19">term</entity> <entity id="W03-0305.20">extraction</entity> <entity id="W03-0305.21">algorithm</entity> . Using these additional <entity id="W03-0305.22">components</entity> , we obtained an <entity id="W03-0305.23">improvement</entity> in the <entity id="W03-0305.24">alignment</entity> <entity id="W03-0305.25">error <entity id="W03-0305.26">rate</entity></entity> .
</abstract>


propose(W03-0305.4,W03-0305.6)
methodapplied(W03-0305.16,W03-0305.21,REVERSE)
wrt(W03-0305.23,W03-0305.25)

</text>

<text id="W03-0902">
<title><entity id="W03-0902.1">Extracting</entity> And <entity id="W03-0902.2">Evaluating</entity> General <entity id="W03-0902.3">World <entity id="W03-0902.4">Knowledge</entity></entity> From The <entity id="W03-0902.5">Brown <entity id="W03-0902.6">Corpus</entity></entity></title>
<abstract>
"We have been <entity id="W03-0902.7">developing</entity> <entity id="W03-0902.8">techniques</entity> for <entity id="W03-0902.9">extracting</entity> general <entity id="W03-0902.10">world knowledge</entity> from miscellaneous <entity id="W03-0902.11">texts</entity> by a <entity id="W03-0902.12">process</entity> of approximate <entity id="W03-0902.13">interpretation</entity> and <entity id="W03-0902.14">abstraction</entity> , <entity id="W03-0902.15">focusing</entity> initially on the <entity id="W03-0902.16">Brown corpus</entity> . We <entity id="W03-0902.17">apply</entity> interpretive <entity id="W03-0902.18">rules</entity> to clausal <entity id="W03-0902.19">patterns</entity> and <entity id="W03-0902.20">patterns</entity> of <entity id="W03-0902.21">modification</entity> , and concurrently <entity id="W03-0902.22">abstract</entity> general ""possi-bilistic"" propositions from the <entity id="W03-0902.23">resulting</entity> <entity id="W03-0902.24">formulas</entity> . Two <entity id="W03-0902.25">examples</entity> are ""A person may believe a proposition"", and ""Children may live with <entity id="W03-0902.26">relatives</entity> "". Our <entity id="W03-0902.27">methods</entity> currently <entity id="W03-0902.28">yield</entity> over 117,000 such propositions (of <entity id="W03-0902.29">variable</entity> <entity id="W03-0902.30">quality</entity> ) for the <entity id="W03-0902.31">Brown <entity id="W03-0902.32">corpus</entity></entity> (more than 2 per <entity id="W03-0902.33">sentence</entity> ). We <entity id="W03-0902.34">report</entity> here on our <entity id="W03-0902.35">efforts</entity> to <entity id="W03-0902.36">evaluate</entity> these <entity id="W03-0902.37">results</entity> with a <entity id="W03-0902.38">judging</entity> <entity id="W03-0902.39">scheme</entity> aimed at determining how many ofthese propositions pass muster as ""reasonable general <entity id="W03-0902.40">claims</entity> "" about the world in the <entity id="W03-0902.41">opinion</entity> of humanjudges. We find that nearly 60% of the <entity id="W03-0902.42">extracted</entity> propositions are favorably <entity id="W03-0902.43">judged</entity> according to our <entity id="W03-0902.44">scheme</entity> by any given <entity id="W03-0902.45">judge</entity> . The <entity id="W03-0902.46">percentage</entity> unanimously <entity id="W03-0902.47">judged</entity> to be reasonable <entity id="W03-0902.48">claims</entity> by multiple <entity id="W03-0902.49">judges</entity> is lower, but still sufficiently high to suggest that our <entity id="W03-0902.50">techniques</entity> may be of some use in tackling the long-standing ""<entity id="W03-0902.51">knowledge</entity> <entity id="W03-0902.52">acquisition</entity> bottleneck"" in AI. "
</abstract>


datasource(W03-0902.3,W03-0902.5)
taskapplied(W03-0902.9,W03-0902.11)
methodapplied(W03-0902.18,W03-0902.19)
methodapplied(W03-0902.27,W03-0902.31)

</text>

<text id="W03-1026">
<title>
How To Get A <entity id="W03-1026.1">Chinese</entity> <entity id="W03-1026.2">Name</entity> ( <entity id="W03-1026.3">Entity</entity> ): Segmentation And <entity id="W03-1026.4">Combination</entity> Issues
</title>
<abstract>
When building a <entity id="W03-1026.5">Chinese</entity> <entity id="W03-1026.6">named</entity> <entity id="W03-1026.7">entity</entity> <entity id="W03-1026.8">recognition system</entity> , one must <entity id="W03-1026.9">deal</entity> with certain <entity id="W03-1026.10">language-specific</entity> <entity id="W03-1026.11">issues</entity> such as whether the <entity id="W03-1026.12">model</entity> should be <entity id="W03-1026.13">based</entity> on characters or <entity id="W03-1026.14">words</entity> . While there is no unique answer to this <entity id="W03-1026.15">question</entity> , we discuss in <entity id="W03-1026.16">detail</entity> <entity id="W03-1026.17">advantages</entity> and disadvantages of each <entity id="W03-1026.18">model</entity> , identify <entity id="W03-1026.19">problems</entity> in segmentation and suggest possible <entity id="W03-1026.20">solutions</entity> , presenting our <entity id="W03-1026.21">observations</entity> , <entity id="W03-1026.22">analysis</entity> , and <entity id="W03-1026.23">experimental</entity> <entity id="W03-1026.24">results</entity> . The second <entity id="W03-1026.25">topic</entity> of this <entity id="W03-1026.26">paper</entity> is <entity id="W03-1026.27">classifier</entity> <entity id="W03-1026.28">combination</entity> . We present and describe four <entity id="W03-1026.29">classifiers</entity> for <entity id="W03-1026.30">Chinese</entity> <entity id="W03-1026.31">named</entity> <entity id="W03-1026.32">entity</entity> <entity id="W03-1026.33">recognition</entity> and describe various <entity id="W03-1026.34">methods</entity> for combining their <entity id="W03-1026.35">outputs</entity> . The <entity id="W03-1026.36">results</entity> demonstrate that <entity id="W03-1026.37">classifier</entity> <entity id="W03-1026.38">combination</entity> is an effective <entity id="W03-1026.39">technique</entity> of <entity id="W03-1026.40">improving</entity> <entity id="W03-1026.41">system</entity> <entity id="W03-1026.42">performance</entity> : <entity id="W03-1026.43">experiments</entity> over a large annotated <entity id="W03-1026.44">corpus</entity> of fine-grained <entity id="W03-1026.45">entity types</entity> exhibit a 10% <entity id="W03-1026.46">relative</entity> <entity id="W03-1026.47">reduction</entity> in F-measure <entity id="W03-1026.48">error</entity> .
</abstract>


propose(W03-1026.26,W03-1026.28)
usedfor(W03-1026.29,W03-1026.33)
usedfor(W03-1026.38,W03-1026.40)
yields(W03-1026.43,W03-1026.47)

</text>

<text id="W03-1101">
<title>
Improving <entity id="W03-1101.1">Summarization</entity> <entity id="W03-1101.2">Performance</entity> By <entity id="W03-1101.3">Sentence</entity> <entity id="W03-1101.4">Compression</entity> - A <entity id="W03-1101.5">Pilot</entity> <entity id="W03-1101.6">Study</entity></title>
<abstract>
In this <entity id="W03-1101.7">paper</entity> we <entity id="W03-1101.8">study</entity> the <entity id="W03-1101.9">effectiveness</entity> of <entity id="W03-1101.10">applying</entity> <entity id="W03-1101.11">sentence</entity> <entity id="W03-1101.12">compression</entity> on an <entity id="W03-1101.13">extraction</entity> <entity id="W03-1101.14">based</entity> multi-document <entity id="W03-1101.15">summarization system</entity> . Our <entity id="W03-1101.16">results</entity> show that pure <entity id="W03-1101.17">syntactic-based</entity> <entity id="W03-1101.18">compression</entity> does not <entity id="W03-1101.19">improve</entity> <entity id="W03-1101.20">system</entity> <entity id="W03-1101.21">performance</entity> . <entity id="W03-1101.22">Topic</entity> signature-based reranking of compressed <entity id="W03-1101.23">sentences</entity> does not <entity id="W03-1101.24">help</entity> much either. However reranking using an <entity id="W03-1101.25">oracle</entity> showed a significant <entity id="W03-1101.26">improvement</entity> remains possible. Keywords: <entity id="W03-1101.27">Text Summarization</entity> , <entity id="W03-1101.28">Sentence</entity> <entity id="W03-1101.29">Extraction</entity> , <entity id="W03-1101.30">Sentence</entity> <entity id="W03-1101.31">Compression</entity> , <entity id="W03-1101.32">Evaluation</entity> .
</abstract>


propose(W03-1101.7,W03-1101.12)
yields(W03-1101.18,W03-1101.21)

</text>

<text id="W99-0611">
<title><entity id="W99-0611.1">Noun Phrase</entity> Coreference As Clustering
</title>
<abstract>
This <entity id="W99-0611.2">paper</entity> introduces a new, unsupervised <entity id="W99-0611.3">algorithm</entity> for <entity id="W99-0611.4">noun phrase</entity> <entity id="W99-0611.5">coreference <entity id="W99-0611.6">resolution</entity></entity> . It differs from existing <entity id="W99-0611.7">methods</entity> in that it views <entity id="W99-0611.8">coreference resolution</entity> as a <entity id="W99-0611.9">clustering</entity> <entity id="W99-0611.10">task</entity> . In an <entity id="W99-0611.11">evaluation</entity> on the MUC-6 <entity id="W99-0611.12">coreference resolution</entity> <entity id="W99-0611.13">corpus</entity> , the <entity id="W99-0611.14">algorithm</entity> achieves an F-measure of 53.6%, placing it firmly between the worst (40%) and best (65%) <entity id="W99-0611.15">systems</entity> in the MUC-6 <entity id="W99-0611.16">evaluation</entity> . More importantly, the <entity id="W99-0611.17">clustering</entity> <entity id="W99-0611.18">approach</entity> outperforms the only MUC-6 <entity id="W99-0611.19">system</entity> to treat <entity id="W99-0611.20">coreference resolution</entity> as a learning <entity id="W99-0611.21">problem</entity> . The <entity id="W99-0611.22">clustering</entity> <entity id="W99-0611.23">algorithm</entity> appears to <entity id="W99-0611.24">provide</entity> a flexible <entity id="W99-0611.25">mechanism</entity> for coordinating the <entity id="W99-0611.26">application</entity> of <entity id="W99-0611.27">context-independent</entity> and <entity id="W99-0611.28">context-dependent</entity> <entity id="W99-0611.29">constraints</entity> and <entity id="W99-0611.30">preferences</entity> for accurate <entity id="W99-0611.31">partitioning</entity> of <entity id="W99-0611.32">noun phrases</entity> into coreference <entity id="W99-0611.33">equivalence classes</entity> .
</abstract>


usedfor(W99-0611.3,W99-0611.5)
methodapplied(W99-0611.11,W99-0611.13)
compare(W99-0611.18,W99-0611.19)
based_on(W99-0611.30,W99-0611.31,REVERSE)

</text>

<text id="W08-0215">
<title>
Psychocomputational <entity id="W08-0215.1">Linguistics</entity> : A Gateway to the <entity id="W08-0215.2">Computational Linguistics</entity> Curriculum
</title>
<abstract><entity id="W08-0215.3">Computational</entity> <entity id="W08-0215.4">modeling</entity> of <entity id="W08-0215.5">human language</entity> <entity id="W08-0215.6">processes</entity> is a small but growing subfield of <entity id="W08-0215.7">computational <entity id="W08-0215.8">linguistics</entity></entity> . This <entity id="W08-0215.9">paper</entity> describes a course that makes use of recent <entity id="W08-0215.10">research</entity> in psychocomputational <entity id="W08-0215.11">modeling</entity> as a <entity id="W08-0215.12">framework</entity> to introduce a <entity id="W08-0215.13">number</entity> of <entity id="W08-0215.14">mainstream</entity> <entity id="W08-0215.15">computational linguistics</entity> <entity id="W08-0215.16">concepts</entity> to an audience of <entity id="W08-0215.17">linguistics</entity> , <entity id="W08-0215.18">cognitive science</entity> and <entity id="W08-0215.19">computer science</entity> doctoral students. The emphasis on what I take to be the largely interdisciplinary <entity id="W08-0215.20">nature</entity> of <entity id="W08-0215.21">computational linguistics</entity> is particularly germane for the <entity id="W08-0215.22">computer science</entity> students. Since 2002  the course has been taught three <entity id="W08-0215.23">times</entity> under the auspices of the MA/PhD <entity id="W08-0215.24">program</entity> in <entity id="W08-0215.25">Linguistics</entity> at The City <entity id="W08-0215.26">University</entity> of New York's <entity id="W08-0215.27">Graduate</entity> <entity id="W08-0215.28">Center</entity> . A brief <entity id="W08-0215.29">description</entity> of some of the students' <entity id="W08-0215.30">experiences</entity> after having taken the course is also <entity id="W08-0215.31">provided</entity> .
</abstract>


part_of(W08-0215.4,W08-0215.7)

</text>

<text id="J80-3003">
<title>
A Plan- <entity id="J80-3003.1">Based</entity> <entity id="J80-3003.2">Analysis</entity> Of Indirect <entity id="J80-3003.3">Speech Act</entity></title>
<abstract>
We <entity id="J80-3003.4">propose</entity> an account of indirect <entity id="J80-3003.5">forms</entity> of <entity id="J80-3003.6">speech acts</entity> to request and inform <entity id="J80-3003.7">based</entity> on the <entity id="J80-3003.8">hypothesis</entity> that <entity id="J80-3003.9">language</entity> <entity id="J80-3003.10">users</entity> can recognize <entity id="J80-3003.11">actions</entity> being <entity id="J80-3003.12">performed</entity> by others, infer <entity id="J80-3003.13">goals</entity> being sought, and cooperate in their achievement. This cooperative <entity id="J80-3003.14">behaviour</entity> is independently motivated and may or may not be intended by speakers. If the hearer believes it is intended, he or she can recognize the <entity id="J80-3003.15">speech act</entity> as indirect; otherwise it is interpreted directly. Heuristics are suggested to decide among the <entity id="J80-3003.16">interpretations</entity> .
</abstract>


study(J80-3003.2,J80-3003.3)

</text>

<text id="J84-3005">
<title>
Strong Generative <entity id="J84-3005.1">Capacity</entity> , Weak Generative <entity id="J84-3005.2">Capacity</entity> , And Modern Linguistic Theories
</title>
<abstract>Pullum , Geoffrey K. , <entity id="J84-3005.3">Syntactic</entity> And <entity id="J84-3005.4">Semantic</entity> Parsability,International Conference On <entity id="J84-3005.5">Computational Linguistics</entity> And Annual Meeting Of The <entity id="J84-3005.6">Association</entity> For <entity id="J84-3005.7">Computation</entity> al <entity id="J84-3005.8">Linguistics</entity> ,1984</abstract>



</text>

<text id="J92-4002">
<title>
Ambiguous <entity id="J92-4002.1">Noun</entity> Phrases In <entity id="J92-4002.2">Logical Form</entity></title>
<abstract>
	"Schubert , Lenhart K.; Pelletier , Francis Jeffry ,From <entity id="J92-4002.3">English</entity> To <entity id="J92-4002.4">Logic</entity> : <entity id="J92-4002.5">Context-</entity> Free <entity id="J92-4002.6">Computation</entity> Of ""Conventional"" Logical <entity id="J92-4002.7">Translation</entity> ,American <entity id="J92-4002.8">Journal</entity> Of <entity id="J92-4002.9">Computation</entity> al <entity id="J92-4002.10">Linguistics</entity> ,1982 *** Hobbs , Jerry R. ,An Improper <entity id="J92-4002.11">Treatment</entity> Of <entity id="J92-4002.12">Quantification</entity> In Ordinary <entity id="J92-4002.13">English</entity> ,Annual Meeting Of The <entity id="J92-4002.14">Association</entity> For <entity id="J92-4002.15">Computation</entity> al <entity id="J92-4002.16">Linguistics</entity> ,1983 *** Pollack , Martha E. ; Pereira , Fernando ,An Integrated <entity id="J92-4002.17">Framework</entity> For <entity id="J92-4002.18">Semantic</entity> And Pragmatic <entity id="J92-4002.19">Interpretation</entity> ,Annual Meeting Of The <entity id="J92-4002.20">Association</entity> For <entity id="J92-4002.21">Computation</entity> al <entity id="J92-4002.22">Linguistics</entity> ,1988 *** Alshawi , Hiyan ; <entity id="J92-4002.23">Van</entity> Eijck , Jan,Logical Forms In The <entity id="J92-4002.24">Core</entity> <entity id="J92-4002.25">Language</entity> <entity id="J92-4002.26">Engine</entity> ,Annual Meeting Of The <entity id="J92-4002.27">Association</entity> For <entity id="J92-4002.28">Computation</entity> al <entity id="J92-4002.29">Linguistics</entity> ,1989 "
</abstract>


usedfor(J92-4002.17,J92-4002.19)

</text>

<text id="J94-3012">
<title>
Commentary On Bird And Klein</title>



</text>

<abstract></abstract>

<text id="J99-4001">
<title><entity id="J99-4001.1">Completeness</entity> Conditions For Mixed <entity id="J99-4001.2">Strategy</entity> Bidirectional <entity id="J99-4001.3">Parsing</entity></title>



</text>

<abstract></abstract>

<text id="J00-3001">
<title><entity id="J00-3001.1">Extracting</entity> The Lowest- <entity id="J00-3001.2">Frequency</entity> <entity id="J00-3001.3">Words</entity> : <entity id="J00-3001.4">Pitfalls</entity> And Possibilities
</title>
<abstract>
	Church, Kenneth Ward ; Hanks , Patrick , <entity id="J00-3001.5">Word</entity> <entity id="J00-3001.6">Association</entity> <entity id="J00-3001.7">Norms</entity> , <entity id="J00-3001.8">Mutual Information</entity> , And Lexicography, <entity id="J00-3001.9">Computation</entity> al <entity id="J00-3001.10">Linguistics</entity> ,1990 *** Dunning , Ted E. ,Accurate <entity id="J00-3001.11">Methods</entity> For The <entity id="J00-3001.12">Statistics</entity> Of Surprise And Coincidence, <entity id="J00-3001.13">Computation</entity> al <entity id="J00-3001.14">Linguistics</entity> ,1993 *** Smadja , Frank A. ,Retrieving Collocations From <entity id="J00-3001.15">Text</entity> : Xtract, <entity id="J00-3001.16">Computation</entity> al <entity id="J00-3001.17">Linguistics</entity> ,1993</abstract>


taskapplied(J00-3001.1,J00-3001.3)

</text>

<text id="P80-1011">
<title>
The Parameters Of Conversational Style
</title>
<abstract>
3. <entity id="P80-1011.1">Focus</entity> on <entity id="P80-1011.2">content</entity> vs. interpersonal involvement.
</abstract>



</text>

<text id="P80-1022">
<title>
The <entity id="P80-1022.1">Computer</entity> As An Active <entity id="P80-1022.2">Communication</entity> Medium
</title>
<abstract><entity id="P80-1022.3">Communication</entity> is often conceived of in basically the following <entity id="P80-1022.4">terms</entity> . A person has some idea which he or she wants to communicate to a second person. The first person <entity id="P80-1022.5">translates</entity> that idea into some <entity id="P80-1022.6">symbol</entity> <entity id="P80-1022.7">system</entity> which is transmitted through some medium to the receiver. The receiver receives the transmission and <entity id="P80-1022.8">translates</entity> it into some internal idea. <entity id="P80-1022.9">Communication</entity> , in this view, is considered good to the <entity id="P80-1022.10">extent</entity> that there is an isomorphism between the idea in the head of the sender before sending the <entity id="P80-1022.11">message</entity> and the idea in the receiver's head after recieving the <entity id="P80-1022.12">message</entity> . A good medium of <entity id="P80-1022.13">communication</entity> , in this view, is one that adds minimal <entity id="P80-1022.14">noise</entity> to the <entity id="P80-1022.15">signal</entity> . Messages are considered good partly to the <entity id="P80-1022.16">extent</entity> that they are unabmiguous. This is, by and large, the view of many of the people <entity id="P80-1022.17">concerned</entity> with <entity id="P80-1022.18">computers</entity> and <entity id="P80-1022.19">communication</entity> .For a moment, consider a quite different view of <entity id="P80-1022.20">communication</entity> . In this view, <entity id="P80-1022.21">communication</entity> is basically a <entity id="P80-1022.22">design-interpretation</entity> <entity id="P80-1022.23">process</entity> . One person has <entity id="P80-1022.24">goals</entity> that they believe can be aided by communicating. The person therefore <entity id="P80-1022.25">designs</entity> a <entity id="P80-1022.26">message</entity> which is intended to facilitate those <entity id="P80-1022.27">goals</entity> . In most <entity id="P80-1022.28">cases</entity> , the <entity id="P80-1022.29">goal</entity> <entity id="P80-1022.30">includes</entity> changing some cognitive <entity id="P80-1022.31">structure</entity> in one or more other people's minds. Each receiver of a <entity id="P80-1022.32">message</entity> however has his or her own <entity id="P80-1022.33">goals</entity> in mind and a <entity id="P80-1022.34">model</entity> of the world ( <entity id="P80-1022.35">including</entity> a <entity id="P80-1022.36">model</entity> of the sender) and interprets the received <entity id="P80-1022.37">message</entity> in light of that other world <entity id="P80-1022.38">information</entity> and <entity id="P80-1022.39">relative</entity> to the perceived <entity id="P80-1022.40">goals</entity> of the sender. This view has been articulated further elsewhere lij.This view originates primarily from putting the <entity id="P80-1022.41">rules</entity> of <entity id="P80-1022.42">language</entity> and the <entity id="P80-1022.43">basic</entity> <entity id="P80-1022.44">nature</entity> of human beings in <entity id="P80-1022.45">perspective</entity> . The <entity id="P80-1022.46">basic</entity> <entity id="P80-1022.47">nature</entity> of human beings is that we are living <entity id="P80-1022.48">organisms</entity> and our <entity id="P80-1022.49">behavior</entity> is goals-directed. The <entity id="P80-1022.50">rules</entity> of <entity id="P80-1022.51">language</entity> are convenient but secondary. We can <entity id="P80-1022.52">language</entity> <entity id="P80-1022.53">rules</entity> for a <entity id="P80-1022.54">purpose</entity> break.Communicating in different media produces different <entity id="P80-1022.55">behaviors</entity> and reactions The interesting first <entity id="P80-1022.56">order</entity> finding however, is that people can communicate using practically any medium that lets any <entity id="P80-1022.57">signal</entity> through if <entity id="P80-1022.58">motivation</entity> is high enough. We can, under some circumstances, communicate with people who use different accents, grammars, or even <entity id="P80-1022.59">languages</entity> . Yet, in other circumstances, people who are ostensibly friends working on a <entity id="P80-1022.60">common</entity> <entity id="P80-1022.61">goal</entity> and who have known each other for years end up shouting at each other: 'You're not listening to me. No, you don't understand!'One fundamental <entity id="P80-1022.62">aspect</entity> of human <entity id="P80-1022.63">communication</entity> then is that it is terrifically adaptive, and <entity id="P80-1022.64">robust</entity> .containing a <entity id="P80-1022.65">number</entity> of sophisticated <entity id="P80-1022.66">mechanisms</entity> such as <entity id="P80-1022.67">explanations</entity> that simultaneously facilitate social and work
</abstract>



</text>

<text id="P98-2228">
<title><entity id="P98-2228.1">Word <entity id="P98-2228.2">Sense Disambiguation</entity></entity> using Optimised Combinations of <entity id="P98-2228.3">Knowledge Sources</entity></title> 
<abstract><entity id="P98-2228.4">Word sense disambiguation</entity> <entity id="P98-2228.5">algorithms</entity> , with few <entity id="P98-2228.6">exceptions</entity> , have made use of only one lexical <entity id="P98-2228.7">knowledge <entity id="P98-2228.8">source</entity></entity> . We describe a <entity id="P98-2228.9">system</entity> which <entity id="P98-2228.10">performs</entity> <entity id="P98-2228.11">word sense disambiguation</entity> on all <entity id="P98-2228.12">content <entity id="P98-2228.13">words</entity></entity> in free <entity id="P98-2228.14">text</entity> by combining different <entity id="P98-2228.15">knowledge sources</entity> : <entity id="P98-2228.16">semantic</entity> <entity id="P98-2228.17">preferences</entity> , <entity id="P98-2228.18">dictionary definitions</entity> and subject/ <entity id="P98-2228.19">domain</entity> <entity id="P98-2228.20">codes</entity> along with <entity id="P98-2228.21">part-of-speech</entity> <entity id="P98-2228.22">tags</entity> , optimised by means of a learning <entity id="P98-2228.23">algorithm</entity> . We also describe the <entity id="P98-2228.24">creation</entity> of a new <entity id="P98-2228.25">sense</entity> <entity id="P98-2228.26">tagged</entity> <entity id="P98-2228.27">corpus</entity> by combining existing <entity id="P98-2228.28">resources</entity> . Tested <entity id="P98-2228.29">accuracy</entity> of our <entity id="P98-2228.30">approach</entity> on this <entity id="P98-2228.31">corpus</entity> exceeds 92% , demonstrating the viability of <entity id="P98-2228.32">all-word</entity> <entity id="P98-2228.33">disambiguation</entity> rather than restricting oneself to a small <entity id="P98-2228.34">sample</entity> .
</abstract>


based_on(P98-2228.1,P98-2228.3)
based_on(P98-2228.5,P98-2228.7)
methodapplied(P98-2228.9,P98-2228.12)
yields(P98-2228.29,P98-2228.30,REVERSE)

</text>

<text id="W08-1138">
<title>
GRAPH: The <entity id="W08-1138.1">Costs</entity> of <entity id="W08-1138.2">Redundancy</entity> in Referring Expressions
</title>
<abstract>
We describe a graph-based <entity id="W08-1138.3">generation <entity id="W08-1138.4">system</entity></entity> that participated in the Tuna attribute <entity id="W08-1138.5">selection</entity> and <entity id="W08-1138.6">realisation</entity> <entity id="W08-1138.7">task</entity> of the reg 2008 <entity id="W08-1138.8">Challenge</entity> . Using a stochastic <entity id="W08-1138.9">cost</entity> <entity id="W08-1138.10">function</entity> (with certain <entity id="W08-1138.11">properties</entity> for free), and trying attributes from cheapest to more expensive, the <entity id="W08-1138.12">system</entity> achieves overall .76 dice and .54 masi scores for attribute <entity id="W08-1138.13">selection</entity> on the <entity id="W08-1138.14">development</entity> set. For <entity id="W08-1138.15">realisation</entity> , it turns out that in some <entity id="W08-1138.16">cases</entity> higher attribute <entity id="W08-1138.17">selection</entity> <entity id="W08-1138.18">accuracy</entity> leads to larger <entity id="W08-1138.19">differences</entity> between <entity id="W08-1138.20">system-generated</entity> and human <entity id="W08-1138.21">descriptions</entity> .
</abstract>


usedfor(W08-1138.3,W08-1138.7)
yields(W08-1138.17,W08-1138.19)

</text>

<text id="W03-2805">
<title>
Colouring Summaries BLEU
</title>
<abstract>
In this <entity id="W03-2805.1">paper</entity> we attempt to <entity id="W03-2805.2">apply</entity> the IBM <entity id="W03-2805.3">algorithm</entity> , BLEU, to the <entity id="W03-2805.4">output</entity> of four different summarizers in <entity id="W03-2805.5">order</entity> to <entity id="W03-2805.6">perform</entity> an intrinsic <entity id="W03-2805.7">evaluation</entity> of their <entity id="W03-2805.8">output</entity> . The <entity id="W03-2805.9">objective</entity> of this <entity id="W03-2805.10">experiment</entity> is to explore whether a <entity id="W03-2805.11">metric</entity> , originally <entity id="W03-2805.12">developed</entity> for the <entity id="W03-2805.13">evaluation</entity> of <entity id="W03-2805.14">machine <entity id="W03-2805.15">translation</entity></entity> <entity id="W03-2805.16">output</entity> , could be used for assessing another <entity id="W03-2805.17">type</entity> of <entity id="W03-2805.18">output</entity> reliably. Changing the <entity id="W03-2805.19">type</entity> of <entity id="W03-2805.20">text</entity> to be <entity id="W03-2805.21">evaluated</entity> by BLEU into automatically <entity id="W03-2805.22">generated</entity> <entity id="W03-2805.23">extracts</entity> and setting the conditions and <entity id="W03-2805.24">parameters</entity> of the <entity id="W03-2805.25">evaluation</entity> <entity id="W03-2805.26">experiment</entity> according to the idiosyncrasies of the <entity id="W03-2805.27">task</entity> , we put the feasibility of <entity id="W03-2805.28">porting</entity> BLEU in different <entity id="W03-2805.29">Natural Language Processing</entity> <entity id="W03-2805.30">research</entity> <entity id="W03-2805.31">areas</entity> under <entity id="W03-2805.32">test</entity> . Furthermore, some important <entity id="W03-2805.33">conclusions</entity> relevant to the <entity id="W03-2805.34">resources</entity> needed for <entity id="W03-2805.35">evaluating</entity> <entity id="W03-2805.36">summaries</entity> have come up as a <entity id="W03-2805.37">side-effect</entity> of running the whole <entity id="W03-2805.38">experiment</entity> .
</abstract>


methodapplied(W03-2805.3,W03-2805.4)
study(W03-2805.7,W03-2805.8)
study(W03-2805.13,W03-2805.14)

</text>

<text id="I08-1029">
<title><entity id="I08-1029.1">Automatic</entity> Prosodic Labeling with Conditional Random Fields and Rich Acoustic <entity id="I08-1029.2">Features</entity></title>
<abstract>
Many acoustic <entity id="I08-1029.3">approaches</entity> to prosodic labeling in <entity id="I08-1029.4">English</entity> have employed only local <entity id="I08-1029.5">classifiers</entity> , although <entity id="I08-1029.6">text-based</entity> <entity id="I08-1029.7">classification</entity> has employed some sequential <entity id="I08-1029.8">models</entity> . In this <entity id="I08-1029.9">paper</entity> we employ linear <entity id="I08-1029.10">chain</entity> and factorial <entity id="I08-1029.11">conditional random <entity id="I08-1029.12">fields</entity></entity> (CRFs) in <entity id="I08-1029.13">conjunction</entity> with rich, contextually-based prosodic <entity id="I08-1029.14">features</entity> , to exploit sequential <entity id="I08-1029.15">dependencies</entity> and to facilitate <entity id="I08-1029.16">integration</entity> with <entity id="I08-1029.17">lexical features</entity> . <entity id="I08-1029.18">Integration</entity> of <entity id="I08-1029.19">lexical</entity> and prosodic <entity id="I08-1029.20">features</entity> <entity id="I08-1029.21">improves</entity> <entity id="I08-1029.22">pitch</entity> accent <entity id="I08-1029.23">prediction</entity> over either <entity id="I08-1029.24">feature set</entity> alone, and for lower <entity id="I08-1029.25">accuracy</entity> <entity id="I08-1029.26">feature sets</entity> , factorial <entity id="I08-1029.27">CRF <entity id="I08-1029.28">models</entity></entity> can <entity id="I08-1029.29">improve</entity> over linear <entity id="I08-1029.30">chain</entity> <entity id="I08-1029.31">based</entity> <entity id="I08-1029.32">prediction</entity> of <entity id="I08-1029.33">pitch</entity> accent.
</abstract>


usedfor(I08-1029.7,I08-1029.8,REVERSE)
propose(I08-1029.9,I08-1029.11)
affects(I08-1029.18,I08-1029.23)
yields(I08-1029.27,I08-1029.32)

</text>

<text id="W04-0829">
<title>
WSD <entity id="W04-0829.1">Based</entity> On <entity id="W04-0829.2">Mutual Information</entity> And <entity id="W04-0829.3">Syntactic Patterns</entity></title>
<abstract>
This <entity id="W04-0829.4">paper</entity> describes a hybrid <entity id="W04-0829.5">system</entity> for WSD, presented to the <entity id="W04-0829.6">English</entity> <entity id="W04-0829.7">all-words</entity> and <entity id="W04-0829.8">lexical-sample</entity> <entity id="W04-0829.9">tasks</entity> , that relies on two different unsupervised <entity id="W04-0829.10">approaches</entity> . The first one selects the senses according to <entity id="W04-0829.11">mutual information</entity> <entity id="W04-0829.12">proximity</entity> between a <entity id="W04-0829.13">context word</entity> a <entity id="W04-0829.14">variant</entity> of the <entity id="W04-0829.15">sense</entity> . The second heuristic analyzes the <entity id="W04-0829.16">examples</entity> of use in the glosses of the senses so that <entity id="W04-0829.17">simple</entity> <entity id="W04-0829.18">syntactic patterns</entity> are inferred. This <entity id="W04-0829.19">patterns</entity> are <entity id="W04-0829.20">matched</entity> against the <entity id="W04-0829.21">disambiguation</entity> <entity id="W04-0829.22">contexts</entity> . We show that the first heuristic obtains a <entity id="W04-0829.23">precision</entity> and <entity id="W04-0829.24">recall</entity> of .58 and .35 respectively in the all <entity id="W04-0829.25">words</entity> <entity id="W04-0829.26">task</entity> while the second obtains .80 and .25. The high <entity id="W04-0829.27">precision</entity> obtained recommends deeper <entity id="W04-0829.28">research</entity> of the <entity id="W04-0829.29">techniques</entity> . <entity id="W04-0829.30">Results</entity> for the <entity id="W04-0829.31">lexical</entity> <entity id="W04-0829.32">sample</entity> <entity id="W04-0829.33">task</entity> are also <entity id="W04-0829.34">provided</entity> .
</abstract>


propose(W04-0829.4,W04-0829.5)
compare(W04-0829.19,W04-0829.22)

</text>

<text id="W04-0863">
<title>
Joining Forces To Resolve <entity id="W04-0863.1">Lexical</entity> <entity id="W04-0863.2">Ambiguity</entity> : East Meets West In Barcelona
</title>
<abstract>
"This <entity id="W04-0863.3">paper</entity> describes the <entity id="W04-0863.4">component</entity> <entity id="W04-0863.5">models</entity> and <entity id="W04-0863.6">combination</entity> <entity id="W04-0863.7">model</entity> built as a joint <entity id="W04-0863.8">effort</entity> between Swarthmore College, <entity id="W04-0863.9">Hong</entity> Kong PolyU, and HKUST. Though other <entity id="W04-0863.10">models</entity> described elsewhere contributed to the final <entity id="W04-0863.11">combination</entity> <entity id="W04-0863.12">model</entity> , this <entity id="W04-0863.13">paper</entity> <entity id="W04-0863.14">focuses</entity> solely on the joint <entity id="W04-0863.15">contributions</entity> to the ""Swat-HK"" <entity id="W04-0863.16">effort</entity> . "
</abstract>


propose(W04-0863.3,W04-0863.5)
propose(W04-0863.13,W04-0863.15)

</text>

<text id="W04-0914">
<title><entity id="W04-0914.1">Semantic</entity> <entity id="W04-0914.2">Forensics</entity> : An <entity id="W04-0914.3">Application</entity> Of Ontological <entity id="W04-0914.4">Semantics</entity> To <entity id="W04-0914.5">Information</entity> Assurance
</title>
<abstract>
"The <entity id="W04-0914.6">paper</entity> <entity id="W04-0914.7">deals</entity> with the latest <entity id="W04-0914.8">application</entity> of <entity id="W04-0914.9">natural language processing</entity> (NLP), specifically of ontological <entity id="W04-0914.10">semantics</entity> (ONSE) to <entity id="W04-0914.11">natural language</entity> <entity id="W04-0914.12">information</entity> assurance and security (NL IAS). It demonstrates how the existing ideas, <entity id="W04-0914.13">methods</entity> , and <entity id="W04-0914.14">resources</entity> of ontological <entity id="W04-0914.15">semantics</entity> can be <entity id="W04-0914.16">applied</entity> to detect deception in NL <entity id="W04-0914.17">text</entity> (and, eventually, in <entity id="W04-0914.18">data</entity> and other media as well). After stating the <entity id="W04-0914.19">problem</entity> , the <entity id="W04-0914.20">paper</entity> <entity id="W04-0914.21">proceeds</entity> to a brief <entity id="W04-0914.22">introduction</entity> to ONSE, followed by an equally brief <entity id="W04-0914.23">survey</entity> of our 5-year-old <entity id="W04-0914.24">effort</entity> in ""colonizing"" IAS. The <entity id="W04-0914.25">main</entity> <entity id="W04-0914.26">part</entity> of the <entity id="W04-0914.27">paper</entity> <entity id="W04-0914.28">deals</entity> with the <entity id="W04-0914.29">following</entity> <entity id="W04-0914.30">issues</entity> : 
 human deception <entity id="W04-0914.31">detection</entity> <entity id="W04-0914.32">abilities</entity> and NLP <entity id="W04-0914.33">modeling</entity> of it; 
 <entity id="W04-0914.34">manipulation</entity> of fact <entity id="W04-0914.35">repositories</entity> for this <entity id="W04-0914.36">purpose</entity> beyond the <entity id="W04-0914.37">current</entity> state of the art; 
 <entity id="W04-0914.38">acquisition</entity> of <entity id="W04-0914.39">scripts</entity> for <entity id="W04-0914.40">complex</entity> ontological <entity id="W04-0914.41">concepts</entity> ; 
 <entity id="W04-0914.42">degrees</entity> of lying <entity id="W04-0914.43">complexity</entity> and feasibility of their <entity id="W04-0914.44">automatic</entity> <entity id="W04-0914.45">detection</entity> . This is not a <entity id="W04-0914.46">report</entity> on a <entity id="W04-0914.47">system</entity> <entity id="W04-0914.48">implementation</entity> but rather an <entity id="W04-0914.49">application-establishing</entity> <entity id="W04-0914.50">proof-of-concept</entity> <entity id="W04-0914.51">effort</entity> <entity id="W04-0914.52">based</entity> on the algorithmic and <entity id="W04-0914.53">machine-tractable</entity> recombination and <entity id="W04-0914.54">extension</entity> of the previously <entity id="W04-0914.55">implemented</entity> ONSE <entity id="W04-0914.56">modules</entity> . The <entity id="W04-0914.57">strength</entity> of the <entity id="W04-0914.58">approach</entity> is that it emphasizes the use of the existing <entity id="W04-0914.59">NLP applications</entity> , with very few <entity id="W04-0914.60">domain-</entity> and <entity id="W04-0914.61">goal-specific</entity> adjustments, in a most promising and growing new <entity id="W04-0914.62">area</entity> of IAS. So, while clearly <entity id="W04-0914.63">dealing</entity> with a new <entity id="W04-0914.64">application</entity> , the <entity id="W04-0914.65">paper</entity> addresses theoretical and methodological <entity id="W04-0914.66">extensions</entity> of ONSE, as defined currently, that will be useful for other <entity id="W04-0914.67">applications</entity> as well. 1"
</abstract>


propose(W04-0914.6,W04-0914.10)
methodapplied(W04-0914.14,W04-0914.17)
propose(W04-0914.20,W04-0914.22)
propose(W04-0914.65,W04-0914.66)

</text>

<text id="W04-1217">
<title>
Exploiting <entity id="W04-1217.1">Context</entity> For Biomedical <entity id="W04-1217.2">Entity</entity> <entity id="W04-1217.3">Recognition</entity> : From <entity id="W04-1217.4">Syntax</entity> To The Web
</title>
<abstract>
We describe a <entity id="W04-1217.5">machine</entity> learning <entity id="W04-1217.6">system</entity> for the <entity id="W04-1217.7">recognition</entity> of <entity id="W04-1217.8">names</entity> in biomedical <entity id="W04-1217.9">texts</entity> . The <entity id="W04-1217.10">system</entity> makes extensive use of local and <entity id="W04-1217.11">syntactic <entity id="W04-1217.12">features</entity></entity> within the <entity id="W04-1217.13">text</entity> , as well as external <entity id="W04-1217.14">resources</entity> <entity id="W04-1217.15">including</entity> the web and <entity id="W04-1217.16">gazetteers</entity> . It achieves an F-score of 70% on the Coling 2004  NLPBA/BioNLP shared <entity id="W04-1217.17">task</entity> of identifying five biomedical <entity id="W04-1217.18">named</entity> <entity id="W04-1217.19">entities</entity> in the GENIA <entity id="W04-1217.20">corpus</entity> .
</abstract>


based_on(W04-1217.1,W04-1217.3,REVERSE)
usedfor(W04-1217.6,W04-1217.7)
phenomenon(W04-1217.8,W04-1217.9)
based_on(W04-1217.10,W04-1217.11)
phenomenon(W04-1217.19,W04-1217.20)

</text>

<text id="W04-1221">
<title>
Biomedical <entity id="W04-1221.1">Named</entity> <entity id="W04-1221.2">Entity</entity> <entity id="W04-1221.3">Recognition</entity> Using Conditional Random Fields And Rich <entity id="W04-1221.4">Feature</entity> Sets
</title>
<abstract>
As the wealth of biomedical <entity id="W04-1221.5">knowledge</entity> in the <entity id="W04-1221.6">form</entity> of <entity id="W04-1221.7">literature</entity> <entity id="W04-1221.8">increases</entity> , there is a rising need for effective <entity id="W04-1221.9">natural language processing</entity> <entity id="W04-1221.10">tools</entity> to assist in organizing, curating, and retrieving this <entity id="W04-1221.11">information</entity> . To that end, <entity id="W04-1221.12">named</entity> <entity id="W04-1221.13">entity</entity> <entity id="W04-1221.14">recognition</entity> (the <entity id="W04-1221.15">task</entity> of identifying <entity id="W04-1221.16">words</entity> and <entity id="W04-1221.17">phrases</entity> in free <entity id="W04-1221.18">text</entity> that belong to certain <entity id="W04-1221.19">classes</entity> of interest) is an important <entity id="W04-1221.20">first step</entity> for many of these larger <entity id="W04-1221.21">information</entity> <entity id="W04-1221.22">management</entity> <entity id="W04-1221.23">goals</entity> . In recent years, much attention has been <entity id="W04-1221.24">focused</entity> on the <entity id="W04-1221.25">problem</entity> of recognizing <entity id="W04-1221.26">gene</entity> and <entity id="W04-1221.27">protein</entity> <entity id="W04-1221.28">mentions</entity> in biomedical <entity id="W04-1221.29">abstracts</entity> . This <entity id="W04-1221.30">paper</entity> presents a <entity id="W04-1221.31">framework</entity> for simultaneously recognizing <entity id="W04-1221.32">occurrences</entity> of <entity id="W04-1221.33">PROTEIN</entity> , DNA, RNA, CELL-LINE, <entity id="W04-1221.34">CELL-TYPE</entity> F1
</abstract>


based_on(W04-1221.3,W04-1221.4)
propose(W04-1221.30,W04-1221.31)

</text>

<text id="W04-2303">
<title>
Conversational <entity id="W04-2303.1">Dialogue Management</entity> In The FASiL <entity id="W04-2303.2">Project</entity></title>



</text>

<abstract></abstract>

<text id="W04-2903">
<title>
Audio Hot Spotting And <entity id="W04-2903.1">Retrieval</entity> Using Multiple <entity id="W04-2903.2">Features</entity></title>
<abstract>
This <entity id="W04-2903.3">paper</entity> <entity id="W04-2903.4">reports</entity> our on-going <entity id="W04-2903.5">efforts</entity> to exploit multiple <entity id="W04-2903.6">features</entity> derived from an audio <entity id="W04-2903.7">stream</entity> using <entity id="W04-2903.8">source</entity> material such as <entity id="W04-2903.9">broadcast news</entity> , teleconferences, and <entity id="W04-2903.10">meetings</entity> . These <entity id="W04-2903.11">features</entity> are derived from <entity id="W04-2903.12">algorithms</entity> <entity id="W04-2903.13">including</entity> <entity id="W04-2903.14">automatic speech recognition</entity> , <entity id="W04-2903.15">automatic</entity> <entity id="W04-2903.16">speech</entity> <entity id="W04-2903.17">indexing</entity> , speaker <entity id="W04-2903.18">identification</entity> , prosodic and audio <entity id="W04-2903.19">feature</entity> <entity id="W04-2903.20">extraction</entity> . We describe our <entity id="W04-2903.21">research</entity> <entity id="W04-2903.22">prototype</entity> - the Audio Hot Spotting <entity id="W04-2903.23">System</entity> -that allows <entity id="W04-2903.24">users</entity> to <entity id="W04-2903.25">query</entity> and retrieve <entity id="W04-2903.26">data</entity> from multimedia <entity id="W04-2903.27">sources</entity> utilizing these multiple <entity id="W04-2903.28">features</entity> . The <entity id="W04-2903.29">system</entity> aims to accurately find <entity id="W04-2903.30">segments</entity> of <entity id="W04-2903.31">user</entity> interest, i.e., audio hot spots within seconds of the actual <entity id="W04-2903.32">event</entity> . In <entity id="W04-2903.33">addition</entity> to spoken <entity id="W04-2903.34">keywords</entity> , the <entity id="W04-2903.35">system</entity> also retrieves audio hot spots by speaker identity, <entity id="W04-2903.36">word</entity> spoken by a specific speaker, a change of <entity id="W04-2903.37">speech</entity> <entity id="W04-2903.38">rate</entity> , and other <entity id="W04-2903.39">non-lexical features</entity> , <entity id="W04-2903.40">including</entity> applause and laughter. Finally, we discuss our <entity id="W04-2903.41">approach</entity> to <entity id="W04-2903.42">semantic</entity> , morphological, phonetic <entity id="W04-2903.43">query <entity id="W04-2903.44">expansion</entity></entity> to <entity id="W04-2903.45">improve</entity> audio <entity id="W04-2903.46">retrieval</entity> <entity id="W04-2903.47">performance</entity> and to <entity id="W04-2903.48">access</entity> <entity id="W04-2903.49">cross-lingual</entity> <entity id="W04-2903.50">data</entity> .
</abstract>


propose(W04-2903.3,W04-2903.5)
char(W04-2903.6,W04-2903.7)
yields(W04-2903.11,W04-2903.12,REVERSE)
datasource(W04-2903.26,W04-2903.27)
affects(W04-2903.43,W04-2903.47)

</text>

<text id="W04-3006">
<title><entity id="W04-3006.1">Error</entity> <entity id="W04-3006.2">Detection</entity> And <entity id="W04-3006.3">Recovery</entity> In <entity id="W04-3006.4">Spoken Dialogue</entity> <entity id="W04-3006.5">Systems</entity></title>
<abstract>
"This <entity id="W04-3006.6">paper</entity> describes our <entity id="W04-3006.7">research</entity> on both the <entity id="W04-3006.8">detection</entity> and subsequent <entity id="W04-3006.9">resolution</entity> of <entity id="W04-3006.10">recognition</entity> <entity id="W04-3006.11">errors</entity> in spoken <entity id="W04-3006.12">dialogue systems</entity> . The <entity id="W04-3006.13">paper</entity> consists of two major <entity id="W04-3006.14">components</entity> . The first half <entity id="W04-3006.15">concerns</entity> the <entity id="W04-3006.16">design</entity> of the <entity id="W04-3006.17">error</entity> <entity id="W04-3006.18">detection</entity> <entity id="W04-3006.19">mechanism</entity> for resolving city <entity id="W04-3006.20">names</entity> in our mercury flight reservation <entity id="W04-3006.21">system</entity> , and an <entity id="W04-3006.22">investigation</entity> of the behavioral <entity id="W04-3006.23">patterns</entity> of <entity id="W04-3006.24">users</entity> in subsequent subdialogues involving keypad <entity id="W04-3006.25">entry</entity> for <entity id="W04-3006.26">disambiguation</entity> . An important <entity id="W04-3006.27">observation</entity> is that, upon a request for keypad <entity id="W04-3006.28">entry</entity> , <entity id="W04-3006.29">users</entity> are frequently unresponsive to the <entity id="W04-3006.30">extent</entity> of waiting for a <entity id="W04-3006.31">time-out</entity> or hanging up the <entity id="W04-3006.32">phone</entity> . The second half <entity id="W04-3006.33">concerns</entity> a <entity id="W04-3006.34">pilot</entity> <entity id="W04-3006.35">experiment</entity> investigating the feasibility of replacing the solicitation of a keypad <entity id="W04-3006.36">entry</entity> with that of a ""<entity id="W04-3006.37">speak-and-spell</entity> "" <entity id="W04-3006.38">entry</entity> . A <entity id="W04-3006.39">novelty</entity> of our work is the <entity id="W04-3006.40">introduction</entity> of a <entity id="W04-3006.41">speech</entity> synthesizer to simulate the <entity id="W04-3006.42">user</entity> , which facilitates <entity id="W04-3006.43">development</entity> and <entity id="W04-3006.44">evaluation</entity> of our <entity id="W04-3006.45">proposed</entity> <entity id="W04-3006.46">strategy</entity> . We have found that the <entity id="W04-3006.47">speak-and-spell</entity> <entity id="W04-3006.48">strategy</entity> is quite effective in <entity id="W04-3006.49">simulation</entity> <entity id="W04-3006.50">mode</entity> , but it remains to be <entity id="W04-3006.51">tested</entity> in real <entity id="W04-3006.52">user</entity> <entity id="W04-3006.53">dialogues</entity> . "
</abstract>


study(W04-3006.7,W04-3006.11)
propose(W04-3006.13,W04-3006.14)
study(W04-3006.22,W04-3006.23)
study(W04-3006.44,W04-3006.46)

</text>

<text id="W05-0707">
<title><entity id="W05-0707.1">Part Of Speech Tagging</entity> For Amharic Using Conditional Random Fields
</title>
<abstract>
We <entity id="W05-0707.2">applied</entity> Conditional Random Fields (CRFs) to the <entity id="W05-0707.3">tasks</entity> of Amharic <entity id="W05-0707.4">word segmentation</entity> and <entity id="W05-0707.5">POS tagging</entity> using a small annotated <entity id="W05-0707.6">corpus</entity> of 1000 <entity id="W05-0707.7">words</entity> . Given the <entity id="W05-0707.8">size</entity> of the <entity id="W05-0707.9">data</entity> and the large <entity id="W05-0707.10">number</entity> of <entity id="W05-0707.11">unknown <entity id="W05-0707.12">words</entity></entity> in the <entity id="W05-0707.13">test</entity> <entity id="W05-0707.14">corpus</entity> (80%), an <entity id="W05-0707.15">accuracy</entity> of 84% for Amharic <entity id="W05-0707.16">word segmentation</entity> and 74% for <entity id="W05-0707.17">POS tagging</entity> is encouraging, indicating the <entity id="W05-0707.18">applicability</entity> of CRFs for a morphologically <entity id="W05-0707.19">complex</entity> <entity id="W05-0707.20">language</entity> like Amharic.
</abstract>


composed_of(W05-0707.6,W05-0707.7)
char(W05-0707.8,W05-0707.9)
problem(W05-0707.11,W05-0707.14)
yields(W05-0707.15,W05-0707.16,REVERSE)

</text>

<text id="W05-0801">
<title><entity id="W05-0801.1">Association-</entity> <entity id="W05-0801.2">Based</entity> Bilingual <entity id="W05-0801.3">Word Alignment</entity></title>
<abstract>
Bilingual <entity id="W05-0801.4">word alignment</entity> <entity id="W05-0801.5">forms</entity> the foundation of <entity id="W05-0801.6">current</entity> work on <entity id="W05-0801.7">statistical machine translation</entity> . <entity id="W05-0801.8">Standard</entity> <entity id="W05-0801.9">word-alignment</entity> <entity id="W05-0801.10">methods</entity> involve the use of probabilistic <entity id="W05-0801.11">generative <entity id="W05-0801.12">models</entity></entity> that are <entity id="W05-0801.13">complex</entity> to <entity id="W05-0801.14">implement</entity> and slow to <entity id="W05-0801.15">train</entity> . In this <entity id="W05-0801.16">paper</entity> we show that it is possible to <entity id="W05-0801.17">approach</entity> the <entity id="W05-0801.18">alignment</entity> <entity id="W05-0801.19">accuracy</entity> of the <entity id="W05-0801.20">standard</entity> <entity id="W05-0801.21">models</entity> using <entity id="W05-0801.22">algorithms</entity> that are much faster, and in some ways simpler, <entity id="W05-0801.23">based</entity> on <entity id="W05-0801.24">basic</entity> <entity id="W05-0801.25">word-association</entity> <entity id="W05-0801.26">statistics</entity> .
</abstract>


based_on(W05-0801.10,W05-0801.11)
based_on(W05-0801.22,W05-0801.26)

</text>

<text id="W06-0103">
<title>
Mining Atomic <entity id="W06-0103.1">Chinese</entity> <entity id="W06-0103.2">Abbreviation</entity> Pairs: A <entity id="W06-0103.3">Probabilistic <entity id="W06-0103.4">Model</entity></entity> For Single Character <entity id="W06-0103.5">Word</entity> <entity id="W06-0103.6">Recovery</entity></title>
<abstract>
"An HMM-based Single Character <entity id="W06-0103.7">Recovery</entity> (SCR) <entity id="W06-0103.8">Model</entity> is <entity id="W06-0103.9">proposed</entity> in this <entity id="W06-0103.10">paper</entity> to <entity id="W06-0103.11">extract</entity> a large set of ""atomic <entity id="W06-0103.12">abbreviation</entity> <entity id="W06-0103.13">pairs</entity> "" from a large <entity id="W06-0103.14">text</entity> <entity id="W06-0103.15">corpus</entity> . By an ""atomic <entity id="W06-0103.16">abbreviation</entity> <entity id="W06-0103.17">pair</entity> ,"" it refers to an abbreviated <entity id="W06-0103.18">word</entity> and its root <entity id="W06-0103.19">word</entity> (i.e., unabbreviated <entity id="W06-0103.20">form</entity> ) in which the <entity id="W06-0103.21">abbreviation</entity> is a single <entity id="W06-0103.22">Chinese</entity> character. This <entity id="W06-0103.23">task</entity> is interesting since the <entity id="W06-0103.24">abbreviation</entity> <entity id="W06-0103.25">process</entity> for <entity id="W06-0103.26">Chinese</entity> compound <entity id="W06-0103.27">words</entity> seems to be ""compositional""; in other <entity id="W06-0103.28">words</entity> , one can often decode an abbreviated <entity id="W06-0103.29">word</entity> , such as ""nX"" (Taiwan <entity id="W06-0103.30">University</entity> ), character-by-character back to its root <entity id="W06-0103.31">form</entity> . With a large atomic <entity id="W06-0103.32">abbreviation</entity> <entity id="W06-0103.33">dictionary</entity> , one may be able to recover multiple-character <entity id="W06-0103.34">abbreviations</entity> more easily. With only a few <entity id="W06-0103.35">training</entity> <entity id="W06-0103.36">iterations</entity> , the <entity id="W06-0103.37">acquisition</entity> <entity id="W06-0103.38">accuracy</entity> of the <entity id="W06-0103.39">proposed</entity> SCR <entity id="W06-0103.40">model</entity> achieves 62% and 50 % <entity id="W06-0103.41">precision</entity> for <entity id="W06-0103.42">training set</entity> and <entity id="W06-0103.43">test set</entity> , respectively, from the ASWSC-2001 <entity id="W06-0103.44">corpus</entity> . "
</abstract>


usedfor(W06-0103.3,W06-0103.6)
propose(W06-0103.8,W06-0103.10,REVERSE)
datasource(W06-0103.13,W06-0103.15)
yields(W06-0103.40,W06-0103.41)

</text>

<text id="W06-0308">
<title>
Towards A Validated <entity id="W06-0308.1">Model</entity> For Affective <entity id="W06-0308.2">Classification</entity> Of <entity id="W06-0308.3">Texts</entity></title>
<abstract>
In this <entity id="W06-0308.4">paper</entity> , we present the <entity id="W06-0308.5">results</entity> of <entity id="W06-0308.6">experiments</entity> aiming to validate a two-dimensional <entity id="W06-0308.7">typology</entity> of affective states as a suitable <entity id="W06-0308.8">basis</entity> for affective <entity id="W06-0308.9">classification</entity> of <entity id="W06-0308.10">texts</entity> . Using a <entity id="W06-0308.11">corpus</entity> of <entity id="W06-0308.12">English</entity> weblog posts, annotated for <entity id="W06-0308.13">mood</entity> by their authors, we <entity id="W06-0308.14">trained</entity> <entity id="W06-0308.15">support <entity id="W06-0308.16">vector</entity> <entity id="W06-0308.17">machine</entity></entity> binary <entity id="W06-0308.18">classifiers</entity> to distinguish <entity id="W06-0308.19">texts</entity> on the <entity id="W06-0308.20">basis</entity> of their affiliation with one <entity id="W06-0308.21">region</entity> of the <entity id="W06-0308.22">space</entity> . We then <entity id="W06-0308.23">report</entity> on <entity id="W06-0308.24">experiments</entity> which go a <entity id="W06-0308.25">step</entity> further, using <entity id="W06-0308.26">four-class</entity> <entity id="W06-0308.27">classifiers</entity> <entity id="W06-0308.28">based</entity> on automated scoring of <entity id="W06-0308.29">texts</entity> for each <entity id="W06-0308.30">dimension</entity> of the <entity id="W06-0308.31">typology</entity> . Our <entity id="W06-0308.32">results</entity> indicate that it is possible to extend the <entity id="W06-0308.33">standard</entity> binary <entity id="W06-0308.34">sentiment analysis</entity> (positive/negative) <entity id="W06-0308.35">approach</entity> to a two dimensional <entity id="W06-0308.36">model</entity> (positive/negative; active/passive), and <entity id="W06-0308.37">provide</entity> some <entity id="W06-0308.38">evidence</entity> to <entity id="W06-0308.39">support</entity> a more fine-grained <entity id="W06-0308.40">classification</entity> along these two axes.
</abstract>


propose(W06-0308.4,W06-0308.5)
tag(W06-0308.11,W06-0308.13)
methodapplied(W06-0308.15,W06-0308.19)

</text>

<text id="W06-0903">
<title><entity id="W06-0903.1">Automatic</entity> Dating Of <entity id="W06-0903.2">Documents</entity> And Temporal <entity id="W06-0903.3">Text Classification</entity></title>
<abstract>
The <entity id="W06-0903.4">frequency</entity> of <entity id="W06-0903.5">occurrence</entity> of <entity id="W06-0903.6">words</entity> in <entity id="W06-0903.7">natural languages</entity> exhibits a periodic and a non-periodic <entity id="W06-0903.8">component</entity> when analysed as a <entity id="W06-0903.9">time</entity> <entity id="W06-0903.10">series</entity> . This work presents an unsupervised <entity id="W06-0903.11">method</entity> of <entity id="W06-0903.12">extracting</entity> periodicity <entity id="W06-0903.13">information</entity> from <entity id="W06-0903.14">text</entity> , enabling <entity id="W06-0903.15">time</entity> <entity id="W06-0903.16">series</entity> <entity id="W06-0903.17">creation</entity> and filtering to be used in the <entity id="W06-0903.18">creation</entity> of sophisticated <entity id="W06-0903.19">language models</entity> that can discern between repetitive <entity id="W06-0903.20">trends</entity> and non-repetitive writing <entity id="W06-0903.21">patterns</entity> . The <entity id="W06-0903.22">algorithm</entity> <entity id="W06-0903.23">performs</entity> in O(n
</abstract>


char(W06-0903.5,W06-0903.6)
usedfor(W06-0903.11,W06-0903.12)
datasource(W06-0903.13,W06-0903.14)

</text>

<text id="W06-1001">
<title><entity id="W06-1001.1">Lexical</entity> <entity id="W06-1001.2">Markup</entity> <entity id="W06-1001.3">Framework</entity> (LMF) For NLP Multilingual Resources
</title>
<abstract>
Optimizing the production, <entity id="W06-1001.4">maintenance</entity> and <entity id="W06-1001.5">extension</entity> of <entity id="W06-1001.6">lexical resources</entity> is one the crucial <entity id="W06-1001.7">aspects</entity> <entity id="W06-1001.8">impacting</entity> <entity id="W06-1001.9">Natural Language Processing</entity> (NLP). A second <entity id="W06-1001.10">aspect</entity> involves optimizing the <entity id="W06-1001.11">process</entity> leading to their <entity id="W06-1001.12">integration</entity> in <entity id="W06-1001.13">applications</entity> . With this <entity id="W06-1001.14">respect</entity> , we believe that the production of a consensual <entity id="W06-1001.15">specification</entity> on multilingual <entity id="W06-1001.16">lexicons</entity> can be a useful aid for the various NLP actors. Within ISO, one <entity id="W06-1001.17">purpose</entity> of LMF (ISO-24613) is to define a <entity id="W06-1001.18">standard</entity> for <entity id="W06-1001.19">lexicons</entity> that covers multilingual <entity id="W06-1001.20">data</entity> .
</abstract>



</text>

<text id="W06-1107">
<title><entity id="W06-1107.1">Evaluation</entity> Of Several Phonetic <entity id="W06-1107.2">Similarity</entity> <entity id="W06-1107.3">Algorithms</entity> On The <entity id="W06-1107.4">Task</entity> Of Cognate <entity id="W06-1107.5">Identification</entity></title>
<abstract>
We investigate the <entity id="W06-1107.6">problem</entity> of measuring phonetic <entity id="W06-1107.7">similarity</entity> , <entity id="W06-1107.8">focusing</entity> on the <entity id="W06-1107.9">identification</entity> of cognates, <entity id="W06-1107.10">words</entity> of the same origin in different <entity id="W06-1107.11">languages</entity> . We compare <entity id="W06-1107.12">representatives</entity> of two principal <entity id="W06-1107.13">approaches</entity> to <entity id="W06-1107.14">computing</entity> phonetic <entity id="W06-1107.15">similarity</entity> : manually-designed <entity id="W06-1107.16">metrics</entity> , and learning <entity id="W06-1107.17">algorithms</entity> . In particular, we consider a stochastic transducer, a <entity id="W06-1107.18">Pair</entity> HMM, several DBN <entity id="W06-1107.19">models</entity> , and two <entity id="W06-1107.20">constructed</entity> <entity id="W06-1107.21">schemes</entity> . We <entity id="W06-1107.22">test</entity> those <entity id="W06-1107.23">approaches</entity> on the <entity id="W06-1107.24">task</entity> of identifying cognates among Indoeuropean <entity id="W06-1107.25">languages</entity> , both in the supervised and unsupervised <entity id="W06-1107.26">context</entity> . Our <entity id="W06-1107.27">results</entity> suggest that the averaged <entity id="W06-1107.28">context</entity> DBN <entity id="W06-1107.29">model</entity> and the <entity id="W06-1107.30">Pair</entity> HMM achieve the highest <entity id="W06-1107.31">accuracy</entity> given a large <entity id="W06-1107.32">training set</entity> of positive <entity id="W06-1107.33">examples</entity> .
</abstract>


study(W06-1107.1,W06-1107.3)

</text>

<text id="W06-1620">
<title>
Multilingual Deep <entity id="W06-1620.1">Lexical</entity> <entity id="W06-1620.2">Acquisition</entity> For HPSGs Via Supertagging
</title>
<abstract>
We <entity id="W06-1620.3">propose</entity> a <entity id="W06-1620.4">conditional random <entity id="W06-1620.5">field-based</entity></entity> <entity id="W06-1620.6">method</entity> for supertagging, and <entity id="W06-1620.7">apply</entity> it to the <entity id="W06-1620.8">task</entity> of learning new <entity id="W06-1620.9">lexical <entity id="W06-1620.10">items</entity></entity> for HPSG-based <entity id="W06-1620.11">precision</entity> grammars of <entity id="W06-1620.12">English</entity> and <entity id="W06-1620.13">Japanese</entity> . Using a pseudo-likelihood <entity id="W06-1620.14">approximation</entity> we are able to <entity id="W06-1620.15">scale</entity> our <entity id="W06-1620.16">model</entity> to hundreds of supertags and tens-of-thousands of <entity id="W06-1620.17">training</entity> <entity id="W06-1620.18">sentences</entity> . We show that it is possible to achieve start-of-the-art <entity id="W06-1620.19">results</entity> for both <entity id="W06-1620.20">languages</entity> using maximally <entity id="W06-1620.21">language-independent</entity> <entity id="W06-1620.22">lexical features</entity> . Further, we explore the <entity id="W06-1620.23">performance</entity> of the <entity id="W06-1620.24">models</entity> at the <entity id="W06-1620.25">type-</entity> and <entity id="W06-1620.26">token-level</entity> , demonstrating their superior <entity id="W06-1620.27">performance</entity> when compared to a unigram-based baseline and a <entity id="W06-1620.28">transformation-based</entity> <entity id="W06-1620.29">learning approach</entity> .
</abstract>


methodapplied(W06-1620.4,W06-1620.9)

</text>

<text id="W04-0402">
<title>
Paraphrasing Of <entity id="W04-0402.1">Japanese</entity> Light- <entity id="W04-0402.2">Verb</entity> Constructions <entity id="W04-0402.3">Based</entity> On <entity id="W04-0402.4">Lexical</entity> <entity id="W04-0402.5">Conceptual Structure</entity></title>
<abstract>
Some particular <entity id="W04-0402.6">classes</entity> of <entity id="W04-0402.7">lexical</entity> paraphrases such as <entity id="W04-0402.8">verb</entity> alteration and compound <entity id="W04-0402.9">noun</entity> <entity id="W04-0402.10">decomposition</entity> can be handled by a <entity id="W04-0402.11">handful</entity> of general <entity id="W04-0402.12">rules</entity> and <entity id="W04-0402.13">lexical</entity> <entity id="W04-0402.14">semantic knowledge</entity> . In this <entity id="W04-0402.15">paper</entity> , we attempt to capture the <entity id="W04-0402.16">regularity</entity> underlying these <entity id="W04-0402.17">classes</entity> of paraphrases, <entity id="W04-0402.18">focusing</entity> on the paraphrasing of <entity id="W04-0402.19">Japanese</entity> <entity id="W04-0402.20">light-verb</entity> <entity id="W04-0402.21">constructions</entity> (LVCs). We <entity id="W04-0402.22">propose</entity> a paraphrasing <entity id="W04-0402.23">model</entity> for LVCs that is <entity id="W04-0402.24">based</entity> on transforming the <entity id="W04-0402.25">Lexical</entity> Conceptual <entity id="W04-0402.26">Structures</entity> (LCSs) of <entity id="W04-0402.27">verbal</entity> elements. We also <entity id="W04-0402.28">propose</entity> a <entity id="W04-0402.29">refinement</entity> of an existing LCS <entity id="W04-0402.30">dictionary</entity> . <entity id="W04-0402.31">Experimental</entity> <entity id="W04-0402.32">results</entity> show that our LCS-based paraphrasing <entity id="W04-0402.33">model</entity> characterizes some of the <entity id="W04-0402.34">semantic features</entity> of those <entity id="W04-0402.35">verbs</entity> <entity id="W04-0402.36">required</entity> for <entity id="W04-0402.37">generating</entity> paraphrases, such as the <entity id="W04-0402.38">direction</entity> of an <entity id="W04-0402.39">action</entity> and the <entity id="W04-0402.40">relationship</entity> between <entity id="W04-0402.41">arguments</entity> and <entity id="W04-0402.42">surface</entity> <entity id="W04-0402.43">cases</entity> .
</abstract>


propose(W04-0402.15,W04-0402.16)
based_on(W04-0402.23,W04-0402.26)

</text>

<text id="W06-2718">
<title>
A Standoff Annotation <entity id="W06-2718.1">Interface</entity> Between DELPH-In Components
</title>
<abstract>
We present a standoff annotation <entity id="W06-2718.2">framework</entity> for the <entity id="W06-2718.3">integration</entity> of NLP <entity id="W06-2718.4">components</entity> , currently <entity id="W06-2718.5">implemented</entity> in the <entity id="W06-2718.6">context</entity> of the DELPH-IN <entity id="W06-2718.7">tools</entity></abstract>


usedfor(W06-2718.2,W06-2718.3)

</text>

<text id="C00-2134">
<title>
Lexicalized <entity id="C00-2134.1">Tree</entity> <entity id="C00-2134.2">Automata-</entity> <entity id="C00-2134.3">Based</entity> Grammars For Translating Conversational <entity id="C00-2134.4">Texts</entity></title>
<abstract>
We <entity id="C00-2134.5">propose</entity> a new lexicalized grammar <entity id="C00-2134.6">formalism</entity> <entity id="C00-2134.7">called</entity> Lexicalized <entity id="C00-2134.8">Tree</entity> <entity id="C00-2134.9">Automata-based</entity> Grammar, which lexicalizes <entity id="C00-2134.10">tree</entity> acceptors instead of <entity id="C00-2134.11">trees</entity> themselves. We discuss the <entity id="C00-2134.12">properties</entity> of the grammar and present a chart <entity id="C00-2134.13">parsing</entity> <entity id="C00-2134.14">algorithm</entity> . We have <entity id="C00-2134.15">implemented</entity> a <entity id="C00-2134.16">translation</entity> <entity id="C00-2134.17">module</entity> for conversational <entity id="C00-2134.18">texts</entity> using this <entity id="C00-2134.19">formalism</entity> , and <entity id="C00-2134.20">applied</entity> it to an <entity id="C00-2134.21">experimental</entity> <entity id="C00-2134.22">automatic</entity> <entity id="C00-2134.23">interpretation</entity> <entity id="C00-2134.24">system</entity> (speech <entity id="C00-2134.25">translation system</entity> ).
</abstract>


methodapplied(C00-2134.17,C00-2134.18)

</text>

<text id="W04-3203">
<title><entity id="W04-3203.1">Induction</entity> Of Greedy Controllers For Deterministic Treebank Parsers
</title>
<abstract>
Most <entity id="W04-3203.2">statistical</entity> <entity id="W04-3203.3">parsers</entity> have used the <entity id="W04-3203.4">grammar induction</entity> <entity id="W04-3203.5">approach</entity> , in which a stochastic grammar is induced from a treebank. An <entity id="W04-3203.6">alternative</entity> <entity id="W04-3203.7">approach</entity> is to induce a controller for a given <entity id="W04-3203.8">parsing</entity> automaton. Such controllers may be stochastic; here, we <entity id="W04-3203.9">focus</entity> on greedy controllers, which <entity id="W04-3203.10">result</entity> in deterministic <entity id="W04-3203.11">parsers</entity> . We use <entity id="W04-3203.12">decision trees</entity> to learn the controllers. The <entity id="W04-3203.13">resulting</entity> <entity id="W04-3203.14">parsers</entity> are surprisingly accurate and <entity id="W04-3203.15">robust</entity> , considering their <entity id="W04-3203.16">speed</entity> and <entity id="W04-3203.17">simplicity</entity> . They are almost as fast as <entity id="W04-3203.18">current</entity> <entity id="W04-3203.19">part-of-speech</entity> taggers, and considerably more accurate than a <entity id="W04-3203.20">basic</entity> unlexicalized PCFG <entity id="W04-3203.21">parser</entity> . We also describe Markov <entity id="W04-3203.22">parsing</entity> <entity id="W04-3203.23">models</entity> , a general <entity id="W04-3203.24">framework</entity> for <entity id="W04-3203.25">parser</entity> <entity id="W04-3203.26">modeling</entity> and <entity id="W04-3203.27">control</entity> , of which the <entity id="W04-3203.28">parsers</entity> <entity id="W04-3203.29">reported</entity> here are a <entity id="W04-3203.30">special case</entity> .
</abstract>


usedfor(W04-3203.3,W04-3203.5,REVERSE)
char(W04-3203.14,W04-3203.15,REVERSE)
usedfor(W04-3203.24,W04-3203.26)

</text>

<text id="W01-0511">
<title>
Classifying The <entity id="W01-0511.1">Semantic</entity> <entity id="W01-0511.2">Relations</entity> In <entity id="W01-0511.3">Noun</entity> Compounds Via A <entity id="W01-0511.4">Domain-</entity> Specific <entity id="W01-0511.5">Lexical</entity> Hierarchy
</title>
<abstract>
We are <entity id="W01-0511.6">developing</entity> <entity id="W01-0511.7">corpus-based</entity> <entity id="W01-0511.8">techniques</entity> for identifying <entity id="W01-0511.9">semantic <entity id="W01-0511.10">relations</entity></entity> at an intermediate <entity id="W01-0511.11">level</entity> of <entity id="W01-0511.12">description</entity> (more specific than those used in <entity id="W01-0511.13">case</entity> <entity id="W01-0511.14">frames</entity> , but more general than those used in traditional <entity id="W01-0511.15">knowledge representation</entity> <entity id="W01-0511.16">systems</entity> ). In this <entity id="W01-0511.17">paper</entity> we describe a <entity id="W01-0511.18">classification</entity> <entity id="W01-0511.19">algorithm</entity> for identifying <entity id="W01-0511.20">relationships</entity> between <entity id="W01-0511.21">two-word</entity> <entity id="W01-0511.22">noun</entity> compounds. We find that a very <entity id="W01-0511.23">simple</entity> <entity id="W01-0511.24">approach</entity> using a <entity id="W01-0511.25">machine</entity> learning <entity id="W01-0511.26">algorithm</entity> and a <entity id="W01-0511.27">domain-specific</entity> <entity id="W01-0511.28">lexical</entity> hierarchy successfully generalizes from <entity id="W01-0511.29">training</entity> <entity id="W01-0511.30">instances</entity> , <entity id="W01-0511.31">performing</entity> better on previously unseen <entity id="W01-0511.32">words</entity> than a baseline consisting of <entity id="W01-0511.33">training</entity> on the <entity id="W01-0511.34">words</entity> themselves.
</abstract>


usedfor(W01-0511.8,W01-0511.9)
propose(W01-0511.17,W01-0511.19)
based_on(W01-0511.24,W01-0511.26)

</text>

<text id="W07-0401">
<title><entity id="W07-0401.1">Chunk-</entity> <entity id="W07-0401.2">Level</entity> Reordering of <entity id="W07-0401.3">Source Language</entity> <entity id="W07-0401.4">Sentences</entity> with Automatically Learned Rules for <entity id="W07-0401.5">Statistical Machine Translation</entity></title>
<abstract>
In this <entity id="W07-0401.6">paper</entity> , we describe a <entity id="W07-0401.7">source-side</entity> reordering <entity id="W07-0401.8">method</entity> <entity id="W07-0401.9">based</entity> on <entity id="W07-0401.10">syntactic</entity> <entity id="W07-0401.11">chunks</entity> for <entity id="W07-0401.12">phrase-based</entity> <entity id="W07-0401.13">statistical machine translation</entity> . First, we shallow <entity id="W07-0401.14">parse</entity> the <entity id="W07-0401.15">source language</entity> <entity id="W07-0401.16">sentences</entity> . Then, reordering <entity id="W07-0401.17">rules</entity> are automatically learned from <entity id="W07-0401.18">source-side</entity> <entity id="W07-0401.19">chunks</entity> and <entity id="W07-0401.20">word alignments</entity> . During <entity id="W07-0401.21">translation</entity> , the <entity id="W07-0401.22">rules</entity> are used to <entity id="W07-0401.23">generate</entity> a reordering <entity id="W07-0401.24">lattice</entity> for each <entity id="W07-0401.25">sentence</entity> . <entity id="W07-0401.26">Experimental</entity> <entity id="W07-0401.27">results</entity> are <entity id="W07-0401.28">reported</entity> for a <entity id="W07-0401.29">Chinese-to-</entity> <entity id="W07-0401.30">English</entity> <entity id="W07-0401.31">task</entity> , showing an <entity id="W07-0401.32">improvement</entity> of 0.5%-1.8% BLEU score absolute on various <entity id="W07-0401.33">test sets</entity> and better <entity id="W07-0401.34">computational</entity> <entity id="W07-0401.35">efficiency</entity> than reordering during decoding. The <entity id="W07-0401.36">experiments</entity> also show that the reordering at the <entity id="W07-0401.37">chunk-level</entity> <entity id="W07-0401.38">performs</entity> better than at the <entity id="W07-0401.39">POS-level</entity> .
</abstract>


based_on(W07-0401.8,W07-0401.11)
datasource(W07-0401.17,W07-0401.19)
model(W07-0401.24,W07-0401.25)

</text>

<text id="D07-1059">
<title><entity id="D07-1059.1">Generating</entity> <entity id="D07-1059.2">Lexical</entity> Analogies Using <entity id="D07-1059.3">Dependency</entity> <entity id="D07-1059.4">Relations</entity></title>
<abstract>
A <entity id="D07-1059.5">lexical</entity> <entity id="D07-1059.6">analogy</entity> is a <entity id="D07-1059.7">pair</entity> of <entity id="D07-1059.8">word-pairs</entity> that share a similar <entity id="D07-1059.9">semantic relation</entity> . <entity id="D07-1059.10">Lexical</entity> <entity id="D07-1059.11">analogies</entity> occur frequently in <entity id="D07-1059.12">text</entity> and are useful in various <entity id="D07-1059.13">natural language processing tasks</entity> . In this <entity id="D07-1059.14">study</entity> , we present a <entity id="D07-1059.15">system</entity> that <entity id="D07-1059.16">generates</entity> <entity id="D07-1059.17">lexical</entity> <entity id="D07-1059.18">analogies</entity> automatically from <entity id="D07-1059.19">text</entity> <entity id="D07-1059.20">data</entity> . Our <entity id="D07-1059.21">system</entity> discovers semantically related <entity id="D07-1059.22">pairs</entity> of <entity id="D07-1059.23">words</entity> by using <entity id="D07-1059.24">dependency <entity id="D07-1059.25">relations</entity></entity> , and <entity id="D07-1059.26">applies</entity> novel <entity id="D07-1059.27">machine</entity> learning <entity id="D07-1059.28">algorithms</entity> to <entity id="D07-1059.29">match</entity> these <entity id="D07-1059.30">word-pairs</entity> to <entity id="D07-1059.31">form</entity> <entity id="D07-1059.32">lexical</entity> <entity id="D07-1059.33">analogies</entity> . Empirical <entity id="D07-1059.34">evaluation</entity> shows that our <entity id="D07-1059.35">system</entity> <entity id="D07-1059.36">generates</entity> valid <entity id="D07-1059.37">lexical</entity> <entity id="D07-1059.38">analogies</entity> with a <entity id="D07-1059.39">precision</entity> of 70% , and produces <entity id="D07-1059.40">quality</entity> <entity id="D07-1059.41">output</entity> although not at the <entity id="D07-1059.42">level</entity> of the best human-generated <entity id="D07-1059.43">lexical</entity> <entity id="D07-1059.44">analogies</entity> .
</abstract>


isa(D07-1059.6,D07-1059.7)
phenomenon(D07-1059.11,D07-1059.12)
propose(D07-1059.14,D07-1059.15)
datasource(D07-1059.18,D07-1059.20)
based_on(D07-1059.21,D07-1059.24)
yields(D07-1059.35,D07-1059.39)

</text>

<text id="I08-3014">
<title>
An <entity id="I08-3014.1">Optimal</entity> <entity id="I08-3014.2">Order</entity> of Factors for the <entity id="I08-3014.3">Computational</entity> <entity id="I08-3014.4">Treatment</entity> of Personal Anaphoric Devices in Urdu <entity id="I08-3014.5">Discourse</entity></title>
<abstract>
Handling of <entity id="I08-3014.6">human language</entity> by <entity id="I08-3014.7">computer</entity> is a very intricate and <entity id="I08-3014.8">complex</entity> <entity id="I08-3014.9">task</entity> . In <entity id="I08-3014.10">natural languages</entity> , <entity id="I08-3014.11">sentences</entity> are usually <entity id="I08-3014.12">part</entity> of <entity id="I08-3014.13">discourse</entity> <entity id="I08-3014.14">units</entity> just as <entity id="I08-3014.15">words</entity> are <entity id="I08-3014.16">part</entity> of <entity id="I08-3014.17">sentences</entity> . <entity id="I08-3014.18">Anaphora <entity id="I08-3014.19">resolution</entity></entity> plays a significant <entity id="I08-3014.20">role</entity> in <entity id="I08-3014.21">discourse <entity id="I08-3014.22">analysis</entity></entity> for chopping larger <entity id="I08-3014.23">discourse</entity> <entity id="I08-3014.24">units</entity> into smaller ones. This <entity id="I08-3014.25">process</entity> is done for the <entity id="I08-3014.26">purpose</entity> of better <entity id="I08-3014.27">understanding</entity> and making easier the further <entity id="I08-3014.28">processing</entity> of <entity id="I08-3014.29">text</entity> by <entity id="I08-3014.30">computer</entity> . This <entity id="I08-3014.31">paper</entity> is <entity id="I08-3014.32">focused</entity> on the <entity id="I08-3014.33">discussion</entity> of various <entity id="I08-3014.34">factors</entity> and their <entity id="I08-3014.35">optimal</entity> <entity id="I08-3014.36">order</entity> that play an important <entity id="I08-3014.37">role</entity> in personal <entity id="I08-3014.38">anaphora <entity id="I08-3014.39">resolution</entity></entity> in Urdu. <entity id="I08-3014.40">Algorithms</entity> are <entity id="I08-3014.41">developed</entity> that resolves pronominal anaphoric <entity id="I08-3014.42">devices</entity> with 77-80% <entity id="I08-3014.43">success</entity> <entity id="I08-3014.44">rate</entity> .
</abstract>


part_of(I08-3014.11,I08-3014.13)
part_of(I08-3014.15,I08-3014.17)
problem(I08-3014.18,I08-3014.21)
propose(I08-3014.31,I08-3014.34)
affects(I08-3014.36,I08-3014.38)
yields(I08-3014.40,I08-3014.44)

</text>

<text id="I08-4004">
<title>
An Effective Hybrid <entity id="I08-4004.1">Machine <entity id="I08-4004.2">Learning Approach</entity></entity> for <entity id="I08-4004.3">Coreference <entity id="I08-4004.4">Resolution</entity></entity></title>
<abstract>
We present a hybrid <entity id="I08-4004.5">machine</entity> learning <entity id="I08-4004.6">approach</entity> for <entity id="I08-4004.7">coreference <entity id="I08-4004.8">resolution</entity></entity> . In our <entity id="I08-4004.9">method</entity> , we use CRFs as <entity id="I08-4004.10">basic</entity> <entity id="I08-4004.11">training</entity> <entity id="I08-4004.12">model</entity> , use active <entity id="I08-4004.13">learning <entity id="I08-4004.14">method</entity></entity> to <entity id="I08-4004.15">generate</entity> combined <entity id="I08-4004.16">features</entity> so as to make existed <entity id="I08-4004.17">features</entity> used more effectively; at last, we <entity id="I08-4004.18">proposed</entity> a novel <entity id="I08-4004.19">clustering</entity> <entity id="I08-4004.20">algorithm</entity> which used both the <entity id="I08-4004.21">linguistics</entity> <entity id="I08-4004.22">knowledge</entity> and the <entity id="I08-4004.23">statistical</entity> <entity id="I08-4004.24">knowledge</entity> . We built a <entity id="I08-4004.25">coreference <entity id="I08-4004.26">resolution</entity> <entity id="I08-4004.27">system</entity></entity> <entity id="I08-4004.28">based</entity> on the <entity id="I08-4004.29">proposed</entity> <entity id="I08-4004.30">method</entity> and <entity id="I08-4004.31">evaluate</entity> its <entity id="I08-4004.32">performance</entity> from three <entity id="I08-4004.33">aspects</entity> : the <entity id="I08-4004.34">contributions</entity> of <entity id="I08-4004.35">active learning</entity> ; the <entity id="I08-4004.36">effects</entity> of different <entity id="I08-4004.37">clustering</entity> <entity id="I08-4004.38">algorithms</entity> ; and the <entity id="I08-4004.39">resolution</entity> <entity id="I08-4004.40">performance</entity> of different <entity id="I08-4004.41">kinds</entity> of NPs. <entity id="I08-4004.42">Experimental</entity> <entity id="I08-4004.43">results</entity> show that additional <entity id="I08-4004.44">performance</entity> <entity id="I08-4004.45">gain</entity> can be obtained by using <entity id="I08-4004.46">active learning</entity> <entity id="I08-4004.47">method</entity> ; <entity id="I08-4004.48">clustering</entity> <entity id="I08-4004.49">algorithm</entity> has a great <entity id="I08-4004.50">effect</entity> on <entity id="I08-4004.51">coreference resolution</entity> 's <entity id="I08-4004.52">performance</entity> and our <entity id="I08-4004.53">clustering</entity> <entity id="I08-4004.54">algorithm</entity> is very effective; and the key of <entity id="I08-4004.55">coreference resolution</entity> is to <entity id="I08-4004.56">improve</entity> the <entity id="I08-4004.57">performance</entity> of the normal <entity id="I08-4004.58">noun</entity> 's <entity id="I08-4004.59">resolution</entity> , especially the pronoun's <entity id="I08-4004.60">resolution</entity> .
</abstract>


usedfor(I08-4004.1,I08-4004.3)
usedfor(I08-4004.6,I08-4004.7)
yields(I08-4004.13,I08-4004.16)
based_on(I08-4004.20,I08-4004.22)
based_on(I08-4004.25,I08-4004.30)
yields(I08-4004.45,I08-4004.47,REVERSE)
yields(I08-4004.49,I08-4004.52)

</text>

<text id="P07-1122">
<title>
Generalizing <entity id="P07-1122.1">Tree</entity> Transformations for Inductive <entity id="P07-1122.2">Dependency</entity> <entity id="P07-1122.3">Parsing</entity></title>
<abstract>
Previous <entity id="P07-1122.4">studies</entity> in <entity id="P07-1122.5">data-driven</entity> <entity id="P07-1122.6">dependency</entity> <entity id="P07-1122.7">parsing</entity> have shown that <entity id="P07-1122.8">tree</entity> <entity id="P07-1122.9">transformations</entity> can <entity id="P07-1122.10">improve</entity> <entity id="P07-1122.11">parsing</entity> <entity id="P07-1122.12">accuracy</entity> for specific <entity id="P07-1122.13">parsers</entity> and <entity id="P07-1122.14">data</entity> sets. We investigate to what <entity id="P07-1122.15">extent</entity> this can be <entity id="P07-1122.16">generalized</entity> across <entity id="P07-1122.17">languages</entity> /treebanks and <entity id="P07-1122.18">parsers</entity> , <entity id="P07-1122.19">focusing</entity> on pseudo-projective <entity id="P07-1122.20">parsing</entity> , as a way of capturing non-projective <entity id="P07-1122.21">dependencies</entity> , and <entity id="P07-1122.22">transformations</entity> used to facilitate <entity id="P07-1122.23">parsing</entity> of coordinate <entity id="P07-1122.24">structures</entity> and <entity id="P07-1122.25">verb</entity> groups. The <entity id="P07-1122.26">results</entity> indicate that the beneficial <entity id="P07-1122.27">effect</entity> of pseudo-projective <entity id="P07-1122.28">parsing</entity> is independent of <entity id="P07-1122.29">parsing</entity> <entity id="P07-1122.30">strategy</entity> but sensitive to <entity id="P07-1122.31">language</entity> or treebank specific <entity id="P07-1122.32">properties</entity> . By <entity id="P07-1122.33">contrast</entity> , the <entity id="P07-1122.34">construction</entity> specific <entity id="P07-1122.35">transformations</entity> appear to be more sensitive to <entity id="P07-1122.36">parsing</entity> <entity id="P07-1122.37">strategy</entity> but have a constant positive <entity id="P07-1122.38">effect</entity> over several <entity id="P07-1122.39">languages</entity> .
</abstract>


study(P07-1122.4,P07-1122.7)
affects(P07-1122.9,P07-1122.12)
affects(P07-1122.28,P07-1122.31,REVERSE)
affects(P07-1122.35,P07-1122.37,REVERSE)

</text>

<text id="P07-2035">
<title><entity id="P07-2035.1">Construction</entity> of <entity id="P07-2035.2">Domain</entity> <entity id="P07-2035.3">Dictionary</entity> for Fundamental <entity id="P07-2035.4">Vocabulary</entity></title> 
<abstract>Guthrie , Joe A. ; Guthrie , Louise ; Aidinejad, Homa; Wilks , Yorick,Subject-Dependent Co- <entity id="P07-2035.5">Occurrence</entity> And <entity id="P07-2035.6">Word Sense Disambiguation</entity> ,Annual Meeting Of The <entity id="P07-2035.7">Association</entity> For <entity id="P07-2035.8">Computation</entity> al <entity id="P07-2035.9">Linguistics</entity> ,1991</abstract>


datasource(P07-2035.3,P07-2035.4,REVERSE)

</text>

<text id="P08-1118">
<title>
Finding Contradictions in <entity id="P08-1118.1">Text</entity></title>
<abstract>
Detecting conflicting statements is a foundational <entity id="P08-1118.2">text</entity> <entity id="P08-1118.3">understanding</entity> <entity id="P08-1118.4">task</entity> with <entity id="P08-1118.5">applications</entity> in <entity id="P08-1118.6">information</entity> <entity id="P08-1118.7">analysis</entity> . We <entity id="P08-1118.8">propose</entity> an appropriate <entity id="P08-1118.9">definition</entity> of contradiction for <entity id="P08-1118.10">NLP tasks</entity> and <entity id="P08-1118.11">develop</entity> available <entity id="P08-1118.12">corpora</entity> , from which we <entity id="P08-1118.13">construct</entity> a <entity id="P08-1118.14">typology</entity> of contradictions. We demonstrate that a <entity id="P08-1118.15">system</entity> for contradiction needs to make more fine-grained <entity id="P08-1118.16">distinctions</entity> than the <entity id="P08-1118.17">common</entity> <entity id="P08-1118.18">systems</entity> for en-tailment. In particular, we argue for the cen-trality of <entity id="P08-1118.19">event</entity> coreference and therefore incorporate such a <entity id="P08-1118.20">component</entity> <entity id="P08-1118.21">based</entity> on topicality. We present the first detailed breakdown of <entity id="P08-1118.22">performance</entity> on this <entity id="P08-1118.23">task</entity> . Detecting some <entity id="P08-1118.24">types</entity> of contradiction <entity id="P08-1118.25">requires</entity> deeper inferential <entity id="P08-1118.26">paths</entity> than our <entity id="P08-1118.27">system</entity> is capable of, but we achieve good <entity id="P08-1118.28">performance</entity> on <entity id="P08-1118.29">types</entity> arising from <entity id="P08-1118.30">negation</entity> and antonymy.
</abstract>



</text>

<text id="P08-2061">
<title><entity id="P08-2061.1">Extracting</entity> a <entity id="P08-2061.2">Representation</entity> from <entity id="P08-2061.3">Text</entity> for <entity id="P08-2061.4">Semantic Analysis</entity></title>
<abstract>
We present a novel fine-grained <entity id="P08-2061.5">semantic <entity id="P08-2061.6">representation</entity></entity> of <entity id="P08-2061.7">text</entity> and an <entity id="P08-2061.8">approach</entity> to <entity id="P08-2061.9">constructing</entity> it. This <entity id="P08-2061.10">representation</entity> is largely extractable by today's <entity id="P08-2061.11">technologies</entity> and facilitates more detailed <entity id="P08-2061.12">semantic analysis</entity> . We discuss the <entity id="P08-2061.13">requirements</entity> driving the <entity id="P08-2061.14">representation</entity> , suggest how it might be of value in the automated tutoring <entity id="P08-2061.15">domain</entity> , and <entity id="P08-2061.16">provide</entity> <entity id="P08-2061.17">evidence</entity> of its <entity id="P08-2061.18">validity</entity> .
</abstract>


model(P08-2061.2,P08-2061.3)
model(P08-2061.5,P08-2061.7)
yields(P08-2061.10,P08-2061.11)

</text>

<text id="C08-1021">
<title>
KnowNet: Building a Large Net of <entity id="C08-1021.1">Knowledge</entity> from the Web
</title>
<abstract>
This <entity id="C08-1021.2">paper</entity> presents a new fully <entity id="C08-1021.3">automatic</entity> <entity id="C08-1021.4">method</entity> for <entity id="C08-1021.5">building</entity> highly dense and accurate <entity id="C08-1021.6">knowledge <entity id="C08-1021.7">bases</entity></entity> from existing <entity id="C08-1021.8">semantic</entity> <entity id="C08-1021.9">resources</entity> . Basically, the <entity id="C08-1021.10">method</entity> uses a <entity id="C08-1021.11">wide-coverage</entity> and accurate <entity id="C08-1021.12">knowledge-based</entity> <entity id="C08-1021.13">Word Sense Disambiguation</entity> <entity id="C08-1021.14">algorithm</entity> to assign the most appropriate senses to large sets of topically related <entity id="C08-1021.15">words</entity> acquired from the web. KnowNet, the <entity id="C08-1021.16">resulting</entity> <entity id="C08-1021.17">knowledge-base</entity> which connects large sets of <entity id="C08-1021.18">semantically-related</entity> <entity id="C08-1021.19">concepts</entity> is a major <entity id="C08-1021.20">step</entity> towards the autonomous <entity id="C08-1021.21">acquisition</entity> of <entity id="C08-1021.22">knowledge</entity> from raw <entity id="C08-1021.23">corpora</entity> . In fact, KnowNet is several <entity id="C08-1021.24">times</entity> larger than any available <entity id="C08-1021.25">knowledge</entity> <entity id="C08-1021.26">resource</entity> encoding <entity id="C08-1021.27">relations</entity> between synsets, and the <entity id="C08-1021.28">knowledge</entity> KnowNet contains outperform any other <entity id="C08-1021.29">resource</entity> when is empirically <entity id="C08-1021.30">evaluated</entity> in a <entity id="C08-1021.31">common</entity> <entity id="C08-1021.32">framework</entity> .
</abstract>


propose(C08-1021.2,C08-1021.4)
datasource(C08-1021.6,C08-1021.9)
based_on(C08-1021.10,C08-1021.14)
composed_of(C08-1021.17,C08-1021.19)
datasource(C08-1021.22,C08-1021.23)
compare(C08-1021.28,C08-1021.29)

</text>

<text id="D07-1122">
<title>
A Two-Stage <entity id="D07-1122.1">Parser</entity> for Multilingual <entity id="D07-1122.2">Dependency</entity> <entity id="D07-1122.3">Parsing</entity></title>
<abstract>
We present a two-stage multilingual <entity id="D07-1122.4">dependency</entity> <entity id="D07-1122.5">parsing</entity> <entity id="D07-1122.6">system</entity> submitted to the Multilingual Track of CoNLL-2007. The <entity id="D07-1122.7">parser</entity> first identifies <entity id="D07-1122.8">dependencies</entity> using a deterministic <entity id="D07-1122.9">parsing</entity> <entity id="D07-1122.10">method</entity> and then labels those <entity id="D07-1122.11">dependencies</entity> as a <entity id="D07-1122.12">sequence</entity> labeling <entity id="D07-1122.13">problem</entity> . We describe the <entity id="D07-1122.14">features</entity> used in each stage. For four <entity id="D07-1122.15">languages</entity> with different values of ROOT, we <entity id="D07-1122.16">design</entity> some special <entity id="D07-1122.17">features</entity> for the ROOT labeler. Then we present <entity id="D07-1122.18">evaluation results</entity> and <entity id="D07-1122.19">error analyses</entity> <entity id="D07-1122.20">focusing</entity> on <entity id="D07-1122.21">Chinese</entity> .
</abstract>


usedfor(D07-1122.7,D07-1122.10,REVERSE)

</text>

<text id="P02-1035">
<title><entity id="P02-1035.1">Parsing</entity> The <entity id="P02-1035.2">Wall Street <entity id="P02-1035.3">Journal</entity></entity> Using A <entity id="P02-1035.4">Lexical-</entity> Functional Grammar And Discriminative <entity id="P02-1035.5">Estimation</entity> <entity id="P02-1035.6">Techniques</entity></title>
<abstract>
We present a stochastic <entity id="P02-1035.7">parsing</entity> <entity id="P02-1035.8">system</entity> consisting of a <entity id="P02-1035.9">Lexical-</entity> Functional Grammar (LFG), a <entity id="P02-1035.10">constraint-based</entity> <entity id="P02-1035.11">parser</entity> and a stochastic <entity id="P02-1035.12">disambiguation</entity> <entity id="P02-1035.13">model</entity> . We <entity id="P02-1035.14">report</entity> on the <entity id="P02-1035.15">results</entity> of <entity id="P02-1035.16">applying</entity> this <entity id="P02-1035.17">system</entity> to <entity id="P02-1035.18">parsing</entity> the UPenn <entity id="P02-1035.19">Wall Street <entity id="P02-1035.20">Journal</entity></entity> (WSJ) treebank. The <entity id="P02-1035.21">model</entity> combines full and <entity id="P02-1035.22">partial</entity> <entity id="P02-1035.23">parsing</entity> <entity id="P02-1035.24">techniques</entity> to <entity id="P02-1035.25">reach</entity> full grammar <entity id="P02-1035.26">coverage</entity> on unseen <entity id="P02-1035.27">data</entity> . The treebank annotations are used to <entity id="P02-1035.28">provide</entity> partially labeled <entity id="P02-1035.29">data</entity> for discriminative <entity id="P02-1035.30">statistical</entity> <entity id="P02-1035.31">estimation</entity> using exponential <entity id="P02-1035.32">models</entity> . <entity id="P02-1035.33">Disambiguation</entity> <entity id="P02-1035.34">performance</entity> is <entity id="P02-1035.35">evaluated</entity> by measuring <entity id="P02-1035.36">matches</entity> of <entity id="P02-1035.37">predicate-argument</entity> <entity id="P02-1035.38">relations</entity> on two distinct <entity id="P02-1035.39">test sets</entity> . On a <entity id="P02-1035.40">gold standard</entity> of manually annotated <entity id="P02-1035.41">f-structures</entity> for a subset of the WSJ treebank, this <entity id="P02-1035.42">evaluation</entity> <entity id="P02-1035.43">reaches</entity> 79% F-score. An <entity id="P02-1035.44">evaluation</entity> on a <entity id="P02-1035.45">gold <entity id="P02-1035.46">standard</entity></entity> of <entity id="P02-1035.47">dependency relations</entity> for <entity id="P02-1035.48">Brown corpus</entity> <entity id="P02-1035.49">data</entity> achieves 76% F-score.
</abstract>


taskapplied(P02-1035.1,P02-1035.2)
part_of(P02-1035.8,P02-1035.11,REVERSE)
taskapplied(P02-1035.18,P02-1035.19)
part_of(P02-1035.21,P02-1035.24,REVERSE)
usedfor(P02-1035.31,P02-1035.32,REVERSE)
methodapplied(P02-1035.44,P02-1035.45)

</text>

<text id="P02-1053">
<title>
Thumbs Up Or Thumbs Down? <entity id="P02-1053.1">Semantic</entity> <entity id="P02-1053.2">Orientation</entity> <entity id="P02-1053.3">Applied</entity> To Unsupervised <entity id="P02-1053.4">Classification</entity> Of Reviews
</title>
<abstract>
This <entity id="P02-1053.5">paper</entity> presents a <entity id="P02-1053.6">simple</entity> unsupervised <entity id="P02-1053.7">learning <entity id="P02-1053.8">algorithm</entity></entity> for classifying <entity id="P02-1053.9">reviews</entity> as recommended not recommended <entity id="P02-1053.10">semantic</entity> <entity id="P02-1053.11">orientation</entity></abstract>


methodapplied(P02-1053.2,P02-1053.4)
propose(P02-1053.5,P02-1053.7)

</text>

<text id="P03-1038">
<title>
Self-Organizing Markov <entity id="P03-1038.1">Models</entity> And Their <entity id="P03-1038.2">Application</entity> To <entity id="P03-1038.3">Part-</entity> Of- <entity id="P03-1038.4">Speech</entity> <entity id="P03-1038.5">Tagging</entity></title>
<abstract>
This <entity id="P03-1038.6">paper</entity> presents a <entity id="P03-1038.7">method</entity> to <entity id="P03-1038.8">develop</entity> a <entity id="P03-1038.9">class</entity> of <entity id="P03-1038.10">variable</entity> <entity id="P03-1038.11">memory</entity> <entity id="P03-1038.12">Markov <entity id="P03-1038.13">models</entity></entity> that have higher <entity id="P03-1038.14">memory</entity> <entity id="P03-1038.15">capacity</entity> than traditional (uniform <entity id="P03-1038.16">memory</entity> ) <entity id="P03-1038.17">Markov <entity id="P03-1038.18">models</entity></entity> . The <entity id="P03-1038.19">structure</entity> of the <entity id="P03-1038.20">variable</entity> <entity id="P03-1038.21">memory</entity> <entity id="P03-1038.22">models</entity> is induced from a manually annotated <entity id="P03-1038.23">corpus</entity> through a <entity id="P03-1038.24">decision tree</entity> learning <entity id="P03-1038.25">algorithm</entity> . A <entity id="P03-1038.26">series</entity> of comparative <entity id="P03-1038.27">experiments</entity> show the <entity id="P03-1038.28">resulting</entity> <entity id="P03-1038.29">models</entity> outperform uniform <entity id="P03-1038.30">memory</entity> <entity id="P03-1038.31">Markov <entity id="P03-1038.32">models</entity></entity> in a <entity id="P03-1038.33">part-of-speech</entity> <entity id="P03-1038.34">tagging</entity> <entity id="P03-1038.35">task</entity> .
</abstract>


methodapplied(P03-1038.1,P03-1038.5)
propose(P03-1038.6,P03-1038.7)
compare(P03-1038.12,P03-1038.17)
datasource(P03-1038.19,P03-1038.23)
compare(P03-1038.29,P03-1038.31)

</text>

<text id="P04-1037">
<title>
Unsupervised <entity id="P04-1037.1">Sense <entity id="P04-1037.2">Disambiguation</entity></entity> Using Bilingual Probabilistic <entity id="P04-1037.3">Models</entity></title>
<abstract>
We describe two <entity id="P04-1037.4">probabilistic <entity id="P04-1037.5">models</entity></entity> for unsupervised <entity id="P04-1037.6"><entity id="P04-1037.7">word-sense</entity> <entity id="P04-1037.8">disambiguation</entity></entity> using <entity id="P04-1037.9">parallel corpora</entity> . The first <entity id="P04-1037.10">model</entity> , which we <entity id="P04-1037.11">call</entity> the <entity id="P04-1037.12">Sense</entity> <entity id="P04-1037.13">model</entity> , builds on the work of Diab and Resnik (2002) that uses both <entity id="P04-1037.14">parallel text</entity> and a <entity id="P04-1037.15">sense</entity> <entity id="P04-1037.16">inventory</entity> for the <entity id="P04-1037.17">target language</entity> , and recasts their <entity id="P04-1037.18">approach</entity> in a probabilistic <entity id="P04-1037.19">framework</entity> . The second <entity id="P04-1037.20">model</entity> , which we <entity id="P04-1037.21">call</entity> the <entity id="P04-1037.22">Concept</entity> <entity id="P04-1037.23">model</entity> , is a hierarchical <entity id="P04-1037.24">model</entity> that uses a <entity id="P04-1037.25">concept</entity> latent <entity id="P04-1037.26">variable</entity> to relate different <entity id="P04-1037.27">language</entity> specific <entity id="P04-1037.28">sense</entity> labels. We show that both <entity id="P04-1037.29">models</entity> <entity id="P04-1037.30">improve</entity> <entity id="P04-1037.31">performance</entity> on the <entity id="P04-1037.32">word sense disambiguation</entity> <entity id="P04-1037.33">task</entity> over previous unsu-pervised <entity id="P04-1037.34">approaches</entity> , with the <entity id="P04-1037.35">Concept</entity> <entity id="P04-1037.36">model</entity> showing the largest <entity id="P04-1037.37">improvement</entity> . Furthermore, in learning the <entity id="P04-1037.38">Concept</entity> <entity id="P04-1037.39">model</entity> , as a <entity id="P04-1037.40">by-product</entity> , we learn a <entity id="P04-1037.41">sense</entity> <entity id="P04-1037.42">inventory</entity> for the parallel <entity id="P04-1037.43">language</entity> .
</abstract>


usedfor(P04-1037.1,P04-1037.3,REVERSE)
usedfor(P04-1037.4,P04-1037.6)
based_on(P04-1037.24,P04-1037.26)
yields(P04-1037.29,P04-1037.31)
model(P04-1037.42,P04-1037.43)

</text>

<text id="P04-1059">
<title>
Adaptive <entity id="P04-1059.1">Chinese Word Segmentation</entity></title>
<abstract>
This <entity id="P04-1059.2">paper</entity> presents a <entity id="P04-1059.3">Chinese word segmentation</entity> <entity id="P04-1059.4">system</entity> which can <entity id="P04-1059.5">adapt</entity> to different <entity id="P04-1059.6">domains</entity> and <entity id="P04-1059.7">standards</entity> . We first present a <entity id="P04-1059.8">statistical</entity> <entity id="P04-1059.9">framework</entity> where <entity id="P04-1059.10">domain-specific</entity> <entity id="P04-1059.11">words</entity> are identified in a unified <entity id="P04-1059.12">approach</entity> to <entity id="P04-1059.13">word segmentation</entity> <entity id="P04-1059.14">based</entity> on <entity id="P04-1059.15">linear <entity id="P04-1059.16">models</entity></entity> . We explore several <entity id="P04-1059.17">features</entity> and describe how to create <entity id="P04-1059.18">training</entity> <entity id="P04-1059.19">data</entity> by <entity id="P04-1059.20">sampling</entity> . We then describe a <entity id="P04-1059.21">transformation-based</entity> <entity id="P04-1059.22">learning method</entity> used to <entity id="P04-1059.23">adapt</entity> our <entity id="P04-1059.24">system</entity> to different <entity id="P04-1059.25">word segmentation</entity> <entity id="P04-1059.26">standards</entity> . <entity id="P04-1059.27">Evaluation</entity> of the <entity id="P04-1059.28">proposed</entity> <entity id="P04-1059.29">system</entity> on five <entity id="P04-1059.30">test sets</entity> with different <entity id="P04-1059.31">standards</entity> shows that the <entity id="P04-1059.32">system</entity> achieves stateof-the-art <entity id="P04-1059.33">performance</entity> on all of them.
</abstract>


propose(P04-1059.2,P04-1059.4)
based_on(P04-1059.12,P04-1059.15)
study(P04-1059.27,P04-1059.29)
yields(P04-1059.32,P04-1059.33)

</text>

<text id="P04-3029">
<title>
Multimodal <entity id="P04-3029.1">Database</entity> <entity id="P04-3029.2">Access</entity> On Handheld Devices
</title>
<abstract>
We present the final MIAMM <entity id="P04-3029.3">system</entity> , a multimodal <entity id="P04-3029.4">dialogue <entity id="P04-3029.5">system</entity></entity> that employs <entity id="P04-3029.6">speech</entity> , haptic <entity id="P04-3029.7">interaction</entity> and novel <entity id="P04-3029.8">techniques</entity> of <entity id="P04-3029.9">information</entity> <entity id="P04-3029.10">visualization</entity> to allow a <entity id="P04-3029.11">natural</entity> and fast <entity id="P04-3029.12">access</entity> to large multimedia <entity id="P04-3029.13">databases</entity> on small handheld <entity id="P04-3029.14">devices</entity> .
</abstract>


based_on(P04-3029.4,P04-3029.8)

</text>

<text id="P05-1059">
<title>
Stochastic Lexicalized Inversion <entity id="P05-1059.1">Transduction</entity> Grammar For <entity id="P05-1059.2">Alignment</entity></title>
<abstract>
We present a <entity id="P05-1059.3">version</entity> of Inversion <entity id="P05-1059.4">Transduction</entity> Grammar where <entity id="P05-1059.5">rule</entity> <entity id="P05-1059.6">probabilities</entity> are lexicalized throughout the synchronous <entity id="P05-1059.7">parse tree</entity> , along with pruning <entity id="P05-1059.8">techniques</entity> for efficient <entity id="P05-1059.9">training</entity> . <entity id="P05-1059.10">Alignment</entity> <entity id="P05-1059.11">results</entity> <entity id="P05-1059.12">improve</entity> over unlexicalized ITG on short <entity id="P05-1059.13">sentences</entity> for which full EM is feasible, but pruning seems to have a negative <entity id="P05-1059.14">impact</entity> on longer <entity id="P05-1059.15">sentences</entity> .
</abstract>



</text>

<text id="P05-2024">
<title><entity id="P05-2024.1">Corpus-</entity> Oriented <entity id="P05-2024.2">Development</entity> Of <entity id="P05-2024.3">Japanese</entity> HPSG Parsers
</title>
<abstract>
This <entity id="P05-2024.4">paper</entity> <entity id="P05-2024.5">reports</entity> the <entity id="P05-2024.6">corpus-oriented</entity> <entity id="P05-2024.7">development</entity> of a <entity id="P05-2024.8">wide-coverage</entity> <entity id="P05-2024.9">Japanese</entity> HPSG <entity id="P05-2024.10">parser</entity> . We first created an HPSG treebank from the EDR <entity id="P05-2024.11">corpus</entity> by using heuristic <entity id="P05-2024.12">conversion</entity> <entity id="P05-2024.13">rules</entity> , and then <entity id="P05-2024.14">extracted</entity> <entity id="P05-2024.15">lexical <entity id="P05-2024.16">entries</entity></entity> from the <entity id="P05-2024.17">tree-bank</entity> . The grammar <entity id="P05-2024.18">developed</entity> using this <entity id="P05-2024.19">method</entity> attained wide <entity id="P05-2024.20">coverage</entity> that could hardly be obtained by conventional <entity id="P05-2024.21">manual</entity> <entity id="P05-2024.22">development</entity> . We also <entity id="P05-2024.23">trained</entity> a <entity id="P05-2024.24">statistical</entity> <entity id="P05-2024.25">parser</entity> for the grammar on the <entity id="P05-2024.26">tree-bank</entity> , and <entity id="P05-2024.27">evaluated</entity> the <entity id="P05-2024.28">parser</entity> in <entity id="P05-2024.29">terms</entity> of the <entity id="P05-2024.30">accuracy</entity> of <entity id="P05-2024.31">semantic-role</entity> <entity id="P05-2024.32">identification</entity> and <entity id="P05-2024.33">dependency</entity> <entity id="P05-2024.34">analysis</entity> .
</abstract>


propose(P05-2024.4,P05-2024.10)
datasource(P05-2024.15,P05-2024.17)

</text>

<text id="C80-1088">
<title>
The <entity id="C80-1088.1">Morphological Analysis</entity> Of Bahasa Malaysia
</title>



</text>

<abstract></abstract>

<text id="C82-1021">
<title>
A Multilayered <entity id="C82-1021.1">Approach</entity> To The Handling Of <entity id="C82-1021.2">Word</entity> <entity id="C82-1021.3">Formation</entity></title>
<abstract>
The <entity id="C82-1021.4">treatment</entity> of <entity id="C82-1021.5">word</entity> <entity id="C82-1021.6">formations</entity> has until recently been a neglected <entity id="C82-1021.7">topic</entity> in <entity id="C82-1021.8">natural  language</entity> AI <entity id="C82-1021.9">research</entity> . This <entity id="C82-1021.10">paper</entity> <entity id="C82-1021.11">proposes</entity> a multilayered <entity id="C82-1021.12">approach</entity> to <entity id="C82-1021.13">word</entity> <entity id="C82-1021.14">formation</entity> which treats derivatives and compounds on several different <entity id="C82-1021.15">levels</entity> of <entity id="C82-1021.16">processing</entity> within a <entity id="C82-1021.17">natural language</entity> <entity id="C82-1021.18">dialogue system</entity> . <entity id="C82-1021.19">Analysis</entity> and <entity id="C82-1021.20">generation</entity> <entity id="C82-1021.21">strategies</entity> being <entity id="C82-1021.22">developed</entity> for the <entity id="C82-1021.23">dialogue system</entity> HAM-ANS are described. <entity id="C82-1021.24">Identification</entity> of <entity id="C82-1021.25">word</entity> <entity id="C82-1021.26">format</entity> <entity id="C82-1021.27">ions</entity> , <entity id="C82-1021.28">semantic interpretation</entity> , and <entity id="C82-1021.29">evaluation</entity> in the <entity id="C82-1021.30">context</entity> of a <entity id="C82-1021.31">dialogue</entity> are the <entity id="C82-1021.32">main</entity> <entity id="C82-1021.33">levels</entity> of <entity id="C82-1021.34">analysis</entity> on which the <entity id="C82-1021.35">system</entity> successively attempts to infer the implicit <entity id="C82-1021.36">relations</entity> between <entity id="C82-1021.37">word</entity> <entity id="C82-1021.38">formation</entity> <entity id="C82-1021.39">components</entity> . <entity id="C82-1021.40">Generation</entity> of <entity id="C82-1021.41">word</entity> <entity id="C82-1021.42">formations</entity> is viewed as a <entity id="C82-1021.43">process</entity> comparable to the <entity id="C82-1021.44">generation</entity> of elliptical <entity id="C82-1021.45">utterances</entity> .
</abstract>


propose(C82-1021.10,C82-1021.12)

</text>

<text id="C82-1067">
<title>
Man-Assisted <entity id="C82-1067.1">Machine</entity> <entity id="C82-1067.2">Construction</entity> Of A <entity id="C82-1067.3">Semantic</entity> <entity id="C82-1067.4">Dictionary</entity> For <entity id="C82-1067.5">Natural Language</entity> <entity id="C82-1067.6">Processing</entity></title>
<abstract>
This is a <entity id="C82-1067.7">report</entity> on the <entity id="C82-1067.8">semantic</entity> <entity id="C82-1067.9">dictionary</entity> for <entity id="C82-1067.10">natural language processing</entity> we are <entity id="C82-1067.11">constructing</entity> now.   This <entity id="C82-1067.12">paper</entity> explains how to obtain the <entity id="C82-1067.13">semantic <entity id="C82-1067.14">information</entity></entity> for the <entity id="C82-1067.15">dictionary</entity> from an ordinary <entity id="C82-1067.16">Japanese</entity> <entity id="C82-1067.17">language</entity> <entity id="C82-1067.18">dictionary</entity> with about 60,000 <entity id="C82-1067.19">items</entity> (which had already been put into <entity id="C82-1067.20">machine</entity> readable <entity id="C82-1067.21">form</entity> ) and also explains what should be the <entity id="C82-1067.22">frame</entity> for the <entity id="C82-1067.23">representation</entity> of meaning of each <entity id="C82-1067.24">item</entity> ( <entity id="C82-1067.25">word</entity> ).   Then a man-assisted <entity id="C82-1067.26">machine</entity> <entity id="C82-1067.27">procedure</entity> that embeds the <entity id="C82-1067.28">semantic</entity> graph with <entity id="C82-1067.29">respect</entity> to the <entity id="C82-1067.30">head word</entity> of the ordinary <entity id="C82-1067.31">dictionary</entity> into the <entity id="C82-1067.32">frame</entity> of a <entity id="C82-1067.33">head word</entity> is discussed.
</abstract>


based_on(C82-1067.4,C82-1067.6,REVERSE)
propose(C82-1067.7,C82-1067.9)
datasource(C82-1067.13,C82-1067.18)
model(C82-1067.23,C82-1067.24)

</text>

<text id="C86-1077">
<title><entity id="C86-1077.1">Strategies</entity> For Interactive <entity id="C86-1077.2">Machine Translation</entity> : The <entity id="C86-1077.3">Experience</entity> And Implications Of The UMIST <entity id="C86-1077.4">Japanese</entity> <entity id="C86-1077.5">Project</entity></title>
<abstract>
At the Contre for <entity id="C86-1077.6">Computational Linguistics</entity> , we are <entity id="C86-1077.7">designing</entity> and <entity id="C86-1077.8">implementing</entity> an Eng.lish-to- <entity id="C86-1077.9">Japanese</entity> interactive <entity id="C86-1077.10">machine translation system</entity> . The <entity id="C86-1077.11">project</entity> is funded jointly by the Alvey Directorate and International <entity id="C86-1077.12">Computers</entity> Limited (ICL). The <entity id="C86-1077.13">prototype</entity> <entity id="C86-1077.14">system</entity> runs on the ICL PERQ, though much of the <entity id="C86-1077.15">development</entity> work has been done on a VAX 11/750. It is <entity id="C86-1077.16">implemented</entity> in Prolog, in the interests of rapid <entity id="C86-1077.17">prototyping</entity> , but intended for <entity id="C86-1077.18">optimization</entity> . The informing <entity id="C86-1077.19">principles</entity> are those of modern comp1 <entity id="C86-1077.20">ex-feature-based</entity> <entity id="C86-1077.21">linguistic <entity id="C86-1077.22">theories</entity></entity> , in particular <entity id="C86-1077.23">Lexical-</entity> Functional Grammar ( Bresnan (ed.) 1982, Kaplan and  Bresnan 1982 ), and <entity id="C86-1077.24">Generalized Phrase Structure Grammar</entity> ( Gazdar et al. 1985 ). For <entity id="C86-1077.25">development</entity> <entity id="C86-1077.26">purposes</entity> we are using an existing <entity id="C86-1077.27">corpus</entity> of 10,000 <entity id="C86-1077.28">words</entity> of continuous prose from the PERQ's graphics <entity id="C86-1077.29">documentation</entity> ; in the long <entity id="C86-1077.30">term</entity> , the <entity id="C86-1077.31">system</entity> will be extended for use by technical writers in <entity id="C86-1077.32">fields</entity> other than <entity id="C86-1077.33">software</entity> . At the <entity id="C86-1077.34">time</entity> of writing, we have well-developed <entity id="C86-1077.35">system</entity> <entity id="C86-1077.36">development</entity> <entity id="C86-1077.37">software</entity> , <entity id="C86-1077.38">user interface</entity> , and grammar and <entity id="C86-1077.39">dictionary</entity> handling <entity id="C86-1077.40">utilities</entity> . The <entity id="C86-1077.41">English</entity> <entity id="C86-1077.42">analysis</entity> grammar handles most of the <entity id="C86-1077.43">syntactic structures</entity> of the <entity id="C86-1077.44">corpus</entity> , and we have a range of <entity id="C86-1077.45">formats</entity> for <entity id="C86-1077.46">output</entity> of linguistic <entity id="C86-1077.47">representations</entity> and <entity id="C86-1077.48">Japanese</entity> <entity id="C86-1077.49">text</entity> . A <entity id="C86-1077.50">transfer</entity> grammar for <entity id="C86-1077.51">English-</entity> <entity id="C86-1077.52">Japanese</entity> has been prototyped, but is not not yet fully adequate to handle all <entity id="C86-1077.53">constructions</entity> in the <entity id="C86-1077.54">corpus</entity> ; a facility for <entity id="C86-1077.55">dictionary</entity> <entity id="C86-1077.56">entry</entity> in <entity id="C86-1077.57">kanji</entity> is incorporated. The <entity id="C86-1077.58">aspect</entity> of the <entity id="C86-1077.59">system</entity> we will <entity id="C86-1077.60">focus</entity> on in the present <entity id="C86-1077.61">paper</entity> is its interactive <entity id="C86-1077.62">nature</entity> , discussing the range of different <entity id="C86-1077.63">types</entity> of <entity id="C86-1077.64">interaction</entity> which are <entity id="C86-1077.65">provided</entity> or permitted for different <entity id="C86-1077.66">types</entity> of <entity id="C86-1077.67">user</entity> .
</abstract>


isa(C86-1077.19,C86-1077.21)
datasource(C86-1077.27,C86-1077.29)

</text>

<text id="C88-1065">
<title>
Exploiting <entity id="C88-1065.1">Lexical</entity> Regularities In Designing <entity id="C88-1065.2">Natural Language</entity> <entity id="C88-1065.3">Systems</entity></title>
<abstract>
This <entity id="C88-1065.4">paper</entity> presents the <entity id="C88-1065.5">lexical</entity> <entity id="C88-1065.6">component</entity> of the START <entity id="C88-1065.7">Question <entity id="C88-1065.8">Answering system</entity></entity> <entity id="C88-1065.9">developed</entity> at the MIT <entity id="C88-1065.10">Artificial Intelligence</entity> <entity id="C88-1065.11">Laboratory</entity> . START is able to interpret correctly a wide range of <entity id="C88-1065.12">semantic</entity> <entity id="C88-1065.13">relationships</entity> associated with alternate <entity id="C88-1065.14">expressions</entity> of the <entity id="C88-1065.15">arguments</entity> of <entity id="C88-1065.16">verbs</entity> . The <entity id="C88-1065.17">design</entity> of the <entity id="C88-1065.18">system</entity> takes <entity id="C88-1065.19">advantage</entity> of the <entity id="C88-1065.20">results</entity> of recent linguistic <entity id="C88-1065.21">research</entity> into the <entity id="C88-1065.22">structure</entity> of the <entity id="C88-1065.23">lexicon</entity> , allowing START to attain a broader range of <entity id="C88-1065.24">coverage</entity> than many existing <entity id="C88-1065.25">systems</entity> while maintaining modular <entity id="C88-1065.26">organization</entity> .
</abstract>


propose(C88-1065.4,C88-1065.7)
based_on(C88-1065.17,C88-1065.21)

</text>

<text id="C88-2095">
<title><entity id="C88-2095.1">Reasons</entity> Why I Do Not Care Grammar <entity id="C88-2095.2">Formalism</entity></title>
<abstract>
has borrowed a lot of ideas from We could not have <entity id="C88-2095.3">developed</entity> even a <entity id="C88-2095.4">simple</entity> <entity id="C88-2095.5">parser</entity> without the <entity id="C88-2095.6">research</entity> <entity id="C88-2095.7">results</entity> in It is obviously nonsense to <entity id="C88-2095.8">claim</entity> that we, <entity id="C88-2095.9">computational linguists</entity> , do not care <entity id="C88-2095.10">research</entity> <entity id="C88-2095.11">results</entity> in However, the <entity id="C88-2095.12">researchers</entity> in it seems to me, are very fond of especially, those who are <entity id="C88-2095.13">called</entity> They always fight with each other by asserting that their are superior to the others'. They are oversensitive and tend to distinguish people into two groups, and A <entity id="C88-2095.14">computational linguist</entity> using LFG (or LFG) as a small <entity id="C88-2095.15">part</entity> in his total <entity id="C88-2095.16">system</entity> is taken as the <entity id="C88-2095.17">ally</entity> of LFG, and is certainly accused by the other groups. They promptly demonstrate that LFG is wrong, by showing a lot of peculiar <entity id="C88-2095.18">sentences</entity> which rarely appear in real <entity id="C88-2095.19">texts</entity> .Formalisms are prepared for accomplishing specific <entity id="C88-2095.20">purposes</entity> . The <entity id="C88-2095.21">formalisms</entity> in have been <entity id="C88-2095.22">proposed</entity> , roughly speaking, for describing the of distinguishing from arbitrary /ramraa/ica/ <entity id="C88-2095.23">sequences</entity> , and of relating the grammatical <entity id="C88-2095.24">sequences</entity> with the other representational <entity id="C88-2095.25">levels</entity> .On the other <entity id="C88-2095.26">hand</entity> , a <entity id="C88-2095.27">formalism</entity> we need in CL is for different <entity id="C88-2095.28">purposes</entity> . That is, we need a <entity id="C88-2095.29">formalism</entity> for describing the <entity id="C88-2095.30">rules</entity> of distinguishing the most feasible grammatical <entity id="C88-2095.31">structures</entity> from other less feasible but still ones of the same <entity id="C88-2095.32">sentences</entity> We also need a <entity id="C88-2095.33">formalism</entity> in which we can manage systematically a large <entity id="C88-2095.34">amount</entity> of <entity id="C88-2095.35">knowledge</entity> of various sorts necessary for NLP.Formalisms for different <entity id="C88-2095.36">purposes</entity> , of course, should be <entity id="C88-2095.37">evaluated</entity> <entity id="C88-2095.38">based</entity> on different <entity id="C88-2095.39">standards</entity> . The <entity id="C88-2095.40">current</entity> <entity id="C88-2095.41">discussions</entity> of different <entity id="C88-2095.42">formalisms</entity> in TL are irrelevant to our <entity id="C88-2095.43">standards</entity> , though they may be important for their The following is a <entity id="C88-2095.44">list</entity> of the <entity id="C88-2095.45">reasons</entity> why I think so.
</abstract>


based_on(C88-2095.5,C88-2095.7)
phenomenon(C88-2095.18,C88-2095.19)

</text>

<text id="C88-2130">
<title>
Directing The <entity id="C88-2130.1">Generation</entity> Of Living <entity id="C88-2130.2">Space</entity> Descriptions
</title>
<abstract>
We have <entity id="C88-2130.3">developed</entity> a <entity id="C88-2130.4">Computational model</entity> of the <entity id="C88-2130.5">process</entity> of describing the <entity id="C88-2130.6">layout</entity> of an apartment or house, a much-studied <entity id="C88-2130.7">discourse</entity> <entity id="C88-2130.8">task</entity> first characterized linguistically by Linde (1974). The <entity id="C88-2130.9">model</entity> is embodied in a <entity id="C88-2130.10">program</entity> , APT, that can reproduce <entity id="C88-2130.11">segments</entity> of actual tape-recorded <entity id="C88-2130.12">descriptions</entity> , using organizational and <entity id="C88-2130.13">discourse</entity> <entity id="C88-2130.14">strategies</entity> derived through <entity id="C88-2130.15">analysis</entity> of our <entity id="C88-2130.16">corpus</entity> .
</abstract>


study(C88-2130.15,C88-2130.16)

</text>

<text id="C88-2136">
<title>
LangLAB: A <entity id="C88-2136.1">Natural Language Analysis</entity> <entity id="C88-2136.2">System</entity></title>
<abstract>
LangLAB : 
 <entity id="C88-2136.3">Natural Language Analysis</entity> <entity id="C88-2136.4">System</entity> . TOKUNAGA Takenobu , Tadasbi</abstract>



</text>

<text id="C88-2148">
<title><entity id="C88-2148.1">Topic</entity> / <entity id="C88-2148.2">Focus</entity> Articulation And Intensional <entity id="C88-2148.3">Logic</entity></title>
<abstract>
A <entity id="C88-2148.4">semantic <entity id="C88-2148.5">analysis</entity></entity> of <entity id="C88-2148.6">topic</entity> and <entity id="C88-2148.7">focus</entity> as two <entity id="C88-2148.8">parts</entity> of tectograamatical <entity id="C88-2148.9">representation</entity> by means of transparent intensional <entity id="C88-2148.10">logic</entity> (TIL) ia presented. It is pointed out that two <entity id="C88-2148.11">sentences</entity> (more precisely, their tectograamatical <entity id="C88-2148.12">representations</entity> ) differing just in the <entity id="C88-2148.13">topic</entity> / <entity id="C88-2148.14">focus</entity> articulation (TFA) denote different propositions, i.e. that TFA has an <entity id="C88-2148.15">effect</entity> upon the <entity id="C88-2148.16">semantic</entity> <entity id="C88-2148.17">content</entity> of the <entity id="C88-2148.18">sentence</entity> . An inforaal short <entity id="C88-2148.19">description</entity> of an <entity id="C88-2148.20">algorithm</entity> handling the TFA in the <entity id="C88-2148.21">translation</entity> of tectogrammatical <entity id="C88-2148.22">representations</entity> into the <entity id="C88-2148.23">constructions</entity> of TIL is added. The TFA <entity id="C88-2148.24">algorithm</entity> divides a <entity id="C88-2148.25">representation</entity> into two <entity id="C88-2148.26">parts</entity> corresponding to the <entity id="C88-2148.27">topic</entity> and <entity id="C88-2148.28">focus</entity> ; every <entity id="C88-2148.29">part</entity> is analyzed ( <entity id="C88-2148.30">translated</entity> ) in <entity id="C88-2148.31">isolation</entity> and then the <entity id="C88-2148.32">resulting</entity> <entity id="C88-2148.33">construction</entity> is put together. The TIL <entity id="C88-2148.34">construction</entity> discussed here
</abstract>


study(C88-2148.4,C88-2148.6)
phenomenon(C88-2148.17,C88-2148.18)
study(C88-2148.19,C88-2148.20)

</text>

<text id="C90-1021">
<title>
Bilingual <entity id="C90-1021.1">Generation</entity> Of Weather Forecasts In An Operations <entity id="C90-1021.2">Environment</entity></title>
<abstract>
In  1986  the first <entity id="C90-1021.3">experiments</entity> in <entity id="C90-1021.4">text generation</entity> <entity id="C90-1021.5">applied</entity> to weather forecasts <entity id="C90-1021.6">resulted</entity> in a <entity id="C90-1021.7">prototype</entity> <entity id="C90-1021.8">system</entity> (RAREAS[6,3]) for producing <entity id="C90-1021.9">English</entity> marine bulletins from forecast <entity id="C90-1021.10">data</entity> . Subsequent work in 1987 added French <entity id="C90-1021.11">output</entity> to make the initial <entity id="C90-1021.12">system</entity> bilingual (RAREAS-2[llj). During 1988 -1989 a <entity id="C90-1021.13">full-scale</entity> operational <entity id="C90-1021.14">system</entity> was created to meet the needs of daily marine forecast production for three regional centres in the Canadian Atmospheric <entity id="C90-1021.15">Environment</entity> Service
</abstract>


yields(C90-1021.3,C90-1021.8)

</text>

<text id="C90-3009">
<title>
Syllable- <entity id="C90-3009.1">Based</entity> <entity id="C90-3009.2">Morphology</entity></title>
<abstract>
This <entity id="C90-3009.3">paper</entity> presents a <entity id="C90-3009.4">language</entity> for the <entity id="C90-3009.5">description</entity> of morphological <entity id="C90-3009.6">alternations</entity> which is <entity id="C90-3009.7">based</entity> on syllable <entity id="C90-3009.8">structure</entity> . The <entity id="C90-3009.9">justification</entity> for such an <entity id="C90-3009.10">approach</entity> is discussed with <entity id="C90-3009.11">reference</entity> to <entity id="C90-3009.12">examples</entity> from a <entity id="C90-3009.13">variety</entity> of <entity id="C90-3009.14">languages</entity> and the <entity id="C90-3009.15">approach</entity> is compared to Koskenniemi 's <entity id="C90-3009.16">two-level</entity> account of morphonoiogy. Keywords: <entity id="C90-3009.17">morphology</entity> , <entity id="C90-3009.18">phonology</entity> , syllables.
</abstract>


propose(C90-3009.3,C90-3009.4)

</text>

<text id="C92-4211">
<title><entity id="C92-4211.1">Knowledge</entity> <entity id="C92-4211.2">Acquisition</entity> And <entity id="C92-4211.3">Chinese</entity> <entity id="C92-4211.4">Parsing</entity> <entity id="C92-4211.5">Based</entity> On <entity id="C92-4211.6">Corpus</entity></title>
<abstract>
In <entity id="C92-4211.7">Natural Language Processing</entity> (NLP), one key <entity id="C92-4211.8">problem</entity> is how to <entity id="C92-4211.9">design</entity> a <entity id="C92-4211.10">robust</entity> and effective <entity id="C92-4211.11">parsing</entity> <entity id="C92-4211.12">system</entity> . In this <entity id="C92-4211.13">paper</entity> , we will introduce a <entity id="C92-4211.14">corpus</entity> <entity id="C92-4211.15">based</entity> <entity id="C92-4211.16">Chinese</entity> <entity id="C92-4211.17">parsing</entity> <entity id="C92-4211.18">system</entity> . Our <entity id="C92-4211.19">efforts</entity> <entity id="C92-4211.20">arc</entity> concctrated on: (1) <entity id="C92-4211.21">knowledge</entity> <entity id="C92-4211.22">acquisition</entity> and <entity id="C92-4211.23">representation</entity> ; and (2) the <entity id="C92-4211.24">parsing</entity> <entity id="C92-4211.25">scheme</entity> . The <entity id="C92-4211.26">knowledge</entity> of this <entity id="C92-4211.27">system</entity> is principally <entity id="C92-4211.28">extracted</entity> from analyzed <entity id="C92-4211.29">corpus</entity> , others are a few grammatical <entity id="C92-4211.30">principles</entity> , i.e. the four <entity id="C92-4211.31">axioms</entity> of the <entity id="C92-4211.32">Dependency Grammar</entity> (DG). In <entity id="C92-4211.33">addition</entity> , we also <entity id="C92-4211.34">propose</entity> the fifth <entity id="C92-4211.35">axiom</entity> of DG to <entity id="C92-4211.36">support</entity> the <entity id="C92-4211.37">parsing</entity> of <entity id="C92-4211.38">Chinese</entity> <entity id="C92-4211.39">sentences</entity> .
</abstract>


based_on(C92-4211.4,C92-4211.6)
propose(C92-4211.13,C92-4211.18)
datasource(C92-4211.26,C92-4211.29)
taskapplied(C92-4211.37,C92-4211.39)

</text>

<text id="C94-1023">
<title><entity id="C94-1023.1">Automatic</entity> <entity id="C94-1023.2">Model</entity> <entity id="C94-1023.3">Refinement</entity> - With An <entity id="C94-1023.4">Application</entity> To <entity id="C94-1023.5">Tagging</entity></title> 
<abstract><entity id="C94-1023.6">Statistical</entity> NLP <entity id="C94-1023.7">models</entity> usually only consider coarse <entity id="C94-1023.8">information</entity> and very restricted <entity id="C94-1023.9">context</entity> to make the <entity id="C94-1023.10">estimation</entity> of <entity id="C94-1023.11">parameters</entity> feasible. To reduce the <entity id="C94-1023.12">modeling</entity> <entity id="C94-1023.13">error</entity> introduced by a simplified <entity id="C94-1023.14">probabilistic <entity id="C94-1023.15">model</entity></entity> , the <entity id="C94-1023.16">Classification</entity> and <entity id="C94-1023.17">Regression</entity> <entity id="C94-1023.18">Tree</entity> (CART) <entity id="C94-1023.19">method</entity> was adopted in this <entity id="C94-1023.20">paper</entity> to select more discriminative <entity id="C94-1023.21">features</entity> for <entity id="C94-1023.22">automatic</entity> <entity id="C94-1023.23">model</entity> <entity id="C94-1023.24">refinement</entity> . Because the <entity id="C94-1023.25">features</entity> are adopted dependently during <entity id="C94-1023.26">splitting</entity> the <entity id="C94-1023.27">classification</entity> <entity id="C94-1023.28">tree</entity> in CART, the <entity id="C94-1023.29">number</entity> of <entity id="C94-1023.30">training</entity> <entity id="C94-1023.31">data</entity> in each <entity id="C94-1023.32">terminal</entity> <entity id="C94-1023.33">node</entity> is small, which makes the labeling <entity id="C94-1023.34">process</entity> of <entity id="C94-1023.35">terminal</entity> <entity id="C94-1023.36">nodes</entity> not <entity id="C94-1023.37">robust</entity> . This over-tuning <entity id="C94-1023.38">phenomenon</entity> cannot be completely removed by <entity id="C94-1023.39">cross-validation</entity> <entity id="C94-1023.40">process</entity> (i.e., pruning <entity id="C94-1023.41">process</entity> ). A probabilistic <entity id="C94-1023.42">classification <entity id="C94-1023.43">model</entity></entity> <entity id="C94-1023.44">based</entity> on the selected discriminative <entity id="C94-1023.45">features</entity> is thus <entity id="C94-1023.46">proposed</entity> to use the <entity id="C94-1023.47">training</entity> <entity id="C94-1023.48">data</entity> more efficiently. In <entity id="C94-1023.49">tagging</entity> the <entity id="C94-1023.50">Brown <entity id="C94-1023.51">Corpus</entity></entity> , our probabilistic <entity id="C94-1023.52">classification <entity id="C94-1023.53">model</entity></entity> reduces the <entity id="C94-1023.54">error <entity id="C94-1023.55">rate</entity></entity> of the top 10 <entity id="C94-1023.56">error</entity> dominant <entity id="C94-1023.57">words</entity> from 5.71% to 4.35%, which shows 23.82% <entity id="C94-1023.58">improvement</entity> over the unrefined <entity id="C94-1023.59">model</entity> .
</abstract>


yields(C94-1023.13,C94-1023.14,REVERSE)
propose(C94-1023.19,C94-1023.20,REVERSE)
based_on(C94-1023.21,C94-1023.24,REVERSE)
based_on(C94-1023.42,C94-1023.45)
taskapplied(C94-1023.49,C94-1023.50)
yields(C94-1023.52,C94-1023.54)

</text>

<text id="C94-1055">
<title><entity id="C94-1055.1">Generating</entity> Multilingual <entity id="C94-1055.2">Documents</entity> From A <entity id="C94-1055.3">Knowledge <entity id="C94-1055.4">Base</entity></entity> The TECHDOC <entity id="C94-1055.5">Project</entity></title>
<abstract>
TECHDOC is an <entity id="C94-1055.6">implemented</entity> <entity id="C94-1055.7">system</entity> demonstrating the feasibility of <entity id="C94-1055.8">generating</entity> multilingu.il technical <entity id="C94-1055.9">documents</entity> on the <entity id="C94-1055.10">basis</entity> of a <entity id="C94-1055.11">language-independent</entity> <entity id="C94-1055.12">knowledge <entity id="C94-1055.13">base</entity></entity> . Its <entity id="C94-1055.14">application</entity> <entity id="C94-1055.15">domain</entity> is use]- and <entity id="C94-1055.16">maintenance</entity> <entity id="C94-1055.17">instructions</entity> , which are produced from underlying plan <entity id="C94-1055.18">structures</entity> representing the activities, the participating <entity id="C94-1055.19">objects</entity> with their <entity id="C94-1055.20">properties</entity> , <entity id="C94-1055.21">relations</entity> , and so on. This <entity id="C94-1055.22">paper</entity> gives a brief <entity id="C94-1055.23">outline</entity> of the <entity id="C94-1055.24">system <entity id="C94-1055.25">architecture</entity></entity> and discusses some recent <entity id="C94-1055.26">developments</entity> in the <entity id="C94-1055.27">project</entity> : the <entity id="C94-1055.28">addition</entity> of actual <entity id="C94-1055.29">event</entity> <entity id="C94-1055.30">simulation</entity> in the KM, <entity id="C94-1055.31">steps</entity> towards a <entity id="C94-1055.32">document</entity> authoring <entity id="C94-1055.33">tool</entity> , and a multimodal <entity id="C94-1055.34">user interface</entity> .
</abstract>


datasource(C94-1055.2,C94-1055.3)
datasource(C94-1055.9,C94-1055.12)
propose(C94-1055.22,C94-1055.24)

</text>

<text id="C94-2138">
<title>
A Reestimation <entity id="C94-2138.1">Algorithm</entity> For Probabilistic Ttecursive <entity id="C94-2138.2">Transition</entity> <entity id="C94-2138.3">Network</entity></title>
<abstract>
Probabilistic. Recursive <entity id="C94-2138.4">Transition</entity> <entity id="C94-2138.5">Network</entity> (I'KTN) is an elevated <entity id="C94-2138.6">version</entity> of RTN to <entity id="C94-2138.7">model</entity> and <entity id="C94-2138.8">process</entity> <entity id="C94-2138.9">languages</entity> in stochastic, <entity id="C94-2138.10">parameters</entity> . The <entity id="C94-2138.11">representation</entity> is a direct <entity id="C94-2138.12">derivation</entity> from the KTN and keeps much the spirit of <entity id="C94-2138.13">Hidden Markov Model</entity> at the same <entity id="C94-2138.14">time</entity> . We present a reestimation <entity id="C94-2138.15">algorithm</entity> for PHTN that is a <entity id="C94-2138.16">variation</entity> of Inside Outside <entity id="C94-2138.17">algorithm</entity> that <entity id="C94-2138.18">computes</entity> the values of the probabilistic <entity id="C94-2138.19">parameters</entity> from <entity id="C94-2138.20">sample</entity> <entity id="C94-2138.21">sentences</entity> (parsed or uuparsed).
</abstract>


based_on(C94-2138.1,C94-2138.3,REVERSE)
methodapplied(C94-2138.5,C94-2138.9)

</text>

<text id="C94-2188">
<title>
Centering In <entity id="C94-2188.1">Japanese</entity> : A <entity id="C94-2188.2">Step</entity> Towards Better <entity id="C94-2188.3">Interpretation</entity> Of Pronouns And Zero-Pronouns
</title>
<abstract>
"An <entity id="C94-2188.4">extension</entity> of the <entity id="C94-2188.5">notion</entity> of ""<entity id="C94-2188.6">centering</entity> "" is described for interpreting zero-pronouns and overt pronouns in naturally occurring <entity id="C94-2188.7">Japanese</entity> <entity id="C94-2188.8">text</entity> . In previous work, one zero-pronoun encodes the backward-looking <entity id="C94-2188.9">center</entity> , with pronouns and other zero-pronouns handled as if they were overfly expressed. An <entity id="C94-2188.10">investigation</entity> is made, and from it pronouns and zero pronouns are concluded to bo more salient than other overt <entity id="C94-2188.11">noun phrases</entity> , 'flits en ab les better <entity id="C94-2188.12">interpretation</entity> of pronouns and zero-pronouns. "
</abstract>



</text>

<text id="C94-2192">
<title>
Breaking Down Rhetorical <entity id="C94-2192.1">Relations</entity> For The <entity id="C94-2192.2">Purpose</entity> Of Analysing <entity id="C94-2192.3">Discourse</entity> <entity id="C94-2192.4">Structures</entity></title>
<abstract>
In <entity id="C94-2192.5">Rhetorical Structure Theory</entity> (RST) the <entity id="C94-2192.6">definitions</entity> of some <entity id="C94-2192.7">relations</entity> are rather vague because they are given ou a pragmatic <entity id="C94-2192.8">basis</entity> . This <entity id="C94-2192.9">paper</entity> presents another way of seeing the <entity id="C94-2192.10">relations</entity> which leads to a more precise <entity id="C94-2192.11">specification</entity> of the <entity id="C94-2192.12">relations</entity> . The <entity id="C94-2192.13">relations</entity> are associated with <entity id="C94-2192.14">constraints</entity> on the <entity id="C94-2192.15">semantic</entity> <entity id="C94-2192.16">relationships</entity> between the propositioual contents of two <entity id="C94-2192.17">clauses</entity> , their <entity id="C94-2192.18">Modality</entity> and Tense/ <entity id="C94-2192.19">Aspect</entity> .
</abstract>



</text>

<text id="C86-1044">
<title>
Degrees Of <entity id="C86-1044.1">Understanding</entity></title>
<abstract>
	Hajicov&amp;aacute;, Eva ; Vrbova , Jarka ,The <entity id="C86-1044.2">Role</entity> Of The Hierarchy Of Activation In The <entity id="C86-1044.3">Process</entity> Of <entity id="C86-1044.4">Natural Language Understanding</entity> ,International Conference On <entity id="C86-1044.5">Computation</entity> al <entity id="C86-1044.6">Linguistics</entity> ,1982 *** Slocum , Jonathan ,A <entity id="C86-1044.7">Survey</entity> Of <entity id="C86-1044.8">Machine Translation</entity> : Its History, <entity id="C86-1044.9">Current</entity> <entity id="C86-1044.10">Status</entity> , And Future Prospects, <entity id="C86-1044.11">Computation</entity> al <entity id="C86-1044.12">Linguistics</entity> ,1985</abstract>



</text>

<text id="C86-1052">
<title>
DCKR - <entity id="C86-1052.1">Knowledge Representation</entity> In Prolog And Its <entity id="C86-1052.2">Application</entity> To <entity id="C86-1052.3">Natural Language Processing</entity></title>
<abstract>
"important <entity id="C86-1052.4">tasks</entity> for <entity id="C86-1052.5">natural language processing</entity> . Basin to <entity id="C86-1052.6">semantic</entity> <entity id="C86-1052.7">processing</entity> is <entity id="C86-1052.8">descriptions</entity> of <entity id="C86-1052.9">lexical <entity id="C86-1052.10">items</entity></entity> . The most frequently used <entity id="C86-1052.11">form</entity> of <entity id="C86-1052.12">description</entity> of <entity id="C86-1052.13">lexical <entity id="C86-1052.14">items</entity></entity> is probably Frames or Objects. Therefore in what <entity id="C86-1052.15">form</entity> Frames or Objects are expressed is a key <entity id="C86-1052.16">issue</entity> for <entity id="C86-1052.17">natural language processing</entity> . A <entity id="C86-1052.18">method</entity> of the <entity id="C86-1052.19">Object</entity> <entity id="C86-1052.20">representation</entity> in Prolog <entity id="C86-1052.21">called</entity> DCKR will be introduced. It will be seen that if <entity id="C86-1052.22">part</entity> of general <entity id="C86-1052.23">knowledge</entity> and a <entity id="C86-1052.24">dictionary</entity> are described in DCKR, <entity id="C86-1052.25">part</entity> of <entity id="C86-1052.26">context-processing</entity> and the greater <entity id="C86-1052.27">part</entity> of <entity id="C86-1052.28">semantic</entity> <entity id="C86-1052.29">processing</entity> can be left  to the <entity id="C86-1052.30">functions</entity> built in Prolog. 09) se
( <entity id="C86-1052.31">animal</entity> ,age : X,_) :- bottomof(S,B), sem(B,birthYear:Y,_), X is  1986 - Y. 10) seni(face,P,S) :- hasa(eye,P,[face I S]) ; hasa(nose,P,[face IS] ) ; has a(mou th,P,[face !S]). Now the meanings of the gem, isa and hasa predicates, which are important to <entity id="C86-1052.32">descriptions</entity> in DCKR, are explained later using the DCKR <entity id="C86-1052.33">examples</entity> given above. 1. I n troduct i on Relationships    between   <entity id="C86-1052.34">knowledge</entity> represented predicate  <entity id="C86-1052.35">logic</entity> <entity id="C86-1052.36">formulas</entity> and <entity id="C86-1052.37">knowledge</entity> represented Frames    or    Siruciured <entity id="C86-1052.38">objects</entity> are clarified by [Hayes 80],     [ Nilsson 80],     CGoebel  85],[ Bowen 85], al,      but      their      <entity id="C86-1052.39">methods</entity>    <entity id="C86-1052.40">requires</entity> separately <entity id="C86-1052.41">interpreter</entity> for  their <entity id="C86-1052.42">representation</entity> . et an The authors have <entity id="C86-1052.43">developed</entity> a <entity id="C86-1052.44">knowledge representation</entity> <entity id="C86-1052.45">form</entity> <entity id="C86-1052.46">called</entity> DCKR (Definite <entity id="C86-1052.47">Clause</entity> <entity id="C86-1052.48">Knowledge Representation</entity> ) [ Koyama 85]. In DCKR, each of the sip_ts composing of a Structured <entity id="C86-1052.49">Object</entity> (hereinafter simply <entity id="C86-1052.50">called</entity> an <entity id="C86-1052.51">object</entity> ) is represented by a Horn <entity id="C86-1052.52">clause</entity> (a Prolog statement) with the ""<entity id="C86-1052.53">sen</entity> "" predicate (to be explained in <entity id="C86-1052.54">Section</entity> 2) as its head. Therefore, an <entity id="C86-1052.55">Object</entity> can be regarded as a set of Horn <entity id="C86-1052.56">clauses</entity> (slots) headed by the <entity id="C86-1052.57">sen</entity> predicate with the same first <entity id="C86-1052.58">argument</entity> . From the foregoing it follows that almost all of a <entity id="C86-1052.59">program</entity> for <entity id="C86-1052.60">performing</entity> <entity id="C86-1052.61">semantic</entity> intepretations <entity id="C86-1052.62">relative</entity> to <entity id="C86-1052.63">lexical items</entity> described in DCKR can be replaced by <entity id="C86-1052.64">functions</entity> built in Prolog. That is, most of <entity id="C86-1052.65">programming</entity> <entity id="C86-1052.66">efforts</entity> of <entity id="C86-1052.67">semantic</entity> <entity id="C86-1052.68">processing</entity> can be left to the <entity id="C86-1052.69">functions</entity> built in Pro 1og. DCKR will be described in <entity id="C86-1052.70">detail</entity> in <entity id="C86-1052.71">Section</entity> 2. <entity id="C86-1052.72">Section</entity> 3 will discuss <entity id="C86-1052.73">applications</entity> of DCKR to <entity id="C86-1052.74">semantic</entity> <entity id="C86-1052.75">processing</entity> of <entity id="C86-1052.76">natural languages</entity> . "
</abstract>


model(C86-1052.8,C86-1052.9)
model(C86-1052.12,C86-1052.13)
isa(C86-1052.55,C86-1052.56)
propose(C86-1052.72,C86-1052.73)

</text>

<text id="C88-1048">
<title>
Improving <entity id="C88-1048.1">Search Strategies</entity> An <entity id="C88-1048.2">Experiment</entity> In Best-First <entity id="C88-1048.3">Parsing</entity></title>
<abstract>
"Viewing the <entity id="C88-1048.4">syntactic analysis</entity> of <entity id="C88-1048.5">natural language</entity> as a <entity id="C88-1048.6">search</entity> <entity id="C88-1048.7">problem</entity> , the right <entity id="C88-1048.8">choice</entity> of <entity id="C88-1048.9">parsing</entity> <entity id="C88-1048.10">strategy</entity> plays an important <entity id="C88-1048.11">role</entity> in the <entity id="C88-1048.12">performance</entity> of <entity id="C88-1048.13">natural language</entity> <entity id="C88-1048.14">parsers</entity> . After a <entity id="C88-1048.15">motivation</entity> of the use of various heuristic <entity id="C88-1048.16">criteria</entity> , a <entity id="C88-1048.17">framework</entity> for defining and <entity id="C88-1048.18">testing</entity> ' <entity id="C88-1048.19">parsing</entity> <entity id="C88-1048.20">strategies</entity> is presented. On this <entity id="C88-1048.21">basis</entity> systematic <entity id="C88-1048.22">tests</entity> on different <entity id="C88-1048.23">parsing</entity> <entity id="C88-1048.24">strategies</entity> have been <entity id="C88-1048.25">performed</entity> , the <entity id="C88-1048.26">results</entity> of which are dicussed. Generally ;hese <entity id="C88-1048.27">tests</entity> show that a ""guided"" depth-oriented <entity id="C88-1048.28">strategy</entity> gives a considerable <entity id="C88-1048.29">reduction</entity> of <entity id="C88-1048.30">search</entity> <entity id="C88-1048.31">effort</entity> compared to the classical depth first <entity id="C88-1048.32">strategy</entity> . "
</abstract>


affects(C88-1048.10,C88-1048.12)
study(C88-1048.22,C88-1048.24)

</text>

<text id="C88-2122">
<title><entity id="C88-2122.1">Generating</entity> Multimodal <entity id="C88-2122.2">Output-</entity> Conditions, Advantages And <entity id="C88-2122.3">Problems</entity></title>
<abstract>
"In <entity id="C88-2122.4">natural</entity> <entity id="C88-2122.5">communication</entity> <entity id="C88-2122.6">situations</entity> , multimodal <entity id="C88-2122.7">referent</entity> <entity id="C88-2122.8">specification</entity> is frequent and efficient. The linguistic <entity id="C88-2122.9">component</entity> are deictic <entity id="C88-2122.10">expressions</entity> , e.g. 'this' and 'here'. Extralinguistic <entity id="C88-2122.11">devices</entity> in <entity id="C88-2122.12">dialogs</entity> are different body movements, mainly pointing <entity id="C88-2122.13">gestures</entity> . Their functional equivalent in <entity id="C88-2122.14">texts</entity> are means like arrows and <entity id="C88-2122.15">indices</entity> . This <entity id="C88-2122.16">paper</entity> has two intentions. First, it discusses the <entity id="C88-2122.17">advantages</entity> of multimodal <entity id="C88-2122.18">reference</entity> in interhuman <entity id="C88-2122.19">communication</entity> which motivate the <entity id="C88-2122.20">integration</entity> of extralinguistic ""pointing"" <entity id="C88-2122.21">devices</entity> into NL <entity id="C88-2122.22">dialog systems</entity> . The <entity id="C88-2122.23">generation</entity> of multimodal <entity id="C88-2122.24">output</entity> poses specific <entity id="C88-2122.25">problems</entity> , which have no counterpart in the <entity id="C88-2122.26">analysis</entity> of multimodal <entity id="C88-2122.27">input</entity> . The second <entity id="C88-2122.28">part</entity> presents the <entity id="C88-2122.29">strategy</entity> for <entity id="C88-2122.30">generating</entity> multimodal <entity id="C88-2122.31">output</entity> which has been <entity id="C88-2122.32">developed</entity> within the <entity id="C88-2122.33">framework</entity> of the XTRA <entity id="C88-2122.34">system</entity> (a NL <entity id="C88-2122.35">access</entity> <entity id="C88-2122.36">system</entity> to <entity id="C88-2122.37">expert systems</entity> ). XTRA allows the <entity id="C88-2122.38">combination</entity> of <entity id="C88-2122.39">verbal</entity> <entity id="C88-2122.40">descriptions</entity> and pointing <entity id="C88-2122.41">gestures</entity> in <entity id="C88-2122.42">order</entity> to specify elements of the given visual <entity id="C88-2122.43">context</entity> , i.e. a <entity id="C88-2122.44">form</entity> <entity id="C88-2122.45">displayed</entity> on the <entity id="C88-2122.46">screen</entity> . The <entity id="C88-2122.47">component</entity> POPEL <entity id="C88-2122.48">generates</entity> referential <entity id="C88-2122.49">expressions</entity> which may be accompanied by a pointing <entity id="C88-2122.50">gesture</entity> . The appearance of these <entity id="C88-2122.51">gestures</entity> depends on several <entity id="C88-2122.52">factors</entity> , e.g. the <entity id="C88-2122.53">type</entity> of <entity id="C88-2122.54">referent</entity> (whether it is a <entity id="C88-2122.55">region</entity> or an <entity id="C88-2122.56">entry</entity> of the <entity id="C88-2122.57">form</entity> ) and its <entity id="C88-2122.58">complexity</entity> . "
</abstract>


taskapplied(C88-2122.23,C88-2122.24)
study(C88-2122.26,C88-2122.27)
propose(C88-2122.28,C88-2122.29)
taskapplied(C88-2122.30,C88-2122.31)
taskapplied(C88-2122.47,C88-2122.49)
affects(C88-2122.51,C88-2122.52,REVERSE)

</text>

<text id="C90-1008">
<title><entity id="C90-1008.1">Demonstration</entity> Of GENESYS: A Very Large, Semantically <entity id="C90-1008.2">Based</entity> Systemic Functional <entity id="C90-1008.3">Generator</entity></title>
<abstract>
This <entity id="C90-1008.4">paper</entity> <entity id="C90-1008.5">provides</entity> <entity id="C90-1008.6">background</entity> material to the <entity id="C90-1008.7">demonstration</entity> to be given at COLING '90 of the GENESYS <entity id="C90-1008.8">component</entity> of the COMMUNAL <entity id="C90-1008.9">system</entity> . A presenter of such a <entity id="C90-1008.10">demonstration</entity> should say (1) what the <entity id="C90-1008.11">system</entity> is good for; (2) why it is good for it; and (3) what makes it different from <entity id="C90-1008.12">alternative</entity> <entity id="C90-1008.13">systems</entity> . The <entity id="C90-1008.14">system</entity> to be demonstrated is just a pari (though the single most important <entity id="C90-1008.15">part</entity> ) of a much more <entity id="C90-1008.16">complex</entity> <entity id="C90-1008.17">system</entity> , and some of the answers to the <entity id="C90-1008.18">questions</entity> must be related to the overall <entity id="C90-1008.19">system</entity> . So I shall describe that first, and then the <entity id="C90-1008.20">generator</entity> itself.
</abstract>



</text>

<text id="D08-1048">
<title><entity id="D08-1048.1">Automatic</entity> <entity id="D08-1048.2">induction</entity> of FrameNet <entity id="D08-1048.3">lexical</entity> <entity id="D08-1048.4">units</entity></title>
<abstract>
Most attempts to integrate FrameNet in <entity id="D08-1048.5">NLP systems</entity> have so far failed because of its limited <entity id="D08-1048.6">coverage</entity> . In this <entity id="D08-1048.7">paper</entity> , we investigate the <entity id="D08-1048.8">applicability</entity> of distributional and <entity id="D08-1048.9">WordNet-based <entity id="D08-1048.10">models</entity></entity> on the <entity id="D08-1048.11">task</entity> of <entity id="D08-1048.12">lexical</entity> <entity id="D08-1048.13">unit</entity> <entity id="D08-1048.14">induction</entity> ,
</abstract>


propose(D08-1048.7,D08-1048.9)

</text>

<text id="D08-1060">
<title>
Generalizing Local and Non-Local <entity id="D08-1060.1">Word-</entity> Reordering <entity id="D08-1060.2">Patterns</entity> for <entity id="D08-1060.3">Syntax-</entity> <entity id="D08-1060.4">Based</entity> <entity id="D08-1060.5">Machine Translation</entity></title> 
<abstract><entity id="D08-1060.6">Syntactic</entity> <entity id="D08-1060.7">word</entity> reordering is essential for <entity id="D08-1060.8">translations</entity> across different grammar <entity id="D08-1060.9">structures</entity> between syntactically distant <entity id="D08-1060.10">language-pairs</entity> . In this <entity id="D08-1060.11">paper</entity> , we <entity id="D08-1060.12">propose</entity> to embed local and non-local <entity id="D08-1060.13">word</entity> reordering <entity id="D08-1060.14">decisions</entity> in a <entity id="D08-1060.15">synchronous context free grammar</entity> , and <entity id="D08-1060.16">leverages</entity> the grammar in a chart-based <entity id="D08-1060.17">decoder</entity> . Local <entity id="D08-1060.18">word-reordering</entity> is effectively encoded in Hiero-like <entity id="D08-1060.19">rules</entity> ; whereas non-local <entity id="D08-1060.20">word-reordering</entity> , which allows for long-range movements of <entity id="D08-1060.21">syntactic</entity> <entity id="D08-1060.22">chunks</entity> , is represented in <entity id="D08-1060.23">tree-based</entity> reordering <entity id="D08-1060.24">rules</entity> , which contain <entity id="D08-1060.25">variables</entity> correspond to <entity id="D08-1060.26">source-side</entity> <entity id="D08-1060.27">syntactic</entity> <entity id="D08-1060.28">constituents</entity> . We demonstrate how these <entity id="D08-1060.29">rules</entity> are learned from <entity id="D08-1060.30">parallel <entity id="D08-1060.31">corpora</entity></entity> . Our <entity id="D08-1060.32">proposed</entity> shallow <entity id="D08-1060.33">Tree-to-</entity> <entity id="D08-1060.34">String</entity> <entity id="D08-1060.35">rules</entity> show significant <entity id="D08-1060.36">improvements</entity> in <entity id="D08-1060.37">translation <entity id="D08-1060.38">quality</entity></entity> across different <entity id="D08-1060.39">test sets</entity> .
</abstract>


model(D08-1060.18,D08-1060.19,REVERSE)
datasource(D08-1060.29,D08-1060.30)
wrt(D08-1060.36,D08-1060.37)

</text>

<text id="I05-1060">
<title><entity id="I05-1060.1">Automatic</entity> <entity id="I05-1060.2">Acquisition</entity> of <entity id="I05-1060.3">Basic</entity> Katakana <entity id="I05-1060.4">Lexicon</entity> from a Given <entity id="I05-1060.5">Corpus</entity></title> 
<abstract><entity id="I05-1060.6">Abstract</entity> .
</abstract>


datasource(I05-1060.4,I05-1060.5)

</text>

<text id="I05-1063">
<title>
A Twin- <entity id="I05-1063.1">Candidate</entity> <entity id="I05-1063.2">Model</entity> of <entity id="I05-1063.3">Coreference <entity id="I05-1063.4">Resolution</entity></entity> with Non-Anaphor <entity id="I05-1063.5">Identification</entity> <entity id="I05-1063.6">Capability</entity></title> 
<abstract><entity id="I05-1063.7">Abstract</entity> .
</abstract>


model(I05-1063.2,I05-1063.3)

</text>

<text id="I05-2039">
<title>The <entity id="I05-2039.1">Influence</entity> of <entity id="I05-2039.2">Data</entity> <entity id="I05-2039.3">Homogeneity</entity> on <entity id="I05-2039.4">NLP System</entity> <entity id="I05-2039.5">Performance</entity></title>
<abstract>
In this work we <entity id="I05-2039.6">study</entity> the <entity id="I05-2039.7">influence</entity> of <entity id="I05-2039.8">corpus</entity> <entity id="I05-2039.9">homogeneity</entity> on <entity id="I05-2039.10">corpus-based</entity> <entity id="I05-2039.11">NLP system</entity> <entity id="I05-2039.12">performance</entity> . <entity id="I05-2039.13">Experiments</entity> are <entity id="I05-2039.14">performed</entity> on both stochastic <entity id="I05-2039.15">language <entity id="I05-2039.16">models</entity></entity> and an EBMT <entity id="I05-2039.17">system</entity> <entity id="I05-2039.18">translating</entity> from <entity id="I05-2039.19">Japanese</entity> to <entity id="I05-2039.20">English</entity> with a large bicorpus, in <entity id="I05-2039.21">order</entity> to reassess the <entity id="I05-2039.22">assumption</entity> that using only homogeneous <entity id="I05-2039.23">data</entity> tends to make <entity id="I05-2039.24">system</entity> <entity id="I05-2039.25">performance</entity> go up. We describe a <entity id="I05-2039.26">method</entity> to represent <entity id="I05-2039.27">corpus</entity> <entity id="I05-2039.28">homogeneity</entity> as a <entity id="I05-2039.29">distribution</entity> of <entity id="I05-2039.30">similarity</entity> <entity id="I05-2039.31">coefficients</entity> <entity id="I05-2039.32">based</entity> on a <entity id="I05-2039.33">cross-entropic</entity> measure investigated in previous works. We show that beyond minimal <entity id="I05-2039.34">sizes</entity> of <entity id="I05-2039.35">training</entity> <entity id="I05-2039.36">data</entity> the excessive <entity id="I05-2039.37">elimination</entity> of heterogeneous <entity id="I05-2039.38">data</entity> proves prejudicial in <entity id="I05-2039.39">terms</entity> of both <entity id="I05-2039.40">perplexity</entity> and <entity id="I05-2039.41">translation quality</entity> : excessively restricting the <entity id="I05-2039.42">training</entity> <entity id="I05-2039.43">data</entity> to a particular <entity id="I05-2039.44">domain</entity> may be prejudicial in <entity id="I05-2039.45">terms</entity> of In- <entity id="I05-2039.46">Domain</entity> <entity id="I05-2039.47">system</entity> <entity id="I05-2039.48">performance</entity> , and that heterogeneous, Out-of- <entity id="I05-2039.49">Domain</entity> <entity id="I05-2039.50">data</entity> may in fact contribute to better sytem <entity id="I05-2039.51">performance</entity> .
</abstract>


affects(I05-2039.3,I05-2039.5)
affects(I05-2039.9,I05-2039.12)
methodapplied(I05-2039.13,I05-2039.15)
taskapplied(I05-2039.18,I05-2039.19)
char(I05-2039.34,I05-2039.36)
affects(I05-2039.49,I05-2039.51)

</text>

<text id="I05-2046">
<title>
Using <entity id="I05-2046.1">Maximum Entropy</entity> to <entity id="I05-2046.2">Extract</entity> Biomedical <entity id="I05-2046.3">Named</entity> Entities without Dictionaries
</title>
<abstract><entity id="I05-2046.4">Current</entity> NER <entity id="I05-2046.5">approaches</entity> <entity id="I05-2046.6">include</entity> : <entity id="I05-2046.7">dictionary-based</entity> , <entity id="I05-2046.8">rule-based</entity> , or <entity id="I05-2046.9">machine learning</entity> . Since there is no consolidated nomenclature for most biomedical NEs, most NER <entity id="I05-2046.10">systems</entity> relying on limited <entity id="I05-2046.11">dictionaries</entity> or <entity id="I05-2046.12">rules</entity> do not <entity id="I05-2046.13">perform</entity> satisfactorily. In this <entity id="I05-2046.14">paper</entity> , we <entity id="I05-2046.15">apply</entity> <entity id="I05-2046.16">Maximum <entity id="I05-2046.17">Entropy</entity></entity> (ME) to <entity id="I05-2046.18">construct</entity> our NER <entity id="I05-2046.19">framework</entity> . We represent shallow <entity id="I05-2046.20">linguistic information</entity> as <entity id="I05-2046.21">linguistic features</entity> in our ME <entity id="I05-2046.22">model</entity> . On the GENIA 3.02 <entity id="I05-2046.23">corpus</entity> , our <entity id="I05-2046.24">system</entity> achieves satisfactory F-scores of 74.3% in <entity id="I05-2046.25">protein</entity> and 70.0% overall without using any <entity id="I05-2046.26">dictionary</entity> . Our <entity id="I05-2046.27">system</entity> <entity id="I05-2046.28">performs</entity> significantly better than <entity id="I05-2046.29"><entity id="I05-2046.30">dictionary-based</entity> <entity id="I05-2046.31">systems</entity></entity> . Using <entity id="I05-2046.32">partial</entity> <entity id="I05-2046.33">match</entity> <entity id="I05-2046.34">criteria</entity> , our <entity id="I05-2046.35">system</entity> achieves an F-score of 81.3%. Using appropriate <entity id="I05-2046.36">domain knowledge</entity> to modify the <entity id="I05-2046.37">boundaries</entity> , our <entity id="I05-2046.38">system</entity> has the potential to achieve an F-score of over 80%.
</abstract>


based_on(I05-2046.10,I05-2046.11)
based_on(I05-2046.16,I05-2046.19,REVERSE)
compare(I05-2046.27,I05-2046.29)

</text>

<text id="I05-3016">
<title>
Resolving Pronominal References in <entity id="I05-3016.1">Chinese</entity> with the Hobbs <entity id="I05-3016.2">Algorithm</entity></title>
<abstract>
"This <entity id="I05-3016.3">study</entity> addresses pronominal <entity id="I05-3016.4">anaphora <entity id="I05-3016.5">resolution</entity></entity> , <entity id="I05-3016.6">including</entity> zero pronouns, in <entity id="I05-3016.7">Chinese</entity> . A <entity id="I05-3016.8">syntactic</entity> , <entity id="I05-3016.9">rule-based</entity> pronoun <entity id="I05-3016.10">resolution</entity> <entity id="I05-3016.11">algorithm</entity> , the ""Hobbs <entity id="I05-3016.12">algorithm</entity> "" was run on ""<entity id="I05-3016.13">gold <entity id="I05-3016.14">standard</entity></entity> "" <entity id="I05-3016.15">hand</entity> <entity id="I05-3016.16">parses</entity> from the Penn <entity id="I05-3016.17">Chinese</entity> Treebank. While first <entity id="I05-3016.18">proposed</entity> for <entity id="I05-3016.19">English</entity> , the <entity id="I05-3016.20">algorithm</entity> counts for its <entity id="I05-3016.21">success</entity> on two <entity id="I05-3016.22">characteristics</entity> that <entity id="I05-3016.23">Chinese</entity> and <entity id="I05-3016.24">English</entity> have in <entity id="I05-3016.25">common</entity> . Both <entity id="I05-3016.26">languages</entity> are SVO, and both are fixed <entity id="I05-3016.27">word</entity> <entity id="I05-3016.28">order</entity> <entity id="I05-3016.29">languages</entity> . No changes were made to <entity id="I05-3016.30">adapt</entity> the <entity id="I05-3016.31">algorithm</entity> to <entity id="I05-3016.32">Chinese</entity> . The <entity id="I05-3016.33">accuracy</entity> of the <entity id="I05-3016.34">algorithm</entity> on overt, third-person pronouns at the <entity id="I05-3016.35">matrix</entity> <entity id="I05-3016.36">level</entity> was 77.6%, and the <entity id="I05-3016.37">accuracy</entity> for resolving <entity id="I05-3016.38">matrix-level</entity> zero pronouns was 73.3%. In <entity id="I05-3016.39">contrast</entity> , the <entity id="I05-3016.40">accuracy</entity> of the <entity id="I05-3016.41">algorithm</entity> on pronouns that appeared in subordinate <entity id="I05-3016.42">constructions</entity> was only 43.3%, <entity id="I05-3016.43">providing</entity> <entity id="I05-3016.44">support</entity> for Miltsakaki 's <entity id="I05-3016.45">two-mechanism</entity> <entity id="I05-3016.46">proposal</entity> for resolving inter- vs. "
</abstract>


propose(I05-3016.3,I05-3016.4)
methodapplied(I05-3016.12,I05-3016.13)
based_on(I05-3016.20,I05-3016.22)
char(I05-3016.26,I05-3016.28,REVERSE)
yields(I05-3016.33,I05-3016.34,REVERSE)
yields(I05-3016.40,I05-3016.41,REVERSE)

</text>

<text id="I05-3034">
<title><entity id="I05-3034.1">Chinese <entity id="I05-3034.2">Word Segmentation</entity></entity> <entity id="I05-3034.3">Based</entity> On Direct <entity id="I05-3034.4">Maximum <entity id="I05-3034.5">Entropy</entity> <entity id="I05-3034.6">Model</entity></entity></title>
<abstract>
	Och, Franz Josef ; Ney , Hermann ,Discriminative <entity id="I05-3034.7">Training</entity> And <entity id="I05-3034.8">Maximum <entity id="I05-3034.9">Entropy</entity></entity> <entity id="I05-3034.10">Models</entity> For <entity id="I05-3034.11">Statistical <entity id="I05-3034.12">Machine Translation</entity></entity> ,Annual Meeting Of The <entity id="I05-3034.13">Association</entity> For <entity id="I05-3034.14">Computation</entity> al <entity id="I05-3034.15">Linguistics</entity> ,2002 *** Gao , Jianfeng ; Li , Mu; Huang , Changning,Improved <entity id="I05-3034.16">Source-</entity> <entity id="I05-3034.17">Channel</entity> <entity id="I05-3034.18">Models</entity> For <entity id="I05-3034.19">Chinese <entity id="I05-3034.20">Word Segmentation</entity></entity> ,Annual Meeting Of The <entity id="I05-3034.21">Association</entity> For <entity id="I05-3034.22">Computation</entity> al <entity id="I05-3034.23">Linguistics</entity> ,2003</abstract>


based_on(I05-3034.1,I05-3034.4)
usedfor(I05-3034.8,I05-3034.11)
usedfor(I05-3034.18,I05-3034.19)

</text>

<text id="E03-1088">
<title>
Linguistic <entity id="E03-1088.1">Variation</entity> And <entity id="E03-1088.2">Computation</entity> (Invited Talk)
</title>
<abstract><entity id="E03-1088.3">Language</entity> variationists <entity id="E03-1088.4">study</entity> how <entity id="E03-1088.5">languages</entity> vary along geographical or social lines or along lines of age and <entity id="E03-1088.6">gender</entity> . Variationist <entity id="E03-1088.7">data</entity> is available and <entity id="E03-1088.8">challenging</entity> , in particular for dialectology, the <entity id="E03-1088.9">study</entity> of geographical <entity id="E03-1088.10">variation</entity> , which will be the <entity id="E03-1088.11">focus</entity> of this <entity id="E03-1088.12">paper</entity> , although we present <entity id="E03-1088.13">approaches</entity> we expect to <entity id="E03-1088.14">transfer</entity> smoothly to the <entity id="E03-1088.15">study</entity> of <entity id="E03-1088.16">variation</entity> correlating with other extralinguistic <entity id="E03-1088.17">variables</entity> . <entity id="E03-1088.18">Techniques</entity> from <entity id="E03-1088.19">computational linguistics</entity> on the one <entity id="E03-1088.20">hand</entity> , and <entity id="E03-1088.21">standard</entity> <entity id="E03-1088.22">statistical</entity> <entity id="E03-1088.23">data</entity> <entity id="E03-1088.24">reduction</entity> <entity id="E03-1088.25">techniques</entity> on the other, not only shed light on this classic linguistic <entity id="E03-1088.26">problem</entity> , but they also suggest avenues for exploring the <entity id="E03-1088.27">question</entity> at more <entity id="E03-1088.28">abstract</entity> <entity id="E03-1088.29">levels</entity> , and perhaps for seeking the determinants of <entity id="E03-1088.30">variation</entity> .
</abstract>


propose(E03-1088.10,E03-1088.12,REVERSE)

</text>

<text id="E06-1010">
<title>
Constraints On Non-Projective <entity id="E06-1010.1">Dependency</entity> <entity id="E06-1010.2">Parsing</entity></title>
<abstract>
We investigate a <entity id="E06-1010.3">series</entity> of graph-theoretic <entity id="E06-1010.4">constraints</entity> on non-projective <entity id="E06-1010.5">dependency</entity> <entity id="E06-1010.6">parsing</entity> and their <entity id="E06-1010.7">effect</entity> on expressivity, <entity id="E06-1010.8">efficiency</entity> , <entity id="E06-1010.9">degree</entity></abstract>



</text>

<text id="C96-2164">
<title>
A <entity id="C96-2164.1">Method</entity> For Abstracting <entity id="C96-2164.2">Newspaper</entity> Articles By Using <entity id="C96-2164.3">Surface</entity> Clues
</title>
<abstract>
This <entity id="C96-2164.4">paper</entity> describes a <entity id="C96-2164.5">system</entity> which automatically creates an <entity id="C96-2164.6">abstract</entity> of a <entity id="C96-2164.7">newspaper</entity> article by selecting important <entity id="C96-2164.8">sentences</entity> of a given <entity id="C96-2164.9">text</entity> . To determine the <entity id="C96-2164.10">importance</entity> of a <entity id="C96-2164.11">sentence</entity> , several superficial <entity id="C96-2164.12">features</entity> are considered, and <entity id="C96-2164.13">weights</entity> for <entity id="C96-2164.14">features</entity> are determined by <entity id="C96-2164.15">multiple-regression</entity> <entity id="C96-2164.16">analysis</entity> of a <entity id="C96-2164.17">hand</entity> <entity id="C96-2164.18">processed</entity> <entity id="C96-2164.19">corpus</entity> .
</abstract>


propose(C96-2164.4,C96-2164.5)
model(C96-2164.6,C96-2164.7)
part_of(C96-2164.8,C96-2164.9)
study(C96-2164.16,C96-2164.19)

</text>

<text id="C00-1036">
<title>
XML And Multilingual <entity id="C00-1036.1">Document</entity> Authoring: Convergent Trends
</title>
<abstract>
Typical <entity id="C00-1036.2">approaches</entity> to XML authoring view a XML <entity id="C00-1036.3">document</entity> as a <entity id="C00-1036.4">mixture</entity> of <entity id="C00-1036.5">structure</entity> (the <entity id="C00-1036.6">tags</entity> ) and <entity id="C00-1036.7">surface</entity> ( <entity id="C00-1036.8">text</entity> between the <entity id="C00-1036.9">tags</entity> ). We advocate a radical <entity id="C00-1036.10">approach</entity> where the <entity id="C00-1036.11">surface</entity> disappears from the XML <entity id="C00-1036.12">document</entity> altogether to be handled exclusively by rendering <entity id="C00-1036.13">mechanisms</entity> . This move is <entity id="C00-1036.14">based</entity> on the view that the author's <entity id="C00-1036.15">choices</entity> when authoring XML <entity id="C00-1036.16">documents</entity> are best seen as <entity id="C00-1036.17">language-neutral</entity> <entity id="C00-1036.18">semantic</entity> <entity id="C00-1036.19">decisions</entity> , that the <entity id="C00-1036.20">structure</entity> can then be viewed as interlingual <entity id="C00-1036.21">content</entity> , and that the textual <entity id="C00-1036.22">output</entity> should be derived from this <entity id="C00-1036.23">content</entity> by <entity id="C00-1036.24">language-specific</entity> <entity id="C00-1036.25">realization</entity> <entity id="C00-1036.26">mechanisms</entity> , thus assimilating XML authoring to Multilingual <entity id="C00-1036.27">Document</entity> Authoring. However, <entity id="C00-1036.28">standard</entity> XML <entity id="C00-1036.29">tools</entity> have important <entity id="C00-1036.30">limitations</entity> when used for such a <entity id="C00-1036.31">purpose</entity> : (1) they are weak at propagating <entity id="C00-1036.32">semantic</entity> <entity id="C00-1036.33">dependencies</entity> between different <entity id="C00-1036.34">parts</entity> of the <entity id="C00-1036.35">structure</entity> , and, (2) <entity id="C00-1036.36">current</entity> XML rendering <entity id="C00-1036.37">tools</entity> are ill-suited for handling the grammatical <entity id="C00-1036.38">combination</entity> of textual <entity id="C00-1036.39">units</entity> . We present two related <entity id="C00-1036.40">proposals</entity> for overcoming these <entity id="C00-1036.41">limitations</entity> : one (GF) originating in the tradition of mathematical proof editors and constructive <entity id="C00-1036.42">type</entity> <entity id="C00-1036.43">theory</entity> , the other (IG), a specialization of Definite <entity id="C00-1036.44">Clause</entity> Grammars strongly inspired by GF.
</abstract>


methodapplied(C00-1036.11,C00-1036.13,REVERSE)
datasource(C00-1036.22,C00-1036.23)
problem(C00-1036.29,C00-1036.30,REVERSE)

</text>

<text id="C02-1041">
<title><entity id="C02-1041.1">Automatic</entity> <entity id="C02-1041.2">Semantic</entity> Grouping In A <entity id="C02-1041.3">Spoken Language</entity> <entity id="C02-1041.4">User Interface</entity> Toolkit
</title>
<abstract>
With the rapid growth of real <entity id="C02-1041.5">application</entity> <entity id="C02-1041.6">domains</entity> for <entity id="C02-1041.7">NLP systems</entity> , there is a genuine demand for a general toolkit from which programmers with no <entity id="C02-1041.8">linguistic knowledge</entity> can build specific <entity id="C02-1041.9">NLP systems</entity> . Such a toolkit should <entity id="C02-1041.10">provide</entity> an <entity id="C02-1041.11">interface</entity> to accept <entity id="C02-1041.12">sample</entity> <entity id="C02-1041.13">sentences</entity> and convert them into <entity id="C02-1041.14">semantic <entity id="C02-1041.15">representations</entity></entity> so as to allow programmers to <entity id="C02-1041.16">map</entity> them to <entity id="C02-1041.17">domain</entity> <entity id="C02-1041.18">actions</entity> . In <entity id="C02-1041.19">order</entity> to reduce the workload of managing a large <entity id="C02-1041.20">number</entity> of <entity id="C02-1041.21">semantic</entity> <entity id="C02-1041.22">forms</entity> individually, the toolkit will <entity id="C02-1041.23">perform</entity> what we <entity id="C02-1041.24">call</entity> <entity id="C02-1041.25">semantic</entity> grouping to organize the <entity id="C02-1041.26">forms</entity> into meaningful groups. In this <entity id="C02-1041.27">paper</entity> , we present three <entity id="C02-1041.28">semantic</entity> grouping <entity id="C02-1041.29">methods</entity> : <entity id="C02-1041.30">similarity-based</entity> , <entity id="C02-1041.31">verb-based</entity> and <entity id="C02-1041.32">category-based</entity> grouping, and their <entity id="C02-1041.33">implementation</entity> in the SLUI toolkit. We also discuss the pros and <entity id="C02-1041.34">cons</entity> of each <entity id="C02-1041.35">method</entity> and how they can be utilized according to the different <entity id="C02-1041.36">domain</entity> needs.
</abstract>


model(C02-1041.13,C02-1041.14,REVERSE)
propose(C02-1041.27,C02-1041.29)

</text>

<text id="C02-1129">
<title><entity id="C02-1129.1">Decision</entity> Trees As Explicit <entity id="C02-1129.2">Domain</entity> <entity id="C02-1129.3">Term</entity> Definitions
</title>
<abstract><entity id="C02-1129.4">Terminology</entity> <entity id="C02-1129.5">Acquisition</entity> (TA) <entity id="C02-1129.6">knowledge</entity> bottleneck
</abstract>



</text>

<text id="E89-1008">
<title>
Paradigmatic <entity id="E89-1008.1">Morphology</entity></title>
<abstract>
We present a <entity id="E89-1008.2">notation</entity> for the declarative statement of morphological <entity id="E89-1008.3">relationships</entity> and <entity id="E89-1008.4">lexical</entity> <entity id="E89-1008.5">rules</entity> , <entity id="E89-1008.6">based</entity> on the traditional <entity id="E89-1008.7">notion</entity> of <entity id="E89-1008.8">Word</entity> and <entity id="E89-1008.9">Paradigm</entity> Elsewhere Condition, <entity id="E89-1008.10">string</entity> <entity id="E89-1008.11">equations</entity></abstract>


tag(E89-1008.2,E89-1008.3)

</text>

<text id="E99-1022">
<title>
Selective Magic HPSG <entity id="E99-1022.1">Parsing</entity></title>
<abstract>
We <entity id="E99-1022.2">propose</entity> a <entity id="E99-1022.3">parser</entity> for <entity id="E99-1022.4">constraint-logic</entity> grammars <entity id="E99-1022.5">implementing</entity> HPSG that combines the <entity id="E99-1022.6">advantages</entity> of dynamic bottom-up and <entity id="E99-1022.7">advanced</entity> top-down <entity id="E99-1022.8">control</entity> . The <entity id="E99-1022.9">parser</entity> allows the <entity id="E99-1022.10">user</entity> to <entity id="E99-1022.11">apply</entity> magic <entity id="E99-1022.12">compilation</entity> to specific <entity id="E99-1022.13">constraints</entity> in a grammar which as a <entity id="E99-1022.14">result</entity> can be <entity id="E99-1022.15">processed</entity> dynamically in a bottom-up and <entity id="E99-1022.16">goal-directed</entity> <entity id="E99-1022.17">fashion</entity> . State of the art top-down <entity id="E99-1022.18">processing</entity> <entity id="E99-1022.19">techniques</entity> are used to <entity id="E99-1022.20">deal</entity> with the remaining <entity id="E99-1022.21">constraints</entity> . We discuss various <entity id="E99-1022.22">aspects</entity> <entity id="E99-1022.23">concerning</entity> the <entity id="E99-1022.24">implementation</entity> of the <entity id="E99-1022.25">parser</entity> as <entity id="E99-1022.26">part</entity> of a grammar <entity id="E99-1022.27">development</entity> <entity id="E99-1022.28">system</entity> .
</abstract>


based_on(E99-1022.3,E99-1022.8)
methodapplied(E99-1022.12,E99-1022.13)
methodapplied(E99-1022.18,E99-1022.21)
part_of(E99-1022.25,E99-1022.28)

</text>

<text id="E99-1023">
<title>
Representing <entity id="E99-1023.1">Text</entity> Chunks
</title>
<abstract>
"Dividing <entity id="E99-1023.2">sentences</entity> in <entity id="E99-1023.3">chunks</entity> of <entity id="E99-1023.4">words</entity> is a useful preprocessing <entity id="E99-1023.5">step</entity> for <entity id="E99-1023.6">parsing</entity> , <entity id="E99-1023.7">information extraction</entity> and <entity id="E99-1023.8">information retrieval</entity> . ( Ramshaw and  Marcus, 1995 ) have introduced a ""convenient""<entity id="E99-1023.9">data</entity> <entity id="E99-1023.10">representation</entity> for <entity id="E99-1023.11">chunking</entity> by converting it to a <entity id="E99-1023.12">tagging</entity> <entity id="E99-1023.13">task</entity> . In this <entity id="E99-1023.14">paper</entity> we will examine seven different <entity id="E99-1023.15">data</entity> <entity id="E99-1023.16">representations</entity> for the <entity id="E99-1023.17">problem</entity> of recognizing <entity id="E99-1023.18">noun phrase</entity> <entity id="E99-1023.19">chunks</entity> . We will show that the the <entity id="E99-1023.20">data</entity> <entity id="E99-1023.21">representation</entity> <entity id="E99-1023.22">choice</entity> has a minor <entity id="E99-1023.23">influence</entity> on <entity id="E99-1023.24">chunking</entity> <entity id="E99-1023.25">performance</entity> . However, equipped with the most suitable <entity id="E99-1023.26">data</entity> <entity id="E99-1023.27">representation</entity> , our <entity id="E99-1023.28">memory-based</entity> <entity id="E99-1023.29">learning</entity> chunker was able to <entity id="E99-1023.30">improve</entity> the best published <entity id="E99-1023.31">chunking</entity> <entity id="E99-1023.32">results</entity> for a <entity id="E99-1023.33">standard</entity> <entity id="E99-1023.34">data</entity> set."
</abstract>


phenomenon(E99-1023.2,E99-1023.4,REVERSE)
propose(E99-1023.9,E99-1023.10)
study(E99-1023.14,E99-1023.16)
affects(E99-1023.22,E99-1023.25)

</text>

<text id="E99-1024">
<title><entity id="E99-1024.1">Detection</entity> Of <entity id="E99-1024.2">Japanese</entity> Homophone Errors By A <entity id="E99-1024.3">Decision</entity> <entity id="E99-1024.4">List</entity> Including A Written <entity id="E99-1024.5">Word</entity> As A <entity id="E99-1024.6">Default</entity> <entity id="E99-1024.7">Evidence</entity></title>
<abstract>
In this <entity id="E99-1024.8">paper</entity> , we <entity id="E99-1024.9">propose</entity> a practical <entity id="E99-1024.10">method</entity> to detect <entity id="E99-1024.11">Japanese</entity> homophone <entity id="E99-1024.12">errors</entity> in <entity id="E99-1024.13">Japanese</entity> <entity id="E99-1024.14">texts</entity> . It is very important to detect homophone <entity id="E99-1024.15">errors</entity> in <entity id="E99-1024.16">Japanese</entity> <entity id="E99-1024.17">revision</entity> <entity id="E99-1024.18">systems</entity> because <entity id="E99-1024.19">Japanese</entity> <entity id="E99-1024.20">texts</entity> suffer from homophone <entity id="E99-1024.21">errors</entity> frequently. In <entity id="E99-1024.22">order</entity> to detect homophone <entity id="E99-1024.23">errors</entity> , we have only to <entity id="E99-1024.24">solve</entity> the homophone <entity id="E99-1024.25">problem</entity> . We can use the <entity id="E99-1024.26">decision</entity> <entity id="E99-1024.27">list</entity> to do it because the homophone <entity id="E99-1024.28">problem</entity> is equivalent to the <entity id="E99-1024.29">word sense disambiguation</entity> <entity id="E99-1024.30">problem</entity> . However, the homophone <entity id="E99-1024.31">problem</entity> is different from the <entity id="E99-1024.32">word sense disambiguation</entity> <entity id="E99-1024.33">problem</entity> because the former can use the written <entity id="E99-1024.34">word</entity> but the latter cannot. In this <entity id="E99-1024.35">paper</entity> , we incorporate the written <entity id="E99-1024.36">word</entity> into the original <entity id="E99-1024.37">decision</entity> <entity id="E99-1024.38">list</entity> by obtaining the identifying <entity id="E99-1024.39">strength</entity> of the written <entity id="E99-1024.40">word</entity> . The <entity id="E99-1024.41">improved</entity> <entity id="E99-1024.42">decision</entity> <entity id="E99-1024.43">list</entity> can raise the F-measure of <entity id="E99-1024.44">error</entity> <entity id="E99-1024.45">detection</entity> .
</abstract>


composed_of(E99-1024.4,E99-1024.5)
methodapplied(E99-1024.10,E99-1024.12)
phenomenon(E99-1024.15,E99-1024.17)
phenomenon(E99-1024.20,E99-1024.21,REVERSE)
composed_of(E99-1024.36,E99-1024.38,REVERSE)
char(E99-1024.39,E99-1024.40)
wrt(E99-1024.43,E99-1024.45,REVERSE)

</text>

<text id="E99-1025">
<title>
New <entity id="E99-1025.1">Models</entity> For Improving Supertag <entity id="E99-1025.2">Disambiguation</entity></title>
<abstract>
In previous work, supertag <entity id="E99-1025.3">disambiguation</entity> has been presented as a <entity id="E99-1025.4">robust</entity> <entity id="E99-1025.5">partial</entity> <entity id="E99-1025.6">parsing</entity> <entity id="E99-1025.7">technique</entity> . In this <entity id="E99-1025.8">paper</entity> we present two <entity id="E99-1025.9">approaches</entity> : contextual <entity id="E99-1025.10">models</entity> , which exploit a <entity id="E99-1025.11">variety</entity> of <entity id="E99-1025.12">features</entity> in <entity id="E99-1025.13">order</entity> to <entity id="E99-1025.14">improve</entity> supertag <entity id="E99-1025.15">performance</entity> , and <entity id="E99-1025.16">class-based models</entity> , which assign sets of supertags to <entity id="E99-1025.17">words</entity> in <entity id="E99-1025.18">order</entity> to substantially <entity id="E99-1025.19">improve</entity> <entity id="E99-1025.20">accuracy</entity> with only a slight <entity id="E99-1025.21">increase</entity> in <entity id="E99-1025.22">ambiguity</entity> .
</abstract>


usedfor(E99-1025.1,E99-1025.2)
isa(E99-1025.3,E99-1025.7)
propose(E99-1025.8,E99-1025.10,REVERSE)
affects(E99-1025.12,E99-1025.15)
methodapplied(E99-1025.16,E99-1025.17)
wrt(E99-1025.20,E99-1025.22)

</text>

<text id="E99-1026">
<title><entity id="E99-1026.1">Japanese</entity> <entity id="E99-1026.2">Dependency Structure</entity> <entity id="E99-1026.3">Analysis</entity> <entity id="E99-1026.4">Based</entity> On <entity id="E99-1026.5">Maximum Entropy</entity> <entity id="E99-1026.6">Models</entity></title>
<abstract>
This <entity id="E99-1026.7">paper</entity> describes a <entity id="E99-1026.8">dependency structure</entity> <entity id="E99-1026.9">analysis</entity> of <entity id="E99-1026.10">Japanese</entity> <entity id="E99-1026.11">sentences</entity> <entity id="E99-1026.12">based</entity> on the <entity id="E99-1026.13">maximum entropy models</entity> . Our <entity id="E99-1026.14">model</entity> is created by learning the <entity id="E99-1026.15">weights</entity> of some <entity id="E99-1026.16">features</entity> from a <entity id="E99-1026.17">training corpus</entity> to predict the <entity id="E99-1026.18">dependency</entity> between bunsetsus or phrasal <entity id="E99-1026.19">units</entity> . The <entity id="E99-1026.20">dependency</entity> <entity id="E99-1026.21">accuracy</entity> of our <entity id="E99-1026.22">system</entity> is 87.2% using the Kyoto <entity id="E99-1026.23">University</entity> <entity id="E99-1026.24">corpus</entity> . We discuss the <entity id="E99-1026.25">contribution</entity> of each <entity id="E99-1026.26">feature set</entity> and the <entity id="E99-1026.27">relationship</entity> between the <entity id="E99-1026.28">number</entity> of <entity id="E99-1026.29">training</entity> <entity id="E99-1026.30">data</entity> and the <entity id="E99-1026.31">accuracy</entity> .
</abstract>


based_on(E99-1026.3,E99-1026.6)
propose(E99-1026.7,E99-1026.9)
based_on(E99-1026.14,E99-1026.15)
char(E99-1026.21,E99-1026.22)
wrt(E99-1026.30,E99-1026.31,REVERSE)

</text>

<text id="P06-1043">
<title>
Reranking And Self- <entity id="P06-1043.1">Training</entity> For <entity id="P06-1043.2">Parser</entity> <entity id="P06-1043.3">Adaptation</entity></title>
<abstract>
"<entity id="P06-1043.4">Statistical</entity> " <entity id="P06-1043.5">parsers</entity> <entity id="P06-1043.6">trained</entity> and <entity id="P06-1043.7">tested</entity> on the Penn <entity id="P06-1043.8">Wall Street Journal</entity> (wsj) treebank have shown vast <entity id="P06-1043.9">improvements</entity> over the last 10 years. Much of this <entity id="P06-1043.10">improvement</entity> , however, is <entity id="P06-1043.11">based</entity> upon an ever-increasing <entity id="P06-1043.12">number</entity> of <entity id="P06-1043.13">features</entity> to be <entity id="P06-1043.14">trained</entity> on (typically) the wsj treebank <entity id="P06-1043.15">data</entity> . This has led to <entity id="P06-1043.16">concern</entity> that such <entity id="P06-1043.17">parsers</entity> may be too finely tuned to this <entity id="P06-1043.18">corpus</entity> at the expense of <entity id="P06-1043.19">portability</entity> to other <entity id="P06-1043.20">genres</entity> . Such worries have merit. The <entity id="P06-1043.21">standard</entity> ""Charniak <entity id="P06-1043.22">parser</entity> "" <entity id="P06-1043.23">checks</entity> in at a labeled <entity id="P06-1043.24">precision-recall</entity> f-measure of 89.7% on the Penn WSJ <entity id="P06-1043.25">test set</entity> , but only 82.9% on the <entity id="P06-1043.26">test set</entity> from the Brown treebank <entity id="P06-1043.27">corpus</entity> . This <entity id="P06-1043.28">paper</entity> should allay these fears. In particular, we show that the reranking <entity id="P06-1043.29">parser</entity> described in Charniak and Johnson (2005) <entity id="P06-1043.30">improves</entity> <entity id="P06-1043.31">performance</entity> of the <entity id="P06-1043.32">parser</entity> on Brown to 85.2%. Furthermore, use of the <entity id="P06-1043.33">self-training</entity> <entity id="P06-1043.34">techniques</entity> described in ( McClosky et al., 2006 ) raise this to 87.8% (an <entity id="P06-1043.35">error</entity> <entity id="P06-1043.36">reduction</entity> of 28%) again without any use of labeled Brown <entity id="P06-1043.37">data</entity> . This is remarkable since <entity id="P06-1043.38">training</entity> the <entity id="P06-1043.39">parser</entity> and reranker on labeled Brown <entity id="P06-1043.40">data</entity> achieves only 88.4%. "
</abstract>


based_on(P06-1043.5,P06-1043.8)
based_on(P06-1043.10,P06-1043.13)
based_on(P06-1043.17,P06-1043.18)

</text>

<text id="P06-1044">
<title><entity id="P06-1044.1">Automatic</entity> <entity id="P06-1044.2">Classification</entity> Of Verbs In Biomedical <entity id="P06-1044.3">Texts</entity></title> 
<abstract><entity id="P06-1044.4">Lexical</entity> <entity id="P06-1044.5">classes</entity> , when tailored to the <entity id="P06-1044.6">application</entity> and <entity id="P06-1044.7">domain</entity> in <entity id="P06-1044.8">question</entity> , can <entity id="P06-1044.9">provide</entity> an effective means to <entity id="P06-1044.10">deal</entity> with a <entity id="P06-1044.11">number</entity> of <entity id="P06-1044.12">natural language processing</entity> (nlp) <entity id="P06-1044.13">tasks</entity> . While <entity id="P06-1044.14">manual</entity> <entity id="P06-1044.15">construction</entity> of such <entity id="P06-1044.16">classes</entity> is difficult, recent <entity id="P06-1044.17">research</entity> shows that it is possible to automatically induce <entity id="P06-1044.18">verb <entity id="P06-1044.19">classes</entity></entity> from <entity id="P06-1044.20">cross-domain</entity> <entity id="P06-1044.21">corpora</entity> with promising <entity id="P06-1044.22">accuracy</entity> . We <entity id="P06-1044.23">report</entity> a novel <entity id="P06-1044.24">experiment</entity> where similar <entity id="P06-1044.25">technology</entity> is <entity id="P06-1044.26">applied</entity> to the important, <entity id="P06-1044.27">challenging</entity> <entity id="P06-1044.28">domain</entity> of biomedicine. We show that the <entity id="P06-1044.29">resulting</entity> <entity id="P06-1044.30">classification</entity> , acquired from a <entity id="P06-1044.31">corpus</entity> of biomedical <entity id="P06-1044.32">journal</entity> articles, is highly accurate and strongly <entity id="P06-1044.33">domain-specific</entity> . It can be used to aid bio-nlp directly or as useful material for investigating the <entity id="P06-1044.34">syntax</entity> and <entity id="P06-1044.35">semantics</entity> of <entity id="P06-1044.36">verbs</entity> in biomedical <entity id="P06-1044.37">texts</entity> .
</abstract>


taskapplied(P06-1044.2,P06-1044.3)
taskapplied(P06-1044.15,P06-1044.16)
datasource(P06-1044.18,P06-1044.21)
methodapplied(P06-1044.25,P06-1044.28)
based_on(P06-1044.30,P06-1044.31)
datasource(P06-1044.36,P06-1044.37)

</text>

<text id="P06-1082">
<title><entity id="P06-1082.1">Word Alignment</entity> In <entity id="P06-1082.2">English-</entity> Hindi <entity id="P06-1082.3">Parallel Corpus</entity> Using Recency- <entity id="P06-1082.4">Vector</entity> <entity id="P06-1082.5">Approach</entity> : Some <entity id="P06-1082.6">Studies</entity></title> 
<abstract><entity id="P06-1082.7">Word alignment</entity> using <entity id="P06-1082.8">recency-vector</entity> <entity id="P06-1082.9">based</entity> <entity id="P06-1082.10">approach</entity> has recently become popular. One major <entity id="P06-1082.11">advantage</entity> of these <entity id="P06-1082.12">techniques</entity> is that unlike other <entity id="P06-1082.13">approaches</entity> they <entity id="P06-1082.14">perform</entity> well even if the <entity id="P06-1082.15">size</entity> of the <entity id="P06-1082.16">parallel corpora</entity> is small. This makes these <entity id="P06-1082.17">algorithms</entity> worth-studying for <entity id="P06-1082.18">languages</entity> where <entity id="P06-1082.19">resources</entity> are scarce. In this work we <entity id="P06-1082.20">studied</entity> the <entity id="P06-1082.21">performance</entity> of two very popular <entity id="P06-1082.22">recency-vector</entity> <entity id="P06-1082.23">based</entity> <entity id="P06-1082.24">approaches</entity> , <entity id="P06-1082.25">proposed</entity> in ( Fung and  McKeown, 1994 ) and ( Somers, 1998 ), respectively, for <entity id="P06-1082.26">word <entity id="P06-1082.27">alignment</entity></entity> in <entity id="P06-1082.28">English</entity> - Hindi <entity id="P06-1082.29">parallel corpus</entity> . But <entity id="P06-1082.30">performance</entity> of the above <entity id="P06-1082.31">algorithms</entity> was not found to be satisfactory. However, subsequent <entity id="P06-1082.32">addition</entity> of some new <entity id="P06-1082.33">constraints</entity> <entity id="P06-1082.34">improved</entity> the <entity id="P06-1082.35">performance</entity> of the <entity id="P06-1082.36">recency-vector</entity> <entity id="P06-1082.37">based</entity> <entity id="P06-1082.38">alignment</entity> <entity id="P06-1082.39">technique</entity> significantly for the said <entity id="P06-1082.40">corpus</entity> . The present <entity id="P06-1082.41">paper</entity> discusses the new <entity id="P06-1082.42">version</entity> of the <entity id="P06-1082.43">algorithm</entity> and its <entity id="P06-1082.44">performance</entity> in <entity id="P06-1082.45">detail</entity> .
</abstract>


taskapplied(P06-1082.26,P06-1082.28)
propose(P06-1082.41,P06-1082.43)

</text>

<text id="P06-1097">
<title>
Semi-Supervised <entity id="P06-1097.1">Training</entity> For <entity id="P06-1097.2">Statistical</entity> <entity id="P06-1097.3">Word Alignment</entity></title>
<abstract>
We introduce a semi-supervised <entity id="P06-1097.4">approach</entity> to <entity id="P06-1097.5">training</entity> for <entity id="P06-1097.6">statistical <entity id="P06-1097.7">machine translation</entity></entity> that alternates the traditional <entity id="P06-1097.8">Expectation</entity> <entity id="P06-1097.9">Maximization</entity> <entity id="P06-1097.10">step</entity> that is <entity id="P06-1097.11">applied</entity> on a large <entity id="P06-1097.12">training <entity id="P06-1097.13">corpus</entity></entity> with a discriminative <entity id="P06-1097.14">step</entity> aimed at <entity id="P06-1097.15">increasing</entity> <entity id="P06-1097.16">word-alignment</entity> <entity id="P06-1097.17">quality</entity> on a small, manually <entity id="P06-1097.18">word-aligned</entity> <entity id="P06-1097.19">sub-corpus</entity> . We show that our <entity id="P06-1097.20">algorithm</entity> leads not only to <entity id="P06-1097.21">improved</entity> <entity id="P06-1097.22">alignments</entity> but also to <entity id="P06-1097.23">machine translation</entity> <entity id="P06-1097.24">outputs</entity> of higher <entity id="P06-1097.25">quality</entity> .
</abstract>


usedfor(P06-1097.4,P06-1097.6)
methodapplied(P06-1097.10,P06-1097.12)
yields(P06-1097.14,P06-1097.17)

</text>

<text id="P06-1099">
<title>
You Can't Beat <entity id="P06-1099.1">Frequency</entity> (Unless You Use <entity id="P06-1099.2">Linguistic Knowledge</entity> ) - A Qualitative <entity id="P06-1099.3">Evaluation</entity> Of <entity id="P06-1099.4">Association</entity> Measures For <entity id="P06-1099.5">Collocation</entity> And <entity id="P06-1099.6">Term</entity> <entity id="P06-1099.7">Extraction</entity></title>
<abstract>
In the past years, a <entity id="P06-1099.8">number</entity> of <entity id="P06-1099.9">lexical</entity> <entity id="P06-1099.10">association</entity> measures have been <entity id="P06-1099.11">studied</entity> to <entity id="P06-1099.12">help</entity> <entity id="P06-1099.13">extract</entity> new scientific <entity id="P06-1099.14">terminology</entity> or <entity id="P06-1099.15">general-language</entity> <entity id="P06-1099.16">collocations</entity> . The implicit <entity id="P06-1099.17">assumption</entity> of this <entity id="P06-1099.18">research</entity> was that newly <entity id="P06-1099.19">designed</entity> <entity id="P06-1099.20">term</entity> measures involving more sophisticated <entity id="P06-1099.21">statistical</entity> <entity id="P06-1099.22">criteria</entity> would outperform <entity id="P06-1099.23">simple</entity> counts of cooccurrence <entity id="P06-1099.24">frequencies</entity> . We here explicitly <entity id="P06-1099.25">test</entity> this <entity id="P06-1099.26">assumption</entity> . By way of four qualitative <entity id="P06-1099.27">criteria</entity> , we show that purely <entity id="P06-1099.28">statistics-based</entity> measures reveal virtually no <entity id="P06-1099.29">difference</entity> compared with <entity id="P06-1099.30">frequency</entity> of <entity id="P06-1099.31">occurrence</entity> counts, while linguistically more informed <entity id="P06-1099.32">metrics</entity> do reveal such a marked <entity id="P06-1099.33">difference</entity> .
</abstract>


study(P06-1099.3,P06-1099.7)

</text>

<text id="P06-2002">
<title>
A Rote <entity id="P06-2002.1">Extractor</entity> With Edit <entity id="P06-2002.2">Distance-</entity> <entity id="P06-2002.3">Based</entity> Generalisation And Multi- <entity id="P06-2002.4">Corpora</entity> <entity id="P06-2002.5">Precision</entity> <entity id="P06-2002.6">Calculation</entity></title>
<abstract>In this <entity id="P06-2002.7">paper</entity> , we describe a rote <entity id="P06-2002.8">extractor</entity> that learns <entity id="P06-2002.9">patterns</entity> for finding <entity id="P06-2002.10">semantic</entity> <entity id="P06-2002.11">relationships</entity> in unrestricted <entity id="P06-2002.12">text</entity> , with new <entity id="P06-2002.13">procedures</entity> for <entity id="P06-2002.14">pattern</entity> <entity id="P06-2002.15">generalization</entity> and scoring. These <entity id="P06-2002.16">include</entity> the use of <entity id="P06-2002.17">part-of-speech</entity> <entity id="P06-2002.18">tags</entity> to guide the <entity id="P06-2002.19">generalization</entity> , <entity id="P06-2002.20">Named</entity> <entity id="P06-2002.21">Entity</entity> <entity id="P06-2002.22">categories</entity> inside the <entity id="P06-2002.23">patterns</entity> , an <entity id="P06-2002.24">edit-distance-based</entity> <entity id="P06-2002.25">pattern</entity> <entity id="P06-2002.26">generalization</entity> <entity id="P06-2002.27">algorithm</entity> , and a <entity id="P06-2002.28">pattern</entity> <entity id="P06-2002.29">accuracy</entity> <entity id="P06-2002.30">calculation</entity> <entity id="P06-2002.31">procedure</entity> <entity id="P06-2002.32">based</entity> on <entity id="P06-2002.33">evaluating</entity> the <entity id="P06-2002.34">patterns</entity> on several <entity id="P06-2002.35">test</entity> <entity id="P06-2002.36">corpora</entity> . In an <entity id="P06-2002.37">evaluation</entity> with 14 <entity id="P06-2002.38">entities</entity> , the <entity id="P06-2002.39">system</entity> attains a <entity id="P06-2002.40">precision</entity> higher than 50% for half of the <entity id="P06-2002.41">relationships</entity> considered.
</abstract>


propose(P06-2002.7,P06-2002.8)
usedfor(P06-2002.13,P06-2002.15)

</text>

<text id="P06-2013">
<title>
An Empirical <entity id="P06-2013.1">Study</entity> Of <entity id="P06-2013.2">Chinese</entity> Chunking
</title>
<abstract>
In this <entity id="P06-2013.3">paper</entity> , we describe an empirical <entity id="P06-2013.4">study</entity> of <entity id="P06-2013.5">Chinese</entity> <entity id="P06-2013.6">chunking</entity> on a <entity id="P06-2013.7">corpus</entity> , which is <entity id="P06-2013.8">extracted</entity> from UPENN <entity id="P06-2013.9">Chinese</entity> Treebank-4 (CTB4). First, we compare the <entity id="P06-2013.10">performance</entity> of the state-of-the-art <entity id="P06-2013.11">machine</entity> learning <entity id="P06-2013.12">models</entity> . Then we <entity id="P06-2013.13">propose</entity> two <entity id="P06-2013.14">approaches</entity> in <entity id="P06-2013.15">order</entity> to <entity id="P06-2013.16">improve</entity> the <entity id="P06-2013.17">performance</entity> of <entity id="P06-2013.18">Chinese</entity> <entity id="P06-2013.19">chunking</entity> . 1) We <entity id="P06-2013.20">propose</entity> an <entity id="P06-2013.21">approach</entity> to resolve the special <entity id="P06-2013.22">problems</entity> of <entity id="P06-2013.23">Chinese</entity> <entity id="P06-2013.24">chunking</entity> . This <entity id="P06-2013.25">approach</entity> extends the <entity id="P06-2013.26">chunk</entity> <entity id="P06-2013.27">tags</entity> for every <entity id="P06-2013.28">problem</entity> by a <entity id="P06-2013.29">tag-extension</entity> <entity id="P06-2013.30">function</entity> . 2) We <entity id="P06-2013.31">propose</entity> two novel voting <entity id="P06-2013.32">methods</entity> <entity id="P06-2013.33">based</entity> on the <entity id="P06-2013.34">characteristics</entity> of <entity id="P06-2013.35">chunking</entity> <entity id="P06-2013.36">task</entity> . Compared with traditional voting <entity id="P06-2013.37">methods</entity> , the <entity id="P06-2013.38">proposed</entity> voting <entity id="P06-2013.39">methods</entity> consider long <entity id="P06-2013.40">distance</entity> <entity id="P06-2013.41">information</entity> . The <entity id="P06-2013.42">experimental</entity> <entity id="P06-2013.43">results</entity> show that the SVMs <entity id="P06-2013.44">model</entity> outperforms the other <entity id="P06-2013.45">models</entity> and that our <entity id="P06-2013.46">proposed</entity> <entity id="P06-2013.47">approaches</entity> can <entity id="P06-2013.48">improve</entity> <entity id="P06-2013.49">performance</entity> significantly.
</abstract>


study(P06-2013.1,P06-2013.2)
taskapplied(P06-2013.6,P06-2013.7)
wrt(P06-2013.16,P06-2013.19)
based_on(P06-2013.32,P06-2013.35)
compare(P06-2013.37,P06-2013.39)
compare(P06-2013.44,P06-2013.45)
yields(P06-2013.47,P06-2013.49)

</text>

<text id="P06-2014">
<title>
Soft <entity id="P06-2014.1">Syntactic</entity> Constraints For <entity id="P06-2014.2">Word <entity id="P06-2014.3">Alignment</entity></entity> Through Discriminative <entity id="P06-2014.4">Training</entity></title> 
<abstract><entity id="P06-2014.5">Word alignment</entity> <entity id="P06-2014.6">methods</entity> can <entity id="P06-2014.7">gain</entity> valuable guidance by ensuring that their <entity id="P06-2014.8">alignments</entity> maintain <entity id="P06-2014.9">cohesion</entity> with <entity id="P06-2014.10">respect</entity> to the <entity id="P06-2014.11">phrases</entity> specified by a monolingual <entity id="P06-2014.12">dependency tree</entity> . However, this hard <entity id="P06-2014.13">constraint</entity> can also <entity id="P06-2014.14">rule</entity> out correct <entity id="P06-2014.15">alignments</entity> , and its <entity id="P06-2014.16">utility</entity> decreases as <entity id="P06-2014.17">alignment <entity id="P06-2014.18">models</entity></entity> become more <entity id="P06-2014.19">complex</entity> . We use a publicly available <entity id="P06-2014.20">structured</entity> <entity id="P06-2014.21">output</entity> SVM to create a max-margin <entity id="P06-2014.22">syntactic</entity> aligner with a soft <entity id="P06-2014.23">cohesion</entity> <entity id="P06-2014.24">constraint</entity> . The <entity id="P06-2014.25">resulting</entity> aligner is the first, to our <entity id="P06-2014.26">knowledge</entity> , to use a discriminative <entity id="P06-2014.27">learning <entity id="P06-2014.28">method</entity></entity> to <entity id="P06-2014.29">train</entity> an ITG bitext <entity id="P06-2014.30">parser</entity> .
</abstract>


usedfor(P06-2014.1,P06-2014.2)
wrt(P06-2014.9,P06-2014.11)
affects(P06-2014.13,P06-2014.15)
char(P06-2014.17,P06-2014.19,REVERSE)
usedfor(P06-2014.27,P06-2014.30)

</text>

<text id="P06-2023">
<title>
A Bio-Inspired <entity id="P06-2023.1">Approach</entity> For Multi- <entity id="P06-2023.2">Word</entity> <entity id="P06-2023.3">Expression</entity> <entity id="P06-2023.4">Extraction</entity></title>
<abstract>This <entity id="P06-2023.5">paper</entity> <entity id="P06-2023.6">proposes</entity> a new <entity id="P06-2023.7">approach</entity> for <entity id="P06-2023.8">Multi-word</entity> <entity id="P06-2023.9">Expression</entity> (MWE) <entity id="P06-2023.10">extraction</entity> on the <entity id="P06-2023.11">motivation</entity> of <entity id="P06-2023.12">gene</entity> <entity id="P06-2023.13">sequence</entity> <entity id="P06-2023.14">alignment</entity> because textual <entity id="P06-2023.15">sequence</entity> is similar to <entity id="P06-2023.16">gene</entity> <entity id="P06-2023.17">sequence</entity> in <entity id="P06-2023.18">pattern</entity> <entity id="P06-2023.19">analysis</entity> . <entity id="P06-2023.20">Theory</entity> of Longest <entity id="P06-2023.21">Common</entity> <entity id="P06-2023.22">Subsequence</entity> (LCS) originates from <entity id="P06-2023.23">computer science</entity> and has been established as affine <entity id="P06-2023.24">gap</entity> <entity id="P06-2023.25">model</entity> in Bioinformatics. We <entity id="P06-2023.26">perform</entity> this developed LCS <entity id="P06-2023.27">technique</entity> combined with linguistic <entity id="P06-2023.28">criteria</entity> in MWE <entity id="P06-2023.29">extraction</entity> . In <entity id="P06-2023.30">comparison</entity> with traditional <entity id="P06-2023.31">n-gram</entity> <entity id="P06-2023.32">method</entity> , which is the major <entity id="P06-2023.33">technique</entity> for MWE <entity id="P06-2023.34">extraction</entity> , LCS <entity id="P06-2023.35">approach</entity> is <entity id="P06-2023.36">applied</entity> with great <entity id="P06-2023.37">efficiency</entity> and <entity id="P06-2023.38">performance</entity> guarantee. <entity id="P06-2023.39">Experimental</entity> <entity id="P06-2023.40">results</entity> show that <entity id="P06-2023.41">LCS-based <entity id="P06-2023.42">approach</entity></entity> achieves better <entity id="P06-2023.43">results</entity> than <entity id="P06-2023.44">n-gram</entity> .
</abstract>


methodapplied(P06-2023.1,P06-2023.4)
propose(P06-2023.5,P06-2023.7)
taskapplied(P06-2023.9,P06-2023.10,REVERSE)
usedfor(P06-2023.27,P06-2023.29)
yields(P06-2023.41,P06-2023.43)

</text>

<text id="P06-2047">
<title>
Graph Branch <entity id="P06-2047.1">Algorithm</entity> : An Optimum <entity id="P06-2047.2">Tree</entity> <entity id="P06-2047.3">Search</entity> <entity id="P06-2047.4">Method</entity> For Scored <entity id="P06-2047.5">Dependency Graph</entity> With <entity id="P06-2047.6">Arc</entity> Co- <entity id="P06-2047.7">Occurrence</entity> Constraints
</title>
<abstract>
"Various <entity id="P06-2047.8">kinds</entity> of scored <entity id="P06-2047.9">dependency graphs</entity> are <entity id="P06-2047.10">proposed</entity> as packed shared <entity id="P06-2047.11">data</entity> <entity id="P06-2047.12">structures</entity> in <entity id="P06-2047.13">combination</entity> with optimum <entity id="P06-2047.14">dependency tree</entity> <entity id="P06-2047.15">search algorithms</entity> . This <entity id="P06-2047.16">paper</entity> classifies the scored <entity id="P06-2047.17">dependency graphs</entity> and discusses the specific <entity id="P06-2047.18">features</entity> of the ""<entity id="P06-2047.19">Dependency</entity> <entity id="P06-2047.20">Forest</entity> "" (DF) which is the packed shared <entity id="P06-2047.21">data</entity> <entity id="P06-2047.22">structure</entity> adopted in the ""<entity id="P06-2047.23">Preference</entity> <entity id="P06-2047.24">Dependency Grammar</entity> "" (PDG), and <entity id="P06-2047.25">proposes</entity> the ""Graph Branch <entity id="P06-2047.26">Algorithm</entity> "" for <entity id="P06-2047.27">computing</entity> the optimum <entity id="P06-2047.28">dependency tree</entity> from a DF. This <entity id="P06-2047.29">paper</entity> also <entity id="P06-2047.30">reports</entity> the <entity id="P06-2047.31">experiment</entity> showing the <entity id="P06-2047.32">computational</entity> <entity id="P06-2047.33">amount</entity> and <entity id="P06-2047.34">behavior</entity> of the graph branch <entity id="P06-2047.35">algorithm</entity> . "
</abstract>


usedfor(P06-2047.26,P06-2047.27)
phenomenon(P06-2047.34,P06-2047.35)

</text>

<text id="P06-2091">
<title>
Translating HPSG-Style Outputs Of A <entity id="P06-2091.1">Robust</entity> <entity id="P06-2091.2">Parser</entity> Into Typed Dynamic <entity id="P06-2091.3">Logic</entity></title>
<abstract>
The present <entity id="P06-2091.4">paper</entity> <entity id="P06-2091.5">proposes</entity> a <entity id="P06-2091.6">method</entity> by which to <entity id="P06-2091.7">translate</entity> <entity id="P06-2091.8">outputs</entity> of a <entity id="P06-2091.9">robust</entity> HPSG <entity id="P06-2091.10">parser</entity> into <entity id="P06-2091.11">semantic <entity id="P06-2091.12">representations</entity></entity> of Typed Dynamic <entity id="P06-2091.13">Logic</entity> (TDL), a dynamic plural <entity id="P06-2091.14">semantics</entity> defined in <entity id="P06-2091.15">typed</entity> lambda <entity id="P06-2091.16">calculus</entity> . With its <entity id="P06-2091.17">higher-order</entity> <entity id="P06-2091.18">representations</entity> of <entity id="P06-2091.19">contexts</entity> , TDL analyzes and describes the inherently inter-sentential <entity id="P06-2091.20">nature</entity> of <entity id="P06-2091.21">quantification</entity> and anaphora in a strictly lexicalized and compositional <entity id="P06-2091.22">manner</entity> . The present <entity id="P06-2091.23">study</entity> shows that the <entity id="P06-2091.24">proposed</entity> <entity id="P06-2091.25">translation</entity> <entity id="P06-2091.26">method</entity> successfully combines <entity id="P06-2091.27">robustness</entity> and descriptive <entity id="P06-2091.28">adequacy</entity> of contemporary <entity id="P06-2091.29">semantics</entity> . The present <entity id="P06-2091.30">implementation</entity> achieves high <entity id="P06-2091.31">coverage</entity> , approximately 90%, for the real <entity id="P06-2091.32">text</entity> of the <entity id="P06-2091.33">Penn Treebank</entity> <entity id="P06-2091.34">corpus</entity> .
</abstract>


propose(P06-2091.4,P06-2091.6)
tag(P06-2091.8,P06-2091.11,REVERSE)
tag(P06-2091.18,P06-2091.19)
char(P06-2091.26,P06-2091.27,REVERSE)
yields(P06-2091.30,P06-2091.31)
part_of(P06-2091.32,P06-2091.34)

</text>

<text id="P06-2096">
<title>
Adding <entity id="P06-2096.1">Syntax</entity> To <entity id="P06-2096.2">Dynamic Programming</entity> For Aligning Comparable <entity id="P06-2096.3">Texts</entity> For The <entity id="P06-2096.4">Generation</entity> Of Paraphrases
</title>
<abstract>
Multiple <entity id="P06-2096.5">sequence</entity> <entity id="P06-2096.6">alignment</entity> <entity id="P06-2096.7">techniques</entity> have recently <entity id="P06-2096.8">gained</entity> <entity id="P06-2096.9">popularity</entity> in the <entity id="P06-2096.10">Natural Language</entity> <entity id="P06-2096.11">community</entity> , especially for <entity id="P06-2096.12">tasks</entity> such as <entity id="P06-2096.13">machine <entity id="P06-2096.14">translation</entity></entity> , <entity id="P06-2096.15">text generation</entity> , and paraphrase <entity id="P06-2096.16">identification</entity> . Prior work falls into two <entity id="P06-2096.17">categories</entity> , depending on the <entity id="P06-2096.18">type</entity> of <entity id="P06-2096.19">input</entity> used: (a) <entity id="P06-2096.20">parallel corpora</entity> (e.g., multiple <entity id="P06-2096.21">translations</entity> of the same <entity id="P06-2096.22">text</entity> ) or (b) comparable <entity id="P06-2096.23">texts</entity> (non-parallel but on the same <entity id="P06-2096.24">topic</entity> ). So far, only <entity id="P06-2096.25">techniques</entity> <entity id="P06-2096.26">based</entity> on <entity id="P06-2096.27">parallel <entity id="P06-2096.28">texts</entity></entity> have successfully used <entity id="P06-2096.29">syntactic <entity id="P06-2096.30">information</entity></entity> to guide <entity id="P06-2096.31">alignments</entity> . In this <entity id="P06-2096.32">paper</entity> , we describe an <entity id="P06-2096.33">algorithm</entity> for incorporating <entity id="P06-2096.34">syntactic features</entity> in the <entity id="P06-2096.35">alignment</entity> <entity id="P06-2096.36">process</entity> for <entity id="P06-2096.37">non-parallel texts</entity> with the <entity id="P06-2096.38">goal</entity> of <entity id="P06-2096.39">generating</entity> novel paraphrases of existing <entity id="P06-2096.40">texts</entity> . Our <entity id="P06-2096.41">method</entity> uses <entity id="P06-2096.42">dynamic <entity id="P06-2096.43">programming</entity></entity> with <entity id="P06-2096.44">alignment</entity> <entity id="P06-2096.45">decision</entity> <entity id="P06-2096.46">based</entity> on the local <entity id="P06-2096.47">syntactic</entity> <entity id="P06-2096.48">similarity</entity> between two <entity id="P06-2096.49">sentences</entity> . Our <entity id="P06-2096.50">results</entity> show that <entity id="P06-2096.51">syntactic</entity> <entity id="P06-2096.52">alignment</entity> outrivals <entity id="P06-2096.53">syntax-free</entity> <entity id="P06-2096.54">methods</entity> by 20% in both grammatically and fidelity when computed over the novel <entity id="P06-2096.55">sentences</entity> <entity id="P06-2096.56">generated</entity> by <entity id="P06-2096.57">alignment-induced</entity> finite state automata.
</abstract>


usedfor(P06-2096.3,P06-2096.4)
wrt(P06-2096.7,P06-2096.9,REVERSE)
isa(P06-2096.12,P06-2096.13,REVERSE)
taskapplied(P06-2096.21,P06-2096.22)
based_on(P06-2096.25,P06-2096.27)
usedfor(P06-2096.29,P06-2096.31)
propose(P06-2096.32,P06-2096.33)
usedfor(P06-2096.41,P06-2096.42,REVERSE)
based_on(P06-2096.45,P06-2096.48)
compare(P06-2096.52,P06-2096.54)

</text>

<text id="P06-3015">
<title>
Clavius: Bi-Directional <entity id="P06-3015.1">Parsing</entity> For Generic Multimodal <entity id="P06-3015.2">Interaction</entity></title>
<abstract>
We introduce a new multi-threaded <entity id="P06-3015.3">parsing</entity> <entity id="P06-3015.4">algorithm</entity> on <entity id="P06-3015.5">unification</entity> grammars <entity id="P06-3015.6">designed</entity> specifically for multimodal <entity id="P06-3015.7">interaction</entity> and noisy <entity id="P06-3015.8">environments</entity> . By lifting some traditional <entity id="P06-3015.9">constraints</entity> , namely those related to the <entity id="P06-3015.10">ordering</entity> of <entity id="P06-3015.11">constituents</entity> , we overcome several <entity id="P06-3015.12">difficulties</entity> of other <entity id="P06-3015.13">systems</entity> in this <entity id="P06-3015.14">domain</entity> . We also present several <entity id="P06-3015.15">criteria</entity> used in this <entity id="P06-3015.16">model</entity> to constrain the <entity id="P06-3015.17">search</entity> <entity id="P06-3015.18">process</entity> using dynamically loadable scoring <entity id="P06-3015.19">functions</entity> . Some early <entity id="P06-3015.20">analyses</entity> of our <entity id="P06-3015.21">implementation</entity> are discussed.
</abstract>


taskapplied(P06-3015.1,P06-3015.2)
taskapplied(P06-3015.3,P06-3015.7)
problem(P06-3015.9,P06-3015.11)
problem(P06-3015.12,P06-3015.13)
affects(P06-3015.15,P06-3015.18)

</text>

<text id="P06-4002">
<title>
Is It Correct? - Towards Web- <entity id="P06-4002.1">Based</entity> <entity id="P06-4002.2">Evaluation</entity> Of <entity id="P06-4002.3">Automatic</entity> <entity id="P06-4002.4">Natural Language</entity> <entity id="P06-4002.5">Phrase</entity> <entity id="P06-4002.6">Generation</entity></title>
<abstract>
This <entity id="P06-4002.7">paper</entity> describes a novel <entity id="P06-4002.8">approach</entity> for the <entity id="P06-4002.9">automatic</entity> <entity id="P06-4002.10">generation</entity> and <entity id="P06-4002.11">evaluation</entity> of a trivial <entity id="P06-4002.12">dialogue</entity> <entity id="P06-4002.13">phrases</entity></abstract>


study(P06-4002.2,P06-4002.6)
propose(P06-4002.7,P06-4002.8)
taskapplied(P06-4002.10,P06-4002.13)

</text>

<text id="C80-1015">
<title>
A <entity id="C80-1015.1">Model</entity> Of <entity id="C80-1015.2">Natural Language Processing</entity> Of <entity id="C80-1015.3">Time</entity> - <entity id="C80-1015.4">Related</entity> Expressions
</title>


model(C80-1015.1,C80-1015.3)

</text>

<abstract></abstract>

<text id="C80-1063">
<title>
A <entity id="C80-1063.1">Machine <entity id="C80-1063.2">Translation System</entity></entity> From <entity id="C80-1063.3">Japanese</entity> Into <entity id="C80-1063.4">English</entity> - Another <entity id="C80-1063.5">Perspective</entity> Of MT <entity id="C80-1063.6">Systems</entity></title>
<abstract>
A <entity id="C80-1063.7">machine <entity id="C80-1063.8">translation system</entity></entity> from <entity id="C80-1063.9">Japanese</entity> into <entity id="C80-1063.10">English</entity> is described.    The <entity id="C80-1063.11">system</entity> aims at <entity id="C80-1063.12">translation</entity> of <entity id="C80-1063.13">computer</entity> <entity id="C80-1063.14">manuals</entity> , and basically follows to the <entity id="C80-1063.15">transfer</entity> <entity id="C80-1063.16">approach</entity> .    The <entity id="C80-1063.17">design</entity> <entity id="C80-1063.18">principles</entity> of the <entity id="C80-1063.19">system</entity> are discussed in <entity id="C80-1063.20">detail</entity> , together with the overall <entity id="C80-1063.21">constructions</entity> of the <entity id="C80-1063.22">system</entity> . Especially, the <entity id="C80-1063.23">effectiveness</entity> of <entity id="C80-1063.24">lexicon-based</entity> <entity id="C80-1063.25">procedures</entity> , i.e. <entity id="C80-1063.26">lexicon-based</entity> <entity id="C80-1063.27">analysis</entity> , <entity id="C80-1063.28">transfer</entity> , and <entity id="C80-1063.29">synthesis</entity> , is emphasized.    Most of the linguistic <entity id="C80-1063.30">phenomena</entity> are treated by using <entity id="C80-1063.31">lexical</entity> <entity id="C80-1063.32">descriptions</entity> and <entity id="C80-1063.33">lexical</entity> <entity id="C80-1063.34">rules</entity> , instead of by general <entity id="C80-1063.35">syntactic</entity> <entity id="C80-1063.36">rules</entity> .    Because <entity id="C80-1063.37">Japanese</entity> and <entity id="C80-1063.38">English</entity> belong to quite different <entity id="C80-1063.39">language</entity> families, much more <entity id="C80-1063.40">structural</entity> <entity id="C80-1063.41">transfers</entity> are necessary than in other <entity id="C80-1063.42">MT systems</entity> among European <entity id="C80-1063.43">languages</entity> .    Special cares have been paid for <entity id="C80-1063.44">designing</entity> the <entity id="C80-1063.45">transfer</entity> <entity id="C80-1063.46">component</entity> .    Some <entity id="C80-1063.47">translation results</entity> are also given to illustrate the <entity id="C80-1063.48">current</entity> <entity id="C80-1063.49">abilities</entity> of the <entity id="C80-1063.50">system</entity> .
</abstract>


taskapplied(C80-1063.1,C80-1063.3)
taskapplied(C80-1063.7,C80-1063.9)
taskapplied(C80-1063.12,C80-1063.14)
part_of(C80-1063.18,C80-1063.19)
char(C80-1063.23,C80-1063.25)
anto(C80-1063.31,C80-1063.35)
isa(C80-1063.38,C80-1063.39)
phenomenon(C80-1063.49,C80-1063.50)

</text>

<text id="C82-1016">
<title>
Referential Nets With Attributes
</title>
<abstract>
One of the essential <entity id="C82-1016.1">problems</entity> in <entity id="C82-1016.2">natural language</entity> production and <entity id="C82-1016.3">understanding</entity> is the <entity id="C82-1016.4">problem</entity> of <entity id="C82-1016.5">processing</entity> referential <entity id="C82-1016.6">relations</entity> . In this <entity id="C82-1016.7">paper</entity> I describe a <entity id="C82-1016.8">model</entity> for representing and <entity id="C82-1016.9">processing</entity> referential <entity id="C82-1016.10">relations</entity> : referential nets with attributes. Both <entity id="C82-1016.11">processes</entity> (analyzing and <entity id="C82-1016.12">generating</entity> referential <entity id="C82-1016.13">expressions</entity> ) are controlled by attributes. There are two <entity id="C82-1016.14">types</entity> of attributes, on one <entity id="C82-1016.15">hand</entity> , the ones to the internal substitutes of the <entity id="C82-1016.16">objects</entity> spoken about, on the other <entity id="C82-1016.17">hand</entity> , the ones to the <entity id="C82-1016.18">descriptions</entity> of these <entity id="C82-1016.19">objects</entity> .
</abstract>


problem(C82-1016.5,C82-1016.6,REVERSE)
propose(C82-1016.7,C82-1016.8)
taskapplied(C82-1016.9,C82-1016.10)

</text>

<text id="C82-1021">
<title>
A Multilayered <entity id="C82-1021.1">Approach</entity> To The Handling Of <entity id="C82-1021.2">Word</entity> <entity id="C82-1021.3">Formation</entity></title>
<abstract>
The <entity id="C82-1021.4">treatment</entity> of <entity id="C82-1021.5">word</entity> <entity id="C82-1021.6">formations</entity> has until recently been a neglected <entity id="C82-1021.7">topic</entity> in <entity id="C82-1021.8">natural  language</entity> AI <entity id="C82-1021.9">research</entity> . This <entity id="C82-1021.10">paper</entity> <entity id="C82-1021.11">proposes</entity> a multilayered <entity id="C82-1021.12">approach</entity> to <entity id="C82-1021.13">word</entity> <entity id="C82-1021.14">formation</entity> which treats derivatives and compounds on several different <entity id="C82-1021.15">levels</entity> of <entity id="C82-1021.16">processing</entity> within a <entity id="C82-1021.17">natural <entity id="C82-1021.18">language</entity></entity> <entity id="C82-1021.19">dialogue <entity id="C82-1021.20">system</entity></entity> . <entity id="C82-1021.21">Analysis</entity> and <entity id="C82-1021.22">generation</entity> <entity id="C82-1021.23">strategies</entity> being <entity id="C82-1021.24">developed</entity> for the <entity id="C82-1021.25">dialogue <entity id="C82-1021.26">system</entity></entity> HAM-ANS are described. <entity id="C82-1021.27">Identification</entity> of <entity id="C82-1021.28">word</entity> <entity id="C82-1021.29">format</entity> <entity id="C82-1021.30">ions</entity> , <entity id="C82-1021.31">semantic interpretation</entity> , and <entity id="C82-1021.32">evaluation</entity> in the <entity id="C82-1021.33">context</entity> of a <entity id="C82-1021.34">dialogue</entity> are the <entity id="C82-1021.35">main</entity> <entity id="C82-1021.36">levels</entity> of <entity id="C82-1021.37">analysis</entity> on which the <entity id="C82-1021.38">system</entity> successively attempts to infer the implicit <entity id="C82-1021.39">relations</entity> between <entity id="C82-1021.40">word</entity> <entity id="C82-1021.41">formation</entity> <entity id="C82-1021.42">components</entity> . <entity id="C82-1021.43">Generation</entity> of <entity id="C82-1021.44">word</entity> <entity id="C82-1021.45">formations</entity> is viewed as a <entity id="C82-1021.46">process</entity> comparable to the <entity id="C82-1021.47">generation</entity> of elliptical <entity id="C82-1021.48">utterances</entity> .
</abstract>


propose(C82-1021.10,C82-1021.12)
based_on(C82-1021.17,C82-1021.19,REVERSE)
usedfor(C82-1021.23,C82-1021.25)
compare(C82-1021.44,C82-1021.48)

</text>

<text id="C82-1031">
<title>
The Anatomy Of A Systemic <entity id="C82-1031.1">Choice</entity></title> 
<abstract><entity id="C82-1031.2">Choice</entity> is one of the most prominent organizing <entity id="C82-1031.3">concepts</entity> in systemic <entity id="C82-1031.4">linguistics</entity> . <entity id="C82-1031.5">Languages</entity> are described in <entity id="C82-1031.6">terms</entity> of the <entity id="C82-1031.7">choices</entity> available to the speaker and the <entity id="C82-1031.8">relationships</entity> of those <entity id="C82-1031.9">choices</entity> to each other and to the <entity id="C82-1031.10">language</entity> produced. This <entity id="C82-1031.11">paper</entity> addresses the <entity id="C82-1031.12">problems</entity> of
</abstract>


isa(C82-1031.2,C82-1031.3)
study(C82-1031.11,C82-1031.12)

</text>

<text id="C82-1059">
<title><entity id="C82-1059.1">Parsing</entity> German
</title>
<abstract>
The first <entity id="C82-1059.2">part</entity> of this <entity id="C82-1059.3">paper</entity> is dedicated to an <entity id="C82-1059.4">overview</entity> of the <entity id="C82-1059.5">parser</entity> of the <entity id="C82-1059.6">system</entity> VIE-LANG (Viennese <entity id="C82-1059.7">Language Understanding System</entity> ). The <entity id="C82-1059.8">parser</entity> is a <entity id="C82-1059.9">production <entity id="C82-1059.10">system</entity></entity> which uses an interleaved <entity id="C82-1059.11">method</entity> that combines <entity id="C82-1059.12">syntax</entity> and <entity id="C82-1059.13">semantics</entity> . It <entity id="C82-1059.14">parses</entity> directly into the internal <entity id="C82-1059.15">representation</entity> of the <entity id="C82-1059.16">system</entity> , without producing an. intermediate <entity id="C82-1059.17">syntactic structure</entity> . The last <entity id="C82-1059.18">part</entity> discusses the <entity id="C82-1059.19">relationship</entity> between some special <entity id="C82-1059.20">features</entity> of the German <entity id="C82-1059.21">language</entity> , and <entity id="C82-1059.22">properties</entity> of the <entity id="C82-1059.23">parser</entity> that originate in the <entity id="C82-1059.24">language</entity> .
</abstract>


propose(C82-1059.3,C82-1059.5)
isa(C82-1059.8,C82-1059.9)
based_on(C82-1059.11,C82-1059.12)
model(C82-1059.15,C82-1059.16)
tag(C82-1059.20,C82-1059.21)
based_on(C82-1059.23,C82-1059.24)

</text>

<text id="C86-1084">
<title>
Linguistic Bases For <entity id="C86-1084.1">Machine Translation</entity></title>
<abstract>
	Landsbergen, S. P. J. , <entity id="C86-1084.2">Machine Translation</entity> <entity id="C86-1084.3">Based</entity> On Logically Isomorphic Montague Grammars,International Conference On <entity id="C86-1084.4">Computation</entity> al <entity id="C86-1084.5">Linguistics</entity> ,1982 *** Frey , Werner ; Reyle, Uwe ,A PROLOG <entity id="C86-1084.6">Implementation</entity> Of <entity id="C86-1084.7">Lexical</entity> Functional Grammar As A <entity id="C86-1084.8">Base</entity> For A <entity id="C86-1084.9">Natural Language Processing System</entity> ,Conference Of The European <entity id="C86-1084.10">Association</entity> For <entity id="C86-1084.11">Computation</entity> al <entity id="C86-1084.12">Linguistics</entity> ,1983 *** Pereira , Fernando ,Extraposition Grammars,American <entity id="C86-1084.13">Journal</entity> Of <entity id="C86-1084.14">Computation</entity> al <entity id="C86-1084.15">Linguistics</entity> ,1981 ***Berwick, Robert C. , <entity id="C86-1084.16">Computational</entity> <entity id="C86-1084.17">Complexity</entity> And <entity id="C86-1084.18">Lexical-</entity> Functional Grammar,American <entity id="C86-1084.19">Journal</entity> Of <entity id="C86-1084.20">Computation</entity> al <entity id="C86-1084.21">Linguistics</entity> ,1982 *** Johnson , Rod L.; King , Margaret ; Des Tombe, Louis ,EUROTRA: A Multilingual <entity id="C86-1084.22">System</entity> Under <entity id="C86-1084.23">Development</entity> , <entity id="C86-1084.24">Computation</entity> al <entity id="C86-1084.25">Linguistics</entity> ,1985 *** Kay , Martin ,Functional <entity id="C86-1084.26">Unification</entity> Grammar: A <entity id="C86-1084.27">Formalism</entity> For <entity id="C86-1084.28">Machine Translation</entity> ,International Conference On <entity id="C86-1084.29">Computational Linguistics</entity> And Annual Meeting Of The <entity id="C86-1084.30">Association</entity> For <entity id="C86-1084.31">Computation</entity> al <entity id="C86-1084.32">Linguistics</entity> ,1984</abstract>



</text>

<text id="C86-1088">
<title>
Definite <entity id="C86-1088.1">Noun</entity> Phrases And The <entity id="C86-1088.2">Semantics</entity> Of <entity id="C86-1088.3">Discourse</entity></title> 
<abstract><entity id="C86-1088.4">Discourse Representation Theory</entity> (DRT), <entity id="C86-1088.5">developed</entity> by Hans Kamp several years ago ( Kamp 1981 ), belongs, together with Irene Heims narrowly related File Change <entity id="C86-1088.6">Semantics</entity> ( Heim 1982 ) and <entity id="C86-1088.7">Situation</entity> <entity id="C86-1088.8">Semantics</entity> (Barwise/ Perry 1983 ), to a group of theoretical <entity id="C86-1088.9">approaches</entity> which in the early Eighties introduced a dynamic, <entity id="C86-1088.10">context-oriented</entity> <entity id="C86-1088.11">perspective</entity> into the <entity id="C86-1088.12">semantics</entity> of <entity id="C86-1088.13">natural <entity id="C86-1088.14">language</entity></entity> . This recent <entity id="C86-1088.15">development</entity> in theoretical <entity id="C86-1088.16">semantics</entity> indicates a <entity id="C86-1088.17">shift</entity> of interest towards <entity id="C86-1088.18">topics</entity> that have been familiar in <entity id="C86-1088.19">natural language processing</entity> <entity id="C86-1088.20">research</entity> for the last decade: among others, the <entity id="C86-1088.21">interpretation</entity> of new <entity id="C86-1088.22">utterances</entity> with <entity id="C86-1088.23">respect</entity> to a given <entity id="C86-1088.24">context</entity> , and <entity id="C86-1088.25">integration</entity> of the <entity id="C86-1088.26">utterance</entity> <entity id="C86-1088.27">information</entity> into that <entity id="C86-1088.28">context</entity> ; the <entity id="C86-1088.29">step-by-step</entity> <entity id="C86-1088.30">construction</entity> of <entity id="C86-1088.31">representations</entity> for larger pieces of <entity id="C86-1088.32">discourse</entity> ; the <entity id="C86-1088.33">investigation</entity> of <entity id="C86-1088.34">text</entity> <entity id="C86-1088.35">coherence</entity> <entity id="C86-1088.36">phenomena</entity> ; and the <entity id="C86-1088.37">description</entity> of referential <entity id="C86-1088.38">processes</entity> . The <entity id="C86-1088.39">core</entity> of DRT (and File Change <entity id="C86-1088.40">Semantics</entity> ) is the <entity id="C86-1088.41">treatment</entity> of indefinite <entity id="C86-1088.42">noun <entity id="C86-1088.43">phrases</entity></entity> as <entity id="C86-1088.44">reference</entity> establishing <entity id="C86-1088.45">terms</entity> (as opposed to their <entity id="C86-1088.46">standard</entity> truth-conditional <entity id="C86-1088.47">quantifier</entity> <entity id="C86-1088.48">analysis</entity> , but in accordance with the treatmant of indefinites in NLP <entity id="C86-1088.49">research</entity> ) and definite <entity id="C86-1088.50">noun phrases</entity> (pronouns as well as full NPs) as anaphoric <entity id="C86-1088.51">expressions</entity> . It is one of the theoretically most appealing <entity id="C86-1088.52">features</entity> of these <entity id="C86-1088.53">theories</entity> that they <entity id="C86-1088.54">provide</entity> <entity id="C86-1088.55">simple</entity> unified accounts for all indefinites, and for all definites, respectively. This theoretical <entity id="C86-1088.56">simplicity</entity> stands however in sharp <entity id="C86-1088.57">contrast</entity> to the <entity id="C86-1088.58">complexity</entity> of the <entity id="C86-1088.59">process</entity> of etablishing <entity id="C86-1088.60">reference</entity> observed in NLP <entity id="C86-1088.61">research</entity> , and the <entity id="C86-1088.62">variety</entity> of <entity id="C86-1088.63">phenomena</entity> and linguistic <entity id="C86-1088.64">levels</entity> involved. On the one <entity id="C86-1088.65">hand</entity> , this <entity id="C86-1088.66">contrast</entity> is quite <entity id="C86-1088.67">natural</entity> : As a semantically motivated <entity id="C86-1088.68">theory</entity> , DRT should not be expected to incorporate every <entity id="C86-1088.69">detail</entity> of <entity id="C86-1088.70">inferencing</entity> necessary to come up with an <entity id="C86-1088.71">interpretation</entity> for a specific <entity id="C86-1088.72">utterance</entity> in a given <entity id="C86-1088.73">context</entity> ; it can better be thought of as an <entity id="C86-1088.74">interface</entity> relating theoretical, truth-conditional <entity id="C86-1088.75">semantics</entity> and the genuinely pragmatic work of <entity id="C86-1088.76">text</entity> <entity id="C86-1088.77">understanding</entity> . On the other <entity id="C86-1088.78">hand</entity> , if DRT is seriously intended to bridge the <entity id="C86-1088.79">gap</entity> between theoretical <entity id="C86-1088.80">linguistics</entity> and the NLP <entity id="C86-1088.81">approach</entity> , it should take into <entity id="C86-1088.82">consideration</entity> as many factual <entity id="C86-1088.83">restrictions</entity> on NP <entity id="C86-1088.84">reference</entity> , and <entity id="C86-1088.85">distinctions</entity> among subtypes of referential <entity id="C86-1088.86">expressions</entity> , as is possible in a systematic and descriptive way. Several <entity id="C86-1088.87">extensions</entity> of the <entity id="C86-1088.88">standard</entity> <entity id="C86-1088.89">system</entity> are at work, e.g. for the <entity id="C86-1088.90">treatment</entity> of plural and temporal anaphora. Little, however, has yet been done to arrive at a closer view of the <entity id="C86-1088.91">analysis</entity> of (singular) definite <entity id="C86-1088.92">noun phrases</entity> , once the <entity id="C86-1088.93">basic</entity> <entity id="C86-1088.94">concepts</entity> had been established. The only attempt I know about is by Kamp himself, described in Kamp (1983), an unpublished <entity id="C86-1088.95">fragment</entity> . In this talk I will first give a short <entity id="C86-1088.96">overview</entity> of the <entity id="C86-1088.97">basic</entity> DRT <entity id="C86-1088.98">system</entity> , and sketch Kamp 's <entity id="C86-1088.99">proposal</entity> for the <entity id="C86-1088.100">treatment</entity> of definite <entity id="C86-1088.101">noun <entity id="C86-1088.102">phrases</entity></entity> . Then I will indicate how the <entity id="C86-1088.103">basic</entity> <entity id="C86-1088.104">reference</entity> establishing <entity id="C86-1088.105">function</entity> and the '<entity id="C86-1088.106">side-effects</entity> 'of different <entity id="C86-1088.107">types</entity> of definite NPs can be described in more <entity id="C86-1088.108">detail</entity> . In doing this, I will refer to the work about anaphora done in the NLP <entity id="C86-1088.109">area</entity> (esp. by Barbara Grosz , Candy Sidner , and Bonnie Webber ), integrating some of their <entity id="C86-1088.110">assumptions</entity> into the DRT <entity id="C86-1088.111">framework</entity> , and critically commenting on some others.
</abstract>


study(C86-1088.2,C86-1088.3)
study(C86-1088.12,C86-1088.13)
wrt(C86-1088.15,C86-1088.16)
based_on(C86-1088.21,C86-1088.24)
datasource(C86-1088.26,C86-1088.27,REVERSE)
study(C86-1088.33,C86-1088.36)
model(C86-1088.37,C86-1088.38)
study(C86-1088.41,C86-1088.42)
based_on(C86-1088.71,C86-1088.73)
part_of(C86-1088.87,C86-1088.89)
study(C86-1088.100,C86-1088.101)

</text>

<text id="C86-1091">
<title>
Towards The <entity id="C86-1091.1">Automatic</entity> <entity id="C86-1091.2">Acquisition</entity> Of <entity id="C86-1091.3">Lexical</entity> <entity id="C86-1091.4">Data</entity></title>
<abstract>
"Creating a <entity id="C86-1091.5">knowledge <entity id="C86-1091.6">base</entity></entity> has always been a bottleneck in the <entity id="C86-1091.7">implementation</entity> of AI <entity id="C86-1091.8">systems</entity> . This is also Lrue for <entity id="C86-1091.9">Natural Language Understanding</entity> (NEU) <entity id="C86-1091.10">systems</entity> , particularly for <entity id="C86-1091.11">data-driven</entity> ones. While a perfect <entity id="C86-1091.12">system</entity> for <entity id="C86-1091.13">automatic</entity> <entity id="C86-1091.14">acquisition</entity> of all sorts of <entity id="C86-1091.15">knowledge</entity> is still feir from being realized, <entity id="C86-1091.16">partial</entity> <entity id="C86-1091.17">solutions</entity> are possible. This holds especially for <entity id="C86-1091.18">lexical</entity> <entity id="C86-1091.19">data</entity> . Nevertheless, the <entity id="C86-1091.20">task</entity> is not trivial, in particular when <entity id="C86-1091.21">dealing</entity> with <entity id="C86-1091.22">languages</entity> rich in inflectional Horms like German. Our: <entity id="C86-1091.23">system</entity> is to be used by persons with no specific <entity id="C86-1091.24">linguistic knowledge</entity> , thus linguistic expertise has been put into the <entity id="C86-1091.25">system</entity> to ascertain correct <entity id="C86-1091.26">classification</entity> of."" <entity id="C86-1091.27">words</entity> . <entity id="C86-1091.28">Classification</entity> is done by means of a small <entity id="C86-1091.29">rule</entity> <entity id="C86-1091.30">based</entity> <entity id="C86-1091.31">system</entity> with <entity id="C86-1091.32">Lexical <entity id="C86-1091.33">knowledge</entity></entity> and <entity id="C86-1091.34">language-specific</entity> heuristics. The key idea is the <entity id="C86-1091.35">identification</entity> of three sorts of <entity id="C86-1091.36">knowledge</entity> which are <entity id="C86-1091.37">processed</entity> distinctly and the <entity id="C86-1091.38">optimal</entity> use of <entity id="C86-1091.39">knowledge</entity> already contained in the existing <entity id="C86-1091.40">Lexicon</entity> . 1
 <entity id="C86-1091.41">Introduction</entity> in this <entity id="C86-1091.42">paper</entity> we introduce a <entity id="C86-1091.43">system</entity> for the <entity id="C86-1091.44">semi-automatic</entity> enlargement of a morphological 1 ex <entity id="C86-1091.45">icon</entity> . If <entity id="C86-1091.46">forms</entity> <entity id="C86-1091.47">part</entity> of VIE-BANG, a German <entity id="C86-1091.48">Language</entity> <entity id="C86-1091.49">dialogue system</entity> ( Buchberger et al. 1982 ) . VI K-l. ANG serves not only as an ob ject but as a meta <entity id="C86-1091.50">system</entity> as we 11 : i ts <entity id="C86-1091.51">knowledge base</entity> is to be enlarged, and its facilities are used L:o <entity id="C86-1091.52">support</entity> that <entity id="C86-1091.53">process</entity> : the parsor serves to analyze the i nput to the acquisj ti on <entity id="C86-1091.54">system</entity> , the <entity id="C86-1091.55">generator</entity>  i. s used  to <entity id="C86-1091.56">provide</entity> exampl es. Ln <entity id="C86-1091.57">contrast</entity> to <entity id="C86-1091.58">English</entity> the <entity id="C86-1091.59">morphological <entity id="C86-1091.60">analysis</entity></entity> of German <entity id="C86-1091.61">words</entity>  is no trivial <entity id="C86-1091.62">task</entity> ,  <entity id="C86-1091.63">due</entity> to two causes: - First, there is a rich inflectional <entity id="C86-1091.64">system</entity> , consisting of about 60 different endings (where most endings have various different <entity id="C86-1091.65">interpretations</entity> ), some <entity id="C86-1091.66">prefixes</entity> ('go-PPP, "
</abstract>


taskapplied(C86-1091.2,C86-1091.4)
problem(C86-1091.5,C86-1091.8)
taskapplied(C86-1091.26,C86-1091.27)
based_on(C86-1091.28,C86-1091.32)
propose(C86-1091.42,C86-1091.43)
study(C86-1091.59,C86-1091.61)

</text>

<text id="C88-1041">
<title>The PSI/PHI <entity id="C88-1041.1">Architecture</entity> For Prosodic <entity id="C88-1041.2">Parsing</entity></title>
<abstract>
In is in as a a
</abstract>


usedfor(C88-1041.1,C88-1041.2)

</text>

<text id="C88-2134">
<title><entity id="C88-2134.1">Optimization</entity> <entity id="C88-2134.2">Algorithms</entity> Of Deciphering As The Elements Of A <entity id="C88-2134.3">Linguistic Theory</entity></title>
<abstract>
This <entity id="C88-2134.4">paper</entity> presents an <entity id="C88-2134.5">outline</entity> of the <entity id="C88-2134.6">linguistic theory</entity> which may be identified with the partially <entity id="C88-2134.7">ordered</entity> set of <entity id="C88-2134.8">optimization</entity> <entity id="C88-2134.9">algorithms</entity> of deciphering. An <entity id="C88-2134.10">algorithm</entity> of deciphering is the operational <entity id="C88-2134.11">definition</entity> of a given linguistic <entity id="C88-2134.12">phenomenon</entity> which han the following three <entity id="C88-2134.13">components</entity> : a set of admissible <entity id="C88-2134.14">solutions</entity> , an <entity id="C88-2134.15">objective function</entity> and a <entity id="C88-2134.16">procedure</entity> which finds out the ministurn or the maximum of the <entity id="C88-2134.17">objective function</entity> . The <entity id="C88-2134.18">paper</entity> contains the <entity id="C88-2134.19">description</entity> of the four <entity id="C88-2134.20">algorithms</entity> of the <entity id="C88-2134.21">proposed</entity> <entity id="C88-2134.22">type</entity> : 1. The <entity id="C88-2134.23">algorithm</entity> which classifies the letters into <entity id="C88-2134.24">vowels</entity> and <entity id="C88-2134.25">consonants</entity> . 2. The <entity id="C88-2134.26">algorithm</entity> which identifies the morphemes in the <entity id="C88-2134.27">text</entity> without the <entity id="C88-2134.28">boundaries</entity> between <entity id="C88-2134.29">words</entity> . 3. The <entity id="C88-2134.30">algorithm</entity> whioh finds out the <entity id="C88-2134.31">dependency <entity id="C88-2134.32">tree</entity></entity> of a <entity id="C88-2134.33">sentence</entity> .
</abstract>


study(C88-2134.19,C88-2134.20)
phenomenon(C88-2134.28,C88-2134.29)
tag(C88-2134.31,C88-2134.33)

</text>

<text id="C90-2012">
<title>
The <entity id="C90-2012.1">E-Framework</entity> : Emerging <entity id="C90-2012.2">Problems</entity></title>
<abstract>
Bech &amp; Nygaard (1988) have described a <entity id="C90-2012.3">formalism</entity> for NLP, the <entity id="C90-2012.4">E-Framework</entity> (EFW). Two <entity id="C90-2012.5">kinds</entity> of <entity id="C90-2012.6">problem</entity> are emerging. Formally, there are <entity id="C90-2012.7">problems</entity> with a complete formalisation of certain <entity id="C90-2012.8">details</entity> of the EFW, but these will not be examined in this <entity id="C90-2012.9">paper</entity> . Substantively, the <entity id="C90-2012.10">question</entity> arises as to what mileage there is in this <entity id="C90-2012.11">formalism</entity> for the MT <entity id="C90-2012.12">problem</entity> . Possibly this <entity id="C90-2012.13">question</entity> arises about any new NLP <entity id="C90-2012.14">formalism</entity> , but Raw et al (1988) describe the EFW in an MT <entity id="C90-2012.15">context</entity> . The EFW arose in reaction to the <entity id="C90-2012.16">CAT</entity> <entity id="C90-2012.17">formalism</entity> for MT (Arnold (?,{ <entity id="C90-2012.18">cat</entity> =s}).[ (gov,{ <entity id="C90-2012.19">cat</entity> =v}), : argl, =>(s).[ vp.C
</abstract>



</text>

<text id="C90-2046">
<title>
Tenets For An Interlingual <entity id="C90-2046.1">Representation</entity> Of Definite NPs
</title>
<abstract>
The <entity id="C90-2046.2">main</entity> <entity id="C90-2046.3">goal</entity> of this <entity id="C90-2046.4">paper</entity> (as in Keenan and  Stavi 1986 ) is to characterize the possible <entity id="C90-2046.5">determiner</entity> denotations in <entity id="C90-2046.6">order</entity> to <entity id="C90-2046.7">develop</entity> a <entity id="C90-2046.8">computational</entity> <entity id="C90-2046.9">approach</entity> that makes explicit use of this <entity id="C90-2046.10">information</entity> . To cope with the <entity id="C90-2046.11">constraints</entity> that <entity id="C90-2046.12">languages</entity> impose when <entity id="C90-2046.13">generating</entity> <entity id="C90-2046.14">determiners</entity> , a <entity id="C90-2046.15">computational model</entity> has to follow the laws that <entity id="C90-2046.16">map</entity> d
finiteness to <entity id="C90-2046.17">structures</entity> and <entity id="C90-2046.18">strings</entity> and viceversa. In the following <entity id="C90-2046.19">proposal</entity> I distantiate from K. B
hlers Deixis <entity id="C90-2046.20">Theory</entity> and Weinrichs (76) <entity id="C90-2046.21">proposal</entity> where indefinites suggest subsequent <entity id="C90-2046.22">information</entity> , while definite point out facts from the previous <entity id="C90-2046.23">information</entity> . This very general position is insufficient if we want to formalize NP-definiteness. The <entity id="C90-2046.24">semantics</entity> of NP defmiteness must be captured adequately in <entity id="C90-2046.25">computational</entity> <entity id="C90-2046.26">frameworks</entity> for such <entity id="C90-2046.27">tasks</entity> as answering quantified NL-- <entity id="C90-2046.28">questions</entity> , or in a <entity id="C90-2046.29">MT system</entity> to convert NPs from one <entity id="C90-2046.30">language</entity> into another. In the first <entity id="C90-2046.31">part</entity> of this <entity id="C90-2046.32">paper</entity> I draw a <entity id="C90-2046.33">typology</entity> of defmiteness ; later I reflect on the defmiteness of NPs in an <entity id="C90-2046.34">IL-representation</entity> . The major <entity id="C90-2046.35">result</entity> is given by the <entity id="C90-2046.36">determiner</entity> <entity id="C90-2046.37">generators</entity> . Defmiteness should be <entity id="C90-2046.38">evaluated</entity> in a Q-A <entity id="C90-2046.39">system</entity> and in MT. The extensive <entity id="C90-2046.40">functionality</entity>    of   defmiteness    is first elaborated in the <entity id="C90-2046.41">parsing</entity> and <entity id="C90-2046.42">results</entity> in an <entity id="C90-2046.43">IL-representation</entity> ; finally the <entity id="C90-2046.44">determiner</entity> <entity id="C90-2046.45">generators</entity> create correct morphological <entity id="C90-2046.46">determiners</entity> and right <entity id="C90-2046.47">determiner</entity> <entity id="C90-2046.48">structures</entity> .
</abstract>


propose(C90-2046.32,C90-2046.33)

</text>

<text id="C90-2050">
<title>
A Head-Driven <entity id="C90-2050.1">Approach</entity> To Incremental And Parallel <entity id="C90-2050.2">Generation</entity> Of <entity id="C90-2050.3">Syntactic</entity> <entity id="C90-2050.4">Structures</entity></title> 
<abstract><entity id="C90-2050.5">Abstract</entity> :
</abstract>



</text>

<text id="C90-2057">
<title><entity id="C90-2057.1">Lexical</entity> Gaps And Idioms In <entity id="C90-2057.2">Machine Translation</entity></title>
<abstract>
This <entity id="C90-2057.3">paper</entity> describes the <entity id="C90-2057.4">treatment</entity> of <entity id="C90-2057.5">lexical</entity> <entity id="C90-2057.6">gaps</entity> , <entity id="C90-2057.7">collocation</entity> <entity id="C90-2057.8">information</entity> and <entity id="C90-2057.9">idioms</entity> in the <entity id="C90-2057.10">English</entity> to Portuguese <entity id="C90-2057.11">machine <entity id="C90-2057.12">translation system</entity></entity> PORTUGA. The <entity id="C90-2057.13">perspective</entity> is strictly bilingual, in the <entity id="C90-2057.14">sense</entity> that all <entity id="C90-2057.15">problems</entity> referenced above are considered to belong to the <entity id="C90-2057.16">transfer</entity> <entity id="C90-2057.17">phase</entity> , and not, as in other <entity id="C90-2057.18">systems</entity> , to <entity id="C90-2057.19">analysis</entity> or <entity id="C90-2057.20">generation</entity> . The <entity id="C90-2057.21">solution</entity> presented invokes a <entity id="C90-2057.22">parser</entity> for the <entity id="C90-2057.23">target language</entity> (Portuguese) that <entity id="C90-2057.24">analyses</entity> , producing the corresponding graph <entity id="C90-2057.25">structure</entity> , the <entity id="C90-2057.26">multiword <entity id="C90-2057.27">expression</entity></entity> selected as the <entity id="C90-2057.28">result</entity> of <entity id="C90-2057.29">lexical</entity> <entity id="C90-2057.30">transfer</entity> . This <entity id="C90-2057.31">process</entity> seems to bring considerable <entity id="C90-2057.32">advantage</entity> in what <entity id="C90-2057.33">readability</entity> and ease of bilingual <entity id="C90-2057.34">dictionary</entity> <entity id="C90-2057.35">development</entity> is <entity id="C90-2057.36">concerned</entity> , and to furnish maximal <entity id="C90-2057.37">flexibility</entity> together with minimal <entity id="C90-2057.38">storage</entity> <entity id="C90-2057.39">requirements</entity> . Finally, it also <entity id="C90-2057.40">provides</entity> complete <entity id="C90-2057.41">independence</entity> between <entity id="C90-2057.42">dictionary</entity> and grammar <entity id="C90-2057.43">formalisms</entity> .
</abstract>


propose(C90-2057.3,C90-2057.11)
taskapplied(C90-2057.22,C90-2057.26)

</text>

<text id="C90-3017">
<title>
A Symmetrical <entity id="C90-3017.1">Approach</entity> To <entity id="C90-3017.2">Parsing</entity> And <entity id="C90-3017.3">Generation</entity></title> 
<abstract><entity id="C90-3017.4">Abstract</entity> . <entity id="C90-3017.5">Lexical</entity> Grammars guide;
</abstract>



</text>

<text id="C90-3079">
<title>
Intelligent Handling Of Weather Forecasts
</title>
<abstract>
Some typical <entity id="C90-3079.1">cases</entity> of intelligent handling of weather forecasts such as <entity id="C90-3079.2">translation</entity> , <entity id="C90-3079.3">visualization</entity> , etc. are decomposed into two subprocesses <entity id="C90-3079.4">analysis</entity> and <entity id="C90-3079.5">synthesis</entity> . Specific <entity id="C90-3079.6">techniques</entity> are presented for <entity id="C90-3079.7">analysis</entity> and <entity id="C90-3079.8">synthesis</entity> of weather forecast <entity id="C90-3079.9">texts</entity> as well as for <entity id="C90-3079.10">generation</entity> of weather <entity id="C90-3079.11">maps</entity> . These <entity id="C90-3079.12">techniques</entity> <entity id="C90-3079.13">deal</entity> with the weather forecasts at different <entity id="C90-3079.14">levels</entity> <entity id="C90-3079.15">syntactic</entity> , <entity id="C90-3079.16">discourse</entity> and <entity id="C90-3079.17">semantic</entity> . They are <entity id="C90-3079.18">based</entity> on a conceptual <entity id="C90-3079.19">model</entity> underlying weather forecasts as well as on formal <entity id="C90-3079.20">descriptions</entity> of the means of <entity id="C90-3079.21">expression</entity> used in particular <entity id="C90-3079.22">natural</entity> and cartographic sublanguages.
</abstract>


cohyp(C90-3079.4,C90-3079.5)

</text>

<text id="C92-1013">
<title>
Synchronous TAGs And French Pronominal Clitics
</title>
<abstract>
"- as a consequence of both above <entity id="C92-1013.1">properties</entity> , it allows die grammar to be totally lcxicalized ( Schabes et al. 1988 ). However, a certain <entity id="C92-1013.2">number</entity> of <entity id="C92-1013.3">syntactic</entity> <entity id="C92-1013.4">phenomena</entity> are difficult to represent in this <entity id="C92-1013.5">framework</entity> . We <entity id="C92-1013.6">focus</entity> here on French pronominal clitics which <entity id="C92-1013.7">arc</entity> <entity id="C92-1013.8">cases</entity> of non canonical <entity id="C92-1013.9">argument</entity> <entity id="C92-1013.10">realization</entity> . We show how they can be naturally handled using the ""Synchronous <entity id="C92-1013.11">TAG</entity> "" <entity id="C92-1013.12">extension</entity> of the <entity id="C92-1013.13">formalism</entity> as a further set of wcllformcdness conditions on the <entity id="C92-1013.14">language</entity> ami we extend this <entity id="C92-1013.15">treatment</entity> to other <entity id="C92-1013.16">cases</entity> of <entity id="C92-1013.17">mismatch</entity> between <entity id="C92-1013.18">syntactic</entity> <entity id="C92-1013.19">attachment</entity> and <entity id="C92-1013.20">semantic role</entity> . "
</abstract>



</text>

<text id="C92-1037">
<title>
Genetic NPs And Habitual VPs
</title>
<abstract>
We <entity id="C92-1037.1">propose</entity> a <entity id="C92-1037.2">simple</entity> , intuitively satisfying <entity id="C92-1037.3">treatment</entity> of the <entity id="C92-1037.4">semantics</entity> of bare plural NPs . This <entity id="C92-1037.5">treatment</entity> avoids the use of nonstandard <entity id="C92-1037.6">logics</entity> , and avoids the need for systematic <entity id="C92-1037.7">ambiguity</entity> of <entity id="C92-1037.8">verb</entity> <entity id="C92-1037.9">semantics</entity> .
</abstract>


study(C92-1037.3,C92-1037.4)
problem(C92-1037.7,C92-1037.9)

</text>

<text id="C92-1049">
<title>
Using Linguistic, World, And Contextual <entity id="C92-1049.1">Knowledge</entity> In A Plan <entity id="C92-1049.2">Recognition</entity> <entity id="C92-1049.3">Model</entity> Of <entity id="C92-1049.4">Dialogue</entity></title>
<abstract>This <entity id="C92-1049.5">paper</entity> presents a <entity id="C92-1049.6">plan-based <entity id="C92-1049.7">model</entity></entity> of <entity id="C92-1049.8">dialogue</entity> that combines world, linguistic, and contextual <entity id="C92-1049.9">knowledge</entity> in <entity id="C92-1049.10">order</entity> to recognize <entity id="C92-1049.11">complex</entity> communicative <entity id="C92-1049.12">actions</entity> such as expressing doubt. <entity id="C92-1049.13">Linguistic knowledge</entity> suggests certain <entity id="C92-1049.14">discourse</entity> acts, a speaker's beliefs, and the <entity id="C92-1049.15">strength</entity> of those beliefs; contextual <entity id="C92-1049.16">knowledge</entity> suggests the most coherent continuation of the <entity id="C92-1049.17">dialogue</entity> ; and <entity id="C92-1049.18">world knowledge</entity> <entity id="C92-1049.19">provides</entity> <entity id="C92-1049.20">evidence</entity> that the <entity id="C92-1049.21">applicability</entity> conditions hold for those <entity id="C92-1049.22">discourse</entity> acts that capture the <entity id="C92-1049.23">relationship</entity> of the <entity id="C92-1049.24">current</entity> <entity id="C92-1049.25">utterance</entity> to the <entity id="C92-1049.26">discourse</entity> as a whole.
</abstract>


model(C92-1049.3,C92-1049.4)
propose(C92-1049.5,C92-1049.6)

</text>

<text id="C92-1052">
<title>
Temporal <entity id="C92-1052.1">Structure</entity> Of <entity id="C92-1052.2">Discourse</entity></title>
<abstract>
In this <entity id="C92-1052.3">paper</entity> <entity id="C92-1052.4">discourse</entity> <entity id="C92-1052.5">segments</entity> are defined and a <entity id="C92-1052.6">method</entity> for <entity id="C92-1052.7">discourse</entity> segmentation primarily <entity id="C92-1052.8">based</entity> on abduction of <entity id="C92-1052.9">temporal relations</entity> between <entity id="C92-1052.10">segments</entity> is <entity id="C92-1052.11">proposed</entity> . This <entity id="C92-1052.12">method</entity> is precise and computationally feasible and is <entity id="C92-1052.13">supported</entity> by previous work in the <entity id="C92-1052.14">area</entity> of temporal <entity id="C92-1052.15">anaphora <entity id="C92-1052.16">resolution</entity></entity> .
</abstract>


char(C92-1052.1,C92-1052.2)
methodapplied(C92-1052.6,C92-1052.7)
methodapplied(C92-1052.12,C92-1052.15)

</text>

<text id="C92-1053">
<title>
Organizing <entity id="C92-1053.1">Dialogue</entity> From An Incoherent <entity id="C92-1053.2">Stream</entity> Of Goals
</title>
<abstract>
their <entity id="C92-1053.3">reasoning</entity> for <entity id="C92-1053.4">structure</entity> their <entity id="C92-1053.5">dialogues</entity> . Instead, <entity id="C92-1053.6">computer-generated</entity> <entity id="C92-1053.7">conversation</entity> must rely on some other <entity id="C92-1053.8">mechanism</entity> for its organisation. In this <entity id="C92-1053.9">paper</entity> , we discuss such <entity id="C92-1053.10">mechanism</entity> . We describe <entity id="C92-1053.11">provides</entity> a guide for <entity id="C92-1053.12">conversation</entity> . The <entity id="C92-1053.13">template</entity> is built from <entity id="C92-1053.14">schemata</entity> representing <entity id="C92-1053.15">discourse</entity> <entity id="C92-1053.16">convention</entity> . As <entity id="C92-1053.17">goals</entity> arrive from the <entity id="C92-1053.18">problem</entity> <entity id="C92-1053.19">solver</entity> they are added to the <entity id="C92-1053.20">template</entity> . Because accepted <entity id="C92-1053.21">discourse structures</entity> are used to connect a new <entity id="C92-1053.22">goal</entity> to the existing <entity id="C92-1053.23">template</entity> , <entity id="C92-1053.24">goals</entity> are organised into sub-groups that follow conventional, coherent <entity id="C92-1053.25">patterns</entity> of <entity id="C92-1053.26">discourse</entity> . We present JUDIS , an <entity id="C92-1053.27">interface</entity> to <entity id="C92-1053.28">distributed</entity> <entity id="C92-1053.29">problem</entity> <entity id="C92-1053.30">solver</entity> that uses this <entity id="C92-1053.31">approach</entity> to organise <entity id="C92-1053.32">dialogues</entity> from incoherent of <entity id="C92-1053.33">goals</entity> .
</abstract>


char(C92-1053.25,C92-1053.26)

</text>

<text id="C92-2108">
<title>
Preventing False Temporal Implicatures: Interactive <entity id="C92-2108.1">Defaults</entity> For <entity id="C92-2108.2">Text Generation</entity></title>
<abstract>
Given the causal and <entity id="C92-2108.3">temporal <entity id="C92-2108.4">relations</entity></entity> between <entity id="C92-2108.5">events</entity> in a <entity id="C92-2108.6">knowledge base</entity> , what are the ways they can be described in <entity id="C92-2108.7">text</entity> ? Elsewhere, we have argued that during <entity id="C92-2108.8">interpretation</entity> , the reader-hearer // must infer certain temporal <entity id="C92-2108.9">information</entity> from <entity id="C92-2108.10">knowledge</entity> about the world, <entity id="C92-2108.11">language</entity> use and pragmatics. It is generally agreed that <entity id="C92-2108.12">processes</entity> of Gricean implicature <entity id="C92-2108.13">help</entity> determine the <entity id="C92-2108.14">interpretation</entity> of <entity id="C92-2108.15">text</entity> in <entity id="C92-2108.16">context</entity> . But without a <entity id="C92-2108.17">notion</entity> of logical <entity id="C92-2108.18">con</entity> se quo ii ce to underwrite them, the <entity id="C92-2108.19">inferences</entity>
-often defeasible in <entity id="C92-2108.20">nature</entity> - will appear arbitrary, and unprincipled. Hence, we have explored the <entity id="C92-2108.21">requirements</entity> on a formal <entity id="C92-2108.22">model</entity> of temporal implicature, and <entity id="C92-2108.23">outlined</entity> one possible nonmonotonic <entity id="C92-2108.24">framework</entity> for <entity id="C92-2108.25">discourse</entity> <entity id="C92-2108.26">interpretation</entity> (Lascarides &amp;; Asher [1991], Lascarides     Oberlander [1992a]). Here, we argue that if the writer-speaker 22077.
</abstract>


phenomenon(C92-2108.3,C92-2108.5)
based_on(C92-2108.14,C92-2108.16)

</text>

<text id="C92-2110">
<title><entity id="C92-2110.1">Design</entity> <entity id="C92-2110.2">Tool</entity> <entity id="C92-2110.3">Combining</entity> <entity id="C92-2110.4">Keyword</entity> <entity id="C92-2110.5">Analyzer</entity> And <entity id="C92-2110.6">Case-</entity> <entity id="C92-2110.7">Based</entity> <entity id="C92-2110.8">Parser</entity> For <entity id="C92-2110.9">Developing</entity> <entity id="C92-2110.10">Natural Language</entity> <entity id="C92-2110.11">Database</entity> Interfaces
</title>
<abstract>
We have <entity id="C92-2110.12">designed</entity> and experimentally <entity id="C92-2110.13">implemented</entity> a <entity id="C92-2110.14">tool</entity> for <entity id="C92-2110.15">developing</entity> a <entity id="C92-2110.16">natural <entity id="C92-2110.17">language systems</entity></entity> that can accept extra-grammatical <entity id="C92-2110.18">expressions</entity> , <entity id="C92-2110.19">keyword</entity> <entity id="C92-2110.20">sequences</entity> , and linguistic <entity id="C92-2110.21">fragments</entity> , as well as ordinary <entity id="C92-2110.22">natural language</entity> <entity id="C92-2110.23">queries</entity> . The key to this <entity id="C92-2110.24">tool</entity> 's <entity id="C92-2110.25">efficiency</entity> is its effective use of a <entity id="C92-2110.26">simple</entity> <entity id="C92-2110.27">keyword</entity> <entity id="C92-2110.28">analyzer</entity> in <entity id="C92-2110.29">combination</entity> with a conventional <entity id="C92-2110.30">case-based</entity> <entity id="C92-2110.31">parser</entity> . The <entity id="C92-2110.32">keyword</entity> <entity id="C92-2110.33">analyzer</entity> <entity id="C92-2110.34">performs</entity> a <entity id="C92-2110.35">majority</entity> of those <entity id="C92-2110.36">queries</entity> which are <entity id="C92-2110.37">simple</entity> <entity id="C92-2110.38">data</entity> <entity id="C92-2110.39">retrievals</entity> . Since it uses only <entity id="C92-2110.40">keywords</entity> in any <entity id="C92-2110.41">query</entity> , this <entity id="C92-2110.42">analyzer</entity> is <entity id="C92-2110.43">robust</entity> with regard to extra-grammatical <entity id="C92-2110.44">expressions</entity> . Since little <entity id="C92-2110.45">labor</entity> is <entity id="C92-2110.46">required</entity> of the <entity id="C92-2110.47">application</entity> designer in using the <entity id="C92-2110.48">keyword</entity> <entity id="C92-2110.49">analyzer</entity> <entity id="C92-2110.50">portion</entity> of the <entity id="C92-2110.51">tool</entity> , and since the <entity id="C92-2110.52">case-based</entity> <entity id="C92-2110.53">parser</entity> <entity id="C92-2110.54">processes</entity> only those <entity id="C92-2110.55">queries</entity> which the <entity id="C92-2110.56">keyword</entity> <entity id="C92-2110.57">analyzer</entity> fails to interpret, total <entity id="C92-2110.58">labor</entity> <entity id="C92-2110.59">required</entity> of the designer is less than that for a <entity id="C92-2110.60">tool</entity> which employs a conventional <entity id="C92-2110.61">case-based</entity> <entity id="C92-2110.62">parser</entity> alone.
</abstract>


methodapplied(C92-2110.2,C92-2110.11)
methodapplied(C92-2110.14,C92-2110.16)
char(C92-2110.42,C92-2110.43,REVERSE)

</text>

<text id="C92-2119">
<title>
A <entity id="C92-2119.1">Robust</entity> <entity id="C92-2119.2">Approach</entity> For Handling Oral Dialogues
</title>
<abstract>
Present <entity id="C92-2119.3">limits</entity> of <entity id="C92-2119.4">speech <entity id="C92-2119.5">recognition</entity></entity> and <entity id="C92-2119.6">understanding</entity> in the <entity id="C92-2119.7">context</entity> of free spoken <entity id="C92-2119.8">language</entity> (altlwugh with a limited <entity id="C92-2119.9">vocabulary</entity> ) have perverse <entity id="C92-2119.10">effects</entity> on the flow of the <entity id="C92-2119.11">dialogue</entity> with a <entity id="C92-2119.12">system</entity> . Typically a non <entity id="C92-2119.13">robust</entity> <entity id="C92-2119.14">dialogue</entity> <entity id="C92-2119.15">manager</entity> will fail to face with these <entity id="C92-2119.16">limits</entity> and <entity id="C92-2119.17">conversations</entity> will often be a failure. This <entity id="C92-2119.18">paper</entity> presents some <entity id="C92-2119.19">possibilities</entity> of a <entity id="C92-2119.20">structural</entity> <entity id="C92-2119.21">approach</entity> for handling <entity id="C92-2119.22">communication</entity> failures in <entity id="C92-2119.23">task-oriented</entity> oral <entity id="C92-2119.24">dialogues</entity> . Several <entity id="C92-2119.25">types</entity> of <entity id="C92-2119.26">communication</entity> failures are presented and explained. They must be <entity id="C92-2119.27">dealt</entity> with by the <entity id="C92-2119.28">dialogue</entity> <entity id="C92-2119.29">manager</entity> if we strike to have a <entity id="C92-2119.30">robust</entity> <entity id="C92-2119.31">system</entity> . The exposed <entity id="C92-2119.32">strategies</entity> for handling these failures are <entity id="C92-2119.33">based</entity> on a <entity id="C92-2119.34">structural</entity> <entity id="C92-2119.35">approach</entity> of the <entity id="C92-2119.36">conversation</entity> and are <entity id="C92-2119.37">implemented</entity> in the SUNDIAL <entity id="C92-2119.38">system</entity> . We first <entity id="C92-2119.39">recall</entity> some <entity id="C92-2119.40">aspects</entity> of the <entity id="C92-2119.41">model</entity> and then describe the <entity id="C92-2119.42">strategies</entity> for preventing and <entity id="C92-2119.43">repairing</entity> <entity id="C92-2119.44">communication</entity> failure in oral <entity id="C92-2119.45">conversations</entity> with a <entity id="C92-2119.46">system</entity> .
</abstract>


problem(C92-2119.3,C92-2119.4)
propose(C92-2119.18,C92-2119.19)
char(C92-2119.23,C92-2119.24)
usedfor(C92-2119.43,C92-2119.46,REVERSE)

</text>

<text id="C92-3131">
<title>
Causal <entity id="C92-3131.1">Ambiguity</entity> In <entity id="C92-3131.2">Natural Language</entity> : Conceptual <entity id="C92-3131.3">Representation</entity> Of'parce Que/because' And 'puisque/since'
</title>
<abstract>
This <entity id="C92-3131.4">research</entity> <entity id="C92-3131.5">deals</entity> with the <entity id="C92-3131.6">representation</entity> of causal <entity id="C92-3131.7">relations</entity> found in <entity id="C92-3131.8">texts</entity> written in <entity id="C92-3131.9">natural language</entity> , in <entity id="C92-3131.10">order</entity> for KALIPSOS [1], an <entity id="C92-3131.11">NL-understanding</entity> and <entity id="C92-3131.12">question-answering system</entity> , to encode causal <entity id="C92-3131.13">information</entity> in conceptual graphs so as to handle causal <entity id="C92-3131.14">information</entity> and <entity id="C92-3131.15">reasoning</entity> . <entity id="C92-3131.16">Natural <entity id="C92-3131.17">languages</entity></entity> such as French or <entity id="C92-3131.18">English</entity> have many ways to express a causal <entity id="C92-3131.19">relation</entity> . It can be <entity id="C92-3131.20">syntactic</entity> (parce que/because) {provoquer/to produce), (Je me suis cass
e la jambe el je n'ai pas pu venir/1 broke my leg and I couldn't come), parce que/because puisque/since parce que/because puisque/since
</abstract>


model(C92-3131.6,C92-3131.7)
isa(C92-3131.16,C92-3131.18,REVERSE)

</text>

<text id="C92-3132">
<title><entity id="C92-3132.1">Surface</entity> And Deep <entity id="C92-3132.2">Cases</entity></title>
<abstract>
"In this <entity id="C92-3132.3">paper</entity> we show the <entity id="C92-3132.4">relation</entity> between the ""<entity id="C92-3132.5">surface</entity> (morphological) <entity id="C92-3132.6">cases</entity> "" and ""deep <entity id="C92-3132.7">cases</entity> "" ( <entity id="C92-3132.8">participants</entity> ), and the possible way to automate the <entity id="C92-3132.9">creation</entity> of a <entity id="C92-3132.10">syntactic</entity> <entity id="C92-3132.11">dictionary</entity> <entity id="C92-3132.12">provided</entity> with <entity id="C92-3132.13">frames</entity> containing <entity id="C92-3132.14">information</entity> about deep <entity id="C92-3132.15">cases</entity> and their morphemic counterparts of particular <entity id="C92-3132.16">lexical items</entity> (Czech <entity id="C92-3132.17">verbs</entity> )."
</abstract>



</text>

<text id="C92-3147">
<title>
B-SURE: A Believed <entity id="C92-3147.1">Situation</entity> And Uncertain- <entity id="C92-3147.2">Action</entity> <entity id="C92-3147.3">Representation</entity> <entity id="C92-3147.4">Environment</entity></title>
<abstract>
Tliis <entity id="C92-3147.5">paper</entity> presents a <entity id="C92-3147.6">system</entity> that is capable of representing <entity id="C92-3147.7">situations</entity> , states, and nondeterniinistic <entity id="C92-3147.8">nonmonotonic-outcome</entity> <entity id="C92-3147.9">actions</entity> occurring in multiple possible worlds. The <entity id="C92-3147.10">system</entity> <entity id="C92-3147.11">supports</entity> explicit <entity id="C92-3147.12">representations</entity> of <entity id="C92-3147.13">actions</entity> and <entity id="C92-3147.14">situations</entity> used in intentional <entity id="C92-3147.15">action</entity> <entity id="C92-3147.16">theory</entity> and <entity id="C92-3147.17">situation</entity> <entity id="C92-3147.18">theory</entity> , l
oth <entity id="C92-3147.19">types</entity> and <entity id="C92-3147.20">instances</entity> are <entity id="C92-3147.21">supported</entity> . Situations and states before and after nonmonotonic <entity id="C92-3147.22">actions</entity> can be represented simultaneously. Agents have free will as to whether to choose to <entity id="C92-3147.23">perform</entity> an <entity id="C92-3147.24">action</entity> or not. Situations mid <entity id="C92-3147.25">actions</entity> can have expected values, allowing the <entity id="C92-3147.26">system</entity> to <entity id="C92-3147.27">support</entity> <entity id="C92-3147.28">decision-making</entity> and <entity id="C92-3147.29">decision-based</entity> plan <entity id="C92-3147.30">inferencing</entity> . The <entity id="C92-3147.31">system</entity> can <entity id="C92-3147.32">perform</entity> global <entity id="C92-3147.33">reasoning</entity> simultaneously across multiple possible worlds, without being forced to extend each world explicitly. The <entity id="C92-3147.34">resulting</entity> <entity id="C92-3147.35">system</entity> is useful for Biich <entity id="C92-3147.36">natural language</entity> <entity id="C92-3147.37">tasks</entity> as plan <entity id="C92-3147.38">recognition</entity> , intentions <entity id="C92-3147.39">modeling</entity> , and parallel <entity id="C92-3147.40">task</entity> scheduling.
</abstract>


propose(C92-3147.5,C92-3147.6)
cohyp(C92-3147.13,C92-3147.14)
usedfor(C92-3147.26,C92-3147.28)

</text>

<text id="C92-3156">
<title><entity id="C92-3156.1">Parsing</entity> And <entity id="C92-3156.2">Case</entity> <entity id="C92-3156.3">Analysis</entity> In TANKA
</title>
<abstract>Sparck Jones , Karen ; Boguraev , Branimir K. ,Technical <entity id="C92-3156.4">Correspondence</entity> : A <entity id="C92-3156.5">Note</entity> On A <entity id="C92-3156.6">Study</entity> Of <entity id="C92-3156.7">Cases</entity> , <entity id="C92-3156.8">Computation</entity> al <entity id="C92-3156.9">Linguistics</entity> ,1987</abstract>



</text>

<text id="C92-3166">
<title>
Les Experiences D'indexation A L'inist
</title>



</text>

<abstract></abstract>

<text id="C92-4216">
<title>
Analysing <entity id="C92-4216.1">Dictionary</entity> Definitions Of <entity id="C92-4216.2">Motion</entity> Verbs
</title>
<abstract>
Universit
 di Pisa - Dipartimento di Linguistica Via S. Maria , 36 - 561 (K) PISA - Italy Tel. +39-50-560481; Fax +39-50-589055 <entity id="C92-4216.3">e-mail</entity> : LEM1NTER @> ICNUCEVM.
</abstract>



</text>

<text id="C94-1038">
<title>
An <entity id="C94-1038.1">Architecture</entity> For A Universal <entity id="C94-1038.2">Lexicon</entity> A <entity id="C94-1038.3">Case <entity id="C94-1038.4">Study</entity></entity> On Shared <entity id="C94-1038.5">Syntactic <entity id="C94-1038.6">Information</entity></entity> In <entity id="C94-1038.7">Japanese</entity> , Hindi, <entity id="C94-1038.8">Bengali</entity> , <entity id="C94-1038.9">Greek</entity> , And <entity id="C94-1038.10">English</entity></title> 
<abstract>Pustejovsky , James ,The Generative <entity id="C94-1038.11">Lexicon</entity> , <entity id="C94-1038.12">Computation</entity> al <entity id="C94-1038.13">Linguistics</entity> ,1991</abstract>


study(C94-1038.3,C94-1038.5)

</text>

<text id="C94-1047">
<title><entity id="C94-1047.1">Logic</entity> <entity id="C94-1047.2">Compression</entity> Of Dictionaries For Multilingual Spelling Checkers
</title>
<abstract>
"To <entity id="C94-1047.3">provide</entity> practical spelling checkers on <entity id="C94-1047.4">micro-computers</entity> , good <entity id="C94-1047.5">compression</entity> <entity id="C94-1047.6">algorithms</entity> are essential. <entity id="C94-1047.7">Current</entity> <entity id="C94-1047.8">techniques</entity> used to compress <entity id="C94-1047.9">lexicons</entity> for indo-Europcan <entity id="C94-1047.10">languages</entity> <entity id="C94-1047.11">provide</entity> efficient spelling checker. <entity id="C94-1047.12">Applying</entity> the same <entity id="C94-1047.13">methods</entity> to <entity id="C94-1047.14">languages</entity> which have a different morphological <entity id="C94-1047.15">system</entity> (Arabic, Turkish,...) gives insufficient <entity id="C94-1047.16">results</entity> . To get better <entity id="C94-1047.17">results</entity> , we <entity id="C94-1047.18">apply</entity> other ""logical"" <entity id="C94-1047.19">compression</entity> <entity id="C94-1047.20">mechanisms</entity> <entity id="C94-1047.21">based</entity> on the <entity id="C94-1047.22">structure</entity> of the <entity id="C94-1047.23">language</entity> itself. <entity id="C94-1047.24">Experiments</entity> with multilingual <entity id="C94-1047.25">dictionaries</entity> show a significant <entity id="C94-1047.26">reduction</entity> <entity id="C94-1047.27">rate</entity> attributable to our <entity id="C94-1047.28">logic</entity> <entity id="C94-1047.29">compression</entity> alone and even better <entity id="C94-1047.30">results</entity> when using our <entity id="C94-1047.31">method</entity> in <entity id="C94-1047.32">conjunction</entity> with existing <entity id="C94-1047.33">methods</entity> . KEY <entity id="C94-1047.34">WORDS</entity> : "
</abstract>


based_on(C94-1047.20,C94-1047.22)
yields(C94-1047.24,C94-1047.30)

</text>

<text id="C94-1103">
<title>
CLAWS4: The <entity id="C94-1103.1">Tagging</entity> Of The British National <entity id="C94-1103.2">Corpus</entity></title>
<abstract>
The <entity id="C94-1103.3">main</entity> <entity id="C94-1103.4">purpose</entity> of this <entity id="C94-1103.5">paper</entity> is to describe the CLAWS4 <entity id="C94-1103.6">general-purpose</entity> grammatical tagger, used for the <entity id="C94-1103.7">tagging</entity> of the 100- <entity id="C94-1103.8">million-word</entity> British National <entity id="C94-1103.9">Corpus</entity> , of which c.70 million <entity id="C94-1103.10">words</entity> have been <entity id="C94-1103.11">tagged</entity> at the <entity id="C94-1103.12">time</entity> of writing (April  1994 ).tagsets <entity id="C94-1103.13">input</entity> <entity id="C94-1103.14">formats</entity> . <entity id="C94-1103.15">output</entity> <entity id="C94-1103.16">formats</entity> :
</abstract>


taskapplied(C94-1103.1,C94-1103.2)
taskapplied(C94-1103.7,C94-1103.8)

</text>

<text id="C94-2116">
<title><entity id="C94-2116.1">Verbal</entity> <entity id="C94-2116.2">Case</entity> <entity id="C94-2116.3">Frame</entity> <entity id="C94-2116.4">Acquisition</entity> From A Bilingual <entity id="C94-2116.5">Corpus</entity> : Gradual <entity id="C94-2116.6">Knowledge</entity> <entity id="C94-2116.7">Acquisition</entity></title>
<abstract>
This <entity id="C94-2116.8">paper</entity> describes <entity id="C94-2116.9">acquisition</entity> of <entity id="C94-2116.10">English</entity> <entity id="C94-2116.11">surface</entity> <entity id="C94-2116.12">case</entity> <entity id="C94-2116.13">frames</entity> from a <entity id="C94-2116.14">corpus</entity> , <entity id="C94-2116.15">based</entity> on a gradual <entity id="C94-2116.16">knowledge</entity> <entity id="C94-2116.17">acquisition</entity> <entity id="C94-2116.18">approach</entity> . To acquire and unambiguously accumulate precise <entity id="C94-2116.19">knowledge</entity> , the <entity id="C94-2116.20">process</entity> is divided into three <entity id="C94-2116.21">steps</entity> which <entity id="C94-2116.22">arc</entity> assigned to the most appropriate <entity id="C94-2116.23">processor</entity> : either a human or a <entity id="C94-2116.24">computer</entity> . The <entity id="C94-2116.25">data</entity> is prepared by human workers and the <entity id="C94-2116.26">knowledge</entity> is acquired and accumulated by a leaning <entity id="C94-2116.27">program</entity> . By using this <entity id="C94-2116.28">method</entity> , inconsistent human judgement is minimized. The acquired <entity id="C94-2116.29">case</entity> <entity id="C94-2116.30">frames</entity> basically duplicate human work, but are more precise and intelligible.
</abstract>



</text>

<text id="C94-2169">
<title><entity id="C94-2169.1">Thesaurus-</entity> <entity id="C94-2169.2">Based</entity> Efficient <entity id="C94-2169.3">Example</entity> <entity id="C94-2169.4">Retrieval</entity> By <entity id="C94-2169.5">Generating</entity> <entity id="C94-2169.6">Retrieval</entity> Queries From Similarities
</title>
<abstract>
In <entity id="C94-2169.7">example-based</entity> NLP, the <entity id="C94-2169.8">problem</entity> of <entity id="C94-2169.9">computational</entity> <entity id="C94-2169.10">cost</entity> of <entity id="C94-2169.11">example</entity> <entity id="C94-2169.12">retrieval</entity> is severe , since the <entity id="C94-2169.13">retrieval</entity> <entity id="C94-2169.14">time</entity> <entity id="C94-2169.15">increases</entity> in proportion to the <entity id="C94-2169.16">number</entity> of <entity id="C94-2169.17">examples</entity> in the <entity id="C94-2169.18">database</entity> . This <entity id="C94-2169.19">paper</entity> <entity id="C94-2169.20">proposes</entity> a novel <entity id="C94-2169.21">example</entity> <entity id="C94-2169.22">retrieval</entity> <entity id="C94-2169.23">method</entity> for avoiding full <entity id="C94-2169.24">retrieval</entity> of <entity id="C94-2169.25">examples</entity> . The <entity id="C94-2169.26">proposed</entity> <entity id="C94-2169.27">method</entity> has the following three <entity id="C94-2169.28">features</entity> , 1) it <entity id="C94-2169.29">generates</entity></abstract>


problem(C94-2169.10,C94-2169.12)
propose(C94-2169.19,C94-2169.23)

</text>

<text id="C96-1001">
<title>
Discovering The Sounds Of <entity id="C96-1001.1">Discourse Structure</entity> Extended <entity id="C96-1001.2">Abstract</entity></title>
<abstract>
It is widely accepted that <entity id="C96-1001.3">discourses</entity> are composed of <entity id="C96-1001.4">segments</entity> and that the <entity id="C96-1001.5">recognition</entity> of <entity id="C96-1001.6">segment</entity> <entity id="C96-1001.7">boundaries</entity> is essential to a <entity id="C96-1001.8">determination</entity> of <entity id="C96-1001.9">discourse</entity> meaning ( Grosz and  Sidner, 1986 ). Written <entity id="C96-1001.10">language</entity> has orthographic <entity id="C96-1001.11">cues</entity> such as <entity id="C96-1001.12">section</entity> headings, <entity id="C96-1001.13">paragraph</entity> <entity id="C96-1001.14">boundaries</entity> , and <entity id="C96-1001.15">punctuation</entity> which can assist in identifying <entity id="C96-1001.16">discourse structure</entity> . In spoken <entity id="C96-1001.17">language</entity> , into-national <entity id="C96-1001.18">variation</entity> <entity id="C96-1001.19">provides</entity> essential <entity id="C96-1001.20">information</entity> about <entity id="C96-1001.21">discourse structure</entity> . For <entity id="C96-1001.22">instance</entity> , it may be used to mark <entity id="C96-1001.23">structural</entity> <entity id="C96-1001.24">features</entity> of <entity id="C96-1001.25">discourse</entity> at the global <entity id="C96-1001.26">level</entity> , such as <entity id="C96-1001.27">segment</entity> <entity id="C96-1001.28">boundaries</entity> . <entity id="C96-1001.29">Intonation</entity> also <entity id="C96-1001.30">provides</entity> more local <entity id="C96-1001.31">information</entity> about <entity id="C96-1001.32">relations</entity> among <entity id="C96-1001.33">utterances</entity> within a <entity id="C96-1001.34">segment</entity> , for <entity id="C96-1001.35">example</entity> indicating whether <entity id="C96-1001.36">phrases</entity> are parenthetical. It can also <entity id="C96-1001.37">help</entity> distinguish between different <entity id="C96-1001.38">interpretations</entity> of <entity id="C96-1001.39">phrases</entity> that can <entity id="C96-1001.40">function</entity> either as <entity id="C96-1001.41">cue</entity> <entity id="C96-1001.42">phrases</entity> that indicate <entity id="C96-1001.43">discourse</entity> <entity id="C96-1001.44">segment</entity> <entity id="C96-1001.45">boundaries</entity> or sentcntially to convey <entity id="C96-1001.46">domain</entity> <entity id="C96-1001.47">information</entity> . Finally, <entity id="C96-1001.48">variations</entity> in intonational <entity id="C96-1001.49">prominence</entity> may be used to convey <entity id="C96-1001.50">information</entity> about the <entity id="C96-1001.51">discourse</entity> <entity id="C96-1001.52">status</entity> of <entity id="C96-1001.53">entities</entity> referred to by definite <entity id="C96-1001.54">noun phrases</entity> and pronouns. An <entity id="C96-1001.55">understanding</entity> of intonational <entity id="C96-1001.56">variation</entity> and the ways in which it carries <entity id="C96-1001.57">information</entity> about <entity id="C96-1001.58">discourse</entity> <entity id="C96-1001.59">characteristics</entity> of spoken <entity id="C96-1001.60">language</entity> is important for <entity id="C96-1001.61">computer-based</entity> <entity id="C96-1001.62">interpretation</entity> and <entity id="C96-1001.63">generation</entity> of <entity id="C96-1001.64">speech</entity> . From the <entity id="C96-1001.65">interpretation</entity> <entity id="C96-1001.66">perspective</entity> , this <entity id="C96-1001.67">understanding</entity> may <entity id="C96-1001.68">provide</entity> new <entity id="C96-1001.69">techniques</entity> for identifying <entity id="C96-1001.70">discourse <entity id="C96-1001.71">structure</entity></entity> . From the <entity id="C96-1001.72">generation</entity> <entity id="C96-1001.73">perspective</entity> , it would lead to more <entity id="C96-1001.74">natural</entity> synthetic <entity id="C96-1001.75">speech</entity> , making it possible to produce <entity id="C96-1001.76">computer</entity> <entity id="C96-1001.77">speech</entity> that is easier for people to understand and less susceptible to misinterpretation. Three major <entity id="C96-1001.78">challenges</entity> have faced <entity id="C96-1001.79">researchers</entity> attempting to discover the <entity id="C96-1001.80">relationship</entity> between intonational <entity id="C96-1001.81">features</entity> and the <entity id="C96-1001.82">structure</entity> of spoken <entity id="C96-1001.83">discourse</entity> . First, the <entity id="C96-1001.84">collection</entity> of <entity id="C96-1001.85">corpora</entity> of <entity id="C96-1001.86">spontaneous <entity id="C96-1001.87">speech</entity></entity> has <entity id="C96-1001.88">required</entity> the <entity id="C96-1001.89">development</entity> of * The <entity id="C96-1001.90">research</entity> described in this <entity id="C96-1001.91">presentation</entity> was <entity id="C96-1001.92">supported</entity> by the National <entity id="C96-1001.93">Science</entity> Foundation, <entity id="C96-1001.94">Grant</entity> IRI 94-04756. The <entity id="C96-1001.95">research</entity> has been done collaboratively with Julia Hirschberg and Christine Nakatani . David Ahn <entity id="C96-1001.96">provided</entity> invaluable technical assistance. new <entity id="C96-1001.97">experimental</entity> <entity id="C96-1001.98">methodologies</entity> . Whereas it is straightforward to have the same <entity id="C96-1001.99">text</entity> read by many speakers, it is much more difficult to obtain similar <entity id="C96-1001.100">samples</entity> of <entity id="C96-1001.101">spontaneous <entity id="C96-1001.102">speech</entity></entity> from multiple speakers. Second, <entity id="C96-1001.103">techniques</entity> must be <entity id="C96-1001.104">developed</entity> to obtain reliable segmentations and la-belings of the <entity id="C96-1001.105">corpora</entity> . Because <entity id="C96-1001.106">discourse <entity id="C96-1001.107">structure</entity></entity> is rooted in <entity id="C96-1001.108">semantics</entity> rather than <entity id="C96-1001.109">syntax</entity> , this has proved more difficult than <entity id="C96-1001.110">tagging</entity> <entity id="C96-1001.111">corpora</entity> for <entity id="C96-1001.112">sentence structure</entity> . Third, measures of <entity id="C96-1001.113">agreement</entity> among segmentations must be <entity id="C96-1001.114">designed</entity> . In this <entity id="C96-1001.115">area</entity> too, the <entity id="C96-1001.116">semantic</entity> <entity id="C96-1001.117">nature</entity> of <entity id="C96-1001.118">discourse structure</entity> leads to a more <entity id="C96-1001.119">complex</entity> <entity id="C96-1001.120">problem</entity> than comparing <entity id="C96-1001.121">sentence</entity> <entity id="C96-1001.122">parse</entity> <entity id="C96-1001.123">structures</entity> . This talk will begin with a <entity id="C96-1001.124">summary</entity> of <entity id="C96-1001.125">pilot</entity> <entity id="C96-1001.126">studies</entity> that demonstrated reliable <entity id="C96-1001.127">correlations</entity> of <entity id="C96-1001.128">discourse structure</entity> and intonational <entity id="C96-1001.129">features</entity> ( Grosz and  Hirschberg, 1992 ; Hirschbcrg and  Grosz, 1992 ; Hirschbcrg and  Grosz, 1994 ). It will then <entity id="C96-1001.130">focus</entity> on a new <entity id="C96-1001.131">corpus</entity> of <entity id="C96-1001.132">direction-giving</entity> monologues, the Boston Directions <entity id="C96-1001.133">Corpus</entity> ( Nakatani et al., 1995a ; Hirschberg and  Nakatani, 1996 ). I will describe the <entity id="C96-1001.134">methodology</entity> we <entity id="C96-1001.135">developed</entity> to elicit fluent spontaneous <entity id="C96-1001.136">direction-giving</entity> monologues ranging over a <entity id="C96-1001.137">spectrum</entity> of planning <entity id="C96-1001.138">complexity</entity> . Next I will describe the <entity id="C96-1001.139">development</entity> of annotation <entity id="C96-1001.140">instructions</entity> used to <entity id="C96-1001.141">train</entity> labelers to <entity id="C96-1001.142">segment</entity> spoken <entity id="C96-1001.143">discourses</entity> ( Nakatani et ah, 1995b) and will discuss <entity id="C96-1001.144">agreement</entity> among segmentations on the Boston Directions <entity id="C96-1001.145">Corpus</entity> obtained using these <entity id="C96-1001.146">instructions</entity> . Then I will describe <entity id="C96-1001.147">results</entity> of our <entity id="C96-1001.148">analyses</entity> of the <entity id="C96-1001.149">correlation</entity> between <entity id="C96-1001.150">discourse structure</entity> and intonational <entity id="C96-1001.151">features</entity> . Finally, I will present a <entity id="C96-1001.152">list</entity> of <entity id="C96-1001.153">challenges</entity> for future <entity id="C96-1001.154">research</entity> in this <entity id="C96-1001.155">area</entity> .
</abstract>


composed_of(C96-1001.3,C96-1001.4)
taskapplied(C96-1001.5,C96-1001.6)
phenomenon(C96-1001.10,C96-1001.14,REVERSE)
taskapplied(C96-1001.63,C96-1001.64)
usedfor(C96-1001.69,C96-1001.70)
composed_of(C96-1001.85,C96-1001.86)
composed_of(C96-1001.100,C96-1001.101)
char(C96-1001.106,C96-1001.108)
taskapplied(C96-1001.110,C96-1001.111)
taskapplied(C96-1001.142,C96-1001.143)

</text>

<text id="C96-1010">
<title><entity id="C96-1010.1">Parsing</entity> <entity id="C96-1010.2">Spoken <entity id="C96-1010.3">Language</entity></entity> Without <entity id="C96-1010.4">Syntax</entity></title> 
<abstract><entity id="C96-1010.5">Parsing</entity> <entity id="C96-1010.6">spontaneous <entity id="C96-1010.7">speech</entity></entity> is a difficult <entity id="C96-1010.8">task</entity> because of the ungrammatical <entity id="C96-1010.9">nature</entity> of most spoken <entity id="C96-1010.10">utterances</entity> . To overpass this <entity id="C96-1010.11">problem</entity> , we <entity id="C96-1010.12">propose</entity> in this <entity id="C96-1010.13">paper</entity> to handle the spoken <entity id="C96-1010.14">language</entity> without considering <entity id="C96-1010.15">syntax</entity> . We describe thus a microsemantic <entity id="C96-1010.16">parser</entity> which is uniquely <entity id="C96-1010.17">based</entity> on an associative <entity id="C96-1010.18">network</entity> of <entity id="C96-1010.19">semantic</entity> priming. <entity id="C96-1010.20">Experimental</entity> <entity id="C96-1010.21">results</entity> on <entity id="C96-1010.22">spontaneous speech</entity> show that this <entity id="C96-1010.23">parser</entity> stands for a <entity id="C96-1010.24">robust</entity> <entity id="C96-1010.25">alternative</entity> to <entity id="C96-1010.26">standard</entity> ones.
</abstract>


taskapplied(C96-1010.1,C96-1010.2)
taskapplied(C96-1010.5,C96-1010.6)
problem(C96-1010.9,C96-1010.10)

</text>

<text id="C82-2044">
<title>
Meaning Negotiation In <entity id="C82-2044.1">Dialogue</entity></title>



</text>

<abstract></abstract>

<text id="C86-1001">
<title><entity id="C86-1001.1">Lexicon</entity> - Grammar: The <entity id="C86-1001.2">Representation</entity> Of Compound <entity id="C86-1001.3">Words</entity></title>
<abstract></abstract>



</text>

<text id="C86-1014">
<title><entity id="C86-1014.1">Processing</entity> <entity id="C86-1014.2">Word</entity> <entity id="C86-1014.3">Order</entity> <entity id="C86-1014.4">Variation</entity> Within A Modified ID/LP <entity id="C86-1014.5">Framework</entity></title>
<abstract>
"From a ""well represented <entity id="C86-1014.6">sample</entity> of world <entity id="C86-1014.7">languages</entity> Steele (1978) shows that about "
</abstract>


composed_of(C86-1014.6,C86-1014.7)

</text>

<text id="C86-1039">
<title>
The <entity id="C86-1039.1">Commercial</entity> <entity id="C86-1039.2">Application</entity> Of: <entity id="C86-1039.3">Natural Language</entity> Interfaces
</title>



</text>

<abstract></abstract>

<text id="C86-1074">
<title>
A Compositional <entity id="C86-1074.1">Approach</entity> To The <entity id="C86-1074.2">Translation</entity> Of Temporal Expressions In The ROSETTA <entity id="C86-1074.3">System</entity></title>
<abstract>
This <entity id="C86-1074.4">paper</entity> discusses the <entity id="C86-1074.5">translation</entity> of temporal <entity id="C86-1074.6">expressions</entity> , in the <entity id="C86-1074.7">framework</entity> of the <entity id="C86-1074.8">machine translation system</entity> Rosetta. The <entity id="C86-1074.9">translation</entity> <entity id="C86-1074.10">method</entity> of Rosetta, the 'isomorphic grammar <entity id="C86-1074.11">method</entity> ', is <entity id="C86-1074.12">based</entity> on Montague 's Compositionality <entity id="C86-1074.13">Principle</entity> . It is shown that a compositional <entity id="C86-1074.14">approach</entity> leads to a transparent account of the <entity id="C86-1074.15">complex</entity> <entity id="C86-1074.16">aspects</entity> of <entity id="C86-1074.17">time</entity> in <entity id="C86-1074.18">natural language</entity> and can be used for the <entity id="C86-1074.19">translation</entity> of temporal <entity id="C86-1074.20">expressions</entity> .
</abstract>


study(C86-1074.4,C86-1074.5)
taskapplied(C86-1074.19,C86-1074.20)

</text>

<text id="C86-1078">
<title>
Pragmatics In <entity id="C86-1078.1">Machine Translation</entity></title>
<abstract>
TEXAN is a <entity id="C86-1078.2">system</entity> of transferi-oriented <entity id="C86-1078.3">text <entity id="C86-1078.4">analysis</entity></entity> . Its linguistic <entity id="C86-1078.5">concept</entity> is <entity id="C86-1078.6">based</entity> on a communicative <entity id="C86-1078.7">approach</entity> within the <entity id="C86-1078.8">framework</entity> of <entity id="C86-1078.9">speech act</entity> <entity id="C86-1078.10">theory</entity> . In this view <entity id="C86-1078.11">texts</entity> are considered to be the <entity id="C86-1078.12">result</entity> of linguistic <entity id="C86-1078.13">actions</entity> . It is assumed that they <entity id="C86-1078.14">control</entity> the <entity id="C86-1078.15">selection</entity> of <entity id="C86-1078.16">translation</entity> equivalents. The <entity id="C86-1078.17">transition</entity> of this <entity id="C86-1078.18">concept</entity> of linguistic <entity id="C86-1078.19">actions</entity> ( <entity id="C86-1078.20">text</entity> acts) to the <entity id="C86-1078.21">model</entity> of <entity id="C86-1078.22">computer</entity> <entity id="C86-1078.23">analysis</entity> is <entity id="C86-1078.24">performed</entity> by a <entity id="C86-1078.25">context-free</entity> il locution grammar <entity id="C86-1078.26">processing</entity> <entity id="C86-1078.27">categories</entity> of <entity id="C86-1078.28">actions</entity> and a propositional <entity id="C86-1078.29">structure</entity> of states of affairs. The grammar which is related to a <entity id="C86-1078.30">text</entity> <entity id="C86-1078.31">lexicon</entity> <entity id="C86-1078.32">provides</entity> the connection of these <entity id="C86-1078.33">categories</entity> and the linguistic <entity id="C86-1078.34">surface</entity> <entity id="C86-1078.35">units</entity> of a single <entity id="C86-1078.36">language</entity> .
</abstract>


methodapplied(C86-1078.2,C86-1078.3)

</text>

<text id="C86-1091">
<title>
Towards The <entity id="C86-1091.1">Automatic</entity> <entity id="C86-1091.2">Acquisition</entity> Of <entity id="C86-1091.3">Lexical</entity> <entity id="C86-1091.4">Data</entity></title>
<abstract>
"Creating a <entity id="C86-1091.5">knowledge base</entity> has always been a bottleneck in the <entity id="C86-1091.6">implementation</entity> of AI <entity id="C86-1091.7">systems</entity> . This is also Lrue for <entity id="C86-1091.8">Natural Language Understanding</entity> (NEU) <entity id="C86-1091.9">systems</entity> , particularly for <entity id="C86-1091.10">data-driven</entity> ones . While a perfect <entity id="C86-1091.11">system</entity> for <entity id="C86-1091.12">automatic</entity> <entity id="C86-1091.13">acquisition</entity> of all sorts of <entity id="C86-1091.14">knowledge</entity> is still feir from being realized, <entity id="C86-1091.15">partial</entity> <entity id="C86-1091.16">solutions</entity> are possible. This holds especially for <entity id="C86-1091.17">lexical</entity> <entity id="C86-1091.18">data</entity> . Nevertheless, the <entity id="C86-1091.19">task</entity> is not trivial, in particular when <entity id="C86-1091.20">dealing</entity> with <entity id="C86-1091.21">languages</entity> rich in inflectional Horms like German. Our: <entity id="C86-1091.22">system</entity> is to be used by persons with no specific <entity id="C86-1091.23">linguistic knowledge</entity> , thus linguistic expertise has been put into the <entity id="C86-1091.24">system</entity> to ascertain correct <entity id="C86-1091.25">classification</entity> of."" <entity id="C86-1091.26">words</entity> . <entity id="C86-1091.27">Classification</entity> is done by means of a small <entity id="C86-1091.28">rule</entity> <entity id="C86-1091.29">based</entity> <entity id="C86-1091.30">system</entity> with <entity id="C86-1091.31">Lexical knowledge</entity> and <entity id="C86-1091.32">language-specific</entity> heuristics. The key idea is the <entity id="C86-1091.33">identification</entity> of three sorts of <entity id="C86-1091.34">knowledge</entity> which are <entity id="C86-1091.35">processed</entity> distinctly and the <entity id="C86-1091.36">optimal</entity> use of <entity id="C86-1091.37">knowledge</entity> already contained in the existing <entity id="C86-1091.38">Lexicon</entity> . 1
 <entity id="C86-1091.39">Introduction</entity> in this <entity id="C86-1091.40">paper</entity> we introduce a <entity id="C86-1091.41">system</entity> for the <entity id="C86-1091.42">semi-automatic</entity> en.l argeinen t of a morphol og i cal 1 ex <entity id="C86-1091.43">icon</entity> . If <entity id="C86-1091.44">forms</entity> <entity id="C86-1091.45">part</entity> of VIE-BANG, a German <entity id="C86-1091.46">Language</entity> <entity id="C86-1091.47">dialogue system</entity> ( Buchberger et al. 1982 ) . VI K-l. ANG serves not only as an ob ject but as a meta <entity id="C86-1091.48">system</entity> as we 11 : i ts <entity id="C86-1091.49">knowledge base</entity> is to be enlarged, and its facilities are used L:o <entity id="C86-1091.50">support</entity> that <entity id="C86-1091.51">process</entity> : the parsor serves to analyze the i nput to the acquisj ti on <entity id="C86-1091.52">system</entity> , the <entity id="C86-1091.53">generator</entity>  i. s used  to <entity id="C86-1091.54">provide</entity> exampl es. Ln <entity id="C86-1091.55">contrast</entity> to <entity id="C86-1091.56">English</entity> the <entity id="C86-1091.57">morphological <entity id="C86-1091.58">analysis</entity></entity> of German <entity id="C86-1091.59">words</entity>  is no trivial <entity id="C86-1091.60">task</entity> ,  <entity id="C86-1091.61">due</entity> to two causes: - First, there is a rich inflectional <entity id="C86-1091.62">system</entity> , consisting of about 60 different endings (where most endings have various different <entity id="C86-1091.63">interpretations</entity> ), some <entity id="C86-1091.64">prefixes</entity> ('go-PPP, "
</abstract>


char(C86-1091.9,C86-1091.10,REVERSE)
usedfor(C86-1091.27,C86-1091.28,REVERSE)
propose(C86-1091.40,C86-1091.41)
study(C86-1091.57,C86-1091.59)

</text>

<text id="C86-1128">
<title>
A PROLOG <entity id="C86-1128.1">Implementation</entity> Of Government-Binding <entity id="C86-1128.2">Theory</entity></title>
<abstract>
A <entity id="C86-1128.3">parser</entity> which is founded on Chomsky 's Government-Binding <entity id="C86-1128.4">Theory</entity> and <entity id="C86-1128.5">implemented</entity> in PROLOG is described.    By <entity id="C86-1128.6">focussing</entity> on <entity id="C86-1128.7">systems</entity> of <entity id="C86-1128.8">constraints</entity> as <entity id="C86-1128.9">proposed</entity> by this <entity id="C86-1128.10">theory</entity> , the <entity id="C86-1128.11">system</entity> is capable of <entity id="C86-1128.12">parsing</entity> without an elaborate <entity id="C86-1128.13">rule</entity> set and subcategorization <entity id="C86-1128.14">features</entity> on <entity id="C86-1128.15">lexical items</entity> .    In <entity id="C86-1128.16">addition</entity> to the <entity id="C86-1128.17">parse</entity> , theta, binding, and <entity id="C86-1128.18">control</entity> <entity id="C86-1128.19">relations</entity> are determined simultaneously.
</abstract>



</text>

<text id="C86-1133">
<title>
From <entity id="C86-1133.1">Structure</entity> To <entity id="C86-1133.2">Process</entity> <entity id="C86-1133.3">Computer-</entity> Assisted Teaching Of Various <entity id="C86-1133.4">Strategies</entity> For <entity id="C86-1133.5">Generating</entity> Pronoun Constructions In French
</title>
<abstract>
This <entity id="C86-1133.6">paper</entity> describes an <entity id="C86-1133.7">implemented</entity> tutoring <entity id="C86-1133.8">system</entity> (2), <entity id="C86-1133.9">designed</entity> to <entity id="C86-1133.10">help</entity> students to <entity id="C86-1133.11">generate</entity> clitic-constructions in French. While showing various ways of converting a given meaning <entity id="C86-1133.12">structure</entity> into its corresponding <entity id="C86-1133.13">surface</entity> <entity id="C86-1133.14">expression</entity> , the <entity id="C86-1133.15">system</entity> <entity id="C86-1133.16">helps</entity> not only to discover what
</abstract>


propose(C86-1133.6,C86-1133.8)

</text>

<text id="C86-1139">
<title>
Divided And <entity id="C86-1139.1">Valency-</entity> Oriented <entity id="C86-1139.2">Parsing</entity> In <entity id="C86-1139.3">Speech</entity> Undstanding
</title>
<abstract>
A <entity id="C86-1139.4">parsing</entity> <entity id="C86-1139.5">scheme</entity> for spoken <entity id="C86-1139.6">utterances</entity> is <entity id="C86-1139.7">proposed</entity> that deviates from traditional 'one go' left to right <entity id="C86-1139.8">sentence</entity> <entity id="C86-1139.9">parsing</entity> in that it d
vides the <entity id="C86-1139.10">parsing</entity> <entity id="C86-1139.11">process</entity> first into two aeperate parallel <entity id="C86-1139.12">processes</entity> . <entity id="C86-1139.13">Verbal</entity> <entity id="C86-1139.14">constituents</entity> and nominal <entity id="C86-1139.15">phrases</entity> ( <entity id="C86-1139.16">including</entity> prepositonal <entity id="C86-1139.17">phrases</entity> ) are treated seperately and only brought together in an <entity id="C86-1139.18">utterance</entity> <entity id="C86-1139.19">parser</entity> . This allows especially the <entity id="C86-1139.20">utterance</entity> <entity id="C86-1139.21">parser</entity> to draw on <entity id="C86-1139.22">valency</entity> <entity id="C86-1139.23">information</entity> right from beginning when amalgamating the nominal <entity id="C86-1139.24">constituents</entity> to the <entity id="C86-1139.25">verbal</entity> <entity id="C86-1139.26">core</entity> by means of binary <entity id="C86-1139.27">sentence</entity> <entity id="C86-1139.28">rules</entity> . The <entity id="C86-1139.29">paper</entity> also discusses <entity id="C86-1139.30">problems</entity> of representing the <entity id="C86-1139.31">valency</entity> <entity id="C86-1139.32">information</entity> in <entity id="C86-1139.33">case-frames</entity> arising in a spoken <entity id="C86-1139.34">language</entity> <entity id="C86-1139.35">environment</entity> .
</abstract>


taskapplied(C86-1139.4,C86-1139.6)

</text>

<text id="C86-1144">
<title><entity id="C86-1144.1">Computational</entity> <entity id="C86-1144.2">Phonology</entity> : Merged, Not Mixed
</title>
<abstract><entity id="C86-1144.3">Research</entity> into <entity id="C86-1144.4">text-to-speech</entity> <entity id="C86-1144.5">systems</entity> has become a rather important <entity id="C86-1144.6">topic</entity> in the <entity id="C86-1144.7">areas</entity> of <entity id="C86-1144.8">linguistics</entity> and phonetics. Particularly for <entity id="C86-1144.9">English</entity> , several <entity id="C86-1144.10">text-to-speech</entity> <entity id="C86-1144.11">systems</entity> have been established (cf. for <entity id="C86-1144.12">example</entity> Hertz (1982), Klatt (1976)). For Dutch, <entity id="C86-1144.13">text-to-speech</entity> <entity id="C86-1144.14">systems</entity> are being <entity id="C86-1144.15">developed</entity> at the <entity id="C86-1144.16">University</entity> of Nijmegen (cf. Wester (1984)) and at the <entity id="C86-1144.17">Universities</entity> of Utrecht and Leyden and the Institute of Perception <entity id="C86-1144.18">Research</entity> (IPO) Eindhoven as well. In this <entity id="C86-1144.19">paper</entity> we will be <entity id="C86-1144.20">concerned</entity> with the <entity id="C86-1144.21">grapheme-to-phoneme</entity> <entity id="C86-1144.22">conversion</entity> <entity id="C86-1144.23">component</entity> as <entity id="C86-1144.24">part</entity> of the Dutch <entity id="C86-1144.25">text-to-speech</entity> <entity id="C86-1144.26">system</entity> which is being <entity id="C86-1144.27">developed</entity> in Utrecht, Leyden and Eindhoven. One of our primary interests is that the <entity id="C86-1144.28">grapheme-to-phoneme</entity> <entity id="C86-1144.29">system</entity> not only has to <entity id="C86-1144.30">generate</entity> the <entity id="C86-1144.31">input</entity> for <entity id="C86-1144.32">speech <entity id="C86-1144.33">synthesis</entity></entity> , either in allophone or diphone <entity id="C86-1144.34">form</entity> , but that it had to be used for other <entity id="C86-1144.35">purposes</entity> as well. Thus, the <entity id="C86-1144.36">system</entity> has to satisfy the <entity id="C86-1144.37">following</entity> demands: - its <entity id="C86-1144.38">output</entity> must <entity id="C86-1144.39">form</entity> a proper and flexible <entity id="C86-1144.40">input</entity> for diphone as well as allophone <entity id="C86-1144.41">synthesis</entity> ; - it must be possible to easily <entity id="C86-1144.42">generate</entity> phonematized <entity id="C86-1144.43">lists</entity> on the <entity id="C86-1144.44">basis</entity> of orthographic <entity id="C86-1144.45">input</entity> ; - it must be possible to automatically obtain <entity id="C86-1144.46">information</entity> regarding the <entity id="C86-1144.47">relation</entity> between graphemes and <entity id="C86-1144.48">phonemes</entity> in <entity id="C86-1144.49">texts</entity> ; - the <entity id="C86-1144.50">system</entity> has to be <entity id="C86-1144.51">user-friendly</entity> , so that it can be addressed by <entity id="C86-1144.52">linguists</entity> without <entity id="C86-1144.53">computer</entity> <entity id="C86-1144.54">training</entity> (for <entity id="C86-1144.55">example</entity> to <entity id="C86-1144.56">test</entity> their phonological <entity id="C86-1144.57">rules</entity> ). In our view, there are two <entity id="C86-1144.58">aspects</entity> to a <entity id="C86-1144.59">grapheme-to-phoneme</entity> <entity id="C86-1144.60">conversion</entity> <entity id="C86-1144.61">system</entity> : a linguistic and a <entity id="C86-1144.62">computational</entity> one. The <entity id="C86-1144.63">linguist</entity> , in fact, <entity id="C86-1144.64">provides</entity> the grammar necessary for the <entity id="C86-1144.65">conversion</entity> and the engineer <entity id="C86-1144.66">implements</entity> this grammar into a <entity id="C86-1144.67">computer</entity> <entity id="C86-1144.68">system</entity> . Thus, <entity id="C86-1144.69">knowledge</entity> about <entity id="C86-1144.70">spelling</entity> and <entity id="C86-1144.71">linguistics</entity> are separated
</abstract>


study(C86-1144.3,C86-1144.4)
part_of(C86-1144.21,C86-1144.25)
based_on(C86-1144.28,C86-1144.32,REVERSE)
char(C86-1144.50,C86-1144.51,REVERSE)

</text>

<text id="C86-1145">
<title>
Phonological <entity id="C86-1145.1">Pivot</entity> <entity id="C86-1145.2">Parsing</entity></title>
<abstract></abstract>



</text>

<text id="C88-1037">
<title>
Expressing <entity id="C88-1037.1">Quantifier</entity> <entity id="C88-1037.2">Scope</entity> In French <entity id="C88-1037.3">Generation</entity></title>
<abstract>
In this <entity id="C88-1037.4">paper</entity> we <entity id="C88-1037.5">propose</entity> a new <entity id="C88-1037.6">method</entity> to express <entity id="C88-1037.7">quantification</entity> and especially <entity id="C88-1037.8">quantifier</entity> <entity id="C88-1037.9">scope</entity> in French <entity id="C88-1037.10">generation</entity> . Our <entity id="C88-1037.11">approach</entity> is <entity id="C88-1037.12">based</entity> on two points: the <entity id="C88-1037.13">identification</entity> of the <entity id="C88-1037.14">sentence</entity> <entity id="C88-1037.15">components</entity> between which <entity id="C88-1037.16">quantifier</entity> <entity id="C88-1037.17">scope</entity> can indeed be expressed and a <entity id="C88-1037.18">mechanism</entity> to reinforce the <entity id="C88-1037.19">expression</entity> of <entity id="C88-1037.20">quantifier</entity> <entity id="C88-1037.21">scope</entity> . This <entity id="C88-1037.22">approach</entity> is being integrated in a written French <entity id="C88-1037.23">generator</entity> , <entity id="C88-1037.24">called</entity> Herm
s, which will become the <entity id="C88-1037.25">generator</entity> of a portable <entity id="C88-1037.26">natural <entity id="C88-1037.27">language</entity> <entity id="C88-1037.28">interface</entity></entity> .
</abstract>


propose(C88-1037.4,C88-1037.6)
part_of(C88-1037.25,C88-1037.26)

</text>

<text id="C88-1061">
<title><entity id="C88-1061.1">Constituent</entity> <entity id="C88-1061.2">Coordination</entity> In <entity id="C88-1061.3">Lexical-</entity> Functional Grammar
</title>
<abstract>
"<entity id="C88-1061.4">Abstract</entity> : This <entity id="C88-1061.5">paper</entity> <entity id="C88-1061.6">outlines</entity> a <entity id="C88-1061.7">theory</entity> of <entity id="C88-1061.8">constituent</entity> <entity id="C88-1061.9">coordination</entity> for <entity id="C88-1061.10">Lexical-</entity> Functional Grammar. On this <entity id="C88-1061.11">theory</entity> LFG's flat, unstructured sets <entity id="C88-1061.12">arc</entity> used as the functional <entity id="C88-1061.13">representation</entity> of coordinate <entity id="C88-1061.14">constructions</entity> . <entity id="C88-1061.15">Function-application</entity> is extended to sets by treating a sot formally as the <entity id="C88-1061.16">generalization</entity> of its functional elements. This causes <entity id="C88-1061.17">properties</entity> attributed externally to a coordinate <entity id="C88-1061.18">structure</entity> to be uniformly <entity id="C88-1061.19">distributed</entity> across its elements, without <entity id="C88-1061.20">requiring</entity> additional grammatical <entity id="C88-1061.21">specifications</entity> . <entity id="C88-1061.22">Introduction</entity> A proper <entity id="C88-1061.23">treatment</entity> of <entity id="C88-1061.24">coordination</entity> has long been an elusive <entity id="C88-1061.25">goal</entity> of both theoretical and <entity id="C88-1061.26">computational</entity> <entity id="C88-1061.27">approaches</entity> to <entity id="C88-1061.28">language</entity> . The original transformational <entity id="C88-1061.29">formulation</entity> in <entity id="C88-1061.30">terms</entity> of the Coordinate <entity id="C88-1061.31">Reduction</entity> <entity id="C88-1061.32">rule</entity> (e.g. / Dougherty 1970 /) was quickly shown to have many theoretical and empirical inadequacies, and only recently have <entity id="C88-1061.33">linguistic theories</entity> (e g, GPSG / Gazdar et al. 1985 /, <entity id="C88-1061.34">Categorial grammar</entity> (e.g. / Steedman 1985 /) made substantial <entity id="C88-1061.35">progress</entity> on characterizing the <entity id="C88-1061.36">complex</entity> <entity id="C88-1061.37">restrictions</entity> on coordinate <entity id="C88-1061.38">constructions</entity> and also on their <entity id="C88-1061.39">semantic <entity id="C88-1061.40">interpretations</entity></entity> . <entity id="C88-1061.41">Coordination</entity> has also presented descriptive <entity id="C88-1061.42">problems</entity> for <entity id="C88-1061.43">computational</entity> <entity id="C88-1061.44">approaches</entity> . Typically these have been <entity id="C88-1061.45">solved</entity> by special <entity id="C88-1061.46">devices</entity> that are added to the <entity id="C88-1061.47">parsing</entity> <entity id="C88-1061.48">algorithms</entity> to analyze coordinate <entity id="C88-1061.49">constructions</entity> that cannot easily be characterized in explicit <entity id="C88-1061.50">rules</entity> of grammar. The best known <entity id="C88-1061.51">examples</entity> of this <entity id="C88-1061.52">kind</entity> of <entity id="C88-1061.53">approach</entity> are SYSCONJ / Woods 1973 /, ESP / Sager 1981 /, and MSG / Dahl and  McCord 1983 /. <entity id="C88-1061.54">Coordination</entity> <entity id="C88-1061.55">phenomena</entity> are usually divided into two <entity id="C88-1061.56">classes</entity> , the so-called <entity id="C88-1061.57">constituent</entity> <entity id="C88-1061.58">coordinations</entity> where the coordinated elements look like otherwise well-motivated phrasal <entity id="C88-1061.59">constituents</entity> II), and nonconstituent <entity id="C88-1061.60">coordination</entity> where the coordinated elements look like <entity id="C88-1061.61">fragments</entity> of phrasal <entity id="C88-1061.62">constituents</entity> (2). (1) (a)  A girl saw Mary and ran to Iiill. (Coordinated <entity id="C88-1061.63">verb</entity> <entity id="C88-1061.64">phrases</entity> ) (b)  A girl saw and hoard Mary . (Coordinated <entity id="C88-1061.65">verbs</entity> ) (2) Iiill went to Chicago on Wednesday and New York on Thursday. Of course, what is or is not a well-motivated <entity id="C88-1061.66">constituent</entity> depends on the <entity id="C88-1061.67">details</entity> of the particular grammatical <entity id="C88-1061.68">theory</entity> . Constituents in transformationally-oriented <entity id="C88-1061.69">theories</entity> , for <entity id="C88-1061.70">example</entity> , are <entity id="C88-1061.71">units</entity> that simplify the feeding <entity id="C88-1061.72">relations</entity> of transformational <entity id="C88-1061.73">rules</entity> , whereas ""<entity id="C88-1061.74">constituents</entity> "" in <entity id="C88-1061.75">categorial grammars</entity> merely reflect the <entity id="C88-1061.76">order</entity> of binary <entity id="C88-1061.77">combinations</entity> and have no other special <entity id="C88-1061.78">motivation</entity> . In <entity id="C88-1061.79">lexical-functional</entity> grammar, <entity id="C88-1061.80">surface</entity> <entity id="C88-1061.81">constituents</entity> are taken to be the <entity id="C88-1061.82">units</entity> of phonological <entity id="C88-1061.83">interpretation</entity> . These may differ markedly from the <entity id="C88-1061.84">units</entity> of functional or <entity id="C88-1061.85">semantic interpretation</entity> , as shown in the <entity id="C88-1061.86">analysis</entity> of Dutch <entity id="C88-1061.87">cross</entity> serial <entity id="C88-1061.88">dependencies</entity> given by/ Bresnan et al. 1982 /. N'onconstituent <entity id="C88-1061.89">coordination</entity> , of course, presents a wide <entity id="C88-1061.90">variety</entity> of <entity id="C88-1061.91">complex</entity> and difficult descriptive <entity id="C88-1061.92">problems</entity> , but <entity id="C88-1061.93">constituent</entity> <entity id="C88-1061.94">coordination</entity> also raises important linguistic <entity id="C88-1061.95">issues</entity> . It is the latter that we <entity id="C88-1061.96">focus</entity> on in this brief <entity id="C88-1061.97">paper</entity> . To a first <entity id="C88-1061.98">approximation</entity> , <entity id="C88-1061.99">constituent</entity> <entity id="C88-1061.100">coordinations</entity> can be analyzed as the <entity id="C88-1061.101">result</entity> of taking two independent <entity id="C88-1061.102">clauses</entity> and factoring out their <entity id="C88-1061.103">common</entity> subparts. The <entity id="C88-1061.104">verb</entity> <entity id="C88-1061.105">coordination</entity> in (lb) is thus related to the fuller <entity id="C88-1061.106">sentence</entity> <entity id="C88-1061.107">coordination</entity> in (3). This <entity id="C88-1061.108">intuition</entity> , which was the <entity id="C88-1061.109">basis</entity> of the Coordinate <entity id="C88-1061.110">Reduction</entity> <entity id="C88-1061.111">Transformation</entity> , accounts for more <entity id="C88-1061.112">complex</entity> <entity id="C88-1061.113">patterns</entity> of acceptability such as (4) illustrates. The <entity id="C88-1061.114">coordination</entity> in (4c) is acceptable because both (4a) and (4b) are, while (4e) is bad because of the independent subcategorization violation in (4d). (3) A girl saw Mary and a girl heard Mary . (4) (a) A gir l dedicated a pie to Bill . (b) A girl gave a pie to Bill . (c) A girl dedicated and gave a pie to Bill . (d) *A girl ate a pie to Bill . (e) *A girl dedicated and ate a pie to Bill . This first <entity id="C88-1061.115">approximation</entity> is frought with <entity id="C88-1061.116">difficulties</entity> . It ensures that <entity id="C88-1061.117">constituents</entity> of like <entity id="C88-1061.118">categories</entity> can be conjoined only if they share some finer <entity id="C88-1061.119">details</entity> of <entity id="C88-1061.120">specification</entity> , but there are more subtle conditions that it does not cover. For <entity id="C88-1061.121">example</entity> , even though (5a) and (5b) are both independently grammatical, the <entity id="C88-1061.122">coordination</entity> in (5c) is unacceptable: (5) (a) The girl promised John to go. (b) The girl persuaded John to go. (c) ""The girl promised and persuaded John to go, (Hint: Who is going"
</abstract>


study(C88-1061.5,C88-1061.9)
model(C88-1061.12,C88-1061.14)
model(C88-1061.38,C88-1061.39,REVERSE)
problem(C88-1061.41,C88-1061.44)
usedfor(C88-1061.46,C88-1061.48)

</text>

<text id="C88-2089">
<title>
An Integrated <entity id="C88-2089.1">Model</entity> For The <entity id="C88-2089.2">Treatment</entity> Of <entity id="C88-2089.3">Time</entity> In <entity id="C88-2089.4">MT-Systems</entity></title>
<abstract>
One of the ways to achieve a good <entity id="C88-2089.5">translation</entity> of <entity id="C88-2089.6">verbal</entity> foras is the morphosyntactic <entity id="C88-2089.7">approach</entity> , which consists in a <entity id="C88-2089.8">function</entity> <entity id="C88-2089.9">pairing</entity> the different morphological tenses that occur in a given <entity id="C88-2089.10">language</entity> with the tenses of the other <entity id="C88-2089.11">language</entity> . Complicated <entity id="C88-2089.12">rules</entity> must be established to calculate the right <entity id="C88-2089.13">pair</entity> for an <entity id="C88-2089.14">expression</entity> , because of the <entity id="C88-2089.15">amount</entity> of discrepancies that different <entity id="C88-2089.16">languages</entity> show with <entity id="C88-2089.17">respect</entity> to each other. 
he way wa have chosen to <entity id="C88-2089.18">deal</entity> with this <entity id="C88-2089.19">problem</entity> is, conversely, the <entity id="C88-2089.20">projection</entity> of the different values coming from <entity id="C88-2089.21">verbs</entity> ( <entity id="C88-2089.22">type</entity> , processivity, morftense, morfaspect, sioodrequirement), from <entity id="C88-2089.23">adverbs</entity> , <entity id="C88-2089.24">prepositional phrases</entity> and temporal M.?s (deixis, <entity id="C88-2089.25">aspect</entity> , <entity id="C88-2089.26">iteration</entity> ), and from subordinate <entity id="C88-2089.27">conjunctions</entity> ( <entity id="C88-2089.28">aspect</entity> , moodrequirement). All this <entity id="C88-2089.29">information</entity> permits to obtain a final value for <entity id="C88-2089.30">aspect</entity> and tense for the whole <entity id="C88-2089.31">sentence</entity> , which later on is percolated, not only to the <entity id="C88-2089.32">verb</entity> <entity id="C88-2089.33">node</entity> , but also to the the rest of elements conveying <entity id="C88-2089.34">information</entity> . Our <entity id="C88-2089.35">proposal</entity> relies on the fact that tense/ <entity id="C88-2089.36">aspect</entity> <entity id="C88-2089.37">calculation</entity> is relevant not only for a good <entity id="C88-2089.38">translation</entity> of <entity id="C88-2089.39">verbs</entity> , but also for a good <entity id="C88-2089.40">translation</entity> of <entity id="C88-2089.41">adverbs</entity> , PPs, temporal Ni-n and <entity id="C88-2089.42">conjunctions</entity> , as we have intended to demonstrate in this <entity id="C88-2089.43">paper</entity> . I. <entity id="C88-2089.44">Introduction</entity> Thin article <entity id="C88-2089.45">deals</entity> with a <entity id="C88-2089.46">methodology</entity> to achieve the right <entity id="C88-2089.47">translation</entity> of temporal <entity id="C88-2089.48">expressions</entity> by giving account of the temporal <entity id="C88-2089.49">reference</entity> and <entity id="C88-2089.50">temporal relations</entity> in/ between <entity id="C88-2089.51">sentences</entity> . The <entity id="C88-2089.52">task</entity> to accomplish is to <entity id="C88-2089.53">translate</entity> <entity id="C88-2089.54">syntactic</entity> marks into <entity id="C88-2089.55">semantic</entity> values that decide/ reflect the aspectunl value of the <entity id="C88-2089.56">sentences</entity> . For our <entity id="C88-2089.57">treatment</entity> of <entity id="C88-2089.58">time</entity> and <entity id="C88-2089.59">aspect</entity> we draw on the work of Kamp [1979] and Partee [1984] who have argued for taking <entity id="C88-2089.60">status</entity> and <entity id="C88-2089.61">events</entity> as primitives and <entity id="C88-2089.62">relations</entity> of precedence und overlapping between them. The <entity id="C88-2089.63">ordering</entity> <entity id="C88-2089.64">relation</entity> between <entity id="C88-2089.65">events</entity> is crucial for deciding about the <entity id="C88-2089.66">aspect</entity> of the <entity id="C88-2089.67">sentences</entity> involved. The present <entity id="C88-2089.68">proposal</entity> presumes an <entity id="C88-2089.69">analysis</entity> and a <entity id="C88-2089.70">generation</entity> <entity id="C88-2089.71">component</entity> that deliver a set of S- <entity id="C88-2089.72">trees</entity> whose leaves correspond to <entity id="C88-2089.73">words</entity> . The pre-terminals have morphosyntatitic and <entity id="C88-2089.74">relational</entity> <entity id="C88-2089.75">information</entity> . As usual, <entity id="C88-2089.76">features</entity> am percolated and <entity id="C88-2089.77">nodes</entity> get <entity id="C88-2089.78">features</entity> assigned . She tine/ aspectual <entity id="C88-2089.79">problem</entity> ia <entity id="C88-2089.80">dealt</entity> with under the perspectiv
 of MT with the aim of sketching a <entity id="C88-2089.81">system</entity> that can be <entity id="C88-2089.82">implemented</entity> independently of the particular <entity id="C88-2089.83">formalisms</entity> of different <entity id="C88-2089.84">MT-systems</entity> . To <entity id="C88-2089.85">outline</entity> a general <entity id="C88-2089.86">model</entity> for the <entity id="C88-2089.87">time</entity> / <entity id="C88-2089.88">aspect</entity> <entity id="C88-2089.89">calculation</entity> in MT we subsume a <entity id="C88-2089.90">system</entity> with PSG <entity id="C88-2089.91">rules</entity> that obtain some <entity id="C88-2089.92">sentence structure</entity> with no regard to a specific grammar <entity id="C88-2089.93">type</entity> ; it could be an augmented PSG, as in METAL, or some <entity id="C88-2089.94">kind</entity> of deep <entity id="C88-2089.95">syntactic structure</entity> , as it is the <entity id="C88-2089.96">case</entity> in Eurotra. The <entity id="C88-2089.97">problem</entity> is the well known fact that <entity id="C88-2089.98">translations</entity> of temporal <entity id="C88-2089.99">expressions</entity> in Ni does not involve a <entity id="C88-2089.100">simple</entity> <entity id="C88-2089.101">mapping</entity> of tenses and adverbials. We could just compare Spanish, rich in <entity id="C88-2089.102">aspect</entity> and tenses vs. German or <entity id="C88-2089.103">English</entity> . That is, a MT <entity id="C88-2089.104">dealing</entity> with Germanic and Romance <entity id="C88-2089.105">languages</entity> is <entity id="C88-2089.106">concerned</entity> with different <entity id="C88-2089.107">parameters</entity> for each <entity id="C88-2089.108">language</entity> ; the whole <entity id="C88-2089.109">practice</entity> in <entity id="C88-2089.110">MT systems</entity> is to <entity id="C88-2089.111">translate</entity> morphological tenses, and syntactical values into <entity id="C88-2089.112">reference</entity> <entity id="C88-2089.113">times</entity> that <entity id="C88-2089.114">include</entity> <entity id="C88-2089.115">events</entity> or slates
</abstract>


model(C88-2089.1,C88-2089.3)
taskapplied(C88-2089.38,C88-2089.39)
taskapplied(C88-2089.40,C88-2089.41)
study(C88-2089.46,C88-2089.47)
model(C88-2089.72,C88-2089.73)
tag(C88-2089.77,C88-2089.78,REVERSE)

</text>

<text id="C88-2107">
<title>
Hinting By Paraphrasing In An <entity id="C88-2107.1">Instruction</entity> <entity id="C88-2107.2">System</entity></title>
<abstract>
"Previous work has emphasized the need for paraphrases as means of ensuring a <entity id="C88-2107.3">feedback</entity> with a <entity id="C88-2107.4">system</entity> . In this <entity id="C88-2107.5">paper</entity> , uib discuss haw a paraphrase may ho used as a heuristic <entity id="C88-2107.6">device</entity> * viz. as a hint. Wei describe! an <entity id="C88-2107.7">experimental</entity> <entity id="C88-2107.8">instruction</entity> <entity id="C88-2107.9">system</entity> in mathematics incorporating this, <entity id="C88-2107.10">feature</entity> . The <entity id="C88-2107.11">system</entity> accepts a restricted <entity id="C88-2107.12">class</entity> nf algebraic story prablstns, formulated in non-stylized Bulgarian <entity id="C88-2107.13">language</entity> ! I and is capable of <entity id="C88-2107.14">solving</entity> them and <entity id="C88-2107.15">providing</entity> one or more ""hinting"" paraphrases, that is, paraphrases alleviating their formalisation C
'<entity id="C88-2107.16">translation</entity> into <entity id="C88-2107.17">equations</entity> !) . "
</abstract>



</text>

<text id="C88-2138">
<title><entity id="C88-2138.1">Combining</entity> <entity id="C88-2138.2">Lexicon-</entity> Driven <entity id="C88-2138.3">Parsing</entity> And <entity id="C88-2138.4">Phrase-</entity> <entity id="C88-2138.5">Structure-</entity> <entity id="C88-2138.6">Based</entity> <entity id="C88-2138.7">Parsing</entity></title> 
<abstract><entity id="C88-2138.8">Lexicon-driven</entity> <entity id="C88-2138.9">formalisms</entity> (o.g. have explicit <entity id="C88-2138.10">constructions</entity> which power <entity id="C88-2138.11">implementation</entity> <entity id="C88-2138.12">method</entity> driven <entity id="C88-2138.13">parsing</entity> <entity id="C88-2138.14">phrase structure</entity> gmpli-sltuctumd stack.
</abstract>



</text>

<text id="C90-1011">
<title><entity id="C90-1011.1">Concept</entity> <entity id="C90-1011.2">Analysis</entity> And <entity id="C90-1011.3">Terminology</entity> : A <entity id="C90-1011.4">Knowledge-</entity> <entity id="C90-1011.5">Based</entity> <entity id="C90-1011.6">Approach</entity> To <entity id="C90-1011.7">Documentation</entity></title> 
<abstract><entity id="C90-1011.8">ABSTRACT</entity> <entity id="C90-1011.9">concept</entity> <entity id="C90-1011.10">analysis</entity> ,
</abstract>



</text>

<text id="C90-1019">
<title>
Deep <entity id="C90-1019.1">Sentence</entity> <entity id="C90-1019.2">Understanding</entity> In A Restricted <entity id="C90-1019.3">Domain</entity></title>
<abstract>
We present here the <entity id="C90-1019.4">current</entity> <entity id="C90-1019.5">prototype</entity> of the <entity id="C90-1019.6">text</entity> <entity id="C90-1019.7">understanding system</entity> H
</abstract>



</text>

<text id="C90-2018">
<title><entity id="C90-2018.1">Feature</entity> <entity id="C90-2018.2">Logic</entity> With Disjunctive <entity id="C90-2018.3">Unification</entity></title>
<abstract>
We introduce <entity id="C90-2018.4">feature</entity> <entity id="C90-2018.5">terms</entity> containing sorts, <entity id="C90-2018.6">variables</entity> , <entity id="C90-2018.7">negation</entity> and <entity id="C90-2018.8">named</entity> <entity id="C90-2018.9">disjunction</entity> use <entity id="C90-2018.10">implementation</entity> . disjunctive <entity id="C90-2018.11">context</entity> , <entity id="C90-2018.12">context-unique</entity> <entity id="C90-2018.13">feature</entity> <entity id="C90-2018.14">descriptions</entity> ,
</abstract>



</text>

<text id="D08-1047">
<title>
A Discriminative <entity id="D08-1047.1">Candidate</entity> <entity id="D08-1047.2">Generator</entity> for <entity id="D08-1047.3">String</entity> Transformations
</title>
<abstract><entity id="D08-1047.4">String</entity> <entity id="D08-1047.5">transformation</entity> , L1
</abstract>



</text>

<text id="D08-1053">
<title>
Improved <entity id="D08-1053.1">Sentence</entity> <entity id="D08-1053.2">Alignment</entity> on Parallel Web Pages Using a Stochastic <entity id="D08-1053.3">Tree</entity> <entity id="D08-1053.4">Alignment Model</entity></title>
<abstract>
"Parallel <entity id="D08-1053.5">web <entity id="D08-1053.6">pages</entity></entity> are important <entity id="D08-1053.7">source</entity> of <entity id="D08-1053.8">training</entity> <entity id="D08-1053.9">data</entity> for <entity id="D08-1053.10">statistical machine translation</entity> . In this <entity id="D08-1053.11">paper</entity> , we present a new <entity id="D08-1053.12">approach</entity> to <entity id="D08-1053.13">sentence</entity> <entity id="D08-1053.14">alignment</entity> on parallel <entity id="D08-1053.15">web <entity id="D08-1053.16">pages</entity></entity> . Parallel <entity id="D08-1053.17">web pages</entity> tend to have parallel <entity id="D08-1053.18">structures</entity> , and the <entity id="D08-1053.19">structural</entity> <entity id="D08-1053.20">correspondence</entity> can be indicative <entity id="D08-1053.21">information</entity> for identifying parallel <entity id="D08-1053.22">sentences</entity> . In our <entity id="D08-1053.23">approach</entity> , the <entity id="D08-1053.24">web <entity id="D08-1053.25">page</entity></entity> is represented as a <entity id="D08-1053.26">tree</entity> , and a stochastic <entity id="D08-1053.27">tree</entity> <entity id="D08-1053.28">alignment model</entity> is used to exploit the <entity id="D08-1053.29">structural</entity> <entity id="D08-1053.30">correspondence</entity> for <entity id="D08-1053.31">sentence</entity> <entity id="D08-1053.32">alignment</entity> . <entity id="D08-1053.33">Experiments</entity> show that this <entity id="D08-1053.34">method</entity> significantly enhances <entity id="D08-1053.35">alignment</entity> <entity id="D08-1053.36">accuracy</entity> and <entity id="D08-1053.37">robustness</entity> for parallel <entity id="D08-1053.38">web pages</entity> which are much more diverse and noisy than <entity id="D08-1053.39">standard</entity> <entity id="D08-1053.40">parallel corpora</entity> such as ""Hansard"". With <entity id="D08-1053.41">improved</entity> <entity id="D08-1053.42">sentence</entity> <entity id="D08-1053.43">alignment</entity> <entity id="D08-1053.44">performance</entity> , web mining <entity id="D08-1053.45">systems</entity> are able to acquire parallel <entity id="D08-1053.46">sentences</entity> of higher <entity id="D08-1053.47">quality</entity> from the web. "
</abstract>


taskapplied(D08-1053.1,D08-1053.2,REVERSE)
datasource(D08-1053.5,D08-1053.9,REVERSE)
propose(D08-1053.11,D08-1053.12)
taskapplied(D08-1053.14,D08-1053.15)
model(D08-1053.24,D08-1053.26,REVERSE)
yields(D08-1053.34,D08-1053.36)
yields(D08-1053.45,D08-1053.47)

</text>

<text id="D08-1055">
<title>
A <entity id="D08-1055.1">Japanese</entity> <entity id="D08-1055.2">Predicate Argument Structure</entity> <entity id="D08-1055.3">Analysis</entity> using <entity id="D08-1055.4">Decision</entity> Lists
</title>
<abstract>
This <entity id="D08-1055.5">paper</entity> describes a new <entity id="D08-1055.6">automatic</entity> <entity id="D08-1055.7">method</entity> for <entity id="D08-1055.8">Japanese</entity> <entity id="D08-1055.9">predicate <entity id="D08-1055.10">argument structure</entity></entity> <entity id="D08-1055.11">analysis</entity> . The <entity id="D08-1055.12">method</entity> learns relevant <entity id="D08-1055.13">features</entity> to assign <entity id="D08-1055.14">case</entity> <entity id="D08-1055.15">roles</entity> to the <entity id="D08-1055.16">argument</entity> of the <entity id="D08-1055.17">target</entity> predicate using the <entity id="D08-1055.18">features</entity> of the <entity id="D08-1055.19">words</entity> located closest to the <entity id="D08-1055.20">target</entity> predicate under various <entity id="D08-1055.21">constraints</entity> such as <entity id="D08-1055.22">dependency</entity> <entity id="D08-1055.23">types</entity> , <entity id="D08-1055.24">words</entity> , <entity id="D08-1055.25">semantic</entity> <entity id="D08-1055.26">categories</entity> , <entity id="D08-1055.27">parts of speech</entity> , functional <entity id="D08-1055.28">words</entity> and predicate voices. We <entity id="D08-1055.29">constructed</entity> <entity id="D08-1055.30">decision</entity> <entity id="D08-1055.31">lists</entity> in which these <entity id="D08-1055.32">features</entity> were sorted by their learned <entity id="D08-1055.33">weights</entity> . Using our <entity id="D08-1055.34">method</entity> , we integrated the <entity id="D08-1055.35">tasks</entity> of <entity id="D08-1055.36">semantic role</entity> labeling and zero-pronoun <entity id="D08-1055.37">identification</entity> , and achieved a 17% <entity id="D08-1055.38">improvement</entity> compared with a baseline <entity id="D08-1055.39">method</entity> in a <entity id="D08-1055.40">sentence level</entity> <entity id="D08-1055.41">performance</entity> <entity id="D08-1055.42">analysis</entity> .
</abstract>


propose(D08-1055.5,D08-1055.7)
study(D08-1055.9,D08-1055.11,REVERSE)

</text>

<text id="D08-1068">
<title>
Joint Unsupervised <entity id="D08-1068.1">Coreference Resolution</entity> with Markov <entity id="D08-1068.2">Logic</entity></title> 
<abstract><entity id="D08-1068.3">Machine</entity> learning <entity id="D08-1068.4">approaches</entity> to <entity id="D08-1068.5">coreference resolution</entity> are typically supervised, and <entity id="D08-1068.6">require</entity> expensive labeled <entity id="D08-1068.7">data</entity> . Some unsuper-vised <entity id="D08-1068.8">approaches</entity> have been <entity id="D08-1068.9">proposed</entity> (e.g., Haghighi and Klein (2007)), but they are less accurate. In this <entity id="D08-1068.10">paper</entity> , we present the first un-supervised <entity id="D08-1068.11">approach</entity> that is competitive with supervised ones. This is made possible by <entity id="D08-1068.12">performing</entity> joint <entity id="D08-1068.13">inference</entity> across <entity id="D08-1068.14">mentions</entity> , in <entity id="D08-1068.15">contrast</entity> to the pairwise <entity id="D08-1068.16">classification</entity> typically used in supervised <entity id="D08-1068.17">methods</entity> , and by using Markov <entity id="D08-1068.18">logic</entity> as a <entity id="D08-1068.19">representation language</entity> , which enables us to easily express <entity id="D08-1068.20">relations</entity> like apposition and predicate nominals. On MUC and <entity id="D08-1068.21">ACE</entity> datasets, our <entity id="D08-1068.22">model</entity> outperforms Haghigi and Klein 's one using only a fraction of the <entity id="D08-1068.23">training</entity> data, and often <entity id="D08-1068.24">matches</entity> or exceeds the <entity id="D08-1068.25">accuracy</entity> of state-of-the-art supervised <entity id="D08-1068.26">models</entity> .
</abstract>


propose(D08-1068.10,D08-1068.11)

</text>

<text id="E99-1024">
<title><entity id="E99-1024.1">Detection</entity> Of <entity id="E99-1024.2">Japanese</entity> Homophone Errors By A <entity id="E99-1024.3">Decision</entity> <entity id="E99-1024.4">List</entity> Including A Written <entity id="E99-1024.5">Word</entity> As A <entity id="E99-1024.6">Default</entity> <entity id="E99-1024.7">Evidence</entity></title>
<abstract>
In this <entity id="E99-1024.8">paper</entity> , we <entity id="E99-1024.9">propose</entity> a practical <entity id="E99-1024.10">method</entity> to detect <entity id="E99-1024.11">Japanese</entity> homophone <entity id="E99-1024.12">errors</entity> in <entity id="E99-1024.13">Japanese</entity> <entity id="E99-1024.14">texts</entity> . It is very important to detect homophone <entity id="E99-1024.15">errors</entity> in <entity id="E99-1024.16">Japanese</entity> <entity id="E99-1024.17">revision</entity> <entity id="E99-1024.18">systems</entity> because <entity id="E99-1024.19">Japanese</entity> <entity id="E99-1024.20">texts</entity> suffer from homophone <entity id="E99-1024.21">errors</entity> frequently. In <entity id="E99-1024.22">order</entity> to detect homophone <entity id="E99-1024.23">errors</entity> , we have only to <entity id="E99-1024.24">solve</entity> the homophone <entity id="E99-1024.25">problem</entity> . We can use the <entity id="E99-1024.26">decision</entity> <entity id="E99-1024.27">list</entity> to do it because the homophone <entity id="E99-1024.28">problem</entity> is equivalent to the <entity id="E99-1024.29">word sense disambiguation</entity> <entity id="E99-1024.30">problem</entity> . However, the homophone <entity id="E99-1024.31">problem</entity> is different from the <entity id="E99-1024.32">word sense disambiguation</entity> <entity id="E99-1024.33">problem</entity> because the former can use the written <entity id="E99-1024.34">word</entity> but the latter cannot. In this <entity id="E99-1024.35">paper</entity> , we incorporate the written <entity id="E99-1024.36">word</entity> into the original <entity id="E99-1024.37">decision</entity> <entity id="E99-1024.38">list</entity> by obtaining the identifying <entity id="E99-1024.39">strength</entity> of the written <entity id="E99-1024.40">word</entity> . The <entity id="E99-1024.41">improved</entity> <entity id="E99-1024.42">decision</entity> <entity id="E99-1024.43">list</entity> can raise the F-measure of <entity id="E99-1024.44">error</entity> <entity id="E99-1024.45">detection</entity> .
</abstract>


usedfor(E99-1024.1,E99-1024.4,REVERSE)
propose(E99-1024.8,E99-1024.10)
phenomenon(E99-1024.12,E99-1024.14)
phenomenon(E99-1024.20,E99-1024.21,REVERSE)

</text>

<text id="E99-1043">
<title>
The GENIA <entity id="E99-1043.1">Project</entity> : <entity id="E99-1043.2">Corpus-</entity> <entity id="E99-1043.3">Based</entity> <entity id="E99-1043.4">Knowledge</entity> <entity id="E99-1043.5">Acquisition</entity> And <entity id="E99-1043.6">Information Extraction</entity> From Genome <entity id="E99-1043.7">Research</entity> <entity id="E99-1043.8">Papers</entity></title>
<abstract>
We present an <entity id="E99-1043.9">outline</entity> of the genome <entity id="E99-1043.10">information</entity> <entity id="E99-1043.11">acquisition</entity> (GENIA) <entity id="E99-1043.12">project</entity> for automatically <entity id="E99-1043.13">extracting</entity> biochemical <entity id="E99-1043.14">information</entity> from <entity id="E99-1043.15">journal</entity> <entity id="E99-1043.16">papers</entity> and <entity id="E99-1043.17">abstracts</entity> . GENIA will be available over the Internet and is <entity id="E99-1043.18">designed</entity> to aid in <entity id="E99-1043.19">information extraction</entity> , <entity id="E99-1043.20">retrieval</entity> and visualisation and to <entity id="E99-1043.21">help</entity> reduce <entity id="E99-1043.22">information</entity> overload on <entity id="E99-1043.23">researchers</entity> . The vast <entity id="E99-1043.24">repository</entity> of <entity id="E99-1043.25">papers</entity> available online in <entity id="E99-1043.26">databases</entity> such as MEDLINE is a <entity id="E99-1043.27">natural</entity> <entity id="E99-1043.28">environment</entity> in which to <entity id="E99-1043.29">develop</entity> <entity id="E99-1043.30">language</entity> <entity id="E99-1043.31">engineering</entity> <entity id="E99-1043.32">methods</entity> and <entity id="E99-1043.33">tools</entity> and is an opportunity to show how <entity id="E99-1043.34">language</entity> <entity id="E99-1043.35">engineering</entity> can play a key <entity id="E99-1043.36">role</entity> on the Internet.
</abstract>


datasource(E99-1043.14,E99-1043.16)
composed_of(E99-1043.25,E99-1043.26,REVERSE)

</text>

<text id="E03-1032">
<title>
Efficient <entity id="E03-1032.1">Search</entity> For Interactive <entity id="E03-1032.2">Statistical Machine Translation</entity></title>
<abstract>
The <entity id="E03-1032.3">goal</entity> of interactive <entity id="E03-1032.4">machine translation</entity> is to <entity id="E03-1032.5">improve</entity> the productivity of human <entity id="E03-1032.6">translators</entity> . An interactive <entity id="E03-1032.7">machine translation system</entity> operates as follows: the <entity id="E03-1032.8">automatic</entity> <entity id="E03-1032.9">system</entity> <entity id="E03-1032.10">proposes</entity> a <entity id="E03-1032.11">translation</entity> . Now, the human <entity id="E03-1032.12">user</entity> has two <entity id="E03-1032.13">options</entity> : to accept the <entity id="E03-1032.14">suggestion</entity> or to correct it. During the post-editing <entity id="E03-1032.15">process</entity> , the human <entity id="E03-1032.16">user</entity> is assisted by the interactive <entity id="E03-1032.17">system</entity> in the <entity id="E03-1032.18">following</entity> way: the <entity id="E03-1032.19">system</entity> suggests an <entity id="E03-1032.20">extension</entity> of the <entity id="E03-1032.21">current</entity> <entity id="E03-1032.22">translation</entity> <entity id="E03-1032.23">prefix</entity> . Then, the <entity id="E03-1032.24">user</entity> either accepts this <entity id="E03-1032.25">extension</entity> (completely or partially) or ignores it. The two most important <entity id="E03-1032.26">factors</entity> of such an interactive <entity id="E03-1032.27">system</entity> are the <entity id="E03-1032.28">quality</entity> of the <entity id="E03-1032.29">proposed</entity> <entity id="E03-1032.30">extensions</entity> and the response <entity id="E03-1032.31">time</entity> . Here, we will use a fully fledged <entity id="E03-1032.32">translation system</entity> to ensure the <entity id="E03-1032.33">quality</entity> of the <entity id="E03-1032.34">proposed</entity> <entity id="E03-1032.35">extensions</entity> . To achieve fast response <entity id="E03-1032.36">times</entity> , we will use <entity id="E03-1032.37">word</entity> <entity id="E03-1032.38">hypotheses</entity> graphs as an efficient <entity id="E03-1032.39">search space</entity> <entity id="E03-1032.40">representation</entity> . We will show <entity id="E03-1032.41">results</entity> of our <entity id="E03-1032.42">approach</entity> on the Verbmobil <entity id="E03-1032.43">task</entity> and on the Canadian Hansards <entity id="E03-1032.44">task</entity> .
</abstract>



</text>

<text id="E03-1072">
<title>
The <entity id="E03-1072.1">Role</entity> Of <entity id="E03-1072.2">Initiative</entity> In Tutorial <entity id="E03-1072.3">Dialogue</entity></title>
<abstract>
This work is the first systematic <entity id="E03-1072.4">investigation</entity> of <entity id="E03-1072.5">initiative</entity> in human-human tutorial <entity id="E03-1072.6">dialogue</entity> . We <entity id="E03-1072.7">studied</entity> <entity id="E03-1072.8">initiative</entity> <entity id="E03-1072.9">management</entity> in two <entity id="E03-1072.10">dialogue</entity> <entity id="E03-1072.11">strategies</entity> : didactic tutoring and Socratic tutoring. We hypothesized that didactic tutoring would be mostly <entity id="E03-1072.12">tutor-initiative</entity> while Socratic tutoring would be <entity id="E03-1072.13">mixed-initiative</entity> , and that more student <entity id="E03-1072.14">initiative</entity> would lead to more learning (i.e.,
</abstract>



</text>

<text id="E03-1086">
<title>
Interactive <entity id="E03-1086.1">Word Alignment</entity> For <entity id="E03-1086.2">Language</entity> <entity id="E03-1086.3">Engineering</entity></title>
<abstract>
In this <entity id="E03-1086.4">paper</entity> we <entity id="E03-1086.5">report</entity> ongoing work on <entity id="E03-1086.6">developing</entity> an interactive <entity id="E03-1086.7">word <entity id="E03-1086.8">alignment</entity></entity> <entity id="E03-1086.9">environment</entity> that will assist a <entity id="E03-1086.10">user</entity> to quickly produce accurate <entity id="E03-1086.11">full-coverage</entity> <entity id="E03-1086.12">word alignment</entity> in bitexts for different <entity id="E03-1086.13">language</entity> <entity id="E03-1086.14">engineering</entity> <entity id="E03-1086.15">tasks</entity> , such as MT <entity id="E03-1086.16">lexicons</entity> and <entity id="E03-1086.17">gold <entity id="E03-1086.18">standards</entity></entity> for <entity id="E03-1086.19">evaluation</entity> . The <entity id="E03-1086.20">system</entity> uses a graphical <entity id="E03-1086.21">interface</entity> , static and dynamic <entity id="E03-1086.22">resources</entity> as well as <entity id="E03-1086.23">machine</entity> learning <entity id="E03-1086.24">techniques</entity> . We also sketch how the <entity id="E03-1086.25">system</entity> is being integrated with an <entity id="E03-1086.26">automatic</entity> <entity id="E03-1086.27">word</entity> aligner.
</abstract>


study(E03-1086.4,E03-1086.7)
methodapplied(E03-1086.17,E03-1086.19)

</text>

<text id="E06-1019">
<title>
A <entity id="E06-1019.1">Comparison</entity> Of Syntactically Motivated <entity id="E06-1019.2">Word Alignment</entity> Spaces
</title>
<abstract>
This work is <entity id="E06-1019.3">concerned</entity> with the <entity id="E06-1019.4">space</entity> of <entity id="E06-1019.5">alignments</entity> <entity id="E06-1019.6">searched</entity> by <entity id="E06-1019.7">word alignment</entity> <entity id="E06-1019.8">systems</entity> . We <entity id="E06-1019.9">focus</entity> on <entity id="E06-1019.10">situations</entity> where <entity id="E06-1019.11">word</entity> re-ordering is <entity id="E06-1019.12">limited</entity> by <entity id="E06-1019.13">syntax</entity> . We present two new <entity id="E06-1019.14">alignment</entity> <entity id="E06-1019.15">spaces</entity> that <entity id="E06-1019.16">limit</entity> an ITG according to a given <entity id="E06-1019.17">dependency</entity> <entity id="E06-1019.18">parse</entity> . We <entity id="E06-1019.19">provide</entity> D-ITG grammars to <entity id="E06-1019.20">search</entity> these <entity id="E06-1019.21">spaces</entity> completely and without <entity id="E06-1019.22">redundancy</entity> . We conduct a careful <entity id="E06-1019.23">comparison</entity> of five <entity id="E06-1019.24">alignment</entity> <entity id="E06-1019.25">spaces</entity> , and show that <entity id="E06-1019.26">limiting</entity> <entity id="E06-1019.27">search</entity> with an ITG reduces <entity id="E06-1019.28">error rate</entity> by 10%, while a D-ITG produces a 31% <entity id="E06-1019.29">reduction</entity> .
</abstract>



</text>

<text id="E06-1032">
<title>
Re- <entity id="E06-1032.1">Evaluation</entity> The <entity id="E06-1032.2">Role</entity> Of Bleu In <entity id="E06-1032.3">Machine Translation</entity> <entity id="E06-1032.4">Research</entity></title>
<abstract>
We argue that the <entity id="E06-1032.5">machine translation</entity> <entity id="E06-1032.6">community</entity> is overly reliant on the Bleu machine <entity id="E06-1032.7">translation</entity> <entity id="E06-1032.8">evaluation <entity id="E06-1032.9">metric</entity></entity> . We show that an <entity id="E06-1032.10">improved</entity> Bleu score is neither necessary nor sufficient for achieving an actual <entity id="E06-1032.11">improvement</entity> in <entity id="E06-1032.12">translation <entity id="E06-1032.13">quality</entity></entity> , and give two significant counterexamples to Bleu 's <entity id="E06-1032.14">correlation</entity> with human <entity id="E06-1032.15">judgments</entity> of <entity id="E06-1032.16">quality</entity> . This offers new potential for <entity id="E06-1032.17">research</entity> which was previously deemed unpromising by an <entity id="E06-1032.18">inability</entity> to <entity id="E06-1032.19">improve</entity> upon Bleu scores.
</abstract>


usedfor(E06-1032.7,E06-1032.8,REVERSE)
wrt(E06-1032.11,E06-1032.12)

</text>

<text id="E06-1043">
<title>
Automatically Constructing A <entity id="E06-1043.1">Lexicon</entity> Of <entity id="E06-1043.2">Verb</entity> <entity id="E06-1043.3">Phrase</entity> Idiomatic Combinations
</title>
<abstract>
We investigate the <entity id="E06-1043.4">lexical</entity> and <entity id="E06-1043.5">syntactic</entity> <entity id="E06-1043.6">flexibility</entity> of a <entity id="E06-1043.7">class</entity> of idiomatic <entity id="E06-1043.8">expressions</entity> . We <entity id="E06-1043.9">develop</entity> measures that draw on such linguistic <entity id="E06-1043.10">properties</entity> , and demonstrate that these <entity id="E06-1043.11">statistical</entity> , <entity id="E06-1043.12">corpus-based</entity> measures can be successfully used for distinguishing idiomatic <entity id="E06-1043.13">combinations</entity> from non-idiomatic ones. We also <entity id="E06-1043.14">propose</entity> a means for automatically determining which <entity id="E06-1043.15">syntactic</entity> <entity id="E06-1043.16">forms</entity> a particular <entity id="E06-1043.17">idiom</entity> can appear in, and hence should be <entity id="E06-1043.18">included</entity> in its <entity id="E06-1043.19">lexical</entity> <entity id="E06-1043.20">representation</entity> .
</abstract>


composed_of(E06-1043.7,E06-1043.8)
tag(E06-1043.17,E06-1043.20,REVERSE)

</text>

<text id="C96-2163">
<title><entity id="C96-2163.1">Sense</entity> <entity id="C96-2163.2">Classification</entity> Of <entity id="C96-2163.3">Verbal</entity> Polysemy Based-On Bilingual <entity id="C96-2163.4">Class</entity> / <entity id="C96-2163.5">Class</entity> <entity id="C96-2163.6">Association</entity></title>
<abstract>
In the <entity id="C96-2163.7">field</entity> of <entity id="C96-2163.8">statistical</entity> <entity id="C96-2163.9">analysis</entity> of <entity id="C96-2163.10">natural language</entity> data, the measure of <entity id="C96-2163.11">word</entity> / <entity id="C96-2163.12">class</entity> <entity id="C96-2163.13">association</entity> has proved to be quite useful for discovering a meaningful <entity id="C96-2163.14">sense</entity> <entity id="C96-2163.15">cluster</entity> in an arbitrary <entity id="C96-2163.16">level</entity> of the <entity id="C96-2163.17">thesaurus</entity> . In this <entity id="C96-2163.18">paper</entity> , we <entity id="C96-2163.19">apply</entity> its idea to the <entity id="C96-2163.20">sense</entity> <entity id="C96-2163.21">classification</entity> of <entity id="C96-2163.22">Japanese</entity> <entity id="C96-2163.23">verbal</entity> polysemy in <entity id="C96-2163.24">case</entity> <entity id="C96-2163.25">frame</entity> <entity id="C96-2163.26">acquisition</entity> from <entity id="C96-2163.27">Japanese-</entity> <entity id="C96-2163.28">English</entity> <entity id="C96-2163.29">parallel corpora</entity> . Measures of
</abstract>



</text>

<text id="C96-2176">
<title>
"The Internet A ""<entity id="C96-2176.1">natural</entity> "" <entity id="C96-2176.2">Channel</entity> For <entity id="C96-2176.3">Language Learning</entity> "
</title>



</text>

<abstract></abstract>

<text id="C96-2197">
<title>
An Education And <entity id="C96-2197.1">Research</entity> <entity id="C96-2197.2">Tool</entity> For <entity id="C96-2197.3">Computational</entity> <entity id="C96-2197.4">Semantics</entity></title>
<abstract>
This <entity id="C96-2197.5">paper</entity> describes an interactive graphical <entity id="C96-2197.6">environment</entity> for <entity id="C96-2197.7">computational</entity> <entity id="C96-2197.8">semantics</entity> . The <entity id="C96-2197.9">system</entity> <entity id="C96-2197.10">provides</entity> a teaching <entity id="C96-2197.11">tool</entity> , a stand alone extendible grapher, and a <entity id="C96-2197.12">library</entity> of <entity id="C96-2197.13">algorithms</entity> together with <entity id="C96-2197.14">test suites</entity> . The teaching <entity id="C96-2197.15">tool</entity> allows <entity id="C96-2197.16">users</entity> to work <entity id="C96-2197.17">step</entity> by <entity id="C96-2197.18">step</entity> through <entity id="C96-2197.19">derivations</entity> of <entity id="C96-2197.20">semantic representations</entity> , and to compare the <entity id="C96-2197.21">properties</entity> of various <entity id="C96-2197.22">semantic</entity> <entity id="C96-2197.23">formalisms</entity> such as Intensional <entity id="C96-2197.24">Logic</entity> , DRT, and <entity id="C96-2197.25">Situation</entity> <entity id="C96-2197.26">Semantics</entity> . The <entity id="C96-2197.27">system</entity> is freely available on the Internet.
</abstract>


methodapplied(C96-2197.2,C96-2197.4)
datasource(C96-2197.12,C96-2197.13)

</text>

<text id="C00-1006">
<title>
The Effects Of <entity id="C00-1006.1">Word</entity> <entity id="C00-1006.2">Order</entity> And Segmentation On <entity id="C00-1006.3">Translation</entity> <entity id="C00-1006.4">Retrieval</entity> <entity id="C00-1006.5">Performance</entity></title>
<abstract>
This <entity id="C00-1006.6">research</entity> looks at the <entity id="C00-1006.7">effects</entity> of <entity id="C00-1006.8">word</entity> <entity id="C00-1006.9">order</entity> and segmentation on <entity id="C00-1006.10">translation</entity> <entity id="C00-1006.11">retrieval</entity> <entity id="C00-1006.12">performance</entity> for an <entity id="C00-1006.13">experimental</entity> <entity id="C00-1006.14">Japanese-</entity> <entity id="C00-1006.15">English</entity> <entity id="C00-1006.16">translation</entity> <entity id="C00-1006.17">memory</entity> <entity id="C00-1006.18">system</entity> . We <entity id="C00-1006.19">implement</entity> a <entity id="C00-1006.20">number</entity> of both <entity id="C00-1006.21">bag-of-words</entity> and <entity id="C00-1006.22">word</entity> <entity id="C00-1006.23">order-sensitive</entity> <entity id="C00-1006.24">similarity</entity> <entity id="C00-1006.25">metrics</entity> , and <entity id="C00-1006.26">test</entity> each over character-based and <entity id="C00-1006.27">word-based</entity> <entity id="C00-1006.28">indexing</entity> . The <entity id="C00-1006.29">translation</entity> <entity id="C00-1006.30">retrieval</entity> <entity id="C00-1006.31">performance</entity> of each <entity id="C00-1006.32">system</entity> <entity id="C00-1006.33">configuration</entity> is <entity id="C00-1006.34">evaluated</entity> empirically through the <entity id="C00-1006.35">notion</entity> of <entity id="C00-1006.36">word</entity> edit <entity id="C00-1006.37">distance</entity> between <entity id="C00-1006.38">translation</entity> <entity id="C00-1006.39">candidate</entity> <entity id="C00-1006.40">outputs</entity> and the <entity id="C00-1006.41">model</entity> <entity id="C00-1006.42">translation</entity> . Our <entity id="C00-1006.43">results</entity> indicate that character-based <entity id="C00-1006.44">indexing</entity> is consistently superior to <entity id="C00-1006.45">word-based</entity> <entity id="C00-1006.46">indexing</entity> , suggesting that segmentation is an unnecessary luxury in the given <entity id="C00-1006.47">domain</entity> . <entity id="C00-1006.48">Word</entity> <entity id="C00-1006.49">order-sensitive</entity> <entity id="C00-1006.50">approaches</entity> are demonstrated to generally outperform <entity id="C00-1006.51">bag-of-words</entity> <entity id="C00-1006.52">methods</entity> , with <entity id="C00-1006.53">source language</entity> <entity id="C00-1006.54">segment-level</entity> edit <entity id="C00-1006.55">distance</entity> proving the most effective <entity id="C00-1006.56">similarity</entity> <entity id="C00-1006.57">metric</entity> .
</abstract>


compare(C00-1006.49,C00-1006.51)

</text>

<text id="C00-1014">
<title>
Reusing An <entity id="C00-1014.1">Ontology</entity> To <entity id="C00-1014.2">Generate</entity> Numeral Classifiers
</title>
<abstract>
In this <entity id="C00-1014.3">paper</entity> , we present a <entity id="C00-1014.4">solution</entity> to the <entity id="C00-1014.5">problem</entity> of <entity id="C00-1014.6">generating</entity> <entity id="C00-1014.7">Japanese</entity> numeral <entity id="C00-1014.8">classifiers</entity> using <entity id="C00-1014.9">semantic <entity id="C00-1014.10">classes</entity></entity> from an <entity id="C00-1014.11">ontology</entity> . Most <entity id="C00-1014.12">nouns</entity> must take a numeral <entity id="C00-1014.13">classifier</entity> when they are quantified in <entity id="C00-1014.14">languages</entity> such as <entity id="C00-1014.15">Chinese</entity> , <entity id="C00-1014.16">Japanese</entity> , Korean, Malay and Thai. In <entity id="C00-1014.17">order</entity> to select an appropriate <entity id="C00-1014.18">classifier</entity> , we <entity id="C00-1014.19">propose</entity> an <entity id="C00-1014.20">algorithm</entity> which associates <entity id="C00-1014.21">classifiers</entity> with <entity id="C00-1014.22">semantic classes</entity> and uses inheritance to <entity id="C00-1014.23">list</entity> only those <entity id="C00-1014.24">classifiers</entity> which have to be <entity id="C00-1014.25">listed</entity> . It <entity id="C00-1014.26">generates</entity> sortal <entity id="C00-1014.27">classifiers</entity> with an <entity id="C00-1014.28">accuracy</entity> of 81%. We reuse the <entity id="C00-1014.29">ontology</entity> <entity id="C00-1014.30">provided</entity> by Goi-Taikei  a <entity id="C00-1014.31">Japanese</entity> <entity id="C00-1014.32">lexicon</entity> , and show that it is a reasonable <entity id="C00-1014.33">choice</entity> for this <entity id="C00-1014.34">task</entity> , <entity id="C00-1014.35">requiring</entity> <entity id="C00-1014.36">information</entity> to be entered for less than 6% of <entity id="C00-1014.37">individual</entity> <entity id="C00-1014.38">nouns</entity> .
</abstract>


based_on(C00-1014.8,C00-1014.9)
isa(C00-1014.14,C00-1014.15,REVERSE)
isa(C00-1014.29,C00-1014.32)

</text>

<text id="C00-1035">
<title>
Aspects Of <entity id="C00-1035.1">Pattern-</entity> Matching In <entity id="C00-1035.2">Data-</entity> Oriented <entity id="C00-1035.3">Parsing</entity></title> 
<abstract><entity id="C00-1035.4">Data-</entity> Oriented <entity id="C00-1035.5">Parsing</entity> (dop) <entity id="C00-1035.6">ranks</entity> among the best <entity id="C00-1035.7">parsing</entity> <entity id="C00-1035.8">schemes</entity> , <entity id="C00-1035.9">pairing</entity> state-of-the art <entity id="C00-1035.10">parsing</entity> <entity id="C00-1035.11">accuracy</entity> to the psycholinguistic <entity id="C00-1035.12">insight</entity> that larger <entity id="C00-1035.13">chunks</entity> of <entity id="C00-1035.14">syntactic structures</entity> are relevant grammatical and probabilistic <entity id="C00-1035.15">units</entity> . <entity id="C00-1035.16">Parsing</entity> with the <entity id="C00-1035.17">dop-model</entity> , however, seems to involve a lot of CPU <entity id="C00-1035.18">cycles</entity> and a considerable <entity id="C00-1035.19">amount</entity> of double work, brought on by the <entity id="C00-1035.20">concept</entity> of multiple <entity id="C00-1035.21">derivations</entity> , which is necessary for probabilistic <entity id="C00-1035.22">processing</entity> , but which is not convincingly related to a proper linguistic <entity id="C00-1035.23">backbone</entity> . It is however possible to reinterpret the <entity id="C00-1035.24">dop-model</entity> as a <entity id="C00-1035.25">pattern-matching</entity> <entity id="C00-1035.26">model</entity> , which tries to maximize the <entity id="C00-1035.27">size</entity> of the <entity id="C00-1035.28">substructures</entity> that <entity id="C00-1035.29">construct</entity> the <entity id="C00-1035.30">parse</entity> , rather than the <entity id="C00-1035.31">probability</entity> of the <entity id="C00-1035.32">parse</entity> . By emphasizing this <entity id="C00-1035.33">memory-based</entity> <entity id="C00-1035.34">aspect</entity> of the <entity id="C00-1035.35">dop-model</entity> , it is possible to do away with multiple <entity id="C00-1035.36">derivations</entity> , opening up <entity id="C00-1035.37">possibilities</entity> for efficient Viterbi-style <entity id="C00-1035.38">optimizations</entity> , while still retaining acceptable <entity id="C00-1035.39">parsing</entity> <entity id="C00-1035.40">accuracy</entity> through enhanced <entity id="C00-1035.41">context-sensitivity</entity> .
</abstract>


part_of(C00-1035.28,C00-1035.30)

</text>

<text id="C00-1045">
<title>
Pronominalization Revisited
</title>
<abstract>
Pronominalization has been related to the idea of a local <entity id="C00-1045.1">focus</entity> - a set of <entity id="C00-1045.2">discourse</entity> <entity id="C00-1045.3">entities</entity> in the speaker's centre of attention, for <entity id="C00-1045.4">example</entity> in Gundel et al. (1993)'s givenness hierarchy or in <entity id="C00-1045.5">centering</entity> <entity id="C00-1045.6">theory</entity> . Both accounts say that the <entity id="C00-1045.7">determination</entity> of the <entity id="C00-1045.8">focus</entity> depends on <entity id="C00-1045.9">syntactic</entity> as well as pragmatic <entity id="C00-1045.10">factors</entity> , but have not been able to pin those <entity id="C00-1045.11">factors</entity> down. In this <entity id="C00-1045.12">paper</entity> , we uncover the major <entity id="C00-1045.13">factors</entity> which determine the <entity id="C00-1045.14">focus</entity> set in descriptive <entity id="C00-1045.15">texts</entity> . This new <entity id="C00-1045.16">focus</entity> <entity id="C00-1045.17">definition</entity> has been <entity id="C00-1045.18">evaluated</entity> with <entity id="C00-1045.19">respect</entity> to two <entity id="C00-1045.20">corpora</entity> : museum exhibit labels, and <entity id="C00-1045.21">newspaper</entity> articles. It <entity id="C00-1045.22">provides</entity> an operationalizable <entity id="C00-1045.23">basis</entity> for pronoun production, and has been <entity id="C00-1045.24">implemented</entity> as the reusable <entity id="C00-1045.25">module</entity> gnome-np. gnome-np
</abstract>



</text>

<text id="C00-1060">
<title>
A Hybrid <entity id="C00-1060.1">Japanese</entity> <entity id="C00-1060.2">Parser</entity> With <entity id="C00-1060.3">Hand-</entity> Crafted Grammar And <entity id="C00-1060.4">Statistics</entity></title>
<abstract>
This <entity id="C00-1060.5">paper</entity> describes a hybrid <entity id="C00-1060.6">parsing</entity> <entity id="C00-1060.7">method</entity> for <entity id="C00-1060.8">Japanese</entity> which uses both a <entity id="C00-1060.9">hand-crafted</entity> grammar and a <entity id="C00-1060.10">statistical</entity> <entity id="C00-1060.11">technique</entity> . The key <entity id="C00-1060.12">feature</entity> of our <entity id="C00-1060.13">system</entity> is that in <entity id="C00-1060.14">order</entity> to estimate likelihood for a <entity id="C00-1060.15">parse tree</entity> , the <entity id="C00-1060.16">system</entity> uses <entity id="C00-1060.17">information</entity> taken from <entity id="C00-1060.18">alternative</entity> <entity id="C00-1060.19">partial</entity> <entity id="C00-1060.20">parse <entity id="C00-1060.21">trees</entity></entity> <entity id="C00-1060.22">generated</entity> by the grammar. This utilization of <entity id="C00-1060.23">alternative</entity> <entity id="C00-1060.24">trees</entity> enables us to <entity id="C00-1060.25">construct</entity> a new <entity id="C00-1060.26">statistical model</entity> <entity id="C00-1060.27">called</entity> Triplet/Quadruplet <entity id="C00-1060.28">Model</entity> .We
</abstract>


propose(C00-1060.5,C00-1060.7)
datasource(C00-1060.17,C00-1060.20)

</text>

<text id="C00-2097">
<title>
Compiling <entity id="C00-2097.1">Language</entity> <entity id="C00-2097.2">Models</entity> From A Linguistically Motivated <entity id="C00-2097.3">Unification</entity> Grammar
</title>
<abstract><entity id="C00-2097.4">Systems</entity> now exist which are able to compile <entity id="C00-2097.5">unification</entity> grammars into <entity id="C00-2097.6">language models</entity> that can be <entity id="C00-2097.7">included</entity> in a <entity id="C00-2097.8">speech</entity> recognizer, but it is so far unclear whether non-trivial linguistically principled grammars can be used for this <entity id="C00-2097.9">purpose</entity> . We describe a <entity id="C00-2097.10">series</entity> of <entity id="C00-2097.11">experiments</entity> which investigate the <entity id="C00-2097.12">question</entity> empirically, by incrementally <entity id="C00-2097.13">constructing</entity> a grammar and discovering what <entity id="C00-2097.14">problems</entity> emerge when successively larger <entity id="C00-2097.15">versions</entity> are compiled into finite state graph <entity id="C00-2097.16">representations</entity> and used as <entity id="C00-2097.17">language models</entity> for a <entity id="C00-2097.18">medium-vocabulary</entity> <entity id="C00-2097.19">recognition</entity> <entity id="C00-2097.20">task</entity> .
</abstract>



</text>

<text id="C00-2101">
<title><entity id="C00-2101.1">Learning</entity> <entity id="C00-2101.2">Semantic-</entity> <entity id="C00-2101.3">Level</entity> <entity id="C00-2101.4">Information Extraction</entity> Rules By <entity id="C00-2101.5">Type-</entity> Oriented ILP
</title>
<abstract>
This <entity id="C00-2101.6">paper</entity> describes an <entity id="C00-2101.7">approach</entity> to using <entity id="C00-2101.8">semantic representations</entity> <entity id="C00-2101.9">information extraction</entity> (IE) inductive <entity id="C00-2101.10">logic programming</entity> (ILP)
</abstract>


propose(C00-2101.6,C00-2101.7)

</text>

<text id="C00-2105">
<title><entity id="C00-2105.1">Robust</entity> German <entity id="C00-2105.2">Noun</entity> Chunking With A Probabilistic <entity id="C00-2105.3">Context-</entity> Free Grammar
</title>
<abstract>
We present a <entity id="C00-2105.4">noun</entity> chunker for German which is <entity id="C00-2105.5">based</entity> on a head-lexicalised probabilistic <entity id="C00-2105.6">context-free</entity> grammar. A manually <entity id="C00-2105.7">developed</entity> grammar was semi-automatically extended with <entity id="C00-2105.8">robustness</entity> <entity id="C00-2105.9">rules</entity> in <entity id="C00-2105.10">order</entity> to allow <entity id="C00-2105.11">parsing</entity> of unrestricted <entity id="C00-2105.12">text</entity> . The <entity id="C00-2105.13">model <entity id="C00-2105.14">parameters</entity></entity> were learned from unlabelled <entity id="C00-2105.15">training</entity> <entity id="C00-2105.16">data</entity> by a probabilistic <entity id="C00-2105.17">context-free</entity> <entity id="C00-2105.18">parser</entity> . For <entity id="C00-2105.19">extracting</entity> <entity id="C00-2105.20">noun</entity> <entity id="C00-2105.21">chunks</entity> , the <entity id="C00-2105.22">parser</entity> <entity id="C00-2105.23">generates</entity> all possible <entity id="C00-2105.24">noun</entity> <entity id="C00-2105.25">chunk</entity> <entity id="C00-2105.26">analyses</entity> , scores them with a novel <entity id="C00-2105.27">algorithm</entity> which maximizes the best <entity id="C00-2105.28">chunk</entity> <entity id="C00-2105.29">sequence</entity> <entity id="C00-2105.30">criterion</entity> , and chooses the most probable <entity id="C00-2105.31">chunk</entity> <entity id="C00-2105.32">sequence</entity> . An <entity id="C00-2105.33">evaluation</entity> of the chunker on 2,140 <entity id="C00-2105.34">hand-annotated</entity> <entity id="C00-2105.35">noun</entity> <entity id="C00-2105.36">chunks</entity> <entity id="C00-2105.37">yielded</entity> 92% <entity id="C00-2105.38">recall</entity> and 93% <entity id="C00-2105.39">precision</entity> .
</abstract>


usedfor(C00-2105.9,C00-2105.11)
methodapplied(C00-2105.13,C00-2105.16)

</text>

<text id="C00-2147">
<title>
The Week At A Glance - <entity id="C00-2147.1">Cross-</entity> <entity id="C00-2147.2">Language</entity> <entity id="C00-2147.3">Cross-</entity> <entity id="C00-2147.4">Document</entity> <entity id="C00-2147.5">Information Extraction</entity> And <entity id="C00-2147.6">Translation</entity></title>
<abstract>
"Work on the production of <entity id="C00-2147.7">texts</entity> in <entity id="C00-2147.8">English</entity> describing <entity id="C00-2147.9">instances</entity> of a particular <entity id="C00-2147.10">event type</entity> from multiple <entity id="C00-2147.11">news</entity> <entity id="C00-2147.12">sources</entity> will be described. A <entity id="C00-2147.13">system</entity> has been <entity id="C00-2147.14">developed</entity> which <entity id="C00-2147.15">extracts</entity> <entity id="C00-2147.16">events</entity> , such as <entity id="C00-2147.17">meetings</entity> , from <entity id="C00-2147.18">texts</entity> in <entity id="C00-2147.19">English</entity> , Russian, Spanish, and <entity id="C00-2147.20">Japanese</entity> . The <entity id="C00-2147.21">extraction</entity> is currently carried out using only ontological <entity id="C00-2147.22">information</entity> . The <entity id="C00-2147.23">results</entity> of a set of such <entity id="C00-2147.24">extractions</entity> were combined to produce a <entity id="C00-2147.25">table</entity> of <entity id="C00-2147.26">event</entity> <entity id="C00-2147.27">instances</entity> , <entity id="C00-2147.28">date</entity> stamped, with <entity id="C00-2147.29">links</entity> back to the original <entity id="C00-2147.30">documents</entity> . The original <entity id="C00-2147.31">documents</entity> can then be summarized and <entity id="C00-2147.32">translated</entity> by the <entity id="C00-2147.33">system</entity> on demand. By using <entity id="C00-2147.34">techniques</entity> from <entity id="C00-2147.35">information retrieval</entity> , <entity id="C00-2147.36">information extraction</entity> , <entity id="C00-2147.37">summarization</entity> , and <entity id="C00-2147.38">machine translation</entity> , in a <entity id="C00-2147.39">multi-lingual</entity> <entity id="C00-2147.40">environment</entity> , new <entity id="C00-2147.41">documents</entity> can be produced which <entity id="C00-2147.42">provide</entity> ""at a glance"" <entity id="C00-2147.43">access</entity> to <entity id="C00-2147.44">news</entity> on <entity id="C00-2147.45">events</entity> from multiple <entity id="C00-2147.46">sources</entity> . The <entity id="C00-2147.47">paper</entity> concludes with a <entity id="C00-2147.48">discussion</entity> of the key <entity id="C00-2147.49">resources</entity> which need to be <entity id="C00-2147.50">developed</entity> to enhance the <entity id="C00-2147.51">accuracy</entity> and <entity id="C00-2147.52">coverage</entity> of the <entity id="C00-2147.53">techniques</entity> used in our <entity id="C00-2147.54">experiment</entity> . "
</abstract>


isa(C00-2147.16,C00-2147.17,REVERSE)

</text>

<text id="C00-2161">
<title>
Querying Temporal Databases Using Controlled <entity id="C00-2161.1">Natural Language</entity></title>
<abstract>
Recent years have shown a surge in interest in temporal <entity id="C00-2161.2">database</entity> <entity id="C00-2161.3">systems</entity> , which allow <entity id="C00-2161.4">users</entity> to store <entity id="C00-2161.5">time-dependent</entity> <entity id="C00-2161.6">information</entity> . We present a novel controlled <entity id="C00-2161.7">natural language interface</entity> to temporal <entity id="C00-2161.8">databases</entity> , <entity id="C00-2161.9">based</entity> on <entity id="C00-2161.10">translating</entity> <entity id="C00-2161.11">natural language</entity> <entity id="C00-2161.12">questions</entity> into SQL/Temporal, a temporal database <entity id="C00-2161.13">query language</entity> . The <entity id="C00-2161.14">syntactic <entity id="C00-2161.15">analysis</entity></entity> is done using the <entity id="C00-2161.16">Type-</entity> Logical Grammar <entity id="C00-2161.17">framework</entity> , highlighting its <entity id="C00-2161.18">utility</entity> not only as a theoretical <entity id="C00-2161.19">framework</entity> but also as a practical <entity id="C00-2161.20">tool</entity> . The <entity id="C00-2161.21">semantic <entity id="C00-2161.22">analysis</entity></entity> is done using a novel <entity id="C00-2161.23">theory</entity> of the <entity id="C00-2161.24">semantics</entity> of temporal <entity id="C00-2161.25">questions</entity> , <entity id="C00-2161.26">focusing</entity> on the <entity id="C00-2161.27">role</entity> of temporal <entity id="C00-2161.28">preposition</entity> <entity id="C00-2161.29">phrases</entity> rather than the more traditional <entity id="C00-2161.30">focus</entity> on tense and <entity id="C00-2161.31">aspect</entity> . Our <entity id="C00-2161.32">translation</entity> <entity id="C00-2161.33">method</entity> is considerably simpler than previous attempts in this <entity id="C00-2161.34">direction</entity> . We present a <entity id="C00-2161.35">prototype</entity> <entity id="C00-2161.36">software</entity> <entity id="C00-2161.37">implementation</entity> .
</abstract>


usedfor(C00-2161.14,C00-2161.17,REVERSE)
usedfor(C00-2161.21,C00-2161.23,REVERSE)

</text>

<text id="C02-1003">
<title><entity id="C02-1003.1">Learning</entity> <entity id="C02-1003.2">Chinese</entity> <entity id="C02-1003.3">Bracketing</entity> <entity id="C02-1003.4">Knowledge Based</entity> On A Bilingual <entity id="C02-1003.5">Language Model</entity></title>
<abstract>
This <entity id="C02-1003.6">paper</entity> <entity id="C02-1003.7">proposes</entity> a new <entity id="C02-1003.8">method</entity> for <entity id="C02-1003.9">automatic</entity> <entity id="C02-1003.10">acquisition</entity> of <entity id="C02-1003.11">Chinese</entity> <entity id="C02-1003.12">bracketing</entity> <entity id="C02-1003.13">knowledge</entity> from <entity id="C02-1003.14">English-</entity> <entity id="C02-1003.15">Chinese</entity> <entity id="C02-1003.16">sentence-aligned</entity> bilingual <entity id="C02-1003.17">corpora</entity> . Bilingual <entity id="C02-1003.18">sentence</entity> <entity id="C02-1003.19">pairs</entity> are first aligned in <entity id="C02-1003.20">syntactic structure</entity> by combining <entity id="C02-1003.21">English</entity> <entity id="C02-1003.22">parse trees</entity> with a <entity id="C02-1003.23">statistical</entity> bilingual <entity id="C02-1003.24">language model</entity> . <entity id="C02-1003.25">Chinese</entity> <entity id="C02-1003.26">bracketing</entity> <entity id="C02-1003.27">knowledge</entity> is then <entity id="C02-1003.28">extracted</entity> automatically. The preliminary <entity id="C02-1003.29">experiments</entity> show automatically learned <entity id="C02-1003.30">knowledge</entity> accords well with manually annotated <entity id="C02-1003.31">brackets</entity> . The <entity id="C02-1003.32">proposed</entity> <entity id="C02-1003.33">method</entity> is particularly useful to acquire <entity id="C02-1003.34">bracketing</entity> <entity id="C02-1003.35">knowledge</entity> for a less <entity id="C02-1003.36">studied</entity> <entity id="C02-1003.37">language</entity> that <entity id="C02-1003.38">lacks</entity> <entity id="C02-1003.39">tools</entity> and <entity id="C02-1003.40">resources</entity> found in a <entity id="C02-1003.41">second language</entity> more <entity id="C02-1003.42">studied</entity> . Although this <entity id="C02-1003.43">paper</entity> discusses <entity id="C02-1003.44">experiments</entity> with <entity id="C02-1003.45">Chinese</entity> and <entity id="C02-1003.46">English</entity> , the <entity id="C02-1003.47">method</entity> is also applicable to other <entity id="C02-1003.48">language <entity id="C02-1003.49">pairs</entity></entity> .
</abstract>


propose(C02-1003.6,C02-1003.8)
datasource(C02-1003.13,C02-1003.17)
methodapplied(C02-1003.47,C02-1003.48)

</text>

<text id="C02-1007">
<title>
The <entity id="C02-1007.1">Computation</entity> Of <entity id="C02-1007.2">Word</entity> Associations: Comparing Syntagmatic And Paradigmatic <entity id="C02-1007.3">Approaches</entity></title>
<abstract>
It is shown that <entity id="C02-1007.4">basic</entity> <entity id="C02-1007.5">language</entity> <entity id="C02-1007.6">processes</entity> such as the production of free <entity id="C02-1007.7">word</entity> <entity id="C02-1007.8">associations</entity> and the <entity id="C02-1007.9">generation</entity> of <entity id="C02-1007.10">synonyms</entity> can be simulated using <entity id="C02-1007.11">statistical <entity id="C02-1007.12">models</entity></entity> that analyze the <entity id="C02-1007.13">distribution</entity> of <entity id="C02-1007.14">words</entity> in large <entity id="C02-1007.15">text</entity> <entity id="C02-1007.16">corpora</entity> . According to the law of <entity id="C02-1007.17">association</entity> by contiguity, the <entity id="C02-1007.18">acquisition</entity> of <entity id="C02-1007.19">word</entity> <entity id="C02-1007.20">associations</entity> can be explained by Hebbian learning. The free <entity id="C02-1007.21">word</entity> <entity id="C02-1007.22">associations</entity> as produced by subjects on <entity id="C02-1007.23">presentation</entity> of single <entity id="C02-1007.24">stimulus</entity> <entity id="C02-1007.25">words</entity> can thus be predicted by <entity id="C02-1007.26">applying</entity> <entity id="C02-1007.27">first-order</entity> <entity id="C02-1007.28">statistics</entity> to the <entity id="C02-1007.29">frequencies</entity> of <entity id="C02-1007.30">word</entity> co-occurrences as observed in <entity id="C02-1007.31">texts</entity> . The <entity id="C02-1007.32">generation</entity> of <entity id="C02-1007.33">synonyms</entity> can also be conducted on <entity id="C02-1007.34">co-occurrence</entity> <entity id="C02-1007.35">data</entity> but <entity id="C02-1007.36">requires</entity> <entity id="C02-1007.37">second-order</entity> <entity id="C02-1007.38">statistics</entity> . The <entity id="C02-1007.39">reason</entity> is that <entity id="C02-1007.40">synonyms</entity> rarely occur together but appear in similar <entity id="C02-1007.41">lexical</entity> neighborhoods. Both <entity id="C02-1007.42">approaches</entity> are systematically compared and are validated on empirical <entity id="C02-1007.43">data</entity> . It turns out that for both <entity id="C02-1007.44">tasks</entity> the <entity id="C02-1007.45">performance</entity> of the <entity id="C02-1007.46">statistical</entity> <entity id="C02-1007.47">system</entity> is comparable to the <entity id="C02-1007.48">performance</entity> of human subjects .
</abstract>


methodapplied(C02-1007.11,C02-1007.16)
compare(C02-1007.45,C02-1007.48)

</text>

<text id="C02-1023">
<title>
A Chart- <entity id="C02-1023.1">Parsing <entity id="C02-1023.2">Algorithm</entity></entity> For Efficient <entity id="C02-1023.3">Semantic <entity id="C02-1023.4">Analysis</entity></entity></title>
<abstract>
"In some <entity id="C02-1023.5">contexts</entity> , well-formed <entity id="C02-1023.6">natural language</entity> cannot be expected as <entity id="C02-1023.7">input</entity> to <entity id="C02-1023.8">information</entity> or <entity id="C02-1023.9">communication</entity> <entity id="C02-1023.10">systems</entity> . In these <entity id="C02-1023.11">contexts</entity> , the use of grammar-independent <entity id="C02-1023.12">input</entity> ( <entity id="C02-1023.13">sequences</entity> of uninflected <entity id="C02-1023.14">semantic</entity> <entity id="C02-1023.15">units</entity> like e.g. <entity id="C02-1023.16">language-independent</entity> <entity id="C02-1023.17">icons</entity> ) can be an answer to the <entity id="C02-1023.18">users</entity> ' needs. However, this <entity id="C02-1023.19">requires</entity> that an intelligent <entity id="C02-1023.20">system</entity> should be able to interpret this <entity id="C02-1023.21">input</entity> with reasonable <entity id="C02-1023.22">accuracy</entity> and in reasonable <entity id="C02-1023.23">time</entity> . Here we <entity id="C02-1023.24">propose</entity> a <entity id="C02-1023.25">method</entity> allowing a purely <entity id="C02-1023.26">semantic-based</entity> <entity id="C02-1023.27">analysis</entity> of <entity id="C02-1023.28">sequences</entity> of <entity id="C02-1023.29">semantic</entity> <entity id="C02-1023.30">units</entity> . It uses an <entity id="C02-1023.31">algorithm</entity> inspired by the idea of ""chart <entity id="C02-1023.32">parsing</entity> "" known in <entity id="C02-1023.33">Natural Language Processing</entity> , which stores intermediate <entity id="C02-1023.34">parsing</entity> <entity id="C02-1023.35">results</entity> in <entity id="C02-1023.36">order</entity> to bring the <entity id="C02-1023.37">calculation</entity> <entity id="C02-1023.38">time</entity> down. "
</abstract>


methodapplied(C02-1023.1,C02-1023.3)
study(C02-1023.27,C02-1023.28)

</text>

<text id="C02-1024">
<title>
Interleaved <entity id="C02-1024.1">Semantic Interpretation</entity> In <entity id="C02-1024.2">Environment-</entity> <entity id="C02-1024.3">Based</entity> <entity id="C02-1024.4">Parsing</entity></title>
<abstract>
This <entity id="C02-1024.5">paper</entity> extends a <entity id="C02-1024.6">polynomial-time</entity> <entity id="C02-1024.7">parsing</entity> <entity id="C02-1024.8">algorithm</entity> that resolves <entity id="C02-1024.9">structural</entity> <entity id="C02-1024.10">ambiguity</entity> in <entity id="C02-1024.11">input</entity> <entity id="C02-1024.12">sentences</entity> by calculating and comparing the denotations of rival <entity id="C02-1024.13">constituents</entity> , given some <entity id="C02-1024.14">model</entity> of the <entity id="C02-1024.15">application</entity> <entity id="C02-1024.16">environment</entity> ( Schuler, 2001 ). The <entity id="C02-1024.17">algorithm</entity> is extended to incorporate a full set of logical <entity id="C02-1024.18">operators</entity> , <entity id="C02-1024.19">including</entity> <entity id="C02-1024.20">quantifiers</entity> and <entity id="C02-1024.21">conjunctions</entity> , into this <entity id="C02-1024.22">calculation</entity> without <entity id="C02-1024.23">increasing</entity> the <entity id="C02-1024.24">complexity</entity> of the overall <entity id="C02-1024.25">algorithm</entity> beyond polynomial <entity id="C02-1024.26">time</entity> , both in <entity id="C02-1024.27">terms</entity> of the <entity id="C02-1024.28">length</entity> of the <entity id="C02-1024.29">input</entity> and the <entity id="C02-1024.30">number</entity> of <entity id="C02-1024.31">entities</entity> in the <entity id="C02-1024.32">environment</entity> <entity id="C02-1024.33">model</entity> .
</abstract>



</text>

<text id="C02-1026">
<title>
The <entity id="C02-1026.1">Effectiveness</entity> Of <entity id="C02-1026.2">Dictionary</entity> And Web- <entity id="C02-1026.3">Based</entity> Answer Reranking
</title>
<abstract>Srihari , Rohini K.; Li , Wei ,A <entity id="C02-1026.4">Question Answering System</entity> Supported By <entity id="C02-1026.5">Information Extraction</entity> , <entity id="C02-1026.6">Applied Natural Language Processing</entity> Conference And Meeting Of The North American <entity id="C02-1026.7">Association</entity> For <entity id="C02-1026.8">Computation</entity> al <entity id="C02-1026.9">Linguistics</entity> ,2000 *** Abney , Steven ; Collins , Michael John ; Singhal , Amit ,Answer <entity id="C02-1026.10">Extraction</entity> ,Applied <entity id="C02-1026.11">Natural Language Processing Conference</entity> And Meeting Of The North American <entity id="C02-1026.12">Association</entity> For <entity id="C02-1026.13">Computation</entity> al <entity id="C02-1026.14">Linguistics</entity> ,2000 ***Hovy, Eduard ; Hermjakob , Ulf ; Lin , Chin-Yew ; Ravichandran , Deepak ,Using <entity id="C02-1026.15">Knowledge</entity> To Facilitate <entity id="C02-1026.16">Factoid</entity> Answer Pinpointing,International Conference On <entity id="C02-1026.17">Computation</entity> al <entity id="C02-1026.18">Linguistics</entity> ,2002 ***Hermjakob, Ulf , <entity id="C02-1026.19">Parsing</entity> And <entity id="C02-1026.20">Question</entity> <entity id="C02-1026.21">Classification</entity> For <entity id="C02-1026.22">Question Answering</entity> , <entity id="C02-1026.23">Workshop</entity> On Open- <entity id="C02-1026.24">Domain</entity> Question Answering,2001</abstract>



</text>

<text id="C02-1029">
<title>
A Generative <entity id="C02-1029.1">Probability Model</entity> For <entity id="C02-1029.2">Unification-</entity> <entity id="C02-1029.3">Based</entity> Grammars
</title>
<abstract>
A generative <entity id="C02-1029.4">probability model</entity> for <entity id="C02-1029.5">unification-based</entity> grammars is presented in which <entity id="C02-1029.6">rule</entity> <entity id="C02-1029.7">probabilities</entity> depend on the <entity id="C02-1029.8">feature structure</entity> of the expanded <entity id="C02-1029.9">constituent</entity> . The presented <entity id="C02-1029.10">model</entity> is the first <entity id="C02-1029.11">model</entity> which <entity id="C02-1029.12">requires</entity> no <entity id="C02-1029.13">normalization</entity> and allows the <entity id="C02-1029.14">application</entity> of <entity id="C02-1029.15">dynamic <entity id="C02-1029.16">programming</entity> <entity id="C02-1029.17">algorithms</entity></entity> for <entity id="C02-1029.18">disambiguation</entity> ( Viterbi ) and <entity id="C02-1029.19">training</entity> (Inside-Outside). Another <entity id="C02-1029.20">advantage</entity> is the small <entity id="C02-1029.21">number</entity> of <entity id="C02-1029.22">parameters</entity> .
</abstract>


methodapplied(C02-1029.15,C02-1029.18)

</text>

<text id="C02-1038">
<title>
Augmenting <entity id="C02-1038.1">Noun</entity> Taxonomies By <entity id="C02-1038.2">Combining</entity> <entity id="C02-1038.3">Lexical</entity> <entity id="C02-1038.4">Similarity</entity> Metrics
</title>
<abstract>
This <entity id="C02-1038.5">paper</entity> presents a <entity id="C02-1038.6">method</entity> for augmenting <entity id="C02-1038.7">taxonomies</entity> with <entity id="C02-1038.8">domain</entity> <entity id="C02-1038.9">information</entity> using a <entity id="C02-1038.10">simple</entity> <entity id="C02-1038.11">combination</entity> of three existing <entity id="C02-1038.12">lexical</entity> <entity id="C02-1038.13">similarity</entity> <entity id="C02-1038.14">metrics</entity> . The combined <entity id="C02-1038.15">approach</entity> is <entity id="C02-1038.16">evaluated</entity> by comparing their <entity id="C02-1038.17">results</entity> against the annotated SEMCOR <entity id="C02-1038.18">corpus</entity> . An <entity id="C02-1038.19">implementation</entity> is described in which WordNet is augmented with thesaural <entity id="C02-1038.20">information</entity> from the CIDE+ <entity id="C02-1038.21">machine readable dictionary</entity> .
</abstract>


propose(C02-1038.5,C02-1038.6)

</text>

<text id="C02-1045">
<title>
A <entity id="C02-1045.1">Method</entity> Of <entity id="C02-1045.2">Cluster-</entity> <entity id="C02-1045.3">Based</entity> <entity id="C02-1045.4">Indexing</entity> Of Textual <entity id="C02-1045.5">Data</entity></title>
<abstract>
This <entity id="C02-1045.6">paper</entity> presents a <entity id="C02-1045.7">framework</entity> for <entity id="C02-1045.8">clustering</entity> in <entity id="C02-1045.9">text-based</entity> <entity id="C02-1045.10">information retrieval systems</entity> . The prominent <entity id="C02-1045.11">feature</entity> of the <entity id="C02-1045.12">proposed</entity> <entity id="C02-1045.13">method</entity> is that <entity id="C02-1045.14">documents</entity> , <entity id="C02-1045.15">terms</entity> , and other related elements of textual <entity id="C02-1045.16">information</entity> are <entity id="C02-1045.17">clustered</entity> simultaneously into small overlapping <entity id="C02-1045.18">clusters</entity> . In the <entity id="C02-1045.19">paper</entity> , the mathematical <entity id="C02-1045.20">formulation</entity> and <entity id="C02-1045.21">implementation</entity> of the <entity id="C02-1045.22">clustering</entity> <entity id="C02-1045.23">method</entity> are briefly introduced, together with some <entity id="C02-1045.24">experimental</entity> <entity id="C02-1045.25">results</entity> .
</abstract>


methodapplied(C02-1045.4,C02-1045.5)
propose(C02-1045.6,C02-1045.7)

</text>

<text id="C02-1059">
<title><entity id="C02-1059.1">Processing</entity> <entity id="C02-1059.2">Japanese</entity> Self- <entity id="C02-1059.3">Correction</entity> In <entity id="C02-1059.4">Speech</entity> <entity id="C02-1059.5">Dialog</entity> <entity id="C02-1059.6">Systems</entity></title> 
<abstract><entity id="C02-1059.7">Speech</entity> <entity id="C02-1059.8">dialog systems</entity> need to <entity id="C02-1059.9">deal</entity> with various <entity id="C02-1059.10">kinds</entity> of ill-formed <entity id="C02-1059.11">speech</entity> <entity id="C02-1059.12">inputs</entity> that appear in <entity id="C02-1059.13">natural</entity> human-human <entity id="C02-1059.14">dialog</entity> . <entity id="C02-1059.15">Self-correction</entity> (or <entity id="C02-1059.16">speech-repair</entity> ) is a particularly problematic <entity id="C02-1059.17">phenomenon</entity> . Although many ways of <entity id="C02-1059.18">dealing</entity> with <entity id="C02-1059.19">self-correction</entity> have been <entity id="C02-1059.20">proposed</entity> , these have <entity id="C02-1059.21">limitations</entity> in both detecting and correcting for this <entity id="C02-1059.22">phenomenon</entity> . In this <entity id="C02-1059.23">paper</entity> , we <entity id="C02-1059.24">propose</entity> a <entity id="C02-1059.25">method</entity> to overcome these <entity id="C02-1059.26">problems</entity> in <entity id="C02-1059.27">Japanese</entity> <entity id="C02-1059.28">speech</entity> <entity id="C02-1059.29">dialog</entity> . We <entity id="C02-1059.30">evaluate</entity> the <entity id="C02-1059.31">proposed</entity> <entity id="C02-1059.32">method</entity> using our <entity id="C02-1059.33">speech</entity> <entity id="C02-1059.34">dialog</entity> <entity id="C02-1059.35">corpus</entity> and discuss its <entity id="C02-1059.36">limitations</entity> and the work that remains to be done.
</abstract>


propose(C02-1059.23,C02-1059.25)

</text>

<text id="C02-1068">
<title><entity id="C02-1068.1">Learning</entity> Grammars For Different <entity id="C02-1068.2">Parsing</entity> Tasks By <entity id="C02-1068.3">Partition</entity> <entity id="C02-1068.4">Search</entity></title>
<abstract>
This <entity id="C02-1068.5">paper</entity> describes a comparative <entity id="C02-1068.6">application</entity> of Grammar <entity id="C02-1068.7">Learning</entity> by <entity id="C02-1068.8">Partition</entity> <entity id="C02-1068.9">Search</entity> to four different <entity id="C02-1068.10">learning</entity> <entity id="C02-1068.11">tasks</entity> : deep <entity id="C02-1068.12">parsing</entity> , np np np xp
</abstract>


study(C02-1068.5,C02-1068.6)

</text>

<text id="C02-1122">
<title>
Fertilization Of <entity id="C02-1122.1">Case</entity> <entity id="C02-1122.2">Frame</entity> <entity id="C02-1122.3">Dictionary</entity> For <entity id="C02-1122.4">Robust</entity> <entity id="C02-1122.5">Japanese</entity> <entity id="C02-1122.6">Case</entity> <entity id="C02-1122.7">Analysis</entity></title>
<abstract>
This <entity id="C02-1122.8">paper</entity> <entity id="C02-1122.9">proposes</entity> a <entity id="C02-1122.10">method</entity> of fertilizing a <entity id="C02-1122.11">Japanese</entity> <entity id="C02-1122.12">case</entity> <entity id="C02-1122.13">frame</entity> <entity id="C02-1122.14">dictionary</entity> to handle complicated <entity id="C02-1122.15">expressions</entity> : double nominative <entity id="C02-1122.16">sentences</entity> , non-gapping <entity id="C02-1122.17">relation</entity> of <entity id="C02-1122.18">relative</entity> <entity id="C02-1122.19">clauses</entity> , and <entity id="C02-1122.20">case</entity> change. Our <entity id="C02-1122.21">method</entity> is divided into two stages. In the first stage, we <entity id="C02-1122.22">parse</entity> a large <entity id="C02-1122.23">corpus</entity> and <entity id="C02-1122.24">construct</entity> a <entity id="C02-1122.25">Japanese</entity> <entity id="C02-1122.26">case</entity> <entity id="C02-1122.27">frame</entity> <entity id="C02-1122.28">dictionary</entity> automatically from the <entity id="C02-1122.29">parse</entity> <entity id="C02-1122.30">results</entity> . In the second stage, we <entity id="C02-1122.31">apply</entity> <entity id="C02-1122.32">case</entity> <entity id="C02-1122.33">analysis</entity> to the large <entity id="C02-1122.34">corpus</entity> utilizing the <entity id="C02-1122.35">constructed</entity> <entity id="C02-1122.36">case</entity> <entity id="C02-1122.37">frame</entity> <entity id="C02-1122.38">dictionary</entity> , and upgrade the <entity id="C02-1122.39">case</entity> <entity id="C02-1122.40">frame</entity> <entity id="C02-1122.41">dictionary</entity> by incorporating newly acquired <entity id="C02-1122.42">information</entity> .
</abstract>


propose(C02-1122.8,C02-1122.10)

</text>

<text id="C02-1169">
<title>
Open- <entity id="C02-1169.1">Domain</entity> Voice-Activated <entity id="C02-1169.2">Question Answering</entity></title>
<abstract>
Voice-Activated <entity id="C02-1169.3">Question Answering</entity> (VAQA) <entity id="C02-1169.4">systems</entity> represent the next <entity id="C02-1169.5">generation</entity> <entity id="C02-1169.6">capability</entity> for universal <entity id="C02-1169.7">access</entity> by integrating state-of-the-art in <entity id="C02-1169.8">question</entity> answering Q&amp;A and <entity id="C02-1169.9">automatic speech recognition</entity> (ASR) in such a way that the <entity id="C02-1169.10">performance</entity> of the combined <entity id="C02-1169.11">system</entity> is better than the <entity id="C02-1169.12">individual</entity> <entity id="C02-1169.13">components</entity> . This <entity id="C02-1169.14">paper</entity> presents an <entity id="C02-1169.15">implemented</entity> VAQA <entity id="C02-1169.16">system</entity> and describes the <entity id="C02-1169.17">techniques</entity> that enable the terative <entity id="C02-1169.18">refinement</entity> of both Q&amp;A and ASR. The <entity id="C02-1169.19">results</entity> of our <entity id="C02-1169.20">experiments</entity> show that spoken <entity id="C02-1169.21">questions</entity> can be <entity id="C02-1169.22">processed</entity> with surprising <entity id="C02-1169.23">accuracy</entity> when using our VAQA <entity id="C02-1169.24">implementation</entity> .
</abstract>


compare(C02-1169.11,C02-1169.13)
propose(C02-1169.14,C02-1169.16)

</text>

<text id="C02-2018">
<title>
An XML-Based <entity id="C02-2018.1">Document</entity> <entity id="C02-2018.2">Suite</entity></title>
<abstract>
We <entity id="C02-2018.3">report</entity> about the <entity id="C02-2018.4">current</entity> state of <entity id="C02-2018.5">development</entity> of a <entity id="C02-2018.6">document</entity> <entity id="C02-2018.7">suite</entity> and its <entity id="C02-2018.8">applications</entity> . This <entity id="C02-2018.9">collection</entity> of <entity id="C02-2018.10">tools</entity> for the flexible and <entity id="C02-2018.11">robust</entity> <entity id="C02-2018.12">processing</entity> of <entity id="C02-2018.13">documents</entity> in German is <entity id="C02-2018.14">based</entity> on the use of XML as unifying <entity id="C02-2018.15">formalism</entity> for encoding <entity id="C02-2018.16">input</entity> and <entity id="C02-2018.17">output</entity> <entity id="C02-2018.18">data</entity> as well as <entity id="C02-2018.19">process</entity> <entity id="C02-2018.20">information</entity> . It is organized in <entity id="C02-2018.21">modules</entity> with limited responsibilities that can easily be combined into <entity id="C02-2018.22">pipelines</entity> to <entity id="C02-2018.23">solve</entity> <entity id="C02-2018.24">complex</entity> <entity id="C02-2018.25">tasks</entity> . Strong emphasis is laid on a <entity id="C02-2018.26">number</entity> of <entity id="C02-2018.27">techniques</entity> to <entity id="C02-2018.28">deal</entity> with <entity id="C02-2018.29">lexical</entity> and conceptual <entity id="C02-2018.30">gaps</entity> that are typical when starting a new <entity id="C02-2018.31">application</entity> .
</abstract>


based_on(C02-2018.10,C02-2018.15)
cohyp(C02-2018.18,C02-2018.20)

</text>

<text id="C04-1048">
<title><entity id="C04-1048.1">Generating</entity> <entity id="C04-1048.2">Discourse</entity> <entity id="C04-1048.3">Structures</entity> For Written <entity id="C04-1048.4">Text</entity></title>
<abstract>
This <entity id="C04-1048.5">paper</entity> presents a <entity id="C04-1048.6">system</entity> for automatically <entity id="C04-1048.7">generating</entity> <entity id="C04-1048.8">discourse structures</entity> from written <entity id="C04-1048.9">text</entity> . The <entity id="C04-1048.10">system</entity> is divided into two <entity id="C04-1048.11">levels</entity> : <entity id="C04-1048.12">sentence-level</entity> and <entity id="C04-1048.13">text-level</entity> . The <entity id="C04-1048.14">sentence-level</entity> <entity id="C04-1048.15">discourse</entity> <entity id="C04-1048.16">parser</entity> uses <entity id="C04-1048.17">syntactic information</entity> and <entity id="C04-1048.18">cue</entity> <entity id="C04-1048.19">phrases</entity> to <entity id="C04-1048.20">segment</entity> <entity id="C04-1048.21">sentences</entity> into elementary <entity id="C04-1048.22">discourse</entity> <entity id="C04-1048.23">units</entity> and to <entity id="C04-1048.24">generate</entity> <entity id="C04-1048.25">discourse structures</entity> of <entity id="C04-1048.26">sentences</entity> . At the <entity id="C04-1048.27">text-level</entity> , <entity id="C04-1048.28">constraints</entity> about textual adjacency and textual <entity id="C04-1048.29">organization</entity> are integrated in a <entity id="C04-1048.30">beam search</entity> in <entity id="C04-1048.31">order</entity> to <entity id="C04-1048.32">generate</entity> best <entity id="C04-1048.33">discourse structures</entity> . The <entity id="C04-1048.34">experiments</entity> were done with <entity id="C04-1048.35">documents</entity> from the RST <entity id="C04-1048.36">Discourse</entity> Treebank. It shows promising <entity id="C04-1048.37">results</entity> in a reasonable <entity id="C04-1048.38">search space</entity> compared to the <entity id="C04-1048.39">discourse</entity> <entity id="C04-1048.40">trees</entity> <entity id="C04-1048.41">generated</entity> by human <entity id="C04-1048.42">analysts</entity> .
</abstract>


propose(C04-1048.5,C04-1048.6)

</text>

<text id="C04-1050">
<title>
Improving <entity id="C04-1050.1">Japanese</entity> Zero Pronoun <entity id="C04-1050.2">Resolution</entity> By Global <entity id="C04-1050.3">Word Sense Disambiguation</entity></title>
<abstract>
This <entity id="C04-1050.4">paper</entity> <entity id="C04-1050.5">proposes</entity> unsupervised <entity id="C04-1050.6">word sense disambiguation</entity> <entity id="C04-1050.7">based</entity> on automatically <entity id="C04-1050.8">constructed</entity> <entity id="C04-1050.9">case</entity> <entity id="C04-1050.10">frames</entity> and its incorporation into our zero pronoun <entity id="C04-1050.11">resolution</entity> <entity id="C04-1050.12">system</entity> . The <entity id="C04-1050.13">word <entity id="C04-1050.14">sense disambiguation</entity></entity> is <entity id="C04-1050.15">applied</entity> to <entity id="C04-1050.16">verbs</entity> and <entity id="C04-1050.17">nouns</entity> . We consider that <entity id="C04-1050.18">case</entity> <entity id="C04-1050.19">frames</entity> define <entity id="C04-1050.20">verb</entity> senses and <entity id="C04-1050.21">semantic features</entity> in a <entity id="C04-1050.22">thesaurus</entity> define <entity id="C04-1050.23">noun</entity> senses, respectively, and <entity id="C04-1050.24">perform</entity> <entity id="C04-1050.25">sense disambiguation</entity> by selecting them <entity id="C04-1050.26">based</entity> on <entity id="C04-1050.27">case</entity> <entity id="C04-1050.28">analysis</entity> . In <entity id="C04-1050.29">addition</entity> , according to the one <entity id="C04-1050.30">sense</entity> per <entity id="C04-1050.31">discourse</entity> heuristic, the <entity id="C04-1050.32">word sense disambiguation</entity> <entity id="C04-1050.33">results</entity> are cached and <entity id="C04-1050.34">applied</entity> globally to the subsequent <entity id="C04-1050.35">words</entity> . We integrated this global <entity id="C04-1050.36">word sense disambiguation</entity> into our zero pronoun <entity id="C04-1050.37">resolution</entity> <entity id="C04-1050.38">system</entity> , and conducted <entity id="C04-1050.39">experiments</entity> of zero pronoun <entity id="C04-1050.40">resolution</entity> on two different <entity id="C04-1050.41">domain</entity> <entity id="C04-1050.42">corpora</entity> . Both of the <entity id="C04-1050.43">experimental</entity> <entity id="C04-1050.44">results</entity> indicated the <entity id="C04-1050.45">effectiveness</entity> of our <entity id="C04-1050.46">approach</entity> .
</abstract>


propose(C04-1050.4,C04-1050.12)
taskapplied(C04-1050.13,C04-1050.16)
yields(C04-1050.44,C04-1050.46,REVERSE)

</text>

<text id="C04-1134">
<title>
BiFrameNet: Bilingual <entity id="C04-1134.1">Frame</entity> <entity id="C04-1134.2">Semantics</entity> <entity id="C04-1134.3">Resource</entity> <entity id="C04-1134.4">Construction</entity> By <entity id="C04-1134.5">Cross-</entity> <entity id="C04-1134.6">Lingual</entity> <entity id="C04-1134.7">Induction</entity></title>
<abstract>
"We present a novel <entity id="C04-1134.8">automatic</entity> <entity id="C04-1134.9">approach</entity> to <entity id="C04-1134.10">constructing</entity> a bilingual <entity id="C04-1134.11">semantic network</entity>
the BiFrameNet, to enhance <entity id="C04-1134.12">statistical</entity> and <entity id="C04-1134.13">transfer-based</entity> <entity id="C04-1134.14">machine translation systems</entity> . BiFrameNet is a <entity id="C04-1134.15">frame</entity> <entity id="C04-1134.16">semantic representation</entity> , and contains <entity id="C04-1134.17">semantic structure</entity> <entity id="C04-1134.18">transfers</entity> between <entity id="C04-1134.19">English</entity> and <entity id="C04-1134.20">Chinese</entity> . The <entity id="C04-1134.21">English</entity> FrameNet and the <entity id="C04-1134.22">Chinese</entity> HowNet <entity id="C04-1134.23">provide</entity> us with two different views of the <entity id="C04-1134.24">semantic</entity> <entity id="C04-1134.25">distribution</entity> of <entity id="C04-1134.26">lexicon</entity> by <entity id="C04-1134.27">linguists</entity> . We <entity id="C04-1134.28">propose</entity> to induce the <entity id="C04-1134.29">mapping</entity> between the <entity id="C04-1134.30">English</entity> <entity id="C04-1134.31">lexical entries</entity> in FrameNet to <entity id="C04-1134.32">Chinese</entity> <entity id="C04-1134.33">word</entity> senses in HowNet, furnishing a bilingual <entity id="C04-1134.34">semantic lexicon</entity> which simulates the ""<entity id="C04-1134.35">concept</entity> <entity id="C04-1134.36">lexicon</entity> "" supposedly used by human <entity id="C04-1134.37">translators</entity> , and which can thus be beneficial to <entity id="C04-1134.38">machine translation systems</entity> . BiFrameNet also contains bilingual <entity id="C04-1134.39">example</entity> <entity id="C04-1134.40">sentences</entity> that have the same <entity id="C04-1134.41">semantic roles</entity> . We automatically induce <entity id="C04-1134.42">Chinese</entity> <entity id="C04-1134.43">example</entity> <entity id="C04-1134.44">sentences</entity> and their <entity id="C04-1134.45">semantic roles</entity> , <entity id="C04-1134.46">based</entity> on <entity id="C04-1134.47">semantic <entity id="C04-1134.48">structure</entity></entity> <entity id="C04-1134.49">alignment</entity> from the first stage of our work, as well as shallow <entity id="C04-1134.50">syntactic <entity id="C04-1134.51">structure</entity></entity> . In <entity id="C04-1134.52">addition</entity> to its <entity id="C04-1134.53">utility</entity> for <entity id="C04-1134.54">machine-aided</entity> and <entity id="C04-1134.55">machine translations</entity> , our work is also related to the spatial <entity id="C04-1134.56">models</entity> <entity id="C04-1134.57">proposed</entity> by cognitive <entity id="C04-1134.58">scientists</entity> in the <entity id="C04-1134.59">framework</entity> of artifactual <entity id="C04-1134.60">simulations</entity> of the <entity id="C04-1134.61">translation process</entity> . "
</abstract>


cohyp(C04-1134.47,C04-1134.50)

</text>

<text id="C04-1143">
<title>
Fasil Email <entity id="C04-1143.1">Summarisation</entity> <entity id="C04-1143.2">System</entity></title>
<abstract>
Email <entity id="C04-1143.3">summarisation</entity> presents a unique set of <entity id="C04-1143.4">requirements</entity> that are different from general <entity id="C04-1143.5">text</entity> <entity id="C04-1143.6">summarisation</entity> . This work describes the <entity id="C04-1143.7">implementation</entity> of an email <entity id="C04-1143.8">summarisation</entity> <entity id="C04-1143.9">system</entity> for use in a voice-based Virtual Personal Assistant <entity id="C04-1143.10">developed</entity> for the EU FASiL <entity id="C04-1143.11">Project</entity> . <entity id="C04-1143.12">Evaluation results</entity> from the first integrated <entity id="C04-1143.13">version</entity> of the <entity id="C04-1143.14">project</entity> are presented.
</abstract>



</text>

<text id="E83-1013">
<title><entity id="E83-1013.1">Dealing</entity> With Conjunctions In A <entity id="E83-1013.2">Machine Translation</entity> <entity id="E83-1013.3">Environment</entity></title>
<abstract>
"A set of <entity id="E83-1013.4">rules</entity> , <entity id="E83-1013.5">named</entity> CSDC (Conjunct <entity id="E83-1013.6">Scope</entity> <entity id="E83-1013.7">Determination</entity> Constraints), is suggested for attacking the conjunct <entity id="E83-1013.8">scope</entity> <entity id="E83-1013.9">problem</entity> , the major <entity id="E83-1013.10">issue</entity> in the <entity id="E83-1013.11">automatic</entity> <entity id="E83-1013.12">processing</entity> of <entity id="E83-1013.13">conjunctions</entity> which has been raising great <entity id="E83-1013.14">difficulty</entity> for <entity id="E83-1013.15">natural language processing systems</entity> . Grammars embodying the CSDC are incorporated into an existing ATN <entity id="E83-1013.16">parser</entity> , and are <entity id="E83-1013.17">tested</entity> successfully against a wide group of ""and"" conjunctive <entity id="E83-1013.18">sentences</entity> , which are of three <entity id="E83-1013.19">types</entity> , namely clausal <entity id="E83-1013.20">coordination</entity> , phrasal <entity id="E83-1013.21">coordination</entity> , and <entity id="E83-1013.22">gapping</entity> . With phrasal <entity id="E83-1013.23">coordination</entity> the <entity id="E83-1013.24">structure</entity> with two NPs coordinated by ""and"" has been given most attention. It is hoped that an ATN <entity id="E83-1013.25">parser</entity> capable of <entity id="E83-1013.26">dealing</entity> with a large <entity id="E83-1013.27">variety</entity> of <entity id="E83-1013.28">conjunctions</entity> in an efficient way will finally emerge from the present work. "
</abstract>



</text>

<text id="E85-1027">
<title>
A <entity id="E85-1027.1">Computational</entity> <entity id="E85-1027.2">Theory</entity> Of Prose Style For <entity id="E85-1027.3">Natural <entity id="E85-1027.4">Language Generation</entity></entity></title>
<abstract>
"1. Where in the <entity id="E85-1027.5">generation process</entity> style is taken into account. 2. How a particular prose style is represented; what ""stylistic <entity id="E85-1027.6">rules</entity> "" look like; 3. What <entity id="E85-1027.7">modifications</entity> to a <entity id="E85-1027.8">generation</entity> <entity id="E85-1027.9">algorithm</entity> are needed; what the <entity id="E85-1027.10">decision</entity> is that <entity id="E85-1027.11">evaluates</entity> stylistic <entity id="E85-1027.12">alternatives</entity> ; 4. What elaborations to the normal <entity id="E85-1027.13">description</entity> of <entity id="E85-1027.14">surface structure</entity> are necessary to make it usable as a plan for the <entity id="E85-1027.15">text</entity> and a <entity id="E85-1027.16">reference</entity> for these <entity id="E85-1027.17">decisions</entity> ; 5. What <entity id="E85-1027.18">kinds</entity> of <entity id="E85-1027.19">information</entity> <entity id="E85-1027.20">decisions</entity> about style have <entity id="E85-1027.21">access</entity> to. Our <entity id="E85-1027.22">theory</entity> emerged out of <entity id="E85-1027.23">design</entity> <entity id="E85-1027.24">experiments</entity> we have made over the past year with our <entity id="E85-1027.25">natural language generation system</entity> , the Zetalisp <entity id="E85-1027.26">program</entity> MUMBLE. In the <entity id="E85-1027.27">process</entity> we have extended MUMBLE through the <entity id="E85-1027.28">addition</entity> of an additional <entity id="E85-1027.29">process</entity> that now mediates between <entity id="E85-1027.30">content</entity> planning and linguistic <entity id="E85-1027.31">realization</entity> . This new <entity id="E85-1027.32">process</entity> , which we <entity id="E85-1027.33">call</entity> ""<entity id="E85-1027.34">attachment</entity> "", <entity id="E85-1027.35">provides</entity> the further significant <entity id="E85-1027.36">benefit</entity> that <entity id="E85-1027.37">text structure</entity> is no longer dictated by the <entity id="E85-1027.38">structure</entity> of the <entity id="E85-1027.39">message</entity> : the sequential <entity id="E85-1027.40">order</entity> and dominance <entity id="E85-1027.41">relationships</entity> of <entity id="E85-1027.42">concepts</entity> in the <entity id="E85-1027.43">message</entity> no longer force one <entity id="E85-1027.44">form</entity> onto the <entity id="E85-1027.45">words</entity> and <entity id="E85-1027.46">phrases</entity> in the <entity id="E85-1027.47">text</entity> . Instead, rhetorical and intentional directives can be interpreted flexibly in the <entity id="E85-1027.48">context</entity> of the ongoing <entity id="E85-1027.49">discourse</entity> and stylistic <entity id="E85-1027.50">preferences</entity> . The <entity id="E85-1027.51">text</entity> is built up through composition under the <entity id="E85-1027.52">direction</entity> of linguistic organizing <entity id="E85-1027.53">principles</entity> , rather than having to follow conceptual <entity id="E85-1027.54">principles</entity> in lockstep. We will begin by describing what we mean by prose style and then introducing the <entity id="E85-1027.55">generation</entity> <entity id="E85-1027.56">task</entity> that lead us to this <entity id="E85-1027.57">theory</entity> , the reproduction of short <entity id="E85-1027.58">encyclopedia</entity> articles on African tribes. We will then use that <entity id="E85-1027.59">task</entity> to <entity id="E85-1027.60">outline</entity> the <entity id="E85-1027.61">parts</entity> of our <entity id="E85-1027.62">theory</entity> and the <entity id="E85-1027.63">operations</entity> of the <entity id="E85-1027.64">attachment</entity> <entity id="E85-1027.65">process</entity> . Finally we will compare our <entity id="E85-1027.66">techniques</entity> to the related work of Davey , McKeown and Derr , and Gabriel , and consider some of the possible psycholinguistic <entity id="E85-1027.67">hypotheses</entity> that it may lead to. "
</abstract>


methodapplied(E85-1027.2,E85-1027.3)

</text>

<text id="E89-1002">
<title><entity id="E89-1002.1">Parsing</entity> And Derivational <entity id="E89-1002.2">Equivalence</entity></title>
<abstract>
It is a tacit <entity id="E89-1002.3">assumption</entity> of much linguistic <entity id="E89-1002.4">inquiry</entity> that all distinct <entity id="E89-1002.5">derivations</entity> of a <entity id="E89-1002.6">string</entity> should assign distinct meanings. But despite the tidiness of such derivational uniqueness, there seems to be no a priori <entity id="E89-1002.7">reason</entity> to assume that a grammar must have this <entity id="E89-1002.8">property</entity> . If a grammar exhibits derivational <entity id="E89-1002.9">equivalence</entity> , whereby distinct <entity id="E89-1002.10">derivations</entity> of a <entity id="E89-1002.11">string</entity> assign the same meanings, naive exhaustive <entity id="E89-1002.12">search</entity> for all <entity id="E89-1002.13">derivations</entity> will be redundant, and quite possibly intractable. In this <entity id="E89-1002.14">paper</entity> we show how <entity id="E89-1002.15">notions</entity> of <entity id="E89-1002.16">derivation-reduction</entity> and normal <entity id="E89-1002.17">form</entity> can be used to avoid unnecessary work while <entity id="E89-1002.18">parsing</entity> with grammars exhibiting derivational <entity id="E89-1002.19">equivalence</entity> . With grammar regarded as analogous to <entity id="E89-1002.20">logic</entity> , <entity id="E89-1002.21">derivations</entity> are proofs; what we are advocating is <entity id="E89-1002.22">proof-reduction</entity> , and normal <entity id="E89-1002.23">form</entity> proof; the invocation of these logical <entity id="E89-1002.24">techniques</entity> adds a further <entity id="E89-1002.25">paragraph</entity> to the story of <entity id="E89-1002.26">parsing-as-deduction</entity> .
</abstract>



</text>

<text id="E89-1019">
<title><entity id="E89-1019.1">Lexical</entity> <entity id="E89-1019.2">Acquisition</entity> In The <entity id="E89-1019.3">Core</entity> <entity id="E89-1019.4">Language</entity> <entity id="E89-1019.5">Engine</entity></title>
<abstract>
The SRI <entity id="E89-1019.6">Core</entity> <entity id="E89-1019.7">Language</entity> <entity id="E89-1019.8">Engine</entity> (CLE) is a <entity id="E89-1019.9">general-purpose</entity> <entity id="E89-1019.10">natural language</entity> front end for interactive <entity id="E89-1019.11">systems</entity> . It <entity id="E89-1019.12">translates</entity> <entity id="E89-1019.13">English</entity> <entity id="E89-1019.14">expressions</entity> into <entity id="E89-1019.15">representations</entity> of their literal meanings. This <entity id="E89-1019.16">paper</entity> presents the <entity id="E89-1019.17">lexical</entity> <entity id="E89-1019.18">acquisition</entity> <entity id="E89-1019.19">component</entity> of the CLE, which allows the <entity id="E89-1019.20">creation</entity> of <entity id="E89-1019.21">lexicon</entity> <entity id="E89-1019.22">entries</entity> by <entity id="E89-1019.23">users</entity> with <entity id="E89-1019.24">knowledge</entity> of the <entity id="E89-1019.25">application</entity> <entity id="E89-1019.26">domain</entity> but not of <entity id="E89-1019.27">linguistics</entity> or of the <entity id="E89-1019.28">detailed</entity> workings of the <entity id="E89-1019.29">system</entity> . It is argued that the need to cater for a wide range of <entity id="E89-1019.30">types</entity> of back end leads naturally to an <entity id="E89-1019.31">approach</entity> <entity id="E89-1019.32">based</entity> on eliciting grammaticality <entity id="E89-1019.33">judgments</entity> from the <entity id="E89-1019.34">user</entity> . This <entity id="E89-1019.35">approach</entity> , which has been used to define a 1200- <entity id="E89-1019.36">word</entity> <entity id="E89-1019.37">core</entity> <entity id="E89-1019.38">lexicon</entity> of <entity id="E89-1019.39">English</entity> , is described and <entity id="E89-1019.40">evaluated</entity> .
</abstract>



</text>

<text id="E89-1035">
<title>
The <entity id="E89-1035.1">Syntactic</entity> <entity id="E89-1035.2">Regularity</entity> Of <entity id="E89-1035.3">English</entity> <entity id="E89-1035.4">Noun</entity> Phrases
</title>
<abstract>
Approximately, 10,000 naturally occurring <entity id="E89-1035.5">noun phrases</entity> taken from the LOB <entity id="E89-1035.6">corpus</entity> were used <entity id="E89-1035.7">firstly</entity> , to <entity id="E89-1035.8">evaluate</entity> the NP <entity id="E89-1035.9">component</entity> of the Alvey ANLT grammar ( Grover et al., 1987 , 1989) and secondly, to retest Sampson 's (1987a) <entity id="E89-1035.10">claim</entity> that this <entity id="E89-1035.11">data</entity> <entity id="E89-1035.12">provide</entity> <entity id="E89-1035.13">evidence</entity> for the <entity id="E89-1035.14">lack</entity> of a clear-cut <entity id="E89-1035.15">distinction</entity> between grammatical and 'deviant' <entity id="E89-1035.16">examples</entity> . The <entity id="E89-1035.17">examples</entity> were sorted and classified on the <entity id="E89-1035.18">basis</entity> of the <entity id="E89-1035.19">lexical</entity> and <entity id="E89-1035.20">syntactic analysis</entity> undertaken as <entity id="E89-1035.21">part</entity> of the LOB <entity id="E89-1035.22">corpus</entity> <entity id="E89-1035.23">project</entity> ( Sampson, 1987b ). Tokens of each <entity id="E89-1035.24">resulting</entity> <entity id="E89-1035.25">type</entity> were parsed using the ANLT grammar and the <entity id="E89-1035.26">results</entity> analysed to determine the <entity id="E89-1035.27">success</entity> <entity id="E89-1035.28">rate</entity> of the <entity id="E89-1035.29">parses</entity> and the <entity id="E89-1035.30">generality</entity> of the <entity id="E89-1035.31">rules</entity> employed.
</abstract>



</text>

<text id="E89-1039">
<title>
Empirical <entity id="E89-1039.1">Studies</entity> Of <entity id="E89-1039.2">Discourse</entity> Representations For <entity id="E89-1039.3">Natural Language</entity> Interfaces
</title>
<abstract>
We present the <entity id="E89-1039.4">results</entity> from a <entity id="E89-1039.5">series</entity> of <entity id="E89-1039.6">experiments</entity> aimed at uncovering the <entity id="E89-1039.7">discourse structure</entity> of <entity id="E89-1039.8">man-machine</entity> <entity id="E89-1039.9">communication</entity> in <entity id="E89-1039.10">natural language</entity> (Wizard of Oz
</abstract>



</text>

<text id="E91-1031">
<title><entity id="E91-1031.1">Prediction</entity> In Chart <entity id="E91-1031.2">Parsing</entity> <entity id="E91-1031.3">Algorithms</entity> For Categorial <entity id="E91-1031.4">Unification</entity> Grammar
</title>
<abstract><entity id="E91-1031.5">Natural language systems</entity> <entity id="E91-1031.6">based</entity> on Categorial <entity id="E91-1031.7">Unification</entity> Grammar (CUG) have mainly employed bottom-up <entity id="E91-1031.8">parsing</entity> <entity id="E91-1031.9">algorithms</entity> for <entity id="E91-1031.10">processing</entity> . Conventional <entity id="E91-1031.11">prediction</entity> <entity id="E91-1031.12">techniques</entity> to <entity id="E91-1031.13">improve</entity> the <entity id="E91-1031.14">efficiency</entity> of the <entity id="E91-1031.15">parsing</entity> <entity id="E91-1031.16">process</entity> , appear to fall short when <entity id="E91-1031.17">parsing</entity> CUG. Nevertheless, <entity id="E91-1031.18">prediction</entity> seems necessary when <entity id="E91-1031.19">parsing</entity> grammars with highly ambiguous <entity id="E91-1031.20">lexicons</entity> or with non-canonical categorial <entity id="E91-1031.21">rules</entity> . In this <entity id="E91-1031.22">paper</entity> we present a lexicalist <entity id="E91-1031.23">prediction</entity> <entity id="E91-1031.24">technique</entity> for CUG and show that this may lead to considerable <entity id="E91-1031.25">gains</entity> in <entity id="E91-1031.26">efficiency</entity> for both bottom-up and top-down <entity id="E91-1031.27">parsing</entity> .
</abstract>


propose(E91-1031.22,E91-1031.24)

</text>

<text id="E91-1034">
<title><entity id="E91-1034.1">Semantic</entity> <entity id="E91-1034.2">Features</entity> And <entity id="E91-1034.3">Selection</entity> Restrictions
</title>
<abstract>Dahlgren , Kathleen ; McDowell , Joyce , <entity id="E91-1034.4">Kind</entity> Types In <entity id="E91-1034.5">Knowledge Representation</entity> ,International Conference On <entity id="E91-1034.6">Computation</entity> al <entity id="E91-1034.7">Linguistics</entity> ,1986 ***Paducheva, Elena V.; Rakhilina , Ekaterina V. ,Predicting Co- <entity id="E91-1034.8">Occurrence</entity> Restrictions By Using <entity id="E91-1034.9">Semantic</entity> Classifications In The <entity id="E91-1034.10">Lexicon</entity> ,International Conference On <entity id="E91-1034.11">Computation</entity> al <entity id="E91-1034.12">Linguistics</entity> ,1990</abstract>



</text>

</doc>

